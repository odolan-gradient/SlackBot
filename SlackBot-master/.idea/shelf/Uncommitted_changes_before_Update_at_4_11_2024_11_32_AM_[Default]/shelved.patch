Index: Decagon.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\"\"\"\r\nMain worker file\r\n\r\n\"\"\"\r\nimport csv\r\nimport datetime\r\nimport math\r\nimport pickle\r\nimport time\r\nfrom datetime import date, timedelta\r\nfrom datetime import datetime\r\nfrom itertools import zip_longest\r\nfrom os import path\r\nfrom pathlib import Path\r\nfrom shutil import copyfile\r\n\r\nimport matplotlib.pyplot as plt\r\nimport pandas as pd\r\nfrom google.cloud import bigquery\r\n\r\nimport Technician\r\nfrom AIGameData import AIGameData\r\nfrom CIMIS import CIMIS\r\nfrom CimisStation import CimisStation\r\nfrom CwsiProcessor import CwsiProcessor\r\nfrom DBWriter import DBWriter\r\nfrom Field import Field\r\nfrom Grower import Grower\r\nfrom IrrigationRecommendationExpert import IrrigationRecommendationExpert\r\nfrom Logger import Logger\r\nfrom Saulisms import Saulisms\r\nfrom SwitchTestCase import SwitchTestCase\r\nfrom Technician import Technician\r\nfrom WeatherStation import WeatherStation\r\n\r\nDIRECTORY_YEAR = \"2024\"\r\nPICKLE_DIRECTORY = \"H:\\\\Shared drives\\\\Stomato\\\\\" + DIRECTORY_YEAR + \"\\\\Pickle\\\\\"\r\nBACKUP_PICKLE_DIRECTORY = \"H:\\\\Shared drives\\\\Stomato\\\\\" + DIRECTORY_YEAR + \"\\\\Pickle\\\\Backup\\\\\"\r\nPICKLE_NAME = DIRECTORY_YEAR + \"_pickle.pickle\"\r\nPICKLE_PATH = PICKLE_DIRECTORY + PICKLE_NAME\r\n\r\nNOTIFICATIONS_DIRECTORY = \"H:\\\\Shared drives\\\\Stomato\\\\\" + DIRECTORY_YEAR + \"\\\\Notifications\"\r\n\r\n\r\ndef open_pickle(filename: str = PICKLE_NAME, specific_file_path: str = PICKLE_DIRECTORY):\r\n    \"\"\"\r\n    Function to open a pickle and return its contents.\r\n\r\n    :return:\r\n        List fields\r\n    \"\"\"\r\n\r\n    if path.exists(specific_file_path + filename):\r\n        with open(specific_file_path + filename, 'rb') as f:\r\n            content = pickle.load(f)\r\n        return content\r\n\r\n\r\ndef write_pickle(data, filename: str = PICKLE_NAME, specific_file_path: str = PICKLE_DIRECTORY):\r\n    \"\"\"\r\n    Function to write to a pickle.\r\n\r\n    A pickle is a form of permanent storage used to store any data structure. In this case, it's storing\r\n    the list of fields.\r\n\r\n    :param specific_file_path:\r\n    :param filename:\r\n    :param data: List that you want to have writen\r\n    :return:\r\n    \"\"\"\r\n\r\n    # Backup the old pickle before writing to it\r\n    # backup_pickle()\r\n\r\n    if path.exists(specific_file_path):\r\n        with open(specific_file_path + filename, 'wb') as f:\r\n            pickle.dump(data, f)\r\n\r\n\r\ndef backup_pickle(specific_name=None):\r\n    \"\"\"\r\n\r\n    :return:\r\n    \"\"\"\r\n    now = datetime.today()\r\n    if specific_name is not None:\r\n        file_name = specific_name + \"_pickle_backup_\" + str(now.strftime(\"%m-%d-%y  %I_%M_%S %p\")) + \".pickle\"\r\n    else:\r\n        file_name = \"pickle_backup_\" + str(now.strftime(\"%m-%d-%y  %I_%M_%S %p\")) + \".pickle\"\r\n\r\n    print('Backing up Pickle...')\r\n\r\n    # Check if the pickle we want to copy exists and if it does, copy it\r\n    if path.exists(PICKLE_PATH):\r\n        copyfile(\r\n            PICKLE_PATH,\r\n            BACKUP_PICKLE_DIRECTORY + file_name\r\n        )\r\n\r\n    print('Pickle Backed Up - ', file_name)\r\n\r\n\r\ndef reset_notifications(technicians: list[Technician]):\r\n    \"\"\"\r\n    Resets notifications for each technician\r\n\r\n    :param technicians: List of Technician\r\n    :return: None\r\n    \"\"\"\r\n    for tech in technicians:\r\n        # tech.all_notifications = AllNotifications()\r\n        tech.all_notifications.clear_all_notifications()\r\n\r\n\r\ndef get_all_technicians(growers: list[Grower]) -> list[Technician]:\r\n    \"\"\"\r\n    Get a list of all technicians\r\n\r\n    :param growers: List of Growers\r\n    :return: List of Technicians\r\n    \"\"\"\r\n    all_technicians = []\r\n    for grower in growers:\r\n        if grower.technician not in all_technicians and grower.technician is not None:\r\n            all_technicians.append(grower.technician)\r\n    return all_technicians\r\n\r\n\r\ndef update_et_information(\r\n        get_et: bool = False,\r\n        write_to_db: bool = False,\r\n        start_date = None,\r\n        end_date = None\r\n):\r\n    if get_et:\r\n        yesterdayRaw = date.today() - timedelta(1)\r\n        if start_date is None:\r\n            start_date = yesterdayRaw\r\n        if end_date is None:\r\n            end_date = yesterdayRaw\r\n        try:\r\n            all_et_data_dicts = pull_all_et_values(str(start_date), str(end_date))\r\n        except Exception as error:\r\n            print('ERROR in get_et')\r\n            print(error)\r\n    if get_et and write_to_db:\r\n        try:\r\n            write_all_et_values_to_db(all_et_data_dicts)\r\n        except Exception as error:\r\n            print('ERROR in write_et_to_db')\r\n            print(error)\r\n\r\n\r\ndef update_information(get_weather: bool = False, get_data: bool = False, write_to_portal: bool = False,\r\n                       write_to_db: bool = False, check_for_notifications: bool = False,\r\n                       email_notifications: bool = False, all_params: bool = False):\r\n    \"\"\"\r\n    Function to update information from each field with a trial.\r\n\r\n    :return:\r\n    \"\"\"\r\n\r\n    # OLD WAY OF SETTING THE CREDENTIALS FOR GOOGLE CLOUD\r\n    # if os.path.exists('C:\\\\Users\\\\javie\\\\Projects\\\\S-TOMAto\\\\credentials.json'):\r\n    #     os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/javie/Projects/S-TOMAto/credentials.json\"\r\n    # elif os.path.exists('C:\\\\Users\\\\javie\\\\PycharmProjects\\\\Stomato\\\\credentials.json'):\r\n    #     os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/javie/PycharmProjects/Stomato/credentials.json\"\r\n    # elif os.path.exists('C:\\\\Users\\\\jsalcedo\\\\PycharmProjects\\\\Stomato\\\\credentials.json'):\r\n    #     os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/jsalcedo/PycharmProjects/Stomato/credentials.json\"\r\n    # elif os.path.exists('C:\\\\Users\\\\jesus\\\\PycharmProjects\\\\Stomato\\\\credentials.json'):\r\n    #     os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/jesus/PycharmProjects/Stomato/credentials.json\"\r\n\r\n    now = datetime.today()\r\n    print(\">>>>>>>>>>>>>>>>>>>S-TOMAto Program<<<<<<<<<<<<<<<<<<<\")\r\n    print(\"                                 - \" + now.strftime(\"%m/%d/%y  %I:%M %p\"))\r\n    print()\r\n    print()\r\n\r\n    update_information_start_time = time.time()\r\n\r\n    if all_params:\r\n        get_data = True\r\n        get_weather = True\r\n        write_to_portal = True\r\n        write_to_db = True\r\n        check_for_notifications = True\r\n        email_notifications = True\r\n\r\n    # Get growers from pickle\r\n    growers = open_pickle()\r\n\r\n    # Backup current pickle\r\n    backup_pickle()\r\n    print()\r\n\r\n    # Grab the cimis stations pickle to pass in to Logger for ET data updating\r\n    cimis_stations_pickle = open_pickle(filename=\"cimisStation.pickle\")\r\n\r\n    # Iterate through growers and call update on each field which will in turn\r\n    #  call update on each logger in each field\r\n    for ind, grower in enumerate(growers):\r\n        # print(ind)\r\n        # try:\r\n        grower.update(cimis_stations_pickle, get_weather=get_weather, get_data=get_data,\r\n                      write_to_portal=write_to_portal, write_to_db=write_to_db,\r\n                      check_for_notifications=check_for_notifications)\r\n        # except Exception as e:\r\n        # Adding so any\r\n        # print(\"Error in \" + str(g.name) + \" . update\")\r\n        # print(\"Error type: \" + str(e))\r\n        # print(\"Writing growers\")\r\n        write_pickle(growers)\r\n\r\n        if check_for_notifications:\r\n            if hasattr(grower, 'technician'):\r\n                technician = grower.technician\r\n                # technician.all_notifications.write_all_notifications_to_txt(technician.name, g.name)\r\n                # technician.all_notifications.write_all_notifications_to_html(technician.name, g.name)\r\n                technician.all_notifications.write_all_notifications_to_html_v2(technician.name, grower.name)\r\n                technician.all_notifications.clear_all_notifications()\r\n\r\n    if check_for_notifications and email_notifications:\r\n        all_technicians = get_all_technicians(growers)\r\n        for tech in all_technicians:\r\n            # list_of_notifcation_files.append(tech.notification_file_path)\r\n            tech.all_notifications.email_all_notifications(tech.name, tech.email, file_type='html')\r\n\r\n    # Write pickle with updated information after update\r\n    print('Writing data to pickle-')\r\n    write_pickle(growers)\r\n\r\n    update_information_end_time = time.time()\r\n    print(\"----------FINISHED----------\")\r\n    update_information_elapsed_time_seconds = update_information_end_time - update_information_start_time\r\n\r\n    update_information_elapsed_time_hours = int(update_information_elapsed_time_seconds // 3600)\r\n    update_information_elapsed_time_minutes = int((update_information_elapsed_time_seconds % 3600) // 60)\r\n    update_information_elapsed_time_seconds = int(update_information_elapsed_time_seconds % 60)\r\n\r\n    print(f\"Update Information execution time: {update_information_elapsed_time_hours}:\"\r\n            + f\"{update_information_elapsed_time_minutes}:\"\r\n            + f\"{update_information_elapsed_time_seconds} (hours:minutes:seconds)\")\r\n    print()\r\n    print()\r\n\r\n\r\ndef notifications_setup(growers, technicians, file_type='txt'):\r\n    \"\"\"\r\n    Setup notifications files for each technician\r\n\r\n    :param growers: List of growers\r\n    :param technicians: List of technicians\r\n    :return:\r\n    \"\"\"\r\n    now = datetime.today()\r\n    # Clear previous notifications\r\n    growers[0].all_notifications.clear_all_notifications()\r\n\r\n    notif_folder = Path(NOTIFICATIONS_DIRECTORY)\r\n\r\n    saulisms = Saulisms()\r\n\r\n    # Setup Tech Notifications\r\n    for tech in technicians:\r\n        technician_name = tech.name\r\n        saying, saying_date = saulisms.get_random_saulism()\r\n\r\n        # SENSOR ERROR\r\n        sensor_error_notif_folder = Path.joinpath(notif_folder, 'Sensor Error')\r\n        sensor_error_file_name = technician_name + \"_sensor_error_notifications_\" + str(\r\n            now.strftime(\"%m-%d-%y\")\r\n        ) + \".\" + file_type\r\n        sensor_error_file_path = sensor_error_notif_folder / sensor_error_file_name\r\n\r\n        if file_type == 'txt':\r\n            with open(sensor_error_file_path, 'a') as the_file:\r\n                the_file.write(\"\\n\")\r\n                the_file.write(\r\n                    \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  SENSOR ERRORS  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\\n\"\r\n                )\r\n                the_file.write(\r\n                    \"                                                      \" + now.strftime(\"%m/%d/%y  %I:%M %p\")\r\n                )\r\n        elif file_type == 'html':\r\n            with open(sensor_error_file_path, 'a') as the_file:\r\n                the_file.write(\"<!DOCTYPE html>\\n\")\r\n                the_file.write(\"<html>\\n\")\r\n                the_file.write(\"<head>\\n\")\r\n                the_file.write(\"<title>Sensor Error Notifications</title>\\n\")\r\n                the_file.write(\"</head>\\n\")\r\n                the_file.write(\"<body>\\n\")\r\n                the_file.write(\"<style>\\n\")\r\n                the_file.write(\"table { table-layout: fixed; }\\n\")\r\n                the_file.write(\"table, th, td {border: 1px solid black; border-collapse: collapse;}\\n\")\r\n                the_file.write(\"th, td {padding: 15px;}\\n\")\r\n                the_file.write(\"tr:nth-child(even) {background-color: #F0F8FF;}\\n\")\r\n                the_file.write(\"</style>\\n\")\r\n                the_file.write(\"<h2>SENSOR ERRORS</h2>\\n\")\r\n                the_file.write(f\"<h2>{now.strftime('%m/%d/%y  %I:%M %p')}</h2>\\n\")\r\n                the_file.write(f\"<h2 style='font-style: italic; font-size: 150%;'>\\\"{saying}\\\", {saying_date}</h2>\\n\")\r\n                the_file.write(\"<hr>\\n\")\r\n\r\n        # TECH WARNINGS\r\n        # Disabling for the time being\r\n        # tech_warning_notif_folder = Path.joinpath(notif_folder, 'Tech Warning')\r\n        # tech_warning_file_name = technician_name + \"_tech_warning_notifications_\" + str(\r\n        #     now.strftime(\"%m-%d-%y\")\r\n        # ) + \".txt\"\r\n        # tech_warning_file_path = tech_warning_notif_folder / tech_warning_file_name\r\n        #\r\n        # with open(tech_warning_file_path, 'a') as the_file:\r\n        #     the_file.write(\"\\n\")\r\n        #     the_file.write(\r\n        #         \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  TECHNICIAN WARNINGS  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\\n\"\r\n        #     )\r\n        #     the_file.write(\r\n        #         \"                                                      \" + now.strftime(\"%m/%d/%y  %I:%M %p\")\r\n        #     )\r\n\r\n        # LOGGER SETUPS\r\n        logger_setups_notif_folder = Path.joinpath(notif_folder, 'Logger Setups')\r\n        logger_setups_file_name = technician_name + \"_logger_setups_notifications_\" + str(\r\n            now.strftime(\"%m-%d-%y\")\r\n        ) + \".\" + file_type\r\n        logger_setups_file_path = logger_setups_notif_folder / logger_setups_file_name\r\n\r\n        if file_type == 'txt':\r\n            with open(logger_setups_file_path, 'a') as the_file:\r\n                the_file.write(\"\\n\")\r\n                the_file.write(\r\n                    \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  NEW FIELDS CREATED  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\\n\"\r\n                )\r\n                the_file.write(\r\n                    \"                                                      \" + now.strftime(\"%m/%d/%y  %I:%M %p\")\r\n                )\r\n        elif file_type == 'html':\r\n            with open(logger_setups_file_path, 'a') as the_file:\r\n                the_file.write(\"<!DOCTYPE html>\\n\")\r\n                the_file.write(\"<html>\\n\")\r\n                the_file.write(\"<head>\\n\")\r\n                the_file.write(\"<title>Logger Setups Notifications</title>\\n\")\r\n                the_file.write(\"</head>\\n\")\r\n                the_file.write(\"<body>\\n\")\r\n                the_file.write(\"<style>\\n\")\r\n                the_file.write(\"table { table-layout: fixed; }\\n\")\r\n                the_file.write(\"table, th, td {border: 1px solid black; border-collapse: collapse;}\\n\")\r\n                the_file.write(\"th, td {padding: 15px;}\\n\")\r\n                the_file.write(\"tr:nth-child(even) {background-color: #F0F8FF;}\\n\")\r\n                the_file.write(\"</style>\\n\")\r\n                the_file.write(\"<h2>LOGGER SETUPS</h2>\\n\")\r\n                the_file.write(f\"<h2>{now.strftime('%m/%d/%y  %I:%M %p')}</h2>\\n\")\r\n                the_file.write(f\"<h2 style='font-style: italic; font-size: 150%;'>\\\"{saying}\\\", {saying_date}</h2>\\n\")\r\n\r\n\r\ndef add_field_to_grower(growerName, field):\r\n    \"\"\"\r\n\r\n\r\n    :param growerName:\r\n    :param field:\r\n    :return:\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    grower = None\r\n    for item in growers:\r\n        if item.name == growerName:\r\n            grower = item\r\n            break\r\n        else:\r\n            grower = None\r\n\r\n    field.grower = grower\r\n    for logger in field.loggers:\r\n        if logger.grower is None:\r\n            logger.grower = grower\r\n        if logger.field is None:\r\n            logger.field = field\r\n    grower.fields.append(field)\r\n    write_pickle(growers)\r\n\r\n\r\ndef remove_field(growerName, fieldName, avoidUserInput=False):\r\n    \"\"\"\r\n    Function to remove field from a grower\r\n\r\n    :param growerName:\r\n    :param fieldName:\r\n    :param avoidUserInput:\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    for g in growers:\r\n        if g.name == growerName:\r\n            for ind, f in enumerate(g.fields):\r\n                if f.name == fieldName:\r\n                    print('Field found:')\r\n                    f.to_string()\r\n                    print()\r\n                    print('About to remove ' + g.name + ' - ' + f.name + ' at index ' + str(ind))\r\n\r\n                    if avoidUserInput:\r\n                        confirm = 'y'\r\n                    else:\r\n                        confirm = input('Confirm? (Y/N) ').lower().strip()\r\n\r\n                    if confirm[:1] == 'y':\r\n                        print('Confirmed - Field removed')\r\n                        del g.fields[ind]\r\n                        write_pickle(growers)\r\n                    elif confirm[:1] == 'n':\r\n                        print('Canceled')\r\n                    else:\r\n                        print('Invalid Input')\r\n                # else:\r\n                # print('Field not found')\r\n\r\n\r\ndef deactivate_grower(grower_name: str) -> bool:\r\n    \"\"\"\r\n    Function to deactivate a grower to ensure his fields do not get updated\r\n\r\n    :param grower_name:\r\n    :return:\r\n    \"\"\"\r\n    success = False\r\n    growers = open_pickle()\r\n    for g in growers:\r\n        if g.name == grower_name:\r\n            print('Grower {} found:'.format(g.name))\r\n            if g.active:\r\n                g.deactivate()\r\n                success = True\r\n    write_pickle(growers)\r\n    return success\r\n\r\n\r\ndef deactivate_field(grower_name: str, field_name: str) -> bool:\r\n    \"\"\"\r\n    Function to deactivate a field so that the loggers in it no longer update\r\n\r\n    :param grower_name: String of the grower name\r\n    :param field_name: String of the field name\r\n    :return: success - Boolean of whether a field was successfully deactivate or not\r\n    \"\"\"\r\n    success = False\r\n    growers = open_pickle()\r\n    for g in growers:\r\n        if g.name == grower_name:\r\n            for f in g.fields:\r\n                if f.name == field_name:\r\n                    print('Field {} found:'.format(f.name))\r\n                    if f.active:\r\n                        f.deactivate()\r\n                        success = True\r\n    write_pickle(growers)\r\n    return success\r\n\r\n\r\ndef deactivate_logger(grower_name: str, field_name: str, logger_id: str) -> bool:\r\n    \"\"\"\r\n    Function to deactivate a logger so its data no longer gets processed\r\n\r\n    :param grower_name:\r\n    :param field_name:\r\n    :param logger_id:\r\n    :return: success - Boolean of whether a logger was successfully deactivated or not\r\n    \"\"\"\r\n    success = False\r\n    growers = open_pickle()\r\n    for g in growers:\r\n        if g.name == grower_name:\r\n            for f in g.fields:\r\n                if f.name == field_name:\r\n                    for logger in f.loggers:\r\n                        if logger.id == logger_id:\r\n                            print('Logger {} found:'.format(logger.id))\r\n                            if logger.active:\r\n                                logger.deactivate()\r\n                                success = True\r\n    write_pickle(growers)\r\n    return success\r\n\r\n\r\ndef remove_grower(growerName: str) -> None:\r\n    \"\"\"\r\n    Deprecated function. We now 'deactivate' the grower instead to leave them in the pickle\r\n    Function to remove a grower from the pickle\r\n\r\n    :param growerName: String of the grower name\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    for ind, g in enumerate(growers):\r\n        if g.name == growerName:\r\n            print('Grower found:')\r\n            g.to_string()\r\n            print()\r\n            print('About to remove ' + g.name + ' at index ' + str(ind))\r\n\r\n            confirm = input('Confirm? (Y/N) ').lower().strip()\r\n            if confirm[:1] == 'y':\r\n                print('Confirmed - Grower removed')\r\n                del growers[ind]\r\n                write_pickle(growers)\r\n            elif confirm[:1] == 'n':\r\n                print('Canceled')\r\n            else:\r\n                print('Invalid Input')\r\n    print('Growers remaining:')\r\n    for g in growers:\r\n        print(g.name)\r\n\r\n\r\ndef remove_last_grower():\r\n    \"\"\"\r\n    Function to remove the last grower in the pickle.\r\n    Typically, used to remove a grower that was added by mistake\r\n\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    del growers[-1]\r\n    write_pickle(growers)\r\n\r\n\r\ndef removeLogger(growerName: str, fieldName: str, loggerID: str) -> None:\r\n    \"\"\"\r\n    Function to remove a logger from a grower's field\r\n\r\n    :param growerName: String of the grower name\r\n    :param fieldName: String of the field name\r\n    :param loggerID: String of the logger id\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    for g in growers:\r\n        if g.name == growerName:\r\n            for f in g.fields:\r\n                if f.name == fieldName:\r\n                    for ind, l in enumerate(f.loggers):\r\n                        if l.id == loggerID:\r\n                            print('Logger found:')\r\n                            l.to_string()\r\n                            print()\r\n                            print(\r\n                                'About to remove ' + g.name + ' - ' + f.name + ' - ' + l.id + ' at index ' + str(\r\n                                    ind\r\n                                )\r\n                            )\r\n\r\n                            confirm = input('Confirm? (Y/N) ').lower().strip()\r\n                            if confirm[:1] == 'y':\r\n                                print('Confirmed - Field removed')\r\n                                del f.loggers[ind]\r\n                                write_pickle(growers)\r\n                            elif confirm[:1] == 'n':\r\n                                print('Canceled')\r\n                            else:\r\n                                print('Invalid Input')\r\n\r\n\r\ndef addGrowerToGrowers(grower: Grower) -> None:\r\n    \"\"\"\r\n    Function to add a grower to the growers in the pickle\r\n\r\n    :param grower:\r\n    \"\"\"\r\n    growers = open_pickle()\r\n\r\n    growers.append(grower)\r\n\r\n    write_pickle(growers)\r\n\r\n\r\ndef show_pickle(filename: str = PICKLE_NAME, specific_file_path: str = PICKLE_DIRECTORY):\r\n    \"\"\"\r\n        Function to print out the contents of the pickle.\r\n\r\n        :return:\r\n    \"\"\"\r\n    data = open_pickle(filename=filename, specific_file_path=specific_file_path)\r\n    print(\"PICKLE CONTENTS\")\r\n    for d in data:\r\n        d.to_string()\r\n\r\n\r\ndef only_certain_growers_update(\r\n        growerNames: list[str],\r\n        get_weather: bool = False,\r\n        get_data: bool = False,\r\n        write_to_portal: bool = False,\r\n        write_to_db: bool = False,\r\n        check_for_notifications: bool = False,\r\n        subtract_from_mrid: int = 0\r\n) -> None:\r\n    \"\"\"\r\n    Function to only update certain growers\r\n\r\n    :param subtract_from_mrid: Int used to subtract a specific amount from the logger MRIDs for API calls\r\n    :param growerNames: List of grower names in string form\r\n    :param get_et: Boolean, True if you want to get ET, False otherwise\r\n    :param get_weather: Boolean, True if you want to get Weather, False otherwise\r\n    :param get_data: Boolean, True if you want to get Data, False otherwise\r\n    :param write_to_portal: Boolean, True if you want to write data to grower portal, False otherwise\r\n    :param write_to_db: Boolean, True if you want to write to DB, False otherwise\r\n    :param check_for_notifications: Boolean, True if you want to check for notifications, False otherwise\r\n    \"\"\"\r\n    # Grab the cimis stations pickle to pass in to Logger for ET data updating\r\n    cimis_stations_pickle = open_pickle(filename=\"cimisStation.pickle\")\r\n\r\n    print(\"Only updating: \" + str(growerNames))\r\n    cimis_stations_pickle = open_pickle(filename=\"cimisStation.pickle\")\r\n    allGrowers = open_pickle()\r\n    for g in allGrowers:\r\n        if g.name in growerNames:\r\n            g.updated = False\r\n            for field in g.fields:\r\n                field.updated = False\r\n                for logger in field.loggers:\r\n                    logger.updated = False\r\n            g.update(\r\n                cimis_stations_pickle,\r\n                get_weather=get_weather,\r\n                get_data=get_data,\r\n                write_to_portal=write_to_portal,\r\n                write_to_db=write_to_db,\r\n                check_for_notifications=check_for_notifications,\r\n                subtract_from_mrid=subtract_from_mrid\r\n            )\r\n    write_pickle(allGrowers)\r\n\r\n\r\ndef only_certain_growers_field_update(\r\n        grower_name: str,\r\n        field_name: str,\r\n        get_weather: bool = False,\r\n        get_data: bool = False,\r\n        write_to_portal: bool = False,\r\n        write_to_db: bool = False,\r\n        check_for_notifications: bool = False,\r\n        subtract_from_mrid: int = 0\r\n) -> None:\r\n    \"\"\"\r\n    Function to only update a certain field for a grower\r\n\r\n    :param subtract_from_mrid:\r\n    :param grower_name: String of grower name\r\n    :param field_name: String of field name\r\n    :param get_et: Boolean, True if you want to get ET, False otherwise\r\n    :param get_weather: Boolean, True if you want to get Weather, False otherwise\r\n    :param get_data: Boolean, True if you want to get Data, False otherwise\r\n    :param write_to_portal: Boolean, True if you want to write data to grower portal sheet, False otherwise\r\n    :param write_to_db: Boolean, True if you want to write to DB, False otherwise\r\n    :param check_for_notifications: Boolean, True if you want to check for notifications, False otherwise\r\n    \"\"\"\r\n    allGrowers = open_pickle()\r\n    cimis_stations_pickle = open_pickle(filename=\"cimisStation.pickle\")\r\n    for g in allGrowers:\r\n        if g.name == grower_name:\r\n            for f in g.fields:\r\n                if f.name == field_name:\r\n                    f.updated = False\r\n                    for logger in f.loggers:\r\n                        logger.updated = False\r\n                    f.update(\r\n                        cimis_stations_pickle = cimis_stations_pickle,\r\n                        get_weather=get_weather,\r\n                        get_data=get_data,\r\n                        write_to_portal=write_to_portal,\r\n                        write_to_db=write_to_db,\r\n                        check_for_notifications=check_for_notifications,\r\n                        subtract_from_mrid=subtract_from_mrid\r\n                    )\r\n    write_pickle(allGrowers)\r\n\r\n\r\ndef only_certain_growers_fields_update(\r\n        fields: list[str],\r\n        get_weather: bool = False,\r\n        get_data: bool = False,\r\n        write_to_portal: bool = False,\r\n        write_to_db: bool = False,\r\n        check_for_notifications: bool = False,\r\n        subtract_from_mrid: int = 0\r\n) -> None:\r\n    \"\"\"\r\n    Function to only update certain fields\r\n\r\n    :param fields: List of strings\r\n    :param get_et: Boolean, True if you want to get ET, False otherwise\r\n    :param get_weather: Boolean, True if you want to get Weather, False otherwise\r\n    :param get_data: Boolean, True if you want to get Data, False otherwise\r\n    :param write_to_portal: Boolean, True if you want to write data to grower portal sheet, False otherwise\r\n    :param write_to_db: Boolean, True if you want to write to DB, False otherwise\r\n    :param check_for_notifications: Boolean, True if you want to check for notifications, False otherwise\r\n    \"\"\"\r\n    allGrowers = open_pickle()\r\n    for g in allGrowers:\r\n        for f in g.fields:\r\n            if f.name in fields:\r\n                f.updated = False\r\n                for l in f.loggers:\r\n                    l.updated = False\r\n                f.update(\r\n                    get_weather=get_weather,\r\n                    get_data=get_data,\r\n                    write_to_portal=write_to_portal,\r\n                    write_to_db=write_to_db,\r\n                    check_for_notifications=check_for_notifications,\r\n                    subtract_from_mrid=subtract_from_mrid\r\n                )\r\n    write_pickle(allGrowers)\r\n\r\n\r\ndef only_certain_growers_field_logger_update(\r\n        grower_name: str,\r\n        field_name: str,\r\n        logger_name: str,\r\n        write_to_db: bool = False,\r\n        check_for_notifications: bool = False,\r\n        specific_mrid: float = None,\r\n        subtract_from_mrid: float = 0\r\n) -> None:\r\n    \"\"\"\r\n    Function to update a specific Logger\r\n\r\n    :param grower_name: String of grower name\r\n    :param field_name: String of field name\r\n    :param logger_name: String of logger ID\r\n    :param write_to_db: Boolean, True if you want to write to DB, False otherwise\r\n    :param check_for_notifications: Boolean, True if you want to check notifications\r\n    :param specific_mrid: Float value if you want to call METER API with a specific MRID\r\n    :param subtract_from_mrid: Float value if you want to subtract a certain amount from the MRID\r\n                                before calling the METER API\r\n    \"\"\"\r\n    cimis_stations_pickle = open_pickle(filename=\"cimisStation.pickle\")\r\n    all_growers = open_pickle()\r\n    for grower in all_growers:\r\n        if grower.name == grower_name:\r\n            for field in grower.fields:\r\n                if field.name == field_name:\r\n                    field.updated = False\r\n                    for logger in field.loggers:\r\n                        if logger.name == logger_name:\r\n                            logger.updated = False\r\n                            logger.update(\r\n                                cimis_stations_pickle,\r\n                                write_to_db=write_to_db,\r\n                                check_for_notifications=check_for_notifications, specific_mrid=specific_mrid,\r\n                                subtract_from_mrid=subtract_from_mrid\r\n                            )\r\n    write_pickle(all_growers)\r\n\r\n\r\ndef setup_grower(grower_name: str, technician_name: str, email: str = '', region: str = '',\r\n                 active: bool = True) -> Grower:\r\n    \"\"\"\r\n    Function to create a Grower object\r\n\r\n    :param technician_name: \r\n    :param grower_name: String of the grower name\r\n    :param email: String of the grower email\r\n    :param region: String of the grower region\r\n    :param active: Boolean indicating if the grower is active\r\n    :return:\r\n    \"\"\"\r\n    fields = []\r\n\r\n    tech = None\r\n    growers = open_pickle()\r\n    for grower in growers:\r\n        if grower.technician.name == technician_name:\r\n            tech = grower.technician\r\n            break\r\n    if tech is None:\r\n        tech = Technician(technician_name, '')\r\n\r\n    new_grower = Grower(grower_name, fields, tech, email, region=region, active=active)\r\n    growers.append(new_grower)\r\n    write_pickle(growers)\r\n    return new_grower\r\n\r\n\r\ndef setup_field(\r\n        field_name,\r\n        lat,\r\n        long,\r\n        cimis_station,\r\n        acres,\r\n        crop_type,\r\n        grower=None,\r\n        active=True,\r\n        field_type='Commercial'\r\n):\r\n    \"\"\"\r\n    Function to create a Field object\r\n\r\n    :param field_type:\r\n    :param crop_type:\r\n    :param acres:\r\n    :param field_name:\r\n    :param lat:\r\n    :param long:\r\n    :param cimis_station:\r\n    :param grower:\r\n    :param active:\r\n    :return:\r\n    \"\"\"\r\n    loggers = []\r\n    field = Field(field_name, loggers, lat, long, cimis_station, acres, crop_type, grower=grower, active=active, field_type=field_type)\r\n    return field\r\n\r\n\r\ndef setup_logger(logger_id, password, name, crop_type, soil_type, gpm, acres, loggerDirection, lat, long, install_date,\r\n                 planting_date=None, grower=None, field=None, rnd=False, active=True):\r\n    \"\"\"\r\n    Function to set up a new Logger\r\n\r\n    :param install_date:\r\n    :param soil_type:\r\n    :param name:\r\n    :param lat:\r\n    :param long:\r\n    :param loggerDirection:\r\n    :param logger_id:\r\n    :param password:\r\n    :param crop_type:\r\n    :param gpm:\r\n    :param acres:\r\n    :param planting_date:\r\n    :param grower:\r\n    :param field:\r\n    :param rnd:\r\n    :param active:\r\n    :return:\r\n    \"\"\"\r\n    logger = Logger(logger_id, password, name, crop_type, soil_type, gpm, acres, loggerDirection, install_date, lat, long, grower=grower, field=field,\r\n                    planting_date=planting_date, rnd=rnd, active=active)\r\n    return logger\r\n\r\n\r\ndef set_loggers_rnd(logger_ids):\r\n    \"\"\"\r\n\r\n    :param logger_ids: \r\n    \"\"\"\r\n    logger_ids_list = logger_ids\r\n    growers = open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            for logger in field.loggers:\r\n                for logger_id in logger_ids_list:\r\n                    if logger.id == logger_id:\r\n                        print(\"Found id: \" + str(logger_id) + \" and set R&D to TRUE\")\r\n                        logger.rnd = True\r\n                        logger_ids_list.remove(logger_id)\r\n                        print(\" Remaining IDs:\" + str(logger_ids_list))\r\n                        logger.to_string()\r\n    write_pickle(growers)\r\n\r\n\r\ndef get_grower(grower_name: str) -> Grower:\r\n    \"\"\"\r\n    Function to get a grower object from the pickle\r\n\r\n    :param grower_name: String of grower name\r\n    :return: Grower object\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    for grower in growers:\r\n        if grower.name == grower_name:\r\n            return grower\r\n\r\n\r\ndef get_gpm(field_name: str, logger_name: str) -> float:\r\n    \"\"\"\r\n    Function to get the GPM for a logger in a field\r\n\r\n    :param field_name: String of the field name\r\n    :param logger_name: String of the logger name\r\n    :return: float of the Gallons per Minute\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.name == field_name:\r\n                for log in f.loggers:\r\n                    if log.name == logger_name:\r\n                        # print(log.gpm)\r\n                        # print(type(log.gpm))\r\n                        return log.gpm\r\n\r\n\r\ndef get_acres(field_name: str, logger_name: str) -> float:\r\n    \"\"\"\r\n    Function to get the acres for a logger in a field\r\n\r\n    :param logger_name: String of the logger name\r\n    :param field_name: String of the field name\r\n    :return: Float of the acres\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.name == field_name:\r\n                for log in f.loggers:\r\n                    if log.name == logger_name:\r\n                        # print(log.acres)\r\n                        return log.irrigation_set_acres\r\n\r\ndef show_grower(grower_name: str) -> None:\r\n    \"\"\"\r\n    Function to call a grower's to_string()\r\n\r\n    :param grower_name: String of the grower name\r\n    \"\"\"\r\n    g = get_grower(grower_name)\r\n    if g is not None:\r\n        g.to_string()\r\n    else:\r\n        print('Grower -' + grower_name + '- not found')\r\n\r\n\r\ndef get_field(field_name: str, grower_name: str = '') -> Field:\r\n    \"\"\"\r\n    Function to get a field\r\n\r\n    :param field_name: String for the field name\r\n    :param grower_name: Optional parameter of the string for the grower name\r\n    :return: Field object of the field\r\n    \"\"\"\r\n    if grower_name:\r\n        grower = get_grower(grower_name)\r\n        for field in grower.fields:\r\n            if field.name == field_name:\r\n                return field\r\n    else:\r\n        growers = open_pickle()\r\n        for grower in growers:\r\n            for field in grower.fields:\r\n                if field.name == field_name:\r\n                    return field\r\n\r\n\r\ndef show_field(field_name: str, grower_name: str = '') -> None:\r\n    \"\"\"\r\n    Function to pring out to console a field's information (to_string*())\r\n\r\n    :param field_name: String of the field name\r\n    :param grower_name: String of the grower name\r\n    \"\"\"\r\n    f = get_field(field_name, grower_name)\r\n    if f is not None:\r\n        f.to_string()\r\n    else:\r\n        print('Field -' + field_name + '- not found')\r\n\r\n\r\ndef write_new_historical_et_to_db(table, filename, historicalET=\"Historical_ET\", overwrite=False):\r\n    \"\"\"\r\n    Function to write mew historical ET table to DB\r\n\r\n    :param table:\r\n    :param filename:\r\n    :param historicalET:\r\n    :param overwrite:\r\n    \"\"\"\r\n    schema = [\r\n        bigquery.SchemaField(\"Year4\", \"DATE\"),\r\n        bigquery.SchemaField(\"Year4ET\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"Year3\", \"DATE\"),\r\n        bigquery.SchemaField(\"Year3ET\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"Year2\", \"DATE\"),\r\n        bigquery.SchemaField(\"Year2ET\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"Year1\", \"DATE\"),\r\n        bigquery.SchemaField(\"Year1ET\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"Average\", \"FLOAT\"),\r\n    ]\r\n\r\n    dbwriter = DBWriter()\r\n    project = 'stomato-info'\r\n    dbwriter.write_to_table_from_csv(historicalET, table, filename, schema, project, overwrite=overwrite)\r\n\r\n\r\ndef write_new_historical_et_to_db_2(dataset_id, table, data, filename=\"newhistoricalET.csv\", overwrite=False):\r\n    \"\"\"\r\n    Function writes irr scheduling data into csv then creates a db table from csv\r\n\r\n    :param dataset_id:\r\n    :param table:\r\n    :param data:\r\n    :param filename:\r\n    :param overwrite:\r\n    \"\"\"\r\n    print('\\t- writing data to csv')\r\n    with open(filename, \"w\", newline='') as outfile:\r\n        writer = csv.writer(outfile)\r\n        writer.writerow(data.keys())\r\n        # Using zip_longest because dict rows are uneven length due to daily_switch algo issue\r\n        # This will add full null rows for any additional daily_switch list values\r\n        writer.writerows(zip_longest(*data.values()))\r\n    print('...Done - file: ' + filename)\r\n\r\n    schema = [\r\n        bigquery.SchemaField(\"Year_2022\", \"DATE\", mode=\"NULLABLE\"),\r\n        bigquery.SchemaField(\"Year_2022_ET\", \"Float\", mode=\"NULLABLE\"),\r\n        bigquery.SchemaField(\"Year_2021\", \"DATE\", mode=\"NULLABLE\"),\r\n        bigquery.SchemaField(\"Year_2021_ET\", \"Float\", mode=\"NULLABLE\"),\r\n        bigquery.SchemaField(\"Year_2020\", \"DATE\", mode=\"NULLABLE\"),\r\n        bigquery.SchemaField(\"Year_2020_ET\", \"Float\", mode=\"NULLABLE\"),\r\n        bigquery.SchemaField(\"Year_2019\", \"DATE\", mode=\"NULLABLE\"),\r\n        bigquery.SchemaField(\"Year_2019_ET\", \"Float\", mode=\"NULLABLE\"),\r\n        bigquery.SchemaField(\"Year_2018\", \"DATE\", mode=\"NULLABLE\"),\r\n        bigquery.SchemaField(\"Year_2018_ET\", \"Float\", mode=\"NULLABLE\"),\r\n        bigquery.SchemaField(\"Average\", \"Float\", mode=\"NULLABLE\")\r\n    ]\r\n    dbwriter = DBWriter()\r\n    print(\"Writing Data to DB\")\r\n    project = 'stomato-info'\r\n    dbwriter.write_to_table_from_csv(dataset_id, table, filename, schema, project, overwrite=overwrite)\r\n\r\n\r\ndef update_irr_scheduling(table, fieldName, data, filename=\"irrScheduling.csv\", overwrite=False, logger=None):\r\n    \"\"\"\r\n    Function writes irr scheduling data into csv then creates a db table from csv\r\n\r\n    :param table:\r\n    :param fieldName:\r\n    :param data:\r\n    :param filename:\r\n    :param overwrite:\r\n    \"\"\"\r\n    print('\\t- writing data to csv')\r\n    with open(filename, \"w\", newline='') as outfile:\r\n        writer = csv.writer(outfile)\r\n        writer.writerow(data.keys())\r\n        # Using zip_longest because dict rows are uneven length due to daily_switch algo issue\r\n        # This will add full null rows for any additional daily_switch list values\r\n        writer.writerows(zip_longest(*data.values()))\r\n    print('...Done - file: ' + filename)\r\n\r\n    schema = [\r\n        bigquery.SchemaField(\"current_date\", \"DATE\", mode=\"REQUIRED\"),\r\n        bigquery.SchemaField(\"historical_eto\", \"FLOAT\", mode=\"REQUIRED\"),\r\n        bigquery.SchemaField(\"kc\", \"FLOAT\", mode=\"REQUIRED\"),\r\n        bigquery.SchemaField(\"historical_etc\", \"FLOAT\", mode=\"REQUIRED\"),\r\n        bigquery.SchemaField(\"historical_hours\", \"FLOAT\", mode=\"REQUIRED\")\r\n    ]\r\n    dbwriter = DBWriter()\r\n    print(\"Writing Data to DB\")\r\n    # project = 'stomato-' + DATABASE_YEAR\r\n    project = dbwriter.get_db_project(logger.crop_type)\r\n    dbwriter.write_to_table_from_csv(fieldName, table, filename, schema, project, overwrite=overwrite)\r\n\r\n\r\ndef get_all_current_cimis_stations():\r\n    \"\"\"\r\n    Get all the cimis stations for where we have equipment currently in the pickle\r\n\r\n    :return:\r\n    \"\"\"\r\n    cimis_stations = []\r\n    growers = open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.cimis_station not in cimis_stations:\r\n                cimis_stations.append(f.cimis_station)\r\n    print('Cimis Stations currently in pickle: ' + str(cimis_stations))\r\n    return cimis_stations\r\n\r\n\r\ndef pull_all_et_values(start_date, end_date):\r\n    \"\"\"\r\n    Function to grab all ET values from a given starDate through to a given endDate\r\n    for all CIMIS stations in our current pickle\r\n\r\n    :param start_date:\r\n    :param end_date:\r\n    :return:\r\n    \"\"\"\r\n    cimis = CIMIS()\r\n    # cimisStation = CimisStation()\r\n    # stations = get_all_current_cimis_stations()\r\n    # stations = cimisStation.return_list_of_stations()\r\n    cimis_stations_pickle = open_pickle(filename=\"cimisStation.pickle\")\r\n\r\n    all_cimis_station_et = cimis.get_all_stations_et_data(cimis_stations_pickle, start_date, end_date)\r\n\r\n    write_pickle(cimis_stations_pickle, filename=\"cimisStation.pickle\")\r\n    return all_cimis_station_et\r\n\r\ndef update_all_eto_values(start_date: str , end_date: str):\r\n    \"\"\"\r\n    Function to grab all ETo values from a given start_date through to a given end_date\r\n    for all CIMIS stations in our current pickle and update them to the DB to ensure we have current/correct values\r\n\r\n    :param start_date: str indicating first day of data to pull from CIMIS\r\n    :param end_date: str indicating the last day of data to pull from CIMIS\r\n    :return:\r\n    \"\"\"\r\n    record_limit = 1750\r\n    cimis = CIMIS()\r\n    cimis_stations_pickle = open_pickle(filename=\"cimisStation.pickle\")\r\n    # Convert the string dates to datetime objects\r\n    date1 = datetime.strptime(start_date, '%Y-%m-%d')\r\n    date2 = datetime.strptime(end_date, '%Y-%m-%d')\r\n    # Calculate the difference between the two dates\r\n    difference = date2 - date1\r\n\r\n    station_limit = math.floor(record_limit / difference.days)\r\n    all_cimis_station_eto = {}\r\n    for i in range(0, len(cimis_stations_pickle), station_limit):\r\n        current_pairs = cimis_stations_pickle[i:i+station_limit]\r\n        print(f'Pulling data from CIMIS for {len(current_pairs)} stations')\r\n        some_stations = cimis.get_all_stations_et_data(current_pairs, start_date, end_date)\r\n        all_cimis_station_eto.update(some_stations)\r\n\r\n    print(f'Preparing to write CIMIS stations data to DB')\r\n    write_all_et_values_to_db(all_cimis_station_eto, overwrite=True)\r\n\r\n\r\ndef write_all_et_values_to_db(all_cimis_station_et, overwrite: bool = False):\r\n    \"\"\"\r\n    Write all ET values for all CIMIS stations in our current pickle\r\n    to their corresponding ET tables in the DB\r\n\r\n    :return:\r\n    \"\"\"\r\n\r\n    dbwriter = DBWriter()\r\n    project = 'stomato-info'\r\n    dataset_id = 'ET'\r\n    schema = [\r\n        bigquery.SchemaField(\"date\", \"DATE\"),\r\n        bigquery.SchemaField(\"eto\", \"FLOAT\"),\r\n    ]\r\n    filename = 'all et.csv'\r\n\r\n    for et_data_dict_key in all_cimis_station_et:\r\n        # TODO add check to see if data is already in DB before writing duplicates\r\n        # # Check if the data we have is new or already exists in the DB\r\n        # db_dates = dbwriter.grab_specific_column_table_data(\r\n        #     dataset_id,\r\n        #     table_id,\r\n        #     project,\r\n        #     'date'\r\n        # )\r\n        # if db_dates is not None:\r\n        #     db_dates_list = [row[0] for row in db_dates]\r\n        # else:\r\n        #     db_dates_list = []\r\n\r\n        print(f'\\t- writing station {et_data_dict_key} data to csv')\r\n        keys = [\"dates\", \"eto\"]\r\n        just_et_data = {key: all_cimis_station_et[et_data_dict_key][key] for key in keys}\r\n\r\n        with open(filename, \"w\", newline='') as outfile:\r\n            writer = csv.writer(outfile)\r\n            writer.writerow(just_et_data.keys())\r\n            writer.writerows(zip_longest(*just_et_data.values()))\r\n        print('\\t...Done')\r\n\r\n        table_id = et_data_dict_key\r\n        dbwriter.write_to_table_from_csv(dataset_id, table_id, filename, schema, project, overwrite)\r\n\r\n\r\ndef write_et_values_specific_station(start_date: str, end_date: str, cimis_station: str) -> None:\r\n    \"\"\"\r\n    Get et for a specific station for a date range and write those values to the DB\r\n\r\n    :param start_date:\r\n    :param end_date:\r\n    :param cimis_station:\r\n    \"\"\"\r\n    stations = cimis_station\r\n    c = CIMIS()\r\n    dicts = c.getDictForStation(stations, start_date, end_date)\r\n    dbwriter = DBWriter()\r\n    for etDataDict in dicts:\r\n        # write_alletsdicts_to_db(etDataDict)\r\n        if etDataDict is not None:\r\n            dataset_id = 'ET'\r\n            table_id = etDataDict['station']\r\n            schema = [\r\n                bigquery.SchemaField(\"date\", \"DATE\"),\r\n                bigquery.SchemaField(\"eto\", \"FLOAT\"),\r\n            ]\r\n            filename = 'all et.csv'\r\n            print('- writing data to csv')\r\n            keys = [\"dates\", \"eto\"]\r\n            justEtData = {key: etDataDict[key] for key in keys}\r\n\r\n            with open(filename, \"w\", newline='') as outfile:\r\n                writer = csv.writer(outfile)\r\n                writer.writerow(justEtData.keys())\r\n                writer.writerows(zip_longest(*justEtData.values()))\r\n            print('...Done - file: ' + filename)\r\n            #\r\n            project = 'stomato-info'\r\n            dbwriter.write_to_table_from_csv(dataset_id, table_id, filename, schema, project)\r\n\r\n\r\ndef calculate_mrid_subtraction_for_date(startDate):\r\n    \"\"\"\r\n    Calculate the subtraction necessary make to MRID to get values from a specific start date\r\n\r\n    :param startDate:\r\n    :return:\r\n    \"\"\"\r\n    # Turn date string into datetimes\r\n    startDateDT = datetime.strptime(startDate, \"%Y-%m-%d\")\r\n    endDateDT = datetime.today()\r\n    delta = endDateDT - startDateDT + timedelta(days=1)\r\n    days = delta.days - 1\r\n    # print(days)\r\n    subMridResult = (days * 24)\r\n    # print(subMridResult)\r\n\r\n    return subMridResult\r\n\r\n\r\ndef get_previous_data_field(grower_name, field_name, startDate,\r\n                            write_to_db=False, specific_mrid=None):\r\n    \"\"\"\r\n    Grab data for a field from a specific start date\r\n\r\n    :param grower_name:\r\n    :param field_name:\r\n    :param startDate:\r\n    :param write_to_db:\r\n    :param specific_mrid:\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    for grower in growers:\r\n        if grower.name == grower_name:\r\n            for field in grower.fields:\r\n                if field.name == field_name:\r\n                    for logger in field.loggers:\r\n                        print(\"Updating Logger: \" + logger.id)\r\n                        print(\"Converting date to MRID\")\r\n                        print(\"Start Date: \" + startDate)\r\n                        mridResult = calculate_mrid_subtraction_for_date(startDate)\r\n                        print(\"Subtract from MRID: \" + str(mridResult))\r\n                        print(\"This is previous day switch: \" + str(logger.prev_day_switch))\r\n                        print(\"Assigning new prev day switch\")\r\n                        logger.prev_day_switch = 0\r\n                        print(\"New prev day switch: \" + str(logger.prev_day_switch))\r\n                        write_pickle(growers)\r\n                        only_certain_growers_field_logger_update(\r\n                            grower_name, field_name, logger.id,\r\n                            write_to_db=write_to_db,\r\n                            specific_mrid=specific_mrid,\r\n                            subtract_from_mrid=mridResult\r\n                        )\r\n\r\n\r\ndef failed_cimis_update_et_from_prev_day_eto():\r\n    \"\"\"\r\n    Update et tables for all fields\r\n\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            for logger in field.loggers:\r\n                print(f'\\tUpdating et values in Logger {logger.name} table...')\r\n                try:\r\n                    logger.merge_et_db_with_logger_db_values()\r\n                except Exception as err:\r\n                    print(f\"ET Did not update for this logger {logger.name}\")\r\n                    print(err)\r\n\r\n\r\ndef reset_updated_all():\r\n    \"\"\"\r\n    Reset the updated boolean for all growers, fields and loggers\r\n\r\n    \"\"\"\r\n    print('Resetting updated on all growers')\r\n    growers = open_pickle()\r\n    for g in growers:\r\n        g.updated = False\r\n        for f in g.fields:\r\n            f.updated = False\r\n            for logger in f.loggers:\r\n                logger.updated = False\r\n    write_pickle(growers)\r\n    cimisStationsPickle = CimisStation.open_cimis_station_pickle(CimisStation)\r\n    for stations in cimisStationsPickle:\r\n        stations.updated = False\r\n    write_pickle(cimisStationsPickle, filename=\"cimisStation.pickle\")\r\n\r\n\r\ndef set_planting_date_for_field(grower_name, field_name, year, month, day):\r\n    \"\"\"\r\n    Set a planting date for a field\r\n\r\n    :param grower_name:\r\n    :param field_name:\r\n    :param year:\r\n    :param month:\r\n    :param day:\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    for grower in growers:\r\n        if grower.name == grower_name:\r\n            for field in grower.fields:\r\n                if field.name == field_name:\r\n                    for logger in field.loggers:\r\n                        print(\"Old Planting Date: \" + str(logger.planting_date))\r\n                        # print(type(logger.planting_date))\r\n                        newPlantingDate = datetime(year, month, day).date()\r\n                        logger.planting_date = newPlantingDate\r\n                        print(\"New Planting Date: \" + str(logger.planting_date))\r\n    write_pickle(growers)\r\n\r\n\r\ndef update_prev_switch(logger_id, switch):\r\n    \"\"\"\r\n\r\n\r\n    :param logger_id:\r\n    :param switch:\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            for logger in field.loggers:\r\n                if logger.id in logger_id:\r\n                    print(\"Logger ID: \" + str(logger.id))\r\n                    print(\"Prev Switch: \" + str(logger.prev_day_switch))\r\n                    logger.prev_day_switch = switch\r\n                    print(\"New Switch: \" + str(logger.prev_day_switch))\r\n    write_pickle(growers)\r\n\r\n\r\ndef check_successful_updated_growers():\r\n    \"\"\"\r\n    Check and print out the number of growers that updated successfully based on their updated boolean\r\n\r\n    :return:\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    active_growers = get_number_of_active_growers()\r\n    successfulGrowers = 0\r\n    for g in growers:\r\n        if g.updated and g.active:\r\n            successfulGrowers = successfulGrowers + 1\r\n    if successfulGrowers == len(active_growers):\r\n        print(\"\\tAll growers successful! \")\r\n        print(\"\\t{0}/{1}\".format(successfulGrowers, active_growers))\r\n        return True\r\n    else:\r\n        print(\"\\t{0}/{1} active growers updated successfully\".format(successfulGrowers, active_growers))\r\n        return False\r\n\r\n\r\ndef get_number_of_active_growers() -> tuple[float, float]:\r\n    \"\"\"\r\n    Function to calculate the number of active growers\r\n\r\n    :return active_growers: Number of active growers\r\n            inactive_growers: Number of inactive growers\r\n    \"\"\"\r\n    active_growers = 0\r\n    inactive_growers = 0\r\n    growers = open_pickle()\r\n    for grower in growers:\r\n        if grower.active:\r\n            active_growers += 1\r\n        else:\r\n            inactive_growers += 1\r\n    return active_growers, inactive_growers\r\n\r\n\r\ndef get_number_of_active_fields_for_grower(grower: Grower) -> tuple[float, float]:\r\n    \"\"\"\r\n    Function to calculate the number of active fields for a grower\r\n\r\n    :param grower: Grower object\r\n    :return active_fields: Number of active fields\r\n            inactive_fields: Number of inactive fields\r\n    \"\"\"\r\n    active_fields, inactive_fields = grower.get_number_of_active_fields()\r\n    return active_fields, inactive_fields\r\n\r\n\r\ndef get_number_of_active_loggers_for_field(field: Field) -> tuple[float, float]:\r\n    \"\"\"\r\n    Function to calculate the number of active and inactive logger for a field\r\n\r\n    :param field: Field object\r\n    :return active_loggers: Number of active logger\r\n            inactive_loggers: Number of inactive loggers\r\n    \"\"\"\r\n    active_loggers, inactive_loggers = field.get_number_of_active_loggers()\r\n    return active_loggers, inactive_loggers\r\n\r\n\r\ndef updated_run_report() -> bool:\r\n    \"\"\"\r\n    Function to show a report on how many growers/fields/loggers got updated successfully\r\n\r\n    :return:\r\n    \"\"\"\r\n    print('\\t--Updated Run Report--')\r\n    growers = open_pickle()\r\n    successfulGrowers = 0\r\n    successfulFields = 0\r\n    successfulLoggers = 0\r\n    number_of_active_growers, number_of_inactive_growers = get_number_of_active_growers()\r\n    for g in growers:\r\n        if g.active:\r\n            if g.updated:\r\n                successfulGrowers = successfulGrowers + 1\r\n            else:\r\n                print(\"\\tGrower: -{0}- was unsuccessful in updating\".format(g.name))\r\n                for f in g.fields:\r\n                    if f.active:\r\n                        if f.updated:\r\n                            successfulFields = successfulFields + 1\r\n                        else:\r\n                            print(\"\\t due to Field: {0}\".format(f.name))\r\n                            for logger in f.loggers:\r\n                                if logger.active:\r\n                                    if logger.updated:\r\n                                        successfulLoggers = successfulLoggers + 1\r\n                                    else:\r\n                                        print(\"\\t  > Logger: {0}\".format(logger.name))\r\n    if successfulGrowers == number_of_active_growers:\r\n        print('\\t Clean run! All active growers updated successfully!')\r\n        return True\r\n    else:\r\n        return False\r\n\r\n\r\ndef set_cimis_station(field_name, cimisStation):\r\n    \"\"\"\r\n    Set the cimis station for a field\r\n\r\n    :param field_name:\r\n    :param cimisStation:\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            if field.name == field_name:\r\n                field.cimis_station = str(cimisStation)\r\n                print(\"New Cimis Station: \" + field.cimis_station)\r\n    write_pickle(growers)\r\n\r\n\r\ndef apply_ai_recommendation_to_logger(project, dataset, logger_name):\r\n    \"\"\"\r\n    Apply the AI Irrigation recommendation to a specific logger's data\r\n\r\n    :param project:\r\n    :param dataset:\r\n    :param logger_name:\r\n    \"\"\"\r\n    print(f'Grabbing data from {project} - {dataset} for logger {logger_name} - ')\r\n    dml = 'SELECT *' \\\r\n          'FROM `' + project + '.' + dataset + '.' + logger_name + '` ORDER BY date DESC'\r\n    # 'WHERE et_hours is not NULL ORDER BY date DESC'\r\n\r\n    dbwriter = DBWriter()\r\n    expertSys = IrrigationRecommendationExpert()\r\n    result = dbwriter.run_dml(dml, project=project)\r\n    applied_finals = {}\r\n    ai_results = {\"logger_id\": [], \"date\": [], \"time\": [], \"canopy_temperature\": [], \"ambient_temperature\": [],\r\n                  \"vpd\": [], \"vwc_1\": [], \"vwc_2\": [], \"vwc_3\": [], \"field_capacity\": [], \"wilting_point\": [],\r\n                  \"daily_gallons\": [], \"daily_switch\": [], \"daily_hours\": [], \"daily_pressure\": [],\r\n                  \"daily_inches\": [], \"psi\": [], \"psi_threshold\": [], \"psi_critical\": [],\r\n                  \"sdd\": [], \"rh\": [], 'eto': [], 'kc': [], 'etc': [], 'et_hours': [],\r\n                  \"phase1_adjustment\": [], \"phase1_adjusted\": [], \"phase2_adjustment\": [], \"phase2_adjusted\": [],\r\n                  \"phase3_adjustment\": [], \"phase3_adjusted\": [], \"vwc_1_ec\": [], \"vwc_2_ec\": [], \"vwc_3_ec\": [],\r\n                  \"lowest_ambient_temperature\": [], \"gdd\": [], \"crop_stage\": [], \"id\": [], \"planting_date\": [],\r\n                  \"variety\": []}\r\n\r\n    applied_finals['date'] = []\r\n    applied_finals['base'] = []\r\n    applied_finals['final_rec'] = []\r\n    applied_finals['adjustment_values'] = []\r\n    applied_finals['adjustment_steps'] = []\r\n\r\n    planting_date = None\r\n    crop_type = ''\r\n    growers = open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field.name)\r\n            if dataset in field_name:\r\n                for logger in field.loggers:\r\n                    planting_date = logger.planting_date\r\n                    crop_type = logger.crop_type\r\n\r\n    # harvest_date = result[-1][1]\r\n    harvest_date = planting_date + timedelta(days=126)\r\n    prev_et_hours = 0\r\n\r\n    for r in result:\r\n        logger_id = r[0]\r\n        date = r[1]\r\n        time = r[2]\r\n        canopy_temperature = r[3]\r\n        ambient_temperature = r[4]\r\n        vpd = r[5]\r\n        vwc_1 = r[6]\r\n        vwc_2 = r[7]\r\n        vwc_3 = r[8]\r\n        field_capacity = r[9]\r\n        wilting_point = r[10]\r\n        daily_gallons = r[11]\r\n        daily_switch = r[12]\r\n        daily_hours = r[13]\r\n        daily_pressure = r[14]\r\n        daily_inches = r[15]\r\n        psi = r[16]\r\n        psi_threshold = r[17]\r\n        psi_critical = r[18]\r\n        sdd = r[19]\r\n        rh = r[20]\r\n        eto = r[21]\r\n        kc = r[22]\r\n        etc = r[23]\r\n        et_hours = r[24]\r\n        lta = r[34]\r\n        gdd = r[35]\r\n        crop_stage = r[36]\r\n        id = r[37]\r\n        t_planting_date = r[38]\r\n        variety = r[39]\r\n\r\n        rec = expertSys.make_recommendation(\r\n            psi, field_capacity, wilting_point, vwc_1, vwc_2, vwc_3,\r\n            crop='Tomatoes', date=date, planting_date=planting_date,\r\n            harvest_date=harvest_date\r\n        )\r\n        if et_hours is None:\r\n            et_hours = prev_et_hours\r\n        applied_final, applied_steps = expertSys.apply_recommendations(et_hours, rec)\r\n\r\n        ai_results['logger_id'].append(logger_id)\r\n        ai_results['date'].append(date)\r\n        ai_results['time'].append(time)\r\n        ai_results['canopy_temperature'].append(canopy_temperature)\r\n        ai_results['ambient_temperature'].append(ambient_temperature)\r\n        ai_results['vpd'].append(vpd)\r\n        ai_results['vwc_1'].append(vwc_1)\r\n        ai_results['vwc_2'].append(vwc_2)\r\n        ai_results['vwc_3'].append(vwc_3)\r\n        ai_results['field_capacity'].append(field_capacity)\r\n        ai_results['wilting_point'].append(wilting_point)\r\n        ai_results['daily_gallons'].append(daily_gallons)\r\n        ai_results['daily_switch'].append(daily_switch)\r\n        ai_results['daily_hours'].append(daily_hours)\r\n        ai_results['daily_pressure'].append(daily_pressure)\r\n        ai_results['daily_inches'].append(daily_inches)\r\n        ai_results['psi'].append(psi)\r\n        ai_results['psi_threshold'].append(psi_threshold)\r\n        ai_results['psi_critical'].append(psi_critical)\r\n        ai_results['sdd'].append(sdd)\r\n        ai_results['rh'].append(rh)\r\n        ai_results['eto'].append(eto)\r\n        ai_results['kc'].append(kc)\r\n        ai_results['etc'].append(etc)\r\n        ai_results['et_hours'].append(et_hours)\r\n        ai_results['phase1_adjustment'].append(rec.recommendation_info[0])\r\n        ai_results['phase1_adjusted'].append(applied_steps[0])\r\n        ai_results['phase2_adjustment'].append(rec.recommendation_info[1])\r\n        ai_results['phase2_adjusted'].append(applied_steps[1])\r\n        ai_results['lowest_ambient_temperature'].append(lta)\r\n        ai_results['gdd'].append(gdd)\r\n        ai_results['crop_stage'].append(crop_stage)\r\n        ai_results['id'].append(id)\r\n        ai_results['planting_date'].append(t_planting_date)\r\n        ai_results['variety'].append(variety)\r\n\r\n        if et_hours is not None:\r\n            prev_et_hours = et_hours\r\n\r\n    print(f'Adding AI info to DB {dataset} - {logger_name} ')\r\n\r\n    filename = 'ai_data.csv'\r\n    print('\\t- writing data to csv')\r\n    with open(filename, \"w\", newline='') as outfile:\r\n        writer = csv.writer(outfile)\r\n        writer.writerow(ai_results.keys())\r\n        # Using zip_longest because dict rows are uneven length due to daily_switch algo issue\r\n        # This will add full null rows for any additional daily_switch list values\r\n        writer.writerows(zip_longest(*ai_results.values()))\r\n    # print('...Done - file: ' + filename)\r\n\r\n    schema = [\r\n        bigquery.SchemaField(\"logger_id\", \"STRING\"),\r\n        bigquery.SchemaField(\"date\", \"DATE\"),\r\n        bigquery.SchemaField(\"time\", \"STRING\"),\r\n        bigquery.SchemaField(\"canopy_temperature\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"ambient_temperature\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"vpd\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"vwc_1\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"vwc_2\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"vwc_3\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"field_capacity\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"wilting_point\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"daily_gallons\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"daily_switch\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"daily_hours\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"daily_pressure\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"daily_inches\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"psi\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"psi_threshold\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"psi_critical\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"sdd\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"rh\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"eto\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"kc\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"etc\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"et_hours\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"phase1_adjustment\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"phase1_adjusted\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"phase2_adjustment\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"phase2_adjusted\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"phase3_adjustment\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"phase3_adjusted\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"vwc_1_ec\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"vwc_2_ec\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"vwc_3_ec\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"lowest_ambient_temperature\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"gdd\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"crop_stage\", \"STRING\"),\r\n        bigquery.SchemaField(\"id\", \"STRING\"),\r\n        bigquery.SchemaField(\"planting_date\", \"DATE\"),\r\n        bigquery.SchemaField(\"variety\", \"STRING\"),\r\n    ]\r\n    # project = 'stomato-' + DIRECTORY_YEAR\r\n    project = dbwriter.get_db_project(crop_type)\r\n    dbwriter.write_to_table_from_csv(dataset, logger_name, filename, schema, project, overwrite=True)\r\n    print()\r\n\r\n    print('Fully Done')\r\n\r\n\r\ndef apply_cwsi_to_whole_table(dataset, logger_name, crop_type):\r\n    \"\"\"\r\n    Apply CWSI to a specific logger's data table in the DB\r\n\r\n    :param dataset:\r\n    :param logger_name:\r\n    :param crop_type:\r\n    \"\"\"\r\n    dbwriter = DBWriter()\r\n    project = dbwriter.get_db_project(crop_type)\r\n    print(f'Grabbing data from {project} - {dataset} for logger {logger_name} - ')\r\n    dml = 'SELECT *' \\\r\n          'FROM `' + project + '.' + dataset + '.' + logger_name + '` ' \\\r\n                                                                   'WHERE et_hours is not NULL ORDER BY date DESC'\r\n\r\n    cwsi_processor = CwsiProcessor()\r\n    result = dbwriter.run_dml(dml, project=project)\r\n    modified_data = {\"logger_id\": [], \"date\": [], \"time\": [], \"canopy_temperature\": [], \"ambient_temperature\": [],\r\n                     \"vpd\": [], \"vwc_1\": [], \"vwc_2\": [], \"vwc_3\": [], \"field_capacity\": [], \"wilting_point\": [],\r\n                     \"daily_gallons\": [], \"daily_switch\": [], \"daily_hours\": [], \"daily_pressure\": [],\r\n                     \"daily_inches\": [], \"psi\": [], \"psi_threshold\": [], \"psi_critical\": [],\r\n                     \"sdd\": [], \"rh\": [], 'eto': [], 'kc': [], 'etc': [], 'et_hours': [],\r\n                     \"phase1_adjustment\": [], \"phase1_adjusted\": [], \"phase2_adjustment\": [], \"phase2_adjusted\": [],\r\n                     \"phase3_adjustment\": [], \"phase3_adjusted\": [], \"vwc_1_ec\": [], \"vwc_2_ec\": [], \"vwc_3_ec\": []}\r\n\r\n    for r in result:\r\n        logger_name = r[0]\r\n        date = r[1]\r\n        time = r[2]\r\n        canopy_temperature = r[3]\r\n        ambient_temperature = r[4]\r\n        vpd = r[5]\r\n        vwc_1 = r[6]\r\n        vwc_2 = r[7]\r\n        vwc_3 = r[8]\r\n        field_capacity = r[9]\r\n        wilting_point = r[10]\r\n        daily_gallons = r[11]\r\n        daily_switch = r[12]\r\n        daily_hours = r[13]\r\n        daily_pressure = r[14]\r\n        daily_inches = r[15]\r\n        sdd = r[19]\r\n        rh = r[20]\r\n        eto = r[21]\r\n        kc = r[22]\r\n        etc = r[23]\r\n        et_hours = r[24]\r\n\r\n        # def get_cwsi(self, tc, vpd, ta, cropType, rh=0, return_negative=False):\r\n        psi = cwsi_processor.get_cwsi(canopy_temperature, vpd, ambient_temperature, crop_type)\r\n        psi_threshold = 0.5\r\n        psi_critical = 1\r\n\r\n        modified_data['logger_id'].append(logger_name)\r\n        modified_data['date'].append(date)\r\n        modified_data['time'].append(time)\r\n        modified_data['canopy_temperature'].append(canopy_temperature)\r\n        modified_data['ambient_temperature'].append(ambient_temperature)\r\n        modified_data['vpd'].append(vpd)\r\n        modified_data['vwc_1'].append(vwc_1)\r\n        modified_data['vwc_2'].append(vwc_2)\r\n        modified_data['vwc_3'].append(vwc_3)\r\n        modified_data['field_capacity'].append(field_capacity)\r\n        modified_data['wilting_point'].append(wilting_point)\r\n        modified_data['daily_gallons'].append(daily_gallons)\r\n        modified_data['daily_switch'].append(daily_switch)\r\n        modified_data['daily_hours'].append(daily_hours)\r\n        modified_data['daily_pressure'].append(daily_pressure)\r\n        modified_data['daily_inches'].append(daily_inches)\r\n        modified_data['psi'].append(psi)\r\n        modified_data['psi_threshold'].append(psi_threshold)\r\n        modified_data['psi_critical'].append(psi_critical)\r\n        modified_data['sdd'].append(sdd)\r\n        modified_data['rh'].append(rh)\r\n        modified_data['eto'].append(eto)\r\n        modified_data['kc'].append(kc)\r\n        modified_data['etc'].append(etc)\r\n        modified_data['et_hours'].append(et_hours)\r\n        modified_data['phase1_adjustment'].append(None)\r\n        modified_data['phase1_adjusted'].append(None)\r\n        modified_data['phase2_adjustment'].append(None)\r\n        modified_data['phase2_adjusted'].append(None)\r\n        modified_data['phase3_adjustment'].append(None)\r\n        modified_data['phase3_adjusted'].append(None)\r\n        modified_data['vwc_1_ec'].append(None)\r\n        modified_data['vwc_2_ec'].append(None)\r\n        modified_data['vwc_3_ec'].append(None)\r\n\r\n    print(f'Adding PSI modified info to DB {dataset} - {logger_name}')\r\n\r\n    filename = 'psi_modified_data.csv'\r\n    print('\\t- writing data to csv')\r\n    with open(filename, \"w\", newline='') as outfile:\r\n        writer = csv.writer(outfile)\r\n        writer.writerow(modified_data.keys())\r\n        # Using zip_longest because dict rows are uneven length due to daily_switch algo issue\r\n        # This will add full null rows for any additional daily_switch list values\r\n        writer.writerows(zip_longest(*modified_data.values()))\r\n    # print('...Done - file: ' + filename)\r\n\r\n    schema = [\r\n        bigquery.SchemaField(\"logger_id\", \"STRING\"),\r\n        bigquery.SchemaField(\"date\", \"DATE\"),\r\n        bigquery.SchemaField(\"time\", \"STRING\"),\r\n        bigquery.SchemaField(\"canopy_temperature\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"ambient_temperature\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"vpd\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"vwc_1\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"vwc_2\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"vwc_3\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"field_capacity\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"wilting_point\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"daily_gallons\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"daily_switch\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"daily_hours\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"daily_pressure\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"daily_inches\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"psi\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"psi_threshold\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"psi_critical\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"sdd\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"rh\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"eto\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"kc\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"etc\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"et_hours\", \"FLOAT\"),\r\n        bigquery.SchemaField('phase1_adjustment', 'FLOAT'),\r\n        bigquery.SchemaField('phase1_adjusted', 'FLOAT'),\r\n        bigquery.SchemaField('phase2_adjustment', 'FLOAT'),\r\n        bigquery.SchemaField('phase2_adjusted', 'FLOAT'),\r\n        bigquery.SchemaField('phase3_adjustment', 'FLOAT'),\r\n        bigquery.SchemaField('phase3_adjusted', 'FLOAT'),\r\n        bigquery.SchemaField('vwc_1_ec', 'FLOAT'),\r\n        bigquery.SchemaField('vwc_2_ec', 'FLOAT'),\r\n        bigquery.SchemaField('vwc_3_ec', 'FLOAT'),\r\n    ]\r\n    # project = 'stomato-' + DATABASE_YEAR\r\n    project = dbwriter.get_db_project(crop_type)\r\n    dbwriter.write_to_table_from_csv(dataset, logger_name, filename, schema, project, overwrite=True)\r\n    print()\r\n\r\n    print('Fully Done')\r\n\r\n\r\ndef get_crop_stage(data_point_date, harvest_date, planting_date):\r\n    \"\"\"\r\n    Method to get the crop stage for the artificial intelligence irrigation system\r\n     for a tomato crop based on current date, harvest date,\r\n     and planting date. Grabs total crop days and divides that by 4 to get a chunk.\r\n     Chunk 1 is stage 1, chunk 2 is stage 2, and chunk 3 + 4 is stage 3.\r\n\r\n    :param data_point_date:\r\n    :param harvest_date:\r\n    :param planting_date:\r\n    :return:\r\n    \"\"\"\r\n    crop_stage = None\r\n    if harvest_date is not None and planting_date is not None:\r\n        delta = harvest_date - planting_date\r\n        total_crop_days = delta.days\r\n\r\n        one_fourth_chunk = total_crop_days // 4\r\n\r\n        stage_one_start = planting_date\r\n        stage_one_end = planting_date + timedelta(days=one_fourth_chunk)\r\n        stage_two_start = stage_one_end\r\n        stage_two_end = stage_one_end + timedelta(days=one_fourth_chunk * 2)\r\n        stage_three_start = stage_two_end\r\n        stage_three_end = harvest_date\r\n\r\n        print('Stage 1 Start: {}'.format(stage_one_start))\r\n        print('Stage 1 End: {}'.format(stage_one_end))\r\n        print('Stage 2 Start: {}'.format(stage_two_start))\r\n        print('Stage 2 End: {}'.format(stage_two_end))\r\n        print('Stage 3 Start: {}'.format(stage_three_start))\r\n        print('Stage 3 End: {}'.format(stage_three_end))\r\n\r\n        # if stage_one_start <= date <= stage_one_end:\r\n        if data_point_date <= stage_one_end:\r\n            crop_stage = 'Stage 1'\r\n        elif stage_two_start <= data_point_date < stage_two_end:\r\n            crop_stage = 'Stage 2'\r\n        elif stage_three_start <= data_point_date:\r\n            crop_stage = 'Stage 3'\r\n\r\n        print('Crop Stage: {}'.format(crop_stage))\r\n    return crop_stage\r\n\r\n\r\ndef reassign_technician(old_technician_name: str, new_technician_name: str):\r\n    \"\"\"\r\n    Change all growers with a technician to a different technician. Takes in the old technician name and the new \r\n    technician name and pulls up all growers that have the old technician. Then it looks for a technician with the \r\n    new technician name and if it finds one it uses that technician as the new technician for the growers \r\n\r\n    :param old_technician_name:\r\n    :param new_technician_name:\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    all_technicians = get_all_technicians(growers)\r\n    new_technician = None\r\n    for tech in all_technicians:\r\n        if tech.name == new_technician_name:\r\n            new_technician = tech\r\n    for g in growers:\r\n        if g.technician.name == old_technician_name:\r\n            print(\r\n                'Changing Technician for Grower {} \\n from {} to {}'.format(\r\n                    g.name, old_technician_name,\r\n                    new_technician_name\r\n                )\r\n            )\r\n            g.technician = new_technician\r\n    write_pickle(growers)\r\n\r\n\r\ndef deactivate_growers_with_all_inactive_fields():\r\n    \"\"\"\r\n    Method to check if all of a growers fields are inactive and if they are set the grower itself as inactive\r\n\r\n    :return: None\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    all_fields_inactive = True\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.active:\r\n                all_fields_inactive = False\r\n        if all_fields_inactive:\r\n            g.deactivate()\r\n        all_fields_inactive = True\r\n    # for g in growers:\r\n    #     if not g.active:\r\n    #         g.to_string()\r\n    write_pickle(growers)\r\n\r\n\r\ndef remove_inactive_growers_from_pickle():\r\n    \"\"\"\r\n    Method that goes through the current pickle, picks out active growers, and overwrites the current pickle\r\n    only with these active growers. There is a confirmation dialog to make sure we want to run this and a\r\n    pickle backup is also created before overwriting it.\r\n    \"\"\"\r\n    new_growers = []\r\n    growers = open_pickle()\r\n    print('Removing inactive growers from pickle will overwrite current pickle only leaving active growers')\r\n    confirm = input('Are you sure you want to do this? (Y/N) ').lower().strip()\r\n\r\n    if confirm[:1] == 'y':\r\n        backup_pickle('before_removing_inactive')\r\n        for grower in growers:\r\n            if grower.active:\r\n                print('Transferring > ', grower.name)\r\n                new_growers.append(grower)\r\n            else:\r\n                print('Not Transferring >', grower.name)\r\n        write_pickle(new_growers)\r\n\r\n\r\ndef remove_inactive_fields_from_growers_from_pickle():\r\n    \"\"\"\r\n    Method that goes through the current pickle, picks out active growers, and overwrites the current pickle\r\n    only with these active growers. There is a confirmation dialog to make sure we want to run this and a\r\n    pickle backup is also created before overwriting it.\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    print('Removing inactive fields from pickle will overwrite current pickle only leaving active fields')\r\n    confirm = input('Are you sure you want to do this? (Y/N) ').lower().strip()\r\n\r\n    if confirm[:1] == 'y':\r\n        backup_pickle('before_removing_inactive_fields')\r\n        for grower in growers:\r\n            if grower.active:\r\n                active_fields = []\r\n                for field in grower.fields:\r\n                    if field.active:\r\n                        active_fields.append(field)\r\n                    else:\r\n                        print(f'Removing {field.nickname} from {grower.name}')\r\n                grower.fields = active_fields\r\n        write_pickle(growers)\r\n\r\n\r\ndef new_year_pickle_cleanup():\r\n    \"\"\"\r\n    Convenience method to chain a couple of methods together. This should be run when we are ready to setup\r\n    a pickle for the new year. This will first deactivate growers that have all their fields inactive and\r\n    will then remove these growers from the current pickle\r\n    \"\"\"\r\n    deactivate_growers_with_all_inactive_fields()\r\n    remove_inactive_growers_from_pickle()\r\n\r\n\r\ndef get_technician(technician_name: str):\r\n    \"\"\"\r\n    Grab the technician object for a technician with technician_name\r\n\r\n    :param technician_name:\r\n    :return:\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    technicians = get_all_technicians(growers)\r\n    for technician in technicians:\r\n        if technician.name == technician_name:\r\n            print('Got Technician = ', technician_name, technician)\r\n            return technician\r\n    print(\"Technician - \", technician_name, ' - not found')\r\n    return None\r\n\r\n\r\ndef check_technician_clones():\r\n    growers = open_pickle()\r\n    tech_dict = {'Vanessa': [], 'Exsaelth': [], 'Adriana': [], 'Development Test Tech': []}\r\n    for grower in growers:\r\n        # print(grower.name, ' - ', grower.technician.name, ' - ', id(grower.technician))\r\n        if id(grower.technician) not in tech_dict[grower.technician.name]:\r\n            tech_dict[grower.technician.name].append(id(grower.technician))\r\n    for key, values in tech_dict.items():\r\n        print(key, \" : \", values)\r\n\r\n\r\ndef temp_ai_application():\r\n    # AI Logger\r\n    apply_ai_recommendation_to_logger('stomato-2023', 'Lucero_Dillard_RoadD3', 'DI-D3-SE')\r\n\r\n    # Old Control\r\n    # apply_ai_recommendation_to_logger('stomato-2023', 'Lucero_Dillard_RoadD3', 'DI-D3-NW')\r\n\r\n    # New Control\r\n    apply_ai_recommendation_to_logger('stomato-2023', 'Lucero_Dillard_RoadD4', 'DI-D4-W')\r\n\r\n\r\ndef check_for_new_cimis_stations():\r\n    cimisStationsPickle = CimisStation.open_cimis_station_pickle(CimisStation)\r\n    cimisStationList = []\r\n    for stations in cimisStationsPickle:\r\n        cimisStationList.append(stations.station_number)\r\n    growers = open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.cimis_station not in cimisStationList:\r\n                cimisStationList.append(f.cimis_station)\r\n                print(\"Adding Cimis Station: \", f.cimis_station, \" to pickle\")\r\n                x = input(\"ET for \" + f.cimis_station + \"\\n\")\r\n                cimisStation = CimisStation(f.cimis_station, float(x))\r\n                cimisStationsPickle.append(cimisStation)\r\n    CimisStation.write_cimis_station_pickle(CimisStation, cimisStationsPickle)\r\n\r\n\r\ndef write_uninstallation_progress_to_db():\r\n    dbwriter = DBWriter()\r\n    schema = [\r\n        bigquery.SchemaField(\"Grower\", \"STRING\"),\r\n        bigquery.SchemaField(\"Field\", \"STRING\"),\r\n        bigquery.SchemaField(\"Uninstalled_Date\", \"DATE\"),\r\n        bigquery.SchemaField(\"Acres\", \"FLOAT\"),\r\n        bigquery.SchemaField(\"Region\", \"STRING\"),\r\n        bigquery.SchemaField(\"Latt_Long\", \"STRING\")\r\n    ]\r\n    uninstallDictNorth = {\"Grower\": [], \"Field\": [], \"Uninstalled_Date\": [], \"Acres\": [], \"Region\": [], \"Latt_Long\": []}\r\n    uninstallDictSouth = {\"Grower\": [], \"Field\": [], \"Uninstalled_Date\": [], \"Acres\": [], \"Region\": [], \"Latt_Long\": []}\r\n\r\n    growers = open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if g.region == 'North' and f.loggers[-1].crop_type == \"Tomatoes\":\r\n                uninstallDictNorth[\"Grower\"].append(g.name)\r\n                uninstallDictNorth[\"Field\"].append(f.nickname)\r\n                lat_long = str(f.loggers[-1].lat) + \",\" + str(f.loggers[-1].long)\r\n                uninstallDictNorth[\"Latt_Long\"].append(str(lat_long))\r\n            elif g.region == \"South\" and f.loggers[-1].crop_type == \"Tomatoes\":\r\n                uninstallDictSouth[\"Grower\"].append(g.name)\r\n                uninstallDictSouth[\"Field\"].append(f.nickname)\r\n                lat_long = str(f.loggers[-1].lat) + \",\" + str(f.loggers[-1].long)\r\n                uninstallDictSouth[\"Latt_Long\"].append(str(lat_long))\r\n\r\n    print(uninstallDictNorth)\r\n    print(uninstallDictSouth)\r\n\r\n    with open('uninstallation.csv', \"w\", newline='') as outfile:\r\n        writer = csv.writer(outfile)\r\n        writer.writerow(uninstallDictNorth.keys())\r\n        # Using zip_longest because dict rows are uneven length due to daily_switch algo issue\r\n        # This will add full null rows for any additional daily_switch list values\r\n        writer.writerows(zip_longest(*uninstallDictNorth.values()))\r\n    project = 'stomato-info'\r\n    dbwriter.write_to_table_from_csv(\r\n        '1_uninstallation_progress', 'North', 'uninstallation.csv', schema, project\r\n    )\r\n\r\n    with open('uninstallation.csv', \"w\", newline='') as outfile:\r\n        writer = csv.writer(outfile)\r\n        writer.writerow(uninstallDictSouth.keys())\r\n        # Using zip_longest because dict rows are uneven length due to daily_switch algo issue\r\n        # This will add full null rows for any additional daily_switch list values\r\n        writer.writerows(zip_longest(*uninstallDictSouth.values()))\r\n\r\n    dbwriter.write_to_table_from_csv(\r\n        '1_uninstallation_progress', 'South', 'uninstallation.csv', schema, project\r\n    )\r\n\r\n\r\ndef setup_ai_game_data(\r\n        grower_pickle_file_name: str,\r\n        grower_pickle_file_path: str,\r\n        ai_game_pickle_file_name: str,\r\n        ai_game_pickle_file_path: str\r\n):\r\n    ai_game_data = AIGameData()\r\n    dbw = DBWriter()\r\n    tomato_crop = False\r\n    growers = open_pickle(filename=grower_pickle_file_name, specific_file_path=grower_pickle_file_path)\r\n\r\n    for grower in growers:\r\n        if grower.region == 'South':\r\n            for field in grower.fields:\r\n                if field.crop_type in ['Tomatoes', 'tomatoes', 'Tomato', 'tomato'] and field.field_type != 'R&D':\r\n                    for logger in field.loggers:\r\n                        print(f'Adding {logger.field.name} - {logger.name}')\r\n                        ai_game_data.south_pool.append(logger)\r\n                        ai_game_data.all_pool.append(logger)\r\n        elif grower.region == 'North':\r\n            for field in grower.fields:\r\n                if field.crop_type in ['Tomatoes', 'tomatoes', 'Tomato', 'tomato'] and field.field_type != 'R&D':\r\n                    for logger in field.loggers:\r\n                        print(f'Adding {logger.field.name} - {logger.name}')\r\n                        ai_game_data.north_pool.append(logger)\r\n                        ai_game_data.all_pool.append(logger)\r\n    ai_game_data.show_content()\r\n    # print('Total Data Points: {}'.format(ai_game_data.number_of_data_points()))\r\n    # #\r\n    if path.exists(ai_game_pickle_file_path):\r\n        with open(ai_game_pickle_file_path + ai_game_pickle_file_name, 'wb') as f:\r\n            pickle.dump(ai_game_data, f)\r\n\r\n\r\ndef test_switch_cases():\r\n    \"\"\"\r\n    Method to set up and loop through all switch test cases and record results.\r\n\r\n    \"\"\"\r\n\r\n    # Setup test cases\r\n    test_cases = []\r\n\r\n    standard_data = {\r\n        'dates': [datetime(2022, 6, 12, 0, 0), datetime(2022, 6, 12, 1, 0),\r\n                               datetime(2022, 6, 12, 2, 0), datetime(2022, 6, 12, 3, 0),\r\n                               datetime(2022, 6, 12, 4, 0), datetime(2022, 6, 12, 5, 0),\r\n                               datetime(2022, 6, 12, 6, 0), datetime(2022, 6, 12, 7, 0),\r\n                               datetime(2022, 6, 12, 8, 0), datetime(2022, 6, 12, 9, 0),\r\n                               datetime(2022, 6, 12, 10, 0), datetime(2022, 6, 12, 11, 0),\r\n                               datetime(2022, 6, 12, 12, 0), datetime(2022, 6, 12, 13, 0),\r\n                               datetime(2022, 6, 12, 14, 0), datetime(2022, 6, 12, 15, 0),\r\n                               datetime(2022, 6, 12, 16, 0), datetime(2022, 6, 12, 17, 0),\r\n                               datetime(2022, 6, 12, 18, 0), datetime(2022, 6, 12, 19, 0),\r\n                               datetime(2022, 6, 12, 20, 0), datetime(2022, 6, 12, 21, 0),\r\n                               datetime(2022, 6, 12, 22, 0), datetime(2022, 6, 12, 23, 0),\r\n                               datetime(2022, 6, 13, 0, 0), datetime(2022, 6, 13, 1, 0)],\r\n                     'canopy temperature': [76, 77, 88, 93, 78, 76, 88, 83, 76, 89, 79, 93, 84, 80, 81, 94, 85, 78, 80,\r\n                                            94, 89, 87, 76, 82, 93, 89],\r\n                     'ambient temperature': [93, 79, 103, 89, 94, 84, 102, 77, 96, 84, 95, 79, 77, 97, 74, 73, 88, 100,\r\n                                             82, 81, 96, 78, 93, 89, 94, 85],\r\n                     'rh': [31, 56, 46, 15, 15, 41, 39, 21, 16, 43, 34, 16, 55, 29, 33, 51, 28, 54, 23, 32, 58, 42, 24,\r\n                            59, 50, 58],\r\n                     'vpd': [2, 2, 2, 4, 5, 2, 5, 3, 1, 3, 0, 5, 3, 0, 2, 2, 0, 4, 2, 5, 1, 3, 1, 5, 2, 2],\r\n                     'vwc_1': [34, 22, 33, 23, 24, 21, 26, 31, 33, 22, 38, 35, 36, 30, 40, 23, 34, 36, 32, 35, 41, 33,\r\n                               39, 27, 36, 39],\r\n                     'vwc_2': [43, 35, 20, 41, 35, 35, 25, 42, 40, 35, 30, 41, 32, 20, 29, 32, 40, 26, 25, 42, 38, 31,\r\n                               29, 38, 40, 35],\r\n                     'vwc_3': [20, 25, 39, 20, 34, 32, 25, 39, 23, 31, 22, 25, 42, 26, 25, 21, 31, 42, 42, 37, 23, 42,\r\n                               33, 20, 34, 35], 'vwc_1_ec': [], 'vwc_2_ec': [], 'vwc_3_ec': [], 'daily gallons': [],\r\n                     'daily switch': [0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\r\n                                      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\r\n\r\n    standard_data_2023 = {\r\n        'dates': [datetime(2023, 3, 15, 0, 0, 15, 512237), datetime(2023, 3, 15, 1, 0, 15, 512237),\r\n                  datetime(2023, 3, 15, 2, 0, 15, 512237), datetime(2023, 3, 15, 3, 0, 15, 512237),\r\n                  datetime(2023, 3, 15, 4, 0, 15, 512237), datetime(2023, 3, 15, 5, 0, 15, 512237),\r\n                  datetime(2023, 3, 15, 6, 0, 15, 512237), datetime(2023, 3, 15, 7, 0, 15, 512237),\r\n                  datetime(2023, 3, 15, 8, 0, 15, 512237), datetime(2023, 3, 15, 9, 0, 15, 512237),\r\n                  datetime(2023, 3, 15, 10, 0, 15, 512237), datetime(2023, 3, 15, 11, 0, 15, 512237),\r\n                  datetime(2023, 3, 15, 12, 0, 15, 512237), datetime(2023, 3, 15, 13, 0, 15, 512237),\r\n                  datetime(2023, 3, 15, 14, 0, 15, 512237), datetime(2023, 3, 15, 15, 0, 15, 512237),\r\n                  datetime(2023, 3, 15, 16, 0, 15, 512237), datetime(2023, 3, 15, 17, 0, 15, 512237),\r\n                  datetime(2023, 3, 15, 18, 0, 15, 512237), datetime(2023, 3, 15, 19, 0, 15, 512237),\r\n                  datetime(2023, 3, 15, 20, 0, 15, 512237), datetime(2023, 3, 15, 21, 0, 15, 512237),\r\n                  datetime(2023, 3, 15, 22, 0, 15, 512237), datetime(2023, 3, 15, 23, 0, 15, 512237),\r\n                  datetime(2023, 3, 16, 0, 0, 15, 512237), datetime(2023, 3, 16, 1, 0, 15, 512237)],\r\n        'canopy temperature': [90, 83, 93, 91, 94, 93, 81, 78, 90, 76, 92, 94, 88, 77, 91, 86, 84, 90, 94, 86, 85, 85,\r\n                               77, 85, 84, 76],\r\n        'ambient temperature': [104, 74, 76, 100, 99, 83, 92, 101, 81, 77, 76, 78, 82, 90, 96, 101, 100, 92, 89, 84, 97,\r\n                                74, 98, 99, 93, 77],\r\n        'rh': [52, 51, 40, 36, 42, 20, 16, 27, 29, 25, 20, 29, 35, 50, 47, 15, 39, 52, 52, 50, 52, 38, 56, 38, 31, 50],\r\n        'vpd': [4, 1, 0, 1, 3, 2, 5, 2, 4, 1, 5, 5, 1, 1, 4, 5, 0, 1, 4, 3, 2, 4, 0, 5, 0, 4],\r\n        'vwc_1': [38, 24, 41, 34, 30, 29, 41, 26, 23, 34, 27, 38, 31, 40, 39, 41, 30, 44, 39, 31, 31, 29, 23, 23, 29,\r\n                  38],\r\n        'vwc_2': [20, 25, 23, 24, 21, 22, 43, 38, 20, 30, 24, 40, 32, 42, 31, 42, 24, 33, 20, 36, 41, 36, 28, 22, 24,\r\n                  35],\r\n        'vwc_3': [27, 27, 20, 38, 34, 43, 20, 44, 27, 37, 27, 24, 34, 43, 26, 23, 36, 21, 26, 36, 32, 42, 38, 23, 41,\r\n                  29], 'vwc_1_ec': [], 'vwc_2_ec': [], 'vwc_3_ec': [], 'daily gallons': [],\r\n        'daily switch': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60, 60, 60, 60, 60, 60, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\r\n                         0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\r\n\r\n    half_and_half = {\r\n        'dates': [datetime(2023, 3, 15, 12, 0, 8, 544470), datetime(2023, 3, 15, 13, 0, 8, 544470),\r\n                  datetime(2023, 3, 15, 14, 0, 8, 544470), datetime(2023, 3, 15, 15, 0, 8, 544470),\r\n                  datetime(2023, 3, 15, 16, 0, 8, 544470), datetime(2023, 3, 15, 17, 0, 8, 544470),\r\n                  datetime(2023, 3, 15, 18, 0, 8, 544470), datetime(2023, 3, 15, 19, 0, 8, 544470),\r\n                  datetime(2023, 3, 15, 20, 0, 8, 544470), datetime(2023, 3, 15, 21, 0, 8, 544470),\r\n                  datetime(2023, 3, 15, 22, 0, 8, 544470), datetime(2023, 3, 15, 23, 0, 8, 544470),\r\n                  datetime(2023, 3, 16, 0, 0, 8, 544470), datetime(2023, 3, 16, 1, 0, 8, 544470),\r\n                  datetime(2023, 3, 16, 2, 0, 8, 544470), datetime(2023, 3, 16, 3, 0, 8, 544470),\r\n                  datetime(2023, 3, 16, 4, 0, 8, 544470), datetime(2023, 3, 16, 5, 0, 8, 544470),\r\n                  datetime(2023, 3, 16, 6, 0, 8, 544470), datetime(2023, 3, 16, 7, 0, 8, 544470),\r\n                  datetime(2023, 3, 16, 8, 0, 8, 544470), datetime(2023, 3, 16, 9, 0, 8, 544470),\r\n                  datetime(2023, 3, 16, 10, 0, 8, 544470), datetime(2023, 3, 16, 11, 0, 8, 544470),\r\n                  datetime(2023, 3, 16, 12, 0, 8, 544470)],\r\n        'canopy temperature': [76, 76, 78, 88, 78, 90, 78, 91, 82, 83, 82, 91, 93, 80, 93, 90, 83, 78, 82, 79, 89, 87,\r\n                               88, 81, 80],\r\n        'ambient temperature': [90, 103, 85, 103, 88, 76, 86, 103, 88, 75, 98, 89, 74, 93, 74, 103, 91, 95, 100, 100,\r\n                                78, 95, 79, 81, 95],\r\n        'rh': [23, 37, 27, 31, 59, 37, 21, 43, 42, 31, 32, 19, 38, 54, 20, 48, 57, 42, 45, 59, 17, 44, 48, 51, 32],\r\n        'vpd': [4, 3, 1, 3, 1, 4, 1, 5, 3, 5, 4, 3, 0, 3, 4, 4, 5, 4, 1, 2, 2, 0, 3, 3, 3],\r\n        'vwc_1': [39, 23, 20, 20, 42, 43, 28, 40, 39, 25, 41, 28, 41, 29, 37, 25, 38, 30, 28, 21, 43, 37, 20, 36, 44],\r\n        'vwc_2': [21, 42, 25, 32, 38, 31, 22, 39, 24, 28, 44, 25, 31, 29, 33, 23, 38, 38, 38, 24, 30, 24, 42, 44, 20],\r\n        'vwc_3': [40, 33, 25, 30, 40, 26, 23, 23, 41, 44, 36, 29, 40, 23, 43, 43, 25, 24, 28, 37, 20, 31, 20, 39, 25],\r\n        'vwc_1_ec': [], 'vwc_2_ec': [], 'vwc_3_ec': [], 'daily gallons': [],\r\n        'daily switch': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 0.0, 0.0, 0.0, 0.0, 0.0,\r\n                         0.0, 0.0, 0.0, 0.0]}\r\n\r\n    multiple_days = {\r\n        'dates': [datetime(2023, 3, 14, 0, 0, 36, 783492), datetime(2023, 3, 14, 1, 0, 36, 783492),\r\n                  datetime(2023, 3, 14, 2, 0, 36, 783492), datetime(2023, 3, 14, 3, 0, 36, 783492),\r\n                  datetime(2023, 3, 14, 4, 0, 36, 783492), datetime(2023, 3, 14, 5, 0, 36, 783492),\r\n                  datetime(2023, 3, 14, 6, 0, 36, 783492), datetime(2023, 3, 14, 7, 0, 36, 783492),\r\n                  datetime(2023, 3, 14, 8, 0, 36, 783492), datetime(2023, 3, 14, 9, 0, 36, 783492),\r\n                  datetime(2023, 3, 14, 10, 0, 36, 783492), datetime(2023, 3, 14, 11, 0, 36, 783492),\r\n                  datetime(2023, 3, 14, 12, 0, 36, 783492), datetime(2023, 3, 14, 13, 0, 36, 783492),\r\n                  datetime(2023, 3, 14, 14, 0, 36, 783492), datetime(2023, 3, 14, 15, 0, 36, 783492),\r\n                  datetime(2023, 3, 14, 16, 0, 36, 783492), datetime(2023, 3, 14, 17, 0, 36, 783492),\r\n                  datetime(2023, 3, 14, 18, 0, 36, 783492), datetime(2023, 3, 14, 19, 0, 36, 783492),\r\n                  datetime(2023, 3, 14, 20, 0, 36, 783492), datetime(2023, 3, 14, 21, 0, 36, 783492),\r\n                  datetime(2023, 3, 14, 22, 0, 36, 783492), datetime(2023, 3, 14, 23, 0, 36, 783492),\r\n                  datetime(2023, 3, 15, 0, 0, 36, 783492), datetime(2023, 3, 15, 1, 0, 36, 783492),\r\n                  datetime(2023, 3, 15, 2, 0, 36, 783492), datetime(2023, 3, 15, 3, 0, 36, 783492),\r\n                  datetime(2023, 3, 15, 4, 0, 36, 783492), datetime(2023, 3, 15, 5, 0, 36, 783492),\r\n                  datetime(2023, 3, 15, 6, 0, 36, 783492), datetime(2023, 3, 15, 7, 0, 36, 783492),\r\n                  datetime(2023, 3, 15, 8, 0, 36, 783492), datetime(2023, 3, 15, 9, 0, 36, 783492),\r\n                  datetime(2023, 3, 15, 10, 0, 36, 783492), datetime(2023, 3, 15, 11, 0, 36, 783492),\r\n                  datetime(2023, 3, 15, 12, 0, 36, 783492), datetime(2023, 3, 15, 13, 0, 36, 783492),\r\n                  datetime(2023, 3, 15, 14, 0, 36, 783492), datetime(2023, 3, 15, 15, 0, 36, 783492),\r\n                  datetime(2023, 3, 15, 16, 0, 36, 783492), datetime(2023, 3, 15, 17, 0, 36, 783492),\r\n                  datetime(2023, 3, 15, 18, 0, 36, 783492), datetime(2023, 3, 15, 19, 0, 36, 783492),\r\n                  datetime(2023, 3, 15, 20, 0, 36, 783492), datetime(2023, 3, 15, 21, 0, 36, 783492),\r\n                  datetime(2023, 3, 15, 22, 0, 36, 783492), datetime(2023, 3, 15, 23, 0, 36, 783492),\r\n                  datetime(2023, 3, 16, 0, 0, 36, 783492), datetime(2023, 3, 16, 1, 0, 36, 783492)],\r\n        'canopy temperature': [90, 92, 88, 90, 76, 94, 80, 76, 94, 88, 91, 86, 92, 84, 79, 90, 89, 83, 88, 93, 85, 82,\r\n                               94, 76, 93, 76, 89, 81, 83, 80, 82, 86, 78, 84, 89, 76, 93, 79, 76, 89, 92, 79, 82, 83,\r\n                               84, 93, 88, 78, 94, 84],\r\n        'ambient temperature': [101, 76, 75, 87, 81, 85, 99, 101, 99, 101, 97, 97, 90, 89, 91, 98, 89, 76, 87, 77, 87,\r\n                                96, 97, 96, 90, 82, 99, 84, 90, 77, 76, 84, 95, 93, 72, 73, 84, 77, 77, 99, 77, 93, 80,\r\n                                78, 87, 93, 80, 103, 90, 88],\r\n        'rh': [57, 24, 39, 34, 46, 59, 19, 21, 57, 41, 17, 25, 45, 38, 15, 38, 42, 34, 25, 31, 51, 35, 16, 32, 31, 36,\r\n               50, 48, 27, 38, 51, 41, 21, 24, 31, 45, 17, 34, 28, 16, 22, 35, 24, 19, 24, 23, 46, 49, 18, 20],\r\n        'vpd': [5, 0, 5, 1, 1, 2, 4, 1, 4, 5, 2, 4, 5, 5, 4, 0, 5, 2, 3, 2, 1, 4, 4, 1, 0, 3, 2, 1, 4, 3, 4, 5, 0, 3, 4,\r\n                3, 1, 2, 3, 2, 5, 5, 3, 1, 4, 5, 3, 1, 0, 0],\r\n        'vwc_1': [29, 26, 32, 39, 37, 34, 26, 25, 25, 29, 24, 39, 26, 38, 37, 26, 26, 22, 29, 34, 43, 33, 33, 26, 28,\r\n                  31, 36, 22, 25, 44, 43, 20, 31, 22, 23, 22, 43, 39, 21, 34, 40, 43, 24, 36, 22, 24, 36, 21, 30, 34],\r\n        'vwc_2': [26, 33, 21, 38, 20, 20, 24, 33, 32, 30, 25, 26, 24, 21, 31, 31, 30, 28, 31, 32, 23, 38, 31, 35, 30,\r\n                  21, 36, 37, 29, 29, 33, 43, 36, 29, 23, 35, 29, 23, 39, 31, 36, 25, 20, 37, 41, 36, 37, 28, 36, 38],\r\n        'vwc_3': [22, 27, 44, 32, 42, 38, 42, 43, 31, 28, 40, 29, 41, 40, 33, 22, 27, 32, 35, 39, 24, 38, 21, 30, 44,\r\n                  28, 26, 29, 34, 38, 26, 21, 39, 37, 21, 43, 41, 33, 28, 22, 25, 26, 28, 34, 25, 30, 41, 25, 44, 38],\r\n        'vwc_1_ec': [], 'vwc_2_ec': [], 'vwc_3_ec': [], 'daily gallons': [],\r\n        'daily switch': [0.0, 0.0, 60, 60, 60, 60, 60, 60, 60, 60, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\r\n                         0.0, 0.0, 60, 60, 60, 60, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\r\n                         0.0, 0.0, 0.0, 0.0, 0.0, 60, 60, 60, 60, 0.0]}\r\n\r\n    small_edges = {\r\n        'dates': [datetime(2023, 3, 15, 23, 0, 39, 744241), datetime(2023, 3, 16, 0, 0, 39, 744241),\r\n                  datetime(2023, 3, 16, 1, 0, 39, 744241), datetime(2023, 3, 16, 2, 0, 39, 744241),\r\n                  datetime(2023, 3, 16, 3, 0, 39, 744241), datetime(2023, 3, 16, 4, 0, 39, 744241),\r\n                  datetime(2023, 3, 16, 5, 0, 39, 744241), datetime(2023, 3, 16, 6, 0, 39, 744241),\r\n                  datetime(2023, 3, 16, 7, 0, 39, 744241), datetime(2023, 3, 16, 8, 0, 39, 744241),\r\n                  datetime(2023, 3, 16, 9, 0, 39, 744241), datetime(2023, 3, 16, 10, 0, 39, 744241),\r\n                  datetime(2023, 3, 16, 11, 0, 39, 744241), datetime(2023, 3, 16, 12, 0, 39, 744241),\r\n                  datetime(2023, 3, 16, 13, 0, 39, 744241), datetime(2023, 3, 16, 14, 0, 39, 744241),\r\n                  datetime(2023, 3, 16, 15, 0, 39, 744241), datetime(2023, 3, 16, 16, 0, 39, 744241),\r\n                  datetime(2023, 3, 16, 17, 0, 39, 744241), datetime(2023, 3, 16, 18, 0, 39, 744241),\r\n                  datetime(2023, 3, 16, 19, 0, 39, 744241), datetime(2023, 3, 16, 20, 0, 39, 744241),\r\n                  datetime(2023, 3, 16, 21, 0, 39, 744241), datetime(2023, 3, 16, 22, 0, 39, 744241),\r\n                  datetime(2023, 3, 16, 23, 0, 39, 744241), datetime(2023, 3, 17, 0, 0, 39, 744241)],\r\n        'canopy temperature': [77, 81, 90, 77, 92, 93, 79, 87, 87, 81, 86, 78, 91, 88, 88, 76, 92, 94, 88, 79, 93, 80,\r\n                               93, 90, 85, 94],\r\n        'ambient temperature': [85, 92, 90, 104, 82, 80, 86, 102, 89, 74, 79, 84, 78, 102, 103, 98, 97, 103, 84, 88,\r\n                                101, 83, 79, 73, 96, 83],\r\n        'rh': [25, 37, 51, 53, 27, 49, 54, 49, 26, 38, 58, 35, 30, 38, 20, 28, 25, 44, 32, 49, 53, 41, 36, 26, 21, 35],\r\n        'vpd': [1, 2, 5, 3, 1, 5, 3, 5, 3, 1, 2, 5, 1, 1, 4, 3, 2, 4, 5, 4, 5, 5, 3, 3, 5, 4],\r\n        'vwc_1': [34, 37, 41, 41, 42, 33, 36, 21, 42, 31, 34, 28, 33, 39, 30, 38, 25, 22, 35, 24, 39, 23, 20, 33, 39,\r\n                  44],\r\n        'vwc_2': [28, 42, 24, 37, 21, 21, 39, 42, 29, 24, 44, 22, 37, 39, 40, 28, 21, 22, 39, 38, 21, 25, 26, 33, 31,\r\n                  30],\r\n        'vwc_3': [26, 30, 40, 34, 20, 27, 44, 28, 43, 36, 37, 36, 26, 36, 41, 22, 37, 42, 26, 25, 43, 35, 43, 36, 24,\r\n                  34], 'vwc_1_ec': [], 'vwc_2_ec': [], 'vwc_3_ec': [], 'daily gallons': [],\r\n        'daily switch': [60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\r\n                         0.0, 0.0, 0.0, 0.0, 0.0]}\r\n\r\n    lacking_full_days = {\r\n        'dates': [datetime(2023, 3, 16, 16, 0, 32, 92243), datetime(2023, 3, 16, 17, 0, 32, 92243),\r\n                  datetime(2023, 3, 16, 18, 0, 32, 92243), datetime(2023, 3, 16, 19, 0, 32, 92243),\r\n                  datetime(2023, 3, 16, 20, 0, 32, 92243), datetime(2023, 3, 16, 21, 0, 32, 92243),\r\n                  datetime(2023, 3, 16, 22, 0, 32, 92243), datetime(2023, 3, 16, 23, 0, 32, 92243),\r\n                  datetime(2023, 3, 17, 0, 0, 32, 92243), datetime(2023, 3, 17, 1, 0, 32, 92243)],\r\n        'canopy temperature': [86, 88, 88, 83, 76, 86, 91, 82, 80, 84],\r\n        'ambient temperature': [95, 100, 86, 72, 94, 89, 90, 89, 86, 103],\r\n        'rh': [28, 18, 38, 16, 21, 46, 53, 51, 47, 31], 'vpd': [5, 2, 3, 3, 2, 3, 5, 5, 4, 5],\r\n        'vwc_1': [25, 40, 40, 35, 29, 21, 24, 41, 39, 34], 'vwc_2': [37, 23, 35, 26, 38, 36, 44, 32, 30, 34],\r\n        'vwc_3': [23, 40, 23, 31, 29, 44, 38, 27, 37, 33], 'vwc_1_ec': [], 'vwc_2_ec': [], 'vwc_3_ec': [],\r\n        'daily gallons': [], 'daily switch': [0.0, 0.0, 0.0, 60, 60, 60, 60, 60, 60, 0.0]}\r\n\r\n    small_med_edges = {\r\n        'dates': [datetime(2023, 3, 15, 21, 0, 23, 131219), datetime(2023, 3, 15, 22, 0, 23, 131219),\r\n                  datetime(2023, 3, 15, 23, 0, 23, 131219), datetime(2023, 3, 16, 0, 0, 23, 131219),\r\n                  datetime(2023, 3, 16, 1, 0, 23, 131219), datetime(2023, 3, 16, 2, 0, 23, 131219),\r\n                  datetime(2023, 3, 16, 3, 0, 23, 131219), datetime(2023, 3, 16, 4, 0, 23, 131219),\r\n                  datetime(2023, 3, 16, 5, 0, 23, 131219), datetime(2023, 3, 16, 6, 0, 23, 131219),\r\n                  datetime(2023, 3, 16, 7, 0, 23, 131219), datetime(2023, 3, 16, 8, 0, 23, 131219),\r\n                  datetime(2023, 3, 16, 9, 0, 23, 131219), datetime(2023, 3, 16, 10, 0, 23, 131219),\r\n                  datetime(2023, 3, 16, 11, 0, 23, 131219), datetime(2023, 3, 16, 12, 0, 23, 131219),\r\n                  datetime(2023, 3, 16, 13, 0, 23, 131219), datetime(2023, 3, 16, 14, 0, 23, 131219),\r\n                  datetime(2023, 3, 16, 15, 0, 23, 131219), datetime(2023, 3, 16, 16, 0, 23, 131219),\r\n                  datetime(2023, 3, 16, 17, 0, 23, 131219), datetime(2023, 3, 16, 18, 0, 23, 131219),\r\n                  datetime(2023, 3, 16, 19, 0, 23, 131219), datetime(2023, 3, 16, 20, 0, 23, 131219),\r\n                  datetime(2023, 3, 16, 21, 0, 23, 131219), datetime(2023, 3, 16, 22, 0, 23, 131219),\r\n                  datetime(2023, 3, 16, 23, 0, 23, 131219), datetime(2023, 3, 17, 0, 0, 23, 131219),\r\n                  datetime(2023, 3, 17, 1, 0, 23, 131219), datetime(2023, 3, 17, 2, 0, 23, 131219)],\r\n        'canopy temperature': [87, 83, 79, 76, 90, 84, 79, 90, 94, 93, 81, 81, 82, 82, 89, 81, 76, 76, 88, 91, 85, 88,\r\n                               84, 86, 85, 85, 88, 92, 89, 84],\r\n        'ambient temperature': [80, 102, 102, 93, 96, 98, 102, 95, 94, 102, 104, 94, 95, 75, 81, 102, 101, 85, 74, 79,\r\n                                101, 103, 77, 95, 89, 92, 94, 84, 103, 94],\r\n        'rh': [33, 58, 55, 43, 27, 25, 41, 25, 58, 59, 15, 30, 54, 23, 21, 56, 29, 43, 39, 37, 31, 37, 37, 56, 43, 53,\r\n               58, 25, 53, 25],\r\n        'vpd': [4, 5, 3, 5, 2, 4, 5, 2, 1, 4, 3, 1, 3, 3, 1, 4, 5, 5, 1, 4, 4, 5, 3, 3, 4, 1, 2, 2, 1, 2],\r\n        'vwc_1': [26, 26, 37, 29, 42, 37, 40, 25, 35, 35, 33, 42, 20, 35, 33, 23, 21, 23, 42, 39, 21, 28, 35, 43, 44,\r\n                  22, 26, 44, 41, 42],\r\n        'vwc_2': [28, 20, 31, 20, 23, 23, 38, 28, 42, 27, 28, 32, 30, 25, 27, 25, 42, 22, 38, 24, 21, 38, 44, 23, 25,\r\n                  26, 40, 44, 28, 43],\r\n        'vwc_3': [20, 27, 42, 40, 21, 39, 40, 22, 27, 24, 23, 22, 36, 20, 24, 35, 39, 37, 21, 26, 32, 37, 27, 21, 42,\r\n                  32, 22, 41, 29, 42], 'vwc_1_ec': [], 'vwc_2_ec': [], 'vwc_3_ec': [], 'daily gallons': [],\r\n        'daily switch': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60, 60, 60, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\r\n                         0.0, 0.0, 60, 60, 60, 60, 60, 0.0, 0.0, 0.0, 0.0]}\r\n\r\n    med_edges = {\r\n        'dates': [datetime(2023, 3, 15, 16, 0, 21, 121390), datetime(2023, 3, 15, 17, 0, 21, 121390),\r\n                  datetime(2023, 3, 15, 18, 0, 21, 121390), datetime(2023, 3, 15, 19, 0, 21, 121390),\r\n                  datetime(2023, 3, 15, 20, 0, 21, 121390), datetime(2023, 3, 15, 21, 0, 21, 121390),\r\n                  datetime(2023, 3, 15, 22, 0, 21, 121390), datetime(2023, 3, 15, 23, 0, 21, 121390),\r\n                  datetime(2023, 3, 16, 0, 0, 21, 121390), datetime(2023, 3, 16, 1, 0, 21, 121390),\r\n                  datetime(2023, 3, 16, 2, 0, 21, 121390), datetime(2023, 3, 16, 3, 0, 21, 121390),\r\n                  datetime(2023, 3, 16, 4, 0, 21, 121390), datetime(2023, 3, 16, 5, 0, 21, 121390),\r\n                  datetime(2023, 3, 16, 6, 0, 21, 121390), datetime(2023, 3, 16, 7, 0, 21, 121390),\r\n                  datetime(2023, 3, 16, 8, 0, 21, 121390), datetime(2023, 3, 16, 9, 0, 21, 121390),\r\n                  datetime(2023, 3, 16, 10, 0, 21, 121390), datetime(2023, 3, 16, 11, 0, 21, 121390),\r\n                  datetime(2023, 3, 16, 12, 0, 21, 121390), datetime(2023, 3, 16, 13, 0, 21, 121390),\r\n                  datetime(2023, 3, 16, 14, 0, 21, 121390), datetime(2023, 3, 16, 15, 0, 21, 121390),\r\n                  datetime(2023, 3, 16, 16, 0, 21, 121390), datetime(2023, 3, 16, 17, 0, 21, 121390),\r\n                  datetime(2023, 3, 16, 18, 0, 21, 121390), datetime(2023, 3, 16, 19, 0, 21, 121390),\r\n                  datetime(2023, 3, 16, 20, 0, 21, 121390), datetime(2023, 3, 16, 21, 0, 21, 121390),\r\n                  datetime(2023, 3, 16, 22, 0, 21, 121390), datetime(2023, 3, 16, 23, 0, 21, 121390),\r\n                  datetime(2023, 3, 17, 0, 0, 21, 121390), datetime(2023, 3, 17, 1, 0, 21, 121390),\r\n                  datetime(2023, 3, 17, 2, 0, 21, 121390), datetime(2023, 3, 17, 3, 0, 21, 121390),\r\n                  datetime(2023, 3, 17, 4, 0, 21, 121390), datetime(2023, 3, 17, 5, 0, 21, 121390),\r\n                  datetime(2023, 3, 17, 6, 0, 21, 121390), datetime(2023, 3, 17, 7, 0, 21, 121390)],\r\n        'canopy temperature': [91, 87, 87, 85, 76, 93, 86, 88, 78, 84, 91, 79, 91, 81, 83, 82, 82, 78, 77, 94, 79, 92,\r\n                               90, 94, 93, 88, 91, 84, 83, 89, 77, 94, 94, 79, 85, 77, 84, 77, 76, 86],\r\n        'ambient temperature': [100, 74, 90, 80, 98, 90, 96, 85, 77, 92, 87, 76, 88, 102, 95, 77, 83, 96, 80, 104, 95,\r\n                                100, 79, 77, 104, 78, 91, 91, 74, 78, 78, 97, 77, 79, 99, 102, 100, 75, 86, 102],\r\n        'rh': [56, 34, 24, 47, 54, 32, 21, 24, 46, 18, 30, 41, 36, 27, 32, 49, 55, 32, 52, 21, 21, 58, 41, 43, 44, 58,\r\n               27, 51, 50, 22, 46, 18, 48, 43, 32, 46, 49, 33, 51, 56],\r\n        'vpd': [1, 4, 2, 5, 1, 2, 5, 2, 5, 5, 5, 2, 3, 5, 3, 1, 4, 5, 3, 3, 1, 2, 5, 1, 4, 4, 2, 5, 1, 3, 1, 2, 1, 2, 2,\r\n                1, 2, 5, 4, 2],\r\n        'vwc_1': [27, 37, 26, 27, 34, 24, 31, 32, 21, 44, 39, 37, 25, 21, 22, 42, 42, 27, 42, 34, 44, 26, 22, 28, 26,\r\n                  42, 26, 23, 23, 39, 29, 29, 37, 24, 26, 39, 24, 26, 25, 41],\r\n        'vwc_2': [35, 31, 31, 27, 32, 22, 42, 33, 28, 44, 35, 30, 26, 30, 40, 33, 26, 39, 25, 41, 30, 28, 33, 27, 25,\r\n                  31, 20, 43, 31, 38, 44, 39, 24, 37, 43, 31, 20, 22, 42, 44],\r\n        'vwc_3': [27, 20, 40, 24, 37, 34, 34, 35, 38, 44, 24, 37, 32, 28, 29, 26, 22, 25, 23, 34, 32, 43, 23, 40, 28,\r\n                  42, 30, 35, 29, 28, 33, 29, 25, 44, 23, 34, 28, 24, 26, 34], 'vwc_1_ec': [], 'vwc_2_ec': [],\r\n        'vwc_3_ec': [], 'daily gallons': [],\r\n        'daily switch': [0.0, 0.0, 60, 60, 60, 60, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60, 60, 60, 60, 60, 0.0, 0.0, 0.0,\r\n                         0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60, 60, 60, 0.0, 0.0]}\r\n\r\n    overnight_irrigation_day_one = {\r\n        'dates': [datetime(2023, 7, 20, 2, 0), datetime(2023, 7, 20, 3, 0), datetime(2023, 7, 20, 4, 0),\r\n                  datetime(2023, 7, 20, 5, 0), datetime(2023, 7, 20, 6, 0), datetime(2023, 7, 20, 7, 0),\r\n                  datetime(2023, 7, 20, 8, 0), datetime(2023, 7, 20, 9, 0), datetime(2023, 7, 20, 10, 0),\r\n                  datetime(2023, 7, 20, 11, 0), datetime(2023, 7, 20, 12, 0), datetime(2023, 7, 20, 13, 0),\r\n                  datetime(2023, 7, 20, 14, 0), datetime(2023, 7, 20, 15, 0), datetime(2023, 7, 20, 16, 0),\r\n                  datetime(2023, 7, 20, 17, 0), datetime(2023, 7, 20, 18, 0), datetime(2023, 7, 20, 19, 0),\r\n                  datetime(2023, 7, 20, 20, 0), datetime(2023, 7, 20, 21, 0), datetime(2023, 7, 20, 22, 0),\r\n                  datetime(2023, 7, 20, 23, 0), datetime(2023, 7, 21, 0, 0), datetime(2023, 7, 21, 1, 0),\r\n                  datetime(2023, 7, 21, 2, 0), datetime(2023, 7, 21, 3, 0)],\r\n        'canopy temperature': [55.256, 52.646, 50.432, 54.014, 52.646, 54.032, 60.836, 65.53399999999999, 69.476, 73.112, 76.622, 79.43,\r\n                               81.10400000000001, 81.69800000000001, 81.518, 82.4, 81.95, 81.05000000000001, 78.35, 75.992, 69.782,\r\n                               60.980000000000004, 56.678, 54.59, 53.474000000000004, 51.602000000000004],\r\n        'ambient temperature': [63.032, 61.736000000000004, 59.900000000000006, 61.358, 60.403999999999996, 59.252, 64.598, 68.684, 73.346, 78.332, 82.706, 86.36, 89.924, 92.588, 94.244, 95.23400000000001, 95.036, 94.028, 90.878, 86.25200000000001, 81.536, 72.84200000000001, 68.53999999999999, 65.012, 62.852000000000004, 60.8],\r\n        'rh': [80.52663133187149, 84.9819295323405, 85.41674613884034, 80.08178528513635, 80.04695849791608, 83.16846927153982, 75.26573241955552, 70.81848333402235, 62.873531439573505, 56.13080204457853, 53.03899459857565, 50.8968949812234, 46.67802474050185, 40.80560744310242, 34.37989538811474, 33.32984365718972, 32.0236663681046, 31.38527916263018, 36.93748457949296, 39.63722226367993, 40.44633845441565, 59.775765008068696, 70.74914888721767, 78.17381475287601, 82.4200261823118, 82.39672792694286],\r\n        'vpd': [0.3828092904396303, 0.282046319709216, 0.25660811894772273, 0.3691055404373449, 0.35744845339418174, 0.28940161040013845, 0.5136422510676344, 0.6980308939829762, 1.0404511422480271, 1.451343961529694, 1.7920602690880454, 2.1070279709709396, 2.561116696698284, 3.0898708301793576, 3.605490249825002, 3.7765930278545765, 3.8272110422802132, 3.7449728003172726, 3.120902235250944, 2.5812835113023276, 2.1880037708846514, 1.108297234218054, 0.6962406481023409, 0.4598435833744532, 0.3434087461203972, 0.3198197180442852],\r\n        'vwc_1': [37.81065358526901, 37.79828504828351, 37.79004264992585, 37.761214986098366, 37.72419817839436, 37.69954984881112, 37.6380322318548, 37.389371860434025, 36.958990627096796, 36.38341214214202, 35.828577821592766, 35.3420855502482, 34.83238091480594, 35.17096666579316, 38.83677691331808, 39.07367340431285, 39.208122199644, 39.31703769827042, 39.40886566369435, 39.46586716084299, 39.492215771878136, 39.61551279683273, 39.68621804209782, 39.810391166228996, 39.868233487841124, 39.92173395220333],\r\n        'vwc_2': [36.75641704982944, 36.75246138128032, 36.75246138128032, 36.748506339913774, 36.74455192560839, 36.73664497769727, 36.708990394633425, 36.67347955751499, 36.61834103141008, 36.55547508905435, 36.49276815504403, 36.422412301226316, 36.352256358073596, 36.282299619206526, 36.23964604119867, 36.23964604119867, 36.247395730636626, 36.26290244917483, 36.2900627749064, 36.352256358073596, 36.426315708681486, 36.524101777013044, 36.62621047918755, 36.75641704982944, 36.91117861667661, 37.0468830523206],\r\n        'vwc_3': [35.24521542653574, 35.24893394212669, 35.252653037420515, 35.24893394212669, 35.23778013397809, 35.23778013397809, 35.21548815657716, 35.17467361276228, 35.115431652549134, 35.041586267445936, 34.96797005037418, 34.89091860430733, 34.81046666495629, 34.74484591327776, 34.66126258585405, 34.57436120037958, 34.520210985084, 34.513000410496275, 34.49858592464108, 34.51660542005071, 34.54185604711748, 34.58520628060442, 34.63588308364716, 34.690301353063546, 34.7995171730743, 34.98635267312977],\r\n        'vwc_1_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None],\r\n        'vwc_2_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None],\r\n        'vwc_3_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None],\r\n        'daily gallons': [],\r\n        'daily switch': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60]}\r\n\r\n    overnight_irrigation_day_two = {\r\n        'dates': [datetime(2023, 7, 21, 1, 0), datetime(2023, 7, 21, 2, 0), datetime(2023, 7, 21, 3, 0), datetime(2023, 7, 21, 4, 0), datetime(2023, 7, 21, 5, 0), datetime(2023, 7, 21, 6, 0), datetime(2023, 7, 21, 7, 0), datetime(2023, 7, 21, 8, 0), datetime(2023, 7, 21, 9, 0), datetime(2023, 7, 21, 10, 0), datetime(2023, 7, 21, 11, 0), datetime(2023, 7, 21, 12, 0), datetime(2023, 7, 21, 13, 0), datetime(2023, 7, 21, 14, 0), datetime(2023, 7, 21, 15, 0), datetime(2023, 7, 21, 16, 0), datetime(2023, 7, 21, 17, 0), datetime(2023, 7, 21, 18, 0), datetime(2023, 7, 21, 19, 0), datetime(2023, 7, 21, 20, 0), datetime(2023, 7, 21, 21, 0), datetime(2023, 7, 21, 22, 0), datetime(2023, 7, 21, 23, 0), datetime(2023, 7, 22, 0, 0), datetime(2023, 7, 22, 1, 0), datetime(2023, 7, 22, 2, 0)],\r\n        'canopy temperature': [54.59, 53.474000000000004, 51.602000000000004, 50.522, 50.666, 49.226, 54.734, 66.524, 69.512, 74.156, 77.55799999999999, 81.212, 83.732, 85.55000000000001, 85.69399999999999, 86.21600000000001, 85.82, 84.758, 83.94800000000001, 81.68, 73.22, 68.576, 65.39, 62.150000000000006, 60.674, 58.532],\r\n        'ambient temperature': [65.012, 62.852000000000004, 60.8, 59.792, 60.476, 58.298, 59.432, 69.404, 75.686, 80.348, 85.082, 89.042, 92.318, 95.108, 97.052, 98.65400000000001, 99.464, 99.536, 97.538, 94.55000000000001, 83.98400000000001, 77.52199999999999, 73.634, 70.898, 69.44, 66.344],\r\n        'rh': [78.17381475287601, 82.4200261823118, 82.39672792694286, 83.34996194814208, 84.68639802744981, 86.41868764880799, 86.44958779401792, 73.17213815093343, 58.20340342969467, 52.87868262989771, 47.53165878959346, 45.52971631712544, 43.02344763973963, 40.99106914614765, 36.61769065878929, 34.558226440246166, 34.31095218764193, 34.081545019652154, 37.921839234075506, 42.007816273763446, 62.11206565314386, 72.42868645910339, 77.25167903094132, 80.93471469328003, 80.78140174444168, 83.65649351429238],\r\n        'vpd': [0.4598435833744532, 0.3434087461203972, 0.3198197180442852, 0.29185023034442614, 0.2750381305944678, 0.22567762907448796, 0.2344882974855773, 0.6577528738868952, 1.2667506022921484, 1.6655056023450625, 2.161359706479848, 2.5446741768934658, 2.949247191178093, 3.329692538107112, 3.7959085317662358, 4.114938426925017, 4.233006531524808, 4.257040557524185, 3.773291682458248, 3.216586818070887, 1.5066830711980659, 0.8880994207624084, 0.643711958913475, 0.4918571205358999, 0.4717729516669893, 0.36064281091893724],\r\n        'vwc_1': [39.810391166228996, 39.868233487841124, 39.92173395220333, 39.970866930672024, 39.993228886621466, 40.02456588706544, 40.042488610257806, 40.015608853715804, 39.993228886621466, 39.988755055024505, 39.97980955268336, 39.96192718802165, 39.99770343866413, 40.02456588706544, 40.042488610257806, 40.06939435081267, 40.11878911490907, 40.1367725539453, 40.1772776764044, 40.2133315549563, 40.258464284680564, 40.30819432891111, 40.34894814283696, 40.40337855847787, 40.42608897370039, 40.45336563172306],\r\n        'vwc_2': [36.75641704982944, 36.91117861667661, 37.0468830523206, 37.11501074163381, 37.151152973989184, 37.16321188771556, 37.17125436162099, 37.13106756872091, 37.09896412581797, 37.05889220971872, 37.02288191017966, 36.97095787484219, 36.91515947184176, 36.87537934688412, 36.85948496992455, 36.835662315643525, 36.823759491438594, 36.83963118300228, 36.8674308970145, 36.903218802307336, 36.96696815857785, 37.042881272306836, 37.07491333127058, 37.11902399079601, 37.151152973989184, 37.17929939512668],\r\n        'vwc_3': [34.690301353063546, 34.7995171730743, 34.98635267312977, 35.286151001679, 35.552069624724545, 35.74111697485347, 35.881969738714005, 35.96610907095909, 35.95844800581616, 35.90870978026892, 35.820959986301574, 35.710769736515324, 35.61240370425121, 35.53324619765732, 35.48437415173851, 35.45809956500814, 35.45809956500814, 35.503159331271746, 35.60107954599157, 35.74111697485347, 35.88960674851385, 36.04285247977002, 36.10442144014985, 36.14298092881212, 36.18160124622358, 36.1970664323692],\r\n        'vwc_1_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None],\r\n        'vwc_2_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None],\r\n        'vwc_3_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'daily gallons': [],\r\n        'daily switch': [60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60]}\r\n\r\n    overnight_irrigation_day_three = {\r\n        'dates': [datetime(2023, 7, 22, 2, 0), datetime(2023, 7, 22, 3, 0), datetime(2023, 7, 22, 4, 0), datetime(2023, 7, 22, 5, 0), datetime(2023, 7, 22, 6, 0), datetime(2023, 7, 22, 7, 0), datetime(2023, 7, 22, 8, 0), datetime(2023, 7, 22, 9, 0), datetime(2023, 7, 22, 10, 0), datetime(2023, 7, 22, 11, 0), datetime(2023, 7, 22, 12, 0), datetime(2023, 7, 22, 13, 0), datetime(2023, 7, 22, 14, 0), datetime(2023, 7, 22, 15, 0), datetime(2023, 7, 22, 16, 0), datetime(2023, 7, 22, 17, 0), datetime(2023, 7, 22, 18, 0), datetime(2023, 7, 22, 19, 0), datetime(2023, 7, 22, 20, 0), datetime(2023, 7, 22, 21, 0), datetime(2023, 7, 22, 22, 0), datetime(2023, 7, 22, 23, 0), datetime(2023, 7, 23, 0, 0), datetime(2023, 7, 23, 1, 0), datetime(2023, 7, 23, 2, 0), datetime(2023, 7, 23, 3, 0)],\r\n        'canopy temperature': [58.532, 56.948, 55.147999999999996, 54.41, 53.672, 56.804, 66.884, 69.98, 73.922, 77.846, 80.582, 82.886, 85.04599999999999, 85.80199999999999, 85.56800000000001, 85.298, 84.30799999999999, 83.048, 79.016, 73.22, 71.258, 68.594, 66.362, 65.53399999999999, 65.03, 64.958],\r\n        'ambient temperature': [66.344, 65.156, 63.30200000000001, 62.635999999999996, 61.664, 61.772, 70.05199999999999, 76.766, 80.474, 85.51400000000001, 88.952, 91.094, 94.676, 97.412, 99.35600000000001, 100.274, 100.058, 98.76200000000001, 89.78, 81.19399999999999, 77.48599999999999, 75.326, 73.58000000000001, 71.654, 70.646, 69.80000000000001],\r\n        'rh': [83.65649351429238, 84.3944299919226, 84.60400435099564, 83.20356948394618, 83.16993384184633, 84.2357419641575, 75.12122437098719, 55.451363620329666, 52.35162079540826, 46.232604551676936, 41.666313570327986, 43.27197278745828, 40.192790165691264, 36.54826043011582, 32.05664575550409, 31.07477928066611, 30.332670272672672, 35.61829353341872, 60.44205115297182, 70.01781272516467, 75.1569111796218, 75.2687377411146, 78.06462167640082, 80.92529333584851, 82.02210854992953, 82.69107240727365],\r\n        'vpd': [0.36064281091893724, 0.3304383192955198, 0.3055396360133882, 0.32561875158039033, 0.3152731024683151, 0.29643692981774383, 0.6236151620489818, 1.3994917258434119, 1.6910782745029445, 2.2457060686395165, 2.71743947707016, 2.826439812924091, 3.3301628241633403, 3.8420077458036417, 4.3640051256890215, 4.5514258247385175, 4.57058296915861, 4.061556017406509, 1.891439320591132, 1.0893611419507776, 0.7992689936938517, 0.7406031614779964, 0.6195829578734493, 0.5048856790057883, 0.4598469477200515, 0.43015340311300454],\r\n        'vwc_1': [40.45336563172306, 40.485221743660915, 40.49433009094425, 40.50799811634924, 40.5171138043519, 40.51255559316331, 40.49433009094425, 40.4761163309697, 40.462463712173324, 40.44427048247332, 40.42608897370039, 40.42608897370039, 40.41700261223875, 40.430633252480504, 40.44427048247332, 40.47156472479321, 40.49433009094425, 40.5216727500366, 40.55360594588748, 40.5992873219101, 40.63588545758981, 40.66794755055376, 40.67711479316234, 40.68628499071156, 40.700045829668326, 40.709223418807916],\r\n        'vwc_2': [37.17929939512668, 37.19137174675629, 37.211505144535685, 37.22359287557082, 37.2316545700992, 37.227623402036954, 37.19942318350298, 37.17125436162099, 37.14311689484595, 37.11501074163381, 37.09495406646659, 37.066901496992614, 37.0468830523206, 37.02288191017966, 36.99091596624822, 36.97095787484219, 36.97095787484219, 36.98692307955209, 37.030879747926626, 37.09495406646659, 37.15919161031036, 37.19942318350298, 37.227623402036954, 37.25585505876743, 37.2639270265811, 37.267963974456194],\r\n        'vwc_3': [36.1970664323692, 36.22028251350562, 36.23577211351336, 36.251271492631744, 36.27065948021286, 36.27065948021286, 36.243520580199196, 36.200934253560746, 36.13912224465059, 36.07361756452598, 36.00445057900821, 35.90870978026892, 35.8400090624988, 35.79051255997969, 35.77910463132148, 35.78290667726512, 35.824768604829906, 35.91253218883277, 36.07361756452598, 36.23189879702258, 36.29394527203087, 36.33280397887848, 36.348364653062994, 36.36004161270008, 36.37561950376518, 36.37561950376518],\r\n        'vwc_1_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None],\r\n        'vwc_2_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None],\r\n        'vwc_3_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None],\r\n        'daily gallons': [],\r\n        'daily switch': [60, 60, 60, 60, 60, 60, 59, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60]\r\n\r\n    }\r\n\r\n    overnight_irrigation_day_four = {\r\n        'dates': [datetime(2023, 7, 23, 2, 0), datetime(2023, 7, 23, 3, 0), datetime(2023, 7, 23, 4, 0),\r\n                  datetime(2023, 7, 23, 5, 0), datetime(2023, 7, 23, 6, 0), datetime(2023, 7, 23, 7, 0),\r\n                  datetime(2023, 7, 23, 8, 0), datetime(2023, 7, 23, 9, 0), datetime(2023, 7, 23, 10, 0),\r\n                  datetime(2023, 7, 23, 11, 0), datetime(2023, 7, 23, 12, 0), datetime(2023, 7, 23, 13, 0),\r\n                  datetime(2023, 7, 23, 14, 0), datetime(2023, 7, 23, 15, 0), datetime(2023, 7, 23, 16, 0),\r\n                  datetime(2023, 7, 23, 17, 0), datetime(2023, 7, 23, 18, 0), datetime(2023, 7, 23, 19, 0),\r\n                  datetime(2023, 7, 23, 20, 0)],\r\n        'canopy temperature': [58.532, 56.948, 55.147999999999996, 54.41, 53.672, 56.804, 66.884, 69.98, 73.922, 77.846,\r\n                               80.582, 82.886, 85.04599999999999, 85.80199999999999, 85.56800000000001, 85.298,\r\n                               84.30799999999999, 83.048, 79.016],\r\n        'ambient temperature': [66.344, 65.156, 63.30200000000001, 62.635999999999996, 61.664, 61.772,\r\n                                70.05199999999999, 76.766, 80.474, 85.51400000000001, 88.952, 91.094, 94.676, 97.412,\r\n                                99.35600000000001, 100.274, 100.058, 98.76200000000001, 89.78],\r\n        'rh': [83.65649351429238, 84.3944299919226, 84.60400435099564, 83.20356948394618, 83.16993384184633,\r\n               84.2357419641575, 75.12122437098719, 55.451363620329666, 52.35162079540826, 46.232604551676936,\r\n               41.666313570327986, 43.27197278745828, 40.192790165691264, 36.54826043011582, 32.05664575550409,\r\n               31.07477928066611, 30.332670272672672, 35.61829353341872, 60.44205115297182],\r\n        'vpd': [0.36064281091893724, 0.3304383192955198, 0.3055396360133882, 0.32561875158039033, 0.3152731024683151,\r\n                0.29643692981774383, 0.6236151620489818, 1.3994917258434119, 1.6910782745029445, 2.2457060686395165,\r\n                2.71743947707016, 2.826439812924091, 3.3301628241633403, 3.8420077458036417, 4.3640051256890215,\r\n                4.5514258247385175, 4.57058296915861, 4.061556017406509, 1.891439320591132],\r\n        'vwc_1': [40.45336563172306, 40.485221743660915, 40.49433009094425, 40.50799811634924, 40.5171138043519,\r\n                  40.51255559316331, 40.49433009094425, 40.4761163309697, 40.462463712173324, 40.44427048247332,\r\n                  40.42608897370039, 40.42608897370039, 40.41700261223875, 40.430633252480504, 40.44427048247332,\r\n                  40.47156472479321, 40.49433009094425, 40.5216727500366, 40.55360594588748],\r\n        'vwc_2': [37.17929939512668, 37.19137174675629, 37.211505144535685, 37.22359287557082, 37.2316545700992,\r\n                  37.227623402036954, 37.19942318350298, 37.17125436162099, 37.14311689484595, 37.11501074163381,\r\n                  37.09495406646659, 37.066901496992614, 37.0468830523206, 37.02288191017966, 36.99091596624822,\r\n                  36.97095787484219, 36.97095787484219, 36.98692307955209, 37.030879747926626],\r\n        'vwc_3': [36.1970664323692, 36.22028251350562, 36.23577211351336, 36.251271492631744, 36.27065948021286,\r\n                  36.27065948021286, 36.243520580199196, 36.200934253560746, 36.13912224465059, 36.07361756452598,\r\n                  36.00445057900821, 35.90870978026892, 35.8400090624988, 35.79051255997969, 35.77910463132148,\r\n                  35.78290667726512, 35.824768604829906, 35.91253218883277, 36.07361756452598],\r\n        'vwc_1_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None,\r\n                     None, None, None],\r\n        'vwc_2_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None,\r\n                     None, None, None],\r\n        'vwc_3_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None,\r\n                     None, None, None],\r\n        'daily gallons': [],\r\n        'daily switch': [60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60]\r\n\r\n    }\r\n\r\n    overnight_irrigation_day_five = {\r\n        'dates': [datetime(2023, 7, 23, 20, 0), datetime(2023, 7, 23, 21, 0), datetime(2023, 7, 23, 22, 0),\r\n                  datetime(2023, 7, 23, 23, 0), datetime(2023, 7, 24, 0, 0), datetime(2023, 7, 24, 1, 0),\r\n                  datetime(2023, 7, 24, 2, 0), datetime(2023, 7, 24, 3, 0), datetime(2023, 7, 24, 4, 0),\r\n                  datetime(2023, 7, 24, 5, 0), datetime(2023, 7, 24, 6, 0), datetime(2023, 7, 24, 7, 0),\r\n                  datetime(2023, 7, 24, 8, 0), datetime(2023, 7, 24, 9, 0), datetime(2023, 7, 24, 10, 0),\r\n                  datetime(2023, 7, 24, 11, 0), datetime(2023, 7, 24, 12, 0), datetime(2023, 7, 24, 13, 0),\r\n                  datetime(2023, 7, 24, 14, 0), datetime(2023, 7, 24, 15, 0), datetime(2023, 7, 24, 16, 0),\r\n                  datetime(2023, 7, 24, 17, 0), datetime(2023, 7, 24, 18, 0), datetime(2023, 7, 24, 19, 0),\r\n                  datetime(2023, 7, 24, 20, 0), datetime(2023, 7, 24, 21, 0),\r\n                  datetime(2023, 7, 24, 22, 0), datetime(2023, 7, 24, 23, 0), datetime(2023, 7, 25, 0, 0)],\r\n        'canopy temperature': [58.532, 56.948, 55.147999999999996, 54.41, 53.672, 56.804, 66.884, 69.98, 73.922, 77.846,\r\n                               80.582, 82.886, 85.04599999999999, 85.80199999999999, 85.56800000000001, 85.298,\r\n                               84.30799999999999, 83.048, 79.016, 73.22, 71.258, 68.594, 66.362, 65.53399999999999,\r\n                               65.03, 64.958, 0, 0, 0],\r\n        'ambient temperature': [66.344, 65.156, 63.30200000000001, 62.635999999999996, 61.664, 61.772,\r\n                                70.05199999999999, 76.766, 80.474, 85.51400000000001, 88.952, 91.094, 94.676, 97.412,\r\n                                99.35600000000001, 100.274, 100.058, 98.76200000000001, 89.78, 81.19399999999999,\r\n                                77.48599999999999, 75.326, 73.58000000000001, 71.654, 70.646, 69.80000000000001,\r\n                                0, 0, 0],\r\n        'rh': [83.65649351429238, 84.3944299919226, 84.60400435099564, 83.20356948394618, 83.16993384184633,\r\n               84.2357419641575, 75.12122437098719, 55.451363620329666, 52.35162079540826, 46.232604551676936,\r\n               41.666313570327986, 43.27197278745828, 40.192790165691264, 36.54826043011582, 32.05664575550409,\r\n               31.07477928066611, 30.332670272672672, 35.61829353341872, 60.44205115297182, 70.01781272516467,\r\n               75.1569111796218, 75.2687377411146, 78.06462167640082, 80.92529333584851, 82.02210854992953,\r\n               82.69107240727365, 0, 0, 0],\r\n        'vpd': [0.36064281091893724, 0.3304383192955198, 0.3055396360133882, 0.32561875158039033, 0.3152731024683151,\r\n                0.29643692981774383, 0.6236151620489818, 1.3994917258434119, 1.6910782745029445, 2.2457060686395165,\r\n                2.71743947707016, 2.826439812924091, 3.3301628241633403, 3.8420077458036417, 4.3640051256890215,\r\n                4.5514258247385175, 4.57058296915861, 4.061556017406509, 1.891439320591132, 1.0893611419507776,\r\n                0.7992689936938517, 0.7406031614779964, 0.6195829578734493, 0.5048856790057883, 0.4598469477200515,\r\n                0.43015340311300454, 0, 0, 0],\r\n        'vwc_1': [40.45336563172306, 40.485221743660915, 40.49433009094425, 40.50799811634924, 40.5171138043519,\r\n                  40.51255559316331, 40.49433009094425, 40.4761163309697, 40.462463712173324, 40.44427048247332,\r\n                  40.42608897370039, 40.42608897370039, 40.41700261223875, 40.430633252480504, 40.44427048247332,\r\n                  40.47156472479321, 40.49433009094425, 40.5216727500366, 40.55360594588748, 40.5992873219101,\r\n                  40.63588545758981, 40.66794755055376, 40.67711479316234, 40.68628499071156, 40.700045829668326,\r\n                  40.709223418807916, 0, 0, 0],\r\n        'vwc_2': [37.17929939512668, 37.19137174675629, 37.211505144535685, 37.22359287557082, 37.2316545700992,\r\n                  37.227623402036954, 37.19942318350298, 37.17125436162099, 37.14311689484595, 37.11501074163381,\r\n                  37.09495406646659, 37.066901496992614, 37.0468830523206, 37.02288191017966, 36.99091596624822,\r\n                  36.97095787484219, 36.97095787484219, 36.98692307955209, 37.030879747926626, 37.09495406646659,\r\n                  37.15919161031036, 37.19942318350298, 37.227623402036954, 37.25585505876743, 37.2639270265811,\r\n                  37.267963974456194, 0, 0, 0],\r\n        'vwc_3': [36.1970664323692, 36.22028251350562, 36.23577211351336, 36.251271492631744, 36.27065948021286,\r\n                  36.27065948021286, 36.243520580199196, 36.200934253560746, 36.13912224465059, 36.07361756452598,\r\n                  36.00445057900821, 35.90870978026892, 35.8400090624988, 35.79051255997969, 35.77910463132148,\r\n                  35.78290667726512, 35.824768604829906, 35.91253218883277, 36.07361756452598, 36.23189879702258,\r\n                  36.29394527203087, 36.33280397887848, 36.348364653062994, 36.36004161270008, 36.37561950376518,\r\n                  36.37561950376518, 0, 0, 0],\r\n        'vwc_1_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None,\r\n                     None, None, None, None, None, None, None, None, None, None, None, None, None],\r\n        'vwc_2_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None,\r\n                     None, None, None, None, None, None, None, None, None, None, None, None, None],\r\n        'vwc_3_ec': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None,\r\n                     None, None, None, None, None, None, None, None, None, None, None, None, None],\r\n        'daily gallons': [],\r\n        'daily switch': [60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60,\r\n                         60, 60, 0, 0, 0]\r\n\r\n    }\r\n\r\n    # test_case_1 = SwitchTestCase()\r\n    # test_case_standard = SwitchTestCase(120, standard_data_2023, 0, [480])\r\n    # test_case_half_and_half = SwitchTestCase(55, half_and_half, 0, [415, 240])\r\n    # test_case_multiple_days = SwitchTestCase(60, multiple_days, 60, [660, 300])\r\n    # test_case_small_edges = SwitchTestCase(60, small_edges, 0, [660])\r\n    # test_case_lacking_full_days = SwitchTestCase(0, lacking_full_days, 60, [300])\r\n    # test_case_small_med_edges = SwitchTestCase(0, small_med_edges, 0, [480])\r\n    # test_case_med_edges = SwitchTestCase(240, med_edges, 180, [300])\r\n\r\n    test_case_overnight_irrigation_day_one = SwitchTestCase(0, overnight_irrigation_day_one, 240, [506])\r\n    test_case_overnight_irrigation_day_two = SwitchTestCase(0, overnight_irrigation_day_two, 240, [1440])\r\n    test_case_overnight_irrigation_day_three = SwitchTestCase(0, overnight_irrigation_day_three, 240, [1439])\r\n    test_case_overnight_irrigation_day_four = SwitchTestCase(0, overnight_irrigation_day_four, 240, [1260])\r\n    test_case_overnight_irrigation_day_five = SwitchTestCase(0, overnight_irrigation_day_five, 240, [1320])\r\n\r\n    # test_cases.append(test_case_standard)\r\n    # test_cases.append(test_case_half_and_half)\r\n    # test_cases.append(test_case_multiple_days)\r\n    # test_cases.append(test_case_small_edges)\r\n    # test_cases.append(test_case_lacking_full_days)\r\n    # test_cases.append(test_case_small_med_edges)\r\n    # test_cases.append(test_case_med_edges)\r\n    test_cases.append(test_case_overnight_irrigation_day_one)\r\n    test_cases.append(test_case_overnight_irrigation_day_two)\r\n    test_cases.append(test_case_overnight_irrigation_day_three)\r\n    test_cases.append(test_case_overnight_irrigation_day_four)\r\n    test_cases.append(test_case_overnight_irrigation_day_five)\r\n\r\n    # test_cases.append(test_case_small_edges)\r\n\r\n    test_results = []\r\n\r\n    logger = Logger('z6', '', '', 'tomato', 'Clay', 0, 0, 'N', None, planting_date='3/1/2023')\r\n\r\n    # Loop through each test case and record results\r\n    for ind, test_case in enumerate(test_cases):\r\n        print(f'================TEST CASE {ind + 1}================')\r\n        test_result = test_data_pipeline(test_case, logger)\r\n        test_result_tup = (ind, test_result)\r\n        test_results.append(test_result_tup)\r\n    print('All Test Results: ', test_results)\r\n    # print(test_results)\r\n\r\n\r\ndef test_data_pipeline(test_case, logger):\r\n    \"\"\"\r\n    Method to simulate a standard STomato run including switch processing, high/low temp processing,\r\n     final results cleanup, kc calculation, last day removal\r\n    :param test_case: SwitchTestCase instance with all the switch test criteria\r\n    :return:\r\n    \"\"\"\r\n\r\n    # Grab test criteria\r\n    in_prev_switch = test_case.in_prev_switch\r\n    in_test_case_data = test_case.in_test_case_data\r\n    out_prev_switch = test_case.out_prev_switch\r\n    out_switch_values = test_case.out_switch_values\r\n\r\n    test_pass = False\r\n    cwsi_processor = CwsiProcessor()\r\n    # logger = Logger('z6', '', '', 'tomato', 'Clay', 0, 0, 'N', None, planting_date='3/1/2023')\r\n\r\n    for key, values in in_test_case_data.items():\r\n        print(key, \" : \", values)\r\n    print('=========================================')\r\n    print()\r\n    print('>================Testing switch================')\r\n    cwsi_processor.update_irrigation_ledger(in_test_case_data, logger.irrigation_ledger)\r\n    print('After updating ledger: ')\r\n    for date, list in logger.irrigation_ledger.items():\r\n        print(f'{date} : {list}')\r\n    print('<================Testing switch================')\r\n    print()\r\n\r\n    print('>================Testing Getting High and Low Temp Indexes================')\r\n    highest_temp_values_ind, lowest_temp_values_ind, _ = cwsi_processor.get_highest_and_lowest_temperature_indexes(\r\n        in_test_case_data\r\n    )\r\n    print('<================Testing Getting High and Low Temp Indexes================')\r\n    print()\r\n\r\n    print('>================Testing Final Results================')\r\n    final_results_converted = cwsi_processor.final_results(\r\n        in_test_case_data, highest_temp_values_ind, lowest_temp_values_ind, logger\r\n    )\r\n    print('After final results ledger: ')\r\n    for date, list in logger.irrigation_ledger.items():\r\n        print(f'{date} : {list}')\r\n    print('<================Testing Final Results================')\r\n    print()\r\n\r\n    print('>================Testing Switch Overflow================')\r\n    logger.check_and_update_delayed_ledger_filled_lists()\r\n\r\n    print('After switch overflow ledger: ')\r\n    for date, list in logger.irrigation_ledger.items():\r\n        print(f'{date} : {list}')\r\n    print('<================Testing Switch Overflow================')\r\n\r\n    print('>================Testing get kc================')\r\n    final_results_converted = logger.get_kc(final_results_converted)\r\n    print('<================Testing get kc================')\r\n    print()\r\n\r\n    print()\r\n    print('=======================================')\r\n    print('================RESULTS================')\r\n    for key, values in final_results_converted.items():\r\n        print(key, \" : \", values)\r\n    print()\r\n\r\n    switch_list_length_match = False\r\n    switch_list_values_match = False\r\n    output_prev_switch_match = False\r\n\r\n    data_points = len(out_switch_values)\r\n    switch_data_points = len(final_results_converted['daily switch'])\r\n    if data_points == switch_data_points:\r\n        switch_list_length_match = True\r\n\r\n    if switch_list_length_match:\r\n        if final_results_converted['daily switch'] == out_switch_values:\r\n            switch_list_values_match = True\r\n\r\n    if switch_list_length_match and switch_list_values_match:\r\n        test_pass = True\r\n        print('SUCCESS')\r\n    else:\r\n        print('FAIL')\r\n        print('Switch list length match: ', switch_list_length_match)\r\n        print('Switch list values match: ', switch_list_values_match)\r\n    print('=======================================')\r\n    print()\r\n    print()\r\n    return test_pass\r\n\r\n\r\ndef cleanup_cimis_stations_pickle():\r\n    \"\"\"\r\n    Go through the cimis stations pickle and remove any cimis station objects for stations that are no longer part\r\n    of our current operating growers pickle\r\n    \"\"\"\r\n    growers = open_pickle()\r\n    cimis_stations_pickle_list = open_pickle(filename=\"cimisStation.pickle\")\r\n    grower_pickle_cimis_stations = []\r\n\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            if field.cimis_station not in grower_pickle_cimis_stations:\r\n                grower_pickle_cimis_stations.append(field.cimis_station)\r\n\r\n    # print('Grower Pickle Active Stations #:')\r\n    # grower_pickle_cimis_stations.sort()\r\n    # print(grower_pickle_cimis_stations)\r\n\r\n    pickle_indexes_to_be_removed = []\r\n    for ind, station in enumerate(cimis_stations_pickle_list):\r\n        if station.station_number not in grower_pickle_cimis_stations:\r\n            pickle_indexes_to_be_removed.append(ind)\r\n\r\n    # Reverse the list of indexes we will be removing using pop() so we don't run into an index out of bounds issue\r\n    # from removing from our list from the beginning\r\n    pickle_indexes_to_be_removed.reverse()\r\n    for ind in pickle_indexes_to_be_removed:\r\n        cimis_stations_pickle_list.pop(ind)\r\n\r\n    # print('Pickle Cimis Stations:')\r\n    # pickle_stations = []\r\n    # for station in cimis_stations_pickle_list:\r\n    #     pickle_stations.append(station.station_number)\r\n    # pickle_stations.sort()\r\n    # print(pickle_stations)\r\n    write_pickle(cimis_stations_pickle_list, filename=\"cimisStation.pickle\")\r\n\r\n\r\ndef turn_ai_game_data_into_csv(pickle_name, pickle_path, csv_name):\r\n    global ai_game_data, vwc, field_capacity, wilting_point, psi, psi_threshold, psi_critical, et_hours\r\n    grower_pickle_file_name = pickle_name\r\n    grower_pickle_file_path = pickle_path\r\n    ai_game_data = open_pickle(filename=grower_pickle_file_name, specific_file_path=grower_pickle_file_path)\r\n    # ai_game_data.show_content()\r\n    stage_dict = {'Stage 1': 1, 'Stage 2': 2, 'Stage 3': 3, 'Stage 4': 4}\r\n    all_data = []\r\n    all_labels = []\r\n    for data_point in ai_game_data.ai_game_data:\r\n        print(data_point)\r\n        data_point_values = []\r\n\r\n        crop_stage = stage_dict[data_point.crop_stage]\r\n        vwc = data_point.vwc_avg\r\n        field_capacity = data_point.field_capacity\r\n        wilting_point = data_point.wilting_point\r\n        psi = data_point.psi\r\n        psi_threshold = data_point.psi_threshold\r\n        psi_critical = data_point.psi_critical\r\n        et_hours = data_point.et_hours\r\n        label_hours = data_point.human_p2\r\n\r\n        data_point_values.append(crop_stage)\r\n        data_point_values.append(vwc)\r\n        data_point_values.append(field_capacity)\r\n        data_point_values.append(wilting_point)\r\n        data_point_values.append(psi)\r\n        data_point_values.append(psi_threshold)\r\n        data_point_values.append(psi_critical)\r\n        data_point_values.append(et_hours)\r\n        all_data.append(data_point_values)\r\n        all_labels.append(label_hours)\r\n    df = pd.DataFrame(\r\n        all_data,\r\n        columns=['crop_stage', 'vwc', 'field_capacity', 'wilting_point', 'psi', 'psi_threshold',\r\n                 'psi_critical',\r\n                 'et_hours']\r\n    )\r\n    df['irrigation_hours'] = all_labels\r\n    df.to_csv(csv_name + '.csv', index=False)\r\n    print(all_data)\r\n    print(all_labels)\r\n\r\n\r\ndef get_tomato_yield_data(pickle_name: str, pickle_path: str, excel_filename: str, excel_data_start_row: int,\r\n                          excel_data_end_row: int):\r\n    growers = open_pickle(filename=pickle_name, specific_file_path=pickle_path)\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            field.crop_type = field.loggers[0].cropType\r\n            field.net_yield = None\r\n            field.paid_yield = None\r\n\r\n    whole_file_df = pd.read_excel(excel_filename)\r\n    df = whole_file_df.loc[excel_data_start_row:excel_data_end_row,\r\n         ['Grower', 'Field - variety area', 'Grower field #', 'Gradient Field #', 'Loads', 'Acres', 'Net T/A',\r\n          'Paid T/A']]\r\n\r\n    mask_grower = None\r\n    for grower in growers:\r\n        tomato_fields = 0\r\n        for field in grower.fields:\r\n            if field.crop_type in ['Tomato', 'Tomatoes', 'tomato', 'tomatoes']:\r\n                if hasattr(field.loggers[0], 'rnd') and not field.loggers[0].rnd:\r\n                    # print(f'Grower: {grower.name} - Field: {field.nickname}')\r\n                    mask_grower_field = (df['Grower'] == grower.name) & (df['Gradient Field #'] == field.nickname)\r\n                    tomato_fields += 1\r\n                    results_count = mask_grower_field.sum()\r\n                    search_grower_field = df[mask_grower_field]\r\n\r\n                    net_yield_search = search_grower_field.loc[mask_grower_field, 'Net T/A']\r\n                    if not net_yield_search.empty:\r\n                        net_yield = round(net_yield_search.mean(), 1)\r\n                    else:\r\n                        net_yield = None\r\n\r\n                    paid_yield_search = search_grower_field.loc[mask_grower_field, 'Paid T/A']\r\n                    if not paid_yield_search.empty:\r\n                        paid_yield = round(paid_yield_search.mean(), 1)\r\n                    else:\r\n                        paid_yield = None\r\n\r\n                    print(\r\n                        f'{grower.name:25} - {field.nickname:20}\\t Net: {str(net_yield):10}  Paid: {str(paid_yield):10} Results: {results_count}'\r\n                    )\r\n                    field.net_yield = net_yield\r\n                    field.paid_yield = paid_yield\r\n                    results_count = 0\r\n\r\n    write_pickle(growers, filename=pickle_name, specific_file_path=pickle_path)\r\n\r\n\r\ndef graph_yields(pickle_name: str, pickle_path: str, yield_type: str):\r\n    yield_data = []\r\n    growers = open_pickle(filename=pickle_name, specific_file_path=pickle_path)\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            if field.net_yield is not None:\r\n                # field_names.append(grower.name + '-' + field.nickname)\r\n                # net_yields.append(field.net_yield)\r\n                # paid_yields.append(field.paid_yield)\r\n                yield_data.append((grower.name + '-' + field.nickname, field.net_yield, field.paid_yield))\r\n\r\n    # Extract the field names and yield values\r\n    field_names, net_yields, paid_yields = zip(*yield_data)\r\n\r\n    # Create a figure with two subplots\r\n    fig, ax = plt.subplots(ncols=1, figsize=(50, 10))\r\n\r\n    if yield_type in ['Net', 'net', 'n', 'N']:\r\n        # Sort the data by net_yield\r\n        sorted_data = sorted(zip(net_yields, paid_yields, field_names), reverse=True)\r\n\r\n        # Unpack the sorted data into separate lists\r\n        net_yields, paid_yields, field_names = zip(*sorted_data)\r\n\r\n        # Plot the net yields\r\n        ax.bar(field_names, net_yields)\r\n        ax.set_title('Net Yields')\r\n        ax.tick_params(axis='x', rotation=90)  # Rotate x-axis labels by 90 degrees\r\n\r\n        # Add data labels to the net yields bars\r\n        for i, v in enumerate(net_yields):\r\n            ax.text(i, v + 1, str(v), ha='center', fontsize=8)\r\n\r\n    if yield_type in ['Paid', 'paid', 'p', 'P']:\r\n        # Sort the data by paid_yield\r\n        sorted_data = sorted(zip(paid_yields, net_yields, field_names), reverse=True)\r\n\r\n        # Unpack the sorted data into separate lists\r\n        paid_yields, net_yields, field_names = zip(*sorted_data)\r\n\r\n        # Plot the net yields\r\n        ax.bar(field_names, paid_yields)\r\n        ax.set_title('Paid Yields')\r\n        ax.tick_params(axis='x', rotation=90)  # Rotate x-axis labels by 90 degrees\r\n\r\n        # Add data labels to the paid yields bars\r\n        for i, v in enumerate(paid_yields):\r\n            ax.text(i, v + 1, str(v), ha='center', fontsize=8)\r\n\r\n    fig.tight_layout()\r\n    plt.show()\r\n\r\n\r\ndef compare_new_psi_algo_vs_old():\r\n    # all_data = {\r\n    #     'logger': [],\r\n    #     'field': [],\r\n    #     'grower': [],\r\n    #     'soil type': [],\r\n    #     'field capacity': [],\r\n    #     'wilting point': [],\r\n    #     'net yield': [],\r\n    #     'paid yield': [],\r\n    #     'ambient temp hours in opt with sun': [],\r\n    #     'ambient temp hours in opt without sun': [],\r\n    #     'vwc 1 in optimum hours': [],\r\n    #     'vwc 2 in optimum hours': [],\r\n    #     'vwc 3 in optimum hours': [],\r\n    #     'vwc 1 in optimum %': [],\r\n    #     'vwc 2 in optimum %': [],\r\n    #     'vwc 3 in optimum %': [],\r\n    #     'vwc 1_2 in optimum hours': [],\r\n    #     'vwc 2_3 in optimum hours': [],\r\n    #     'vwc 1_2 in optimum %': [],\r\n    #     'vwc 2_3 in optimum %': [],\r\n    #     'vwc total datapoints': [],\r\n    #     'psi average': [],\r\n    #     'psi first 3 values': [],\r\n    #     'psi first 3 dates': []\r\n    # }\r\n\r\n    all_data_pickle_file_name = 'all_2022_analysis.pickle'\r\n    all_data_pickle_file_path = 'H:\\\\Shared drives\\\\Stomato\\\\Data Analysis\\\\All Data\\\\Pickles\\\\'\r\n    new_algo_data = open_pickle(filename=all_data_pickle_file_name, specific_file_path=all_data_pickle_file_path)\r\n\r\n    db_2022_psi_file_name = 'psi_pickle_2022.pickle'\r\n    # db_2022_psi_file_path = 'H:\\\\Shared drives\\\\Stomato\\\\2023\\\\Pickle\\\\'\r\n    db_2022_psi_file_path = 'H:\\\\Shared drives\\\\Stomato\\\\Data Analysis\\\\All Data\\\\Pickles\\\\'\r\n    old_algo_data = open_pickle(filename=db_2022_psi_file_name, specific_file_path=db_2022_psi_file_path)\r\n\r\n    for ind, dp in enumerate(new_algo_data['logger']):\r\n        logger_index = -1\r\n        new_algo_first_date = None\r\n        old_algo_last_date = None\r\n        days_diff = None\r\n        try:\r\n            logger_index = old_algo_data['logger'].index(dp)\r\n        except ValueError:\r\n            print(f'{dp} not in database tables')\r\n\r\n        if logger_index >= 0:\r\n            if new_algo_data['psi first 3 dates'][ind]:\r\n                new_algo_first_date_dt = new_algo_data['psi first 3 dates'][ind][0]\r\n                new_algo_first_date = new_algo_first_date_dt.date()\r\n\r\n            if old_algo_data['dates'][logger_index]:\r\n                old_algo_last_date = old_algo_data['dates'][logger_index][-1]\r\n\r\n        if new_algo_first_date is not None and old_algo_last_date is not None:\r\n            days_diff_dt = new_algo_first_date - old_algo_last_date\r\n            days_diff = days_diff_dt.days\r\n\r\n        print(f'Field: {new_algo_data[\"field\"][ind]}\\tLogger: {dp} found')\r\n        if days_diff is not None:\r\n            print(f'Days between: {days_diff}')\r\n            print(f'New dates: {new_algo_data[\"psi first 3 dates\"][ind]}')\r\n            print(f'Old dates: {old_algo_data[\"dates\"][logger_index]}')\r\n        else:\r\n            print('One of the two dates is None')\r\n            print(f'New: {new_algo_first_date}')\r\n            print(f'Old {old_algo_last_date}')\r\n        print()\r\n\r\n\r\ndef setup_weather_stations():\r\n    updated_stations = []\r\n\r\n    # Atmos 41 Weather Stations\r\n    eight_mile = WeatherStation(\r\n        'z6-07111',\r\n        '99294-35668',\r\n        '8 Mile',\r\n        'Tomatoes',\r\n        datetime(2023, 1, 1).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='248'\r\n    )\r\n    eight_mile.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(eight_mile)\r\n\r\n    ave_7 = WeatherStation(\r\n        'z6-02178',\r\n        '74962-10103',\r\n        'Ave 7',\r\n        'Tomatoes',\r\n        datetime(2023, 1, 1).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='80'\r\n    )\r\n    ave_7.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(ave_7)\r\n\r\n    ben_fast = WeatherStation(\r\n        'z6-15905',\r\n        '28402-51648',\r\n        'Ben Fast',\r\n        'Tomatoes',\r\n        datetime(2023, month=4, day=12).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='5'\r\n    )\r\n    ben_fast.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(ben_fast)\r\n\r\n    bone_farms = WeatherStation(\r\n        'z6-16164',\r\n        '64334-12769',\r\n        'Bone Farms',\r\n        'Tomatoes',\r\n        datetime(2023, 1, 1).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='146'\r\n    )\r\n    bone_farms.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(bone_farms)\r\n\r\n    bullseye = WeatherStation(\r\n        'z6-02054',\r\n        '16128-76869',\r\n        'Bullseye',\r\n        'Tomatoes',\r\n        datetime(2023, 1, 1).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='250'\r\n    )\r\n    bullseye.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(bullseye)\r\n\r\n    bullero = WeatherStation(\r\n        'z6-11967',\r\n        '36891-99736',\r\n        'Bullero',\r\n        'Tomatoes',\r\n        datetime(2023, 1, 1).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='226'\r\n    )\r\n    bullero.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(bullero)\r\n\r\n    david_santos = WeatherStation(\r\n        'z6-12376',\r\n        '78094-52955',\r\n        'David Santos',\r\n        'Tomatoes',\r\n        datetime(2023, 5, 17).date(),\r\n        planting_date=None,\r\n        start_date=datetime(2023, 4, 14).date(),\r\n        end_date=datetime(2023, 9, 2).date(),\r\n        station_type='Weather Station',\r\n        cimis_station='124'\r\n    )\r\n    david_santos.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(david_santos)\r\n\r\n    dresick_n = WeatherStation(\r\n        'z6-16147',\r\n        '13969-76188',\r\n        'Dresick N',\r\n        'Tomatoes',\r\n        datetime(2023, month=4, day=15).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='2'\r\n    )\r\n    dresick_n.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(dresick_n)\r\n\r\n    dresick_s = WeatherStation(\r\n        'z6-16138',\r\n        '65607-66874',\r\n        'Dresick S',\r\n        'Tomatoes',\r\n        datetime(2023, month=4, day=15).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='2'\r\n    )\r\n    dresick_s.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(dresick_s)\r\n\r\n    fantozzi = WeatherStation(\r\n        'z6-23435',\r\n        '92415-62348',\r\n        'Fantozzi',\r\n        'Tomatoes',\r\n        datetime(2023, month=7, day=5).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='71'\r\n    )\r\n    fantozzi.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(fantozzi)\r\n\r\n    lafayet = WeatherStation(\r\n        'z6-07111',\r\n        '99294-35668',\r\n        'Lafayet',\r\n        'Tomatoes',\r\n        datetime(2023, month=6, day=16).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='248'\r\n    )\r\n    lafayet.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(lafayet)\r\n\r\n    matteoli_mb = WeatherStation(\r\n        'z6-11406',\r\n        '71062-40854',\r\n        'Matteoli MB',\r\n        'Tomatoes',\r\n        datetime(2023, month=1, day=1).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='235'\r\n    )\r\n    matteoli_mb.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(matteoli_mb)\r\n\r\n    matteoli_kbasin = WeatherStation(\r\n        'z6-11920',\r\n        '84949-16401',\r\n        'Matteoli KBasin',\r\n        'Tomatoes',\r\n        datetime(2023, month=1, day=1).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='235'\r\n    )\r\n    matteoli_kbasin.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(matteoli_kbasin)\r\n\r\n    nees = WeatherStation(\r\n        'z6-16154',\r\n        '51205-71538',\r\n        'Nees',\r\n        'Tomatoes',\r\n        datetime(2023, month=1, day=1).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='124'\r\n    )\r\n    nees.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(nees)\r\n\r\n    rg_farms = WeatherStation(\r\n        'z6-23255',\r\n        '56884-23705',\r\n        'RG Farms',\r\n        'Tomatoes',\r\n        datetime(2023, month=7, day=27).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='126'\r\n    )\r\n    rg_farms.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(rg_farms)\r\n\r\n    tp = WeatherStation(\r\n        'z6-16139',\r\n        '29296-99927',\r\n        'TP',\r\n        'Tomatoes',\r\n        datetime(2023, month=1, day=1).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='250'\r\n    )\r\n    tp.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(tp)\r\n\r\n    wild_oak = WeatherStation(\r\n        'z6-01874',\r\n        '67392-80462',\r\n        'Wild Oak',\r\n        'Tomatoes',\r\n        datetime(2023, month=1, day=1).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='39'\r\n    )\r\n    wild_oak.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(wild_oak)\r\n\r\n    sanguinetti = WeatherStation(\r\n        'z6-07162',\r\n        '68090-60446',\r\n        'Sanguinetti',\r\n        'Tomatoes',\r\n        datetime(2023, month=5, day=26).date(),\r\n        planting_date=None,\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Weather Station',\r\n        cimis_station='70'\r\n    )\r\n    sanguinetti.uninstall_date = datetime(2023, month=12, day=31).date()\r\n    updated_stations.append(sanguinetti)\r\n\r\n    # Gradient Atmos 14 Stations\r\n    bullseye_oe10_E = WeatherStation(\r\n        'z6-11974',\r\n        '60644-59745',\r\n        'Bullseye OE10 East Gradient',\r\n        'Tomatoes',\r\n        datetime(2023, month=4, day=26).date(),\r\n        planting_date=datetime(2023, month=4, day=16).date(),\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Gradient Station',\r\n        cimis_station='226'\r\n    )\r\n    bullseye_oe10_E.uninstall_date = datetime(2023, month=8, day=11).date()\r\n    updated_stations.append(bullseye_oe10_E)\r\n\r\n    bullseye_oe10_C = WeatherStation(\r\n        'z6-11407',\r\n        '60892-87745',\r\n        'Bullseye OE10 Center Gradient',\r\n        'Tomatoes',\r\n        datetime(2023, month=4, day=26).date(),\r\n        planting_date=datetime(2023, month=4, day=16).date(),\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Gradient Station',\r\n        cimis_station='226'\r\n    )\r\n    bullseye_oe10_C.uninstall_date = datetime(2023, month=8, day=11).date()\r\n    updated_stations.append(bullseye_oe10_C)\r\n\r\n    bullseye_oe10_W = WeatherStation(\r\n        'z6-11580',\r\n        '93196-73070',\r\n        'Bullseye OE10 West Gradient',\r\n        'Tomatoes',\r\n        datetime(2023, month=4, day=26).date(),\r\n        planting_date=datetime(2023, month=4, day=16).date(),\r\n        start_date=None,\r\n        end_date=None,\r\n        station_type='Gradient Station',\r\n        cimis_station='226'\r\n    )\r\n    bullseye_oe10_W.uninstall_date = datetime(2023, month=8, day=11).date()\r\n    updated_stations.append(bullseye_oe10_W)\r\n\r\n    # lucero_towerline_blue_s = WeatherStation(\r\n    #     'z6-12295',\r\n    #     '52213-43606',\r\n    #     'Lucero Towerline Blue S Gradient',\r\n    #     'Tomatoes',\r\n    #     datetime(2023, month=4, day=6).date(),\r\n    #     planting_date=datetime(2023, month=3, day=28).date(),\r\n    #     start_date=None,\r\n    #     end_date=None,\r\n    #     station_type='Gradient Station'\r\n    # )\r\n    # lucero_towerline_blue_s.uninstall_date = datetime(2023, month=7, day=14).date()\r\n    # updated_stations.append(lucero_towerline_blue_s)\r\n\r\n    print()\r\n    pickle_file_name = 'weather_stations_2023.pickle'\r\n    pickle_file_path = 'H:\\\\Shared drives\\\\Stomato\\\\HeatUnits\\\\Pickles\\\\'\r\n    write_pickle(updated_stations, filename=pickle_file_name, specific_file_path=pickle_file_path)\r\n\r\n\r\ndef generate_gradient_grower_fields_report():\r\n    growers = open_pickle()\r\n    data = []\r\n    for grower in growers:\r\n        print(grower.name)\r\n        for field in grower.fields:\r\n            print('\\t', field.nickname, field.crop_type, field.acres)\r\n            rnd = False\r\n            for logger in field.loggers:\r\n                if logger.rnd:\r\n                    print('\\t\\t', logger.name, 'R&D')\r\n                    rnd = True\r\n                    break\r\n            if rnd:\r\n                field_type = 'R&D'\r\n            else:\r\n                field_type = field.field_type\r\n            field_dict = {\r\n                'Grower': grower.name,\r\n                'Field': field.nickname,\r\n                'Crop Type': field.crop_type,\r\n                'Field Type': field_type,\r\n                'Acres': float(field.acres),\r\n                'Region': grower.region\r\n            }\r\n            data.append(field_dict)\r\n    df = pd.DataFrame(data)\r\n    df.to_excel(\"gradient_grower_fields_2023.xlsx\", index=False)\r\n\r\ndef update_grower_field_gpm_and_irrigation_set_acres(grower_name: str, field_name: str, gpm = None, irrigation_set_acres = None):\r\n    growers = open_pickle()\r\n    for grower in growers:\r\n        if grower.name == grower_name:\r\n            for field in grower.fields:\r\n                if field.name == field_name:\r\n                    for logger in field.loggers:\r\n                        if gpm is not None:\r\n                            logger.gpm = float(gpm)\r\n                        if irrigation_set_acres is not None:\r\n                            logger.irrigation_set_acres = float(irrigation_set_acres)\r\n    write_pickle(growers)\r\n\r\n\r\n# show_pickle()\r\n\r\n# growers = open_pickle()\r\n#\r\n# for grower in growers:\r\n#     if grower.name == 'Riley Chaney Farms':\r\n#         for field in grower.fields:\r\n#             print(f'Field: {field.name}')\r\n#             for logger in field.loggers:\r\n#                 print(f'\\tLogger: {logger.name}  |  GPM: {logger.gpm}  |  Irrigation Set Acres: {logger.irrigation_set_acres}')\r\n#\r\n# update_grower_field_gpm_and_irrigation_set_acres('Riley Chaney Farms', 'Riley Chaney Farms18', gpm=380)\r\n# update_grower_field_gpm_and_irrigation_set_acres('Riley Chaney Farms', 'Riley Chaney Farms4W', gpm=520)\r\n# update_grower_field_gpm_and_irrigation_set_acres('Riley Chaney Farms', 'Riley Chaney Farms16', gpm=650)\r\n# update_grower_field_gpm_and_irrigation_set_acres('Riley Chaney Farms', 'Riley Chaney Farms4E', gpm=1000)\r\n# update_grower_field_gpm_and_irrigation_set_acres('Riley Chaney Farms', 'Riley Chaney Farms27', gpm=1270)\r\n#\r\n#\r\n# for grower in growers:\r\n#     if grower.name == 'Riley Chaney Farms':\r\n#         for field in grower.fields:\r\n#             print(f'Field: {field.name}')\r\n#             for logger in field.loggers:\r\n#                 print(f'\\tLogger: {logger.name}  |  GPM: {logger.gpm}  |  Irrigation Set Acres: {logger.irrigation_set_acres}')\r\n\r\n# remove_grower('Riley Chaney Farms')\r\n# remove_field('Riley Chaney Farms', 'Riley Chaney Farms13')\r\n# remove_field('Riley Chaney Farms', 'Riley Chaney Farms3')\r\n# remove_field('Riley Chaney Farms', 'Riley Chaney Farms15')\r\n# remove_field('Riley Chaney Farms', 'Riley Chaney Farms24')\r\n# remove_field('Riley Chaney Farms', 'Riley Chaney Farms27')\r\n\r\n# generate_gradient_grower_fields_report()\r\n\r\n# setup_weather_stations()\r\n\r\n# pickle_file_name = 'weather_stations_2023.pickle'\r\n# # old_pickle_file_name = 'weather_stations_2023 OLD BEFORE CLASS CHANGE.pickle'\r\n# pickle_file_path = 'H:\\\\Shared drives\\\\Stomato\\\\HeatUnits\\\\Pickles\\\\'\r\n# # old_weather_stations = open_pickle(filename=old_pickle_file_name, specific_file_path=pickle_file_path)\r\n# weather_stations = open_pickle(filename=pickle_file_name, specific_file_path=pickle_file_path)\r\n# for station in weather_stations:\r\n#     if station.name == 'Ben Fast':\r\n#         station.id = 'z6-15905'\r\n# write_pickle(weather_stations, filename=pickle_file_name, specific_file_path=pickle_file_path)\r\n# print()\r\n\r\n# varieties = Varieties()\r\n# # varieties.show_all_varieties()\r\n# print(varieties.get_variety_days_to_harvest('1996'))\r\n\r\n# temp_ai_application()\r\n\r\n# cimis = CIMIS()\r\n# cimis_station = CimisStation()\r\n# inactive_cimis_station_list = cimis_station.return_inactive_cimis_stations_list()\r\n# closest_cimis_station = cimis.get_closest_cimis_station(37.8806321, -121.1559947, [])\r\n# print(closest_cimis_station)\r\n\r\n# compare_new_psi_algo_vs_()\r\n# show_pickle()\r\n# only_certain_growers_update(['Riley Chaney Farms'], get_weather=True, get_data=True, write_to_db=True, write_to_portal=True)\r\n# only_certain_growers_field_logger_update('Riley Chaney Farms', 'Riley Chaney Farms3', 'RC-3-NE', write_to_db=True)\r\n\r\n# show_grower('Riley Chaney Farms')\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     if grower.name == 'Riley Chaney Farms':\r\n#         print(grower.name, grower.active)\r\n#         for field in grower.fields:\r\n#             # print('\\t', field.name, 'Active: ', field.active)\r\n#             print(field)\r\n#             for logger in field.loggers:\r\n#                 print('\\t',logger.id, logger.name)\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     if grower.name == 'Riley Chaney Farms':\r\n#         for field in grower.fields:\r\n#             if field.name == 'Riley Chaney Farms3':\r\n#                 for logger in field.loggers:\r\n#                     if logger.id == 'z6-11928':\r\n#                         print(logger.id, logger.password)\r\n#                         logger.password = '12608-28613'\r\n#                         print(logger.id, logger.password)\r\n# write_pickle(growers)\r\n\r\n# new_year_pickle_cleanup()\r\n\r\n# test_switch_cases()\r\n# temp_ai_application()\r\n\r\n\r\n\r\n# setup_ai_game_data(\r\n#     \"2022_pickle.pickle\",\r\n#     \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\",\r\n#     \"2022_ai_game_data.pickle\",\r\n#     \"H:\\\\Shared drives\\\\Stomato\\\\AIIrrigationGame\\\\\"\r\n# )\r\n\r\n# temp_ai_application()\r\n\r\n# show_pickle()\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     print(grower.name)\r\n# print()\r\n# remove_grower('Dwelley Farms')\r\n\r\n# show_pickle()\r\n\r\n# show_pickle()\r\n# cimis_stations_pickle = open_pickle(filename=\"cimisStation.pickle\")\r\n# print()\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     print(grower.name)\r\n\r\n# only_certain_growers_update(['Dwelley Farms'], get_weather=True, get_data=True, write_to_portal=True, write_to_db=True)\r\n# only_certain_growers_field_update('Dwelley Farms', 'Dwelley FarmsTKs', get_weather=True, get_data=True, write_to_portal=True, write_to_db=True)\r\n\r\n\r\n# show_grower('Riley Chaney Farms')\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     if grower.name == 'Riley Chaney Farms':\r\n#         print()\r\n#         for field in grower.fields:\r\n#             if field.name == 'Riley Chaney FarmsRN 2 LLC':\r\n#                 print(field.name, field.nickname)\r\n#                 field.nickname = 'R&N 2 LLC'\r\n#                 print(field.name, field.nickname)\r\n# write_pickle(growers)\r\n\r\n# only_certain_growers_field_update('Barrios Farms', 'Barrios Farms22', get_weather=True, get_data=True, write_to_db=True)\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     if grower.name == 'Barrios Farms':\r\n#         print()\r\n        # for field in grower.fields:\r\n        #     if field.name == 'Riley Chaney FarmsRN 2 LLC':\r\n        #         print(field.name, field.nickname)\r\n        #         field.nickname = 'R&N 2 LLC'\r\n        #         print(field.name, field.nickname)\r\n\r\n# show_pickle()\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             old_opt_low = logger.soil.optimum_lower\r\n#             old_opt_high = logger.soil.optimum_upper\r\n#             new_soil = Soil(field_capacity=logger.soil.field_capacity, wilting_point=logger.soil.wilting_point)\r\n#             logger.soil = new_soil\r\n#             new_soil_low = new_soil.optimum_lower\r\n#             if old_opt_low != new_soil_low:\r\n#                 print(f'Old optimum: {old_opt_low} - {old_opt_high}')\r\n#                 print(f'New optimum: {new_soil_low} - {new_soil.optimum_upper}')\r\n#                 print()\r\n#\r\n# write_pickle(growers)\r\n\r\n\r\n\r\n\r\n# show_pickle()\r\n\r\n\r\n# new_year_pickle_cleanup()\r\n# remove_inactive_fields_from_growers_from_pickle()\r\n\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             if logger.name == 'LM-17J-S':\r\n#                 logger.show_irrigation_ledger()\r\n#                 for date, switch_list in logger.irrigation_ledger.items():\r\n#                     for ind, switch_val in enumerate(switch_list):\r\n#                         if switch_val == 15:\r\n#                             logger.irrigation_ledger[date][ind] = 60\r\n#                 print()\r\n#                 logger.show_irrigation_ledger()\r\n# write_pickle(growers)\r\n# print()\r\n\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     print(grower)\r\n#\r\n# cimis_stations_pickle = open_pickle(filename=\"cimisStation.pickle\")\r\n#\r\n# pickle_file_name = 'weather_stations_2023.pickle'\r\n# pickle_file_path = 'H:\\\\Shared drives\\\\Stomato\\\\HeatUnits\\\\'\r\n# weather_stations = open_pickle(filename=pickle_file_name, specific_file_path=pickle_file_path)\r\n\r\n\r\n\r\n\r\n\r\n# weather_stations = open_pickle(filename=pickle_file_name, specific_file_path=pickle_file_path)\r\n\r\n# only_certain_growers_field_logger_update('Barrios Farms', 'Barrios Farms25E', 'BF-25E-C', write_to_db=True, subtract_from_mrid=62)\r\n\r\n# dbwriter = DBWriter()\r\n# db_dates = dbwriter.grab_specific_column_table_data('Barrios_Farms25E', 'BF-25E-C', 'stomato-2023', 'date')\r\n# db_dates_list = [row[0] for row in db_dates]\r\n# print()\r\n\r\n# reset_updated_all()\r\n# update_information(get_et=True, write_to_db=True)\r\n\r\n\r\n\r\n# for grower in growers:\r\n    # print()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if field.name == 'Lucero Rio VistaB 17-22':\r\n#             for logger in field.loggers:\r\n#                 print(type(logger.daily_switch))\r\n#                 logger.gpm = 4488\r\n#                 logger.irrigation_set_acres = 215\r\n# #     print(logger.name, logger.soil.soil_type)\r\n#             #     logger.soil.set_soil_type('Sandy Clay Loam')\r\n#             #     print(logger.name, logger.soil.soil_type)\r\n# write_pickle(growers)\r\n\r\n# cimis = CIMIS()\r\n# # # cimisStation = CimisStation()\r\n# # # stations = get_all_current_cimis_stations()\r\n# # # stations = cimisStation.return_list_of_stations()\r\n# cimis_stations_pickle = open_pickle(filename=\"cimisStation.pickle\")\r\n# # Convert the integers to strings\r\n# cimis_station_string_list = [str(station.station_number) for station in cimis_stations_pickle]\r\n#\r\n# # Join the strings with commas\r\n# cimis_stations_list_string = ', '.join(cimis_station_string_list)\r\n# print(cimis_stations_list_string)\r\n#\r\n# start_date = str(date.today() - timedelta(3))\r\n# end_date = str(date.today() - timedelta(1))\r\n# all_cimis_station_et = cimis.get_eto(cimis_stations_list_string, start_date, end_date)\r\n# print()\r\n# pprint.pprint(all_cimis_station_et)\r\n\r\n# show_pickle()\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     print(grower.name)\r\n\r\n# Testing new single CIMIS API call\r\n# dict_of_stations = {}\r\n# all_current_cimis_stations = open_pickle(filename=\"cimisStation.pickle\")\r\n# for station in all_current_cimis_stations:\r\n#     dict_of_stations[station.station_number] = {'station': station, 'dates': [], 'eto': []}\r\n# print()\r\n\r\n# ########################################\r\n# ### TESTING CIMIS CALL AT 12\r\n# cimis = CIMIS()\r\n# cimis_stations_pickle = open_pickle(filename=\"cimisStation.pickle\")\r\n# print()\r\n# start_date = str(date.today() - timedelta(1))\r\n# end_date = str(date.today() - timedelta(1))\r\n# for stations in cimis_stations_pickle:\r\n#     stations.updated = False\r\n# all_cimis_station_et = cimis.get_all_stations_et_data(cimis_stations_pickle, start_date, end_date)\r\n# print()\r\n# #########################################\r\n# write_all_et_values_to_db(all_cimis_station_et)\r\n\r\n# print()\r\n\r\n# project = 'stomato-info'\r\n# dataset_id = f\"{project}.ET.105\"\r\n# dataset_id = \"`\" + dataset_id + \"`\"\r\n# #\r\n# dbwriter = DBWriter()\r\n# dml_statement = f\"SELECT * FROM {dataset_id} WHERE date BETWEEN DATE(\\'2023-03-01\\') and DATE(\\'2023-03-25\\') ORDER BY date ASC\"\r\n# result = dbwriter.run_dml(dml_statement, project=project)\r\n#\r\n# date_data = []\r\n# eto_data = []\r\n#\r\n# for row in result:\r\n#     date_data.append(row['date'])\r\n#     eto_data.append(row['eto'])\r\n# print()\r\n\r\n# dml = f\"UPDATE `test.test.test`\" \\\r\n#       + f\" SET daily_switch = 55\"\\\r\n#       + f\", daily_hours = 0.8\"\\\r\n#       + f\", daily_inches = 1.5 WHERE date = 'date'\"\r\n#\r\n# print(dml)\r\n\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             logger.irrigation_ledger = {}\r\n# write_pickle(growers)\r\n# print()\r\n\r\n# for each_dict in dict_of_stations:\r\n#     print(f\"Station: {dict_of_stations[each_dict]['station'].station_number}\")\r\n# print()\r\n\r\n# my_list = ['pear']\r\n# if 'apple' not in my_list:\r\n#     print(\"apple not in list\")\r\n\r\n# all_cimis_station_et = cimis.get_all_stations_et_data(cimis_stations_pickle, start_date, end_date)\r\n\r\n\r\n# show_pickle()\r\n# temp_ai_application()\r\n# Testing writing a html doc for notifications instead of a txt\r\n# lat = 37.0544503152434\r\n# long = -120.80964223605376\r\n# saulisms = Saulisms()\r\n# saying, saying_date = saulisms.get_random_saulism()\r\n# file_path = \"C:\\\\Users\\\\javie\\\\Desktop\\\\notification_html_test.html\"\r\n# with open(file_path, 'a') as the_file:\r\n#     the_file.write(\"<!DOCTYPE html>\\n\")\r\n#     the_file.write(\"<html>\\n\")\r\n#     the_file.write(\"<body>\\n\")\r\n#     the_file.write(\"<h2>SENSOR ERRORS</h2>\\n\")\r\n#     the_file.write(f\"<h2 style='font-style: italic; font-size:150%;'>\\\"{saying}\\\", {saying_date}</h2>\")\r\n#     the_file.write(\"<h3>=== New Grower ===</h3>\\n\")\r\n#     the_file.write(\"<p>-------------------</p>\\n\")\r\n#     the_file.write(\"<p>Field: Lucero Rio Vista74, 75</p>\\n\")\r\n#     the_file.write(\"<p>Logger: RV-74_75-SE</p>\\n\")\r\n#     the_file.write(\"<p>Logger ID: z6-12306</p>\\n\")\r\n#     the_file.write(\"<p>Date: 06/26/23</p>\\n\")\r\n#     the_file.write(\"<p>Sensor: Canopy Temp</p>\\n\")\r\n#     the_file.write(\"<p>-> Canopy Temp is showing None at some point in the day (Not necessarily at the hottest time). Connection issue?</p>\\n\")\r\n#     the_file.write(f\"<a href='https://www.google.com/maps/search/?api=1&query={lat},{long}' target='_blank'>Location</a>\\n\")\r\n#     the_file.write(\"<p>-------------------</p>\\n\")\r\n#     the_file.write(\"</body>\\n\")\r\n#     the_file.write(\"</html>\\n\")\r\n\r\n# show_pickle()\r\n\r\n# Change Soil Type for a Logger\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             if logger.name == 'RC-24-SW':\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 logger.soil.set_soil_type('Clay Loam')\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 print('---------------------')\r\n#             if logger.name == 'RN-2LLC-E':\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 logger.soil.set_soil_type('Clay Loam')\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 print('---------------------')\r\n#             if logger.name == 'RN-2LLC-N':\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 logger.soil.set_soil_type('Sandy Clay Loam')\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 print('---------------------')\r\n#             if logger.name == 'RN-2LLC-W':\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 logger.soil.set_soil_type('Sandy Clay Loam')\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 print('---------------------')\r\n#             if logger.name == 'RC-16-E':\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 logger.soil.set_soil_type('Clay Loam')\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 print('---------------------')\r\n#             if logger.name == 'RC-13-E':\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 logger.soil.set_soil_type('Clay Loam')\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 print('---------------------')\r\n#             if logger.name == 'RC-4E-C':\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 logger.soil.set_soil_type('Clay Loam')\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 print('---------------------')\r\n#             if logger.name == 'RC-3-NE':\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 logger.soil.set_soil_type('Sandy Loam')\r\n#                 print(logger.name, logger.soil.soil_type, logger.soil.field_capacity, logger.soil.wilting_point)\r\n#                 print('---------------------')\r\n#\r\n#\r\n# write_pickle(growers)\r\n\r\n# # Testing some notification generation and writing\r\n# growers = open_pickle()\r\n# techs = get_all_technicians(growers)\r\n# notifications_setup(growers, techs, file_type='html')\r\n# reset_updated_all()\r\n# update_information(get_data=True, check_for_notifications=True)\r\n\r\n# only_certain_growers_field_logger_update('Saul', 'Meza', 'Development-C', check_for_notifications=True, subtract_from_mrid=24)\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             print()\r\n#             print(f\"https://www.google.com/maps/search/?api=1&query={logger.lat},{logger.long}\")\r\n#             print()\r\n#         if field.crop_type not in ['Tomatoes', 'tomatoes', 'tomato', 'Tomato']:\r\n#             print(field.name, field.crop_type)\r\n#         if field.loggers[0].rnd:\r\n#             field.field_type = 'R&D'\r\n#         else:\r\n#             field.field_type = 'Commercial'\r\n# print(f'{field.name} - {field.field_type}')\r\n# write_pickle(growers)\r\n\r\n# print(field.name)\r\n# for logger in field.loggers:\r\n#     print(f'\\t{logger.name} - {logger.rnd}')\r\n\r\n# df = pd.DataFrame(columns=['Gradient Grower', 'Gradient Grower-Field', 'Gradient Field', 'Gradient Planting Date', 'Gradient Uninstall Date'])\r\n#\r\n# pickle_file_name = \"2022_pickle.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\"\r\n# growers = open_pickle(filename=pickle_file_name, specific_file_path=pickle_file_path)\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if field.crop_type in ['Tomatoes', 'tomatoes', 'tomato', 'Tomato']:\r\n#             df = df.append({'Gradient Grower': grower.name, 'Gradient Grower-Field': field.name, 'Gradient Field': field.nickname, 'Gradient Planting Date': field.loggers[0].planting_date, 'Gradient Uninstall Date': field.loggers[0].uninstall_date}, ignore_index=True)\r\n#\r\n# print()\r\n# print(df)\r\n# df.to_excel('growers_fields.xlsx', index=False)\r\n\r\n# pickle_file_name = \"ai_game_2023_data_errors.pickle\"\r\n# pickle_file_path = \"C:\\\\Users\\\\javie\\\\Desktop\\\\AI Game v3 Distribution\\\\\"\r\n# ai_data = open_pickle(filename=pickle_file_name, specific_file_path=pickle_file_path)\r\n# print()\r\n# ai_data = []\r\n#\r\n# write_pickle(ai_data, filename=pickle_file_name, specific_file_path=pickle_file_path)\r\n\r\n\r\n# pickle_file_name = \"2022_pickle.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\"\r\n# growers = open_pickle(filename=pickle_file_name, specific_file_path=pickle_file_path)\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if field.loggers[0].rnd:\r\n#             field.field_type = 'R&D'\r\n#         else:\r\n#             field.field_type = 'Commercial'\r\n#         print(f'{field.name} - {field.field_type}')\r\n# write_pickle(growers, filename=pickle_file_name, specific_file_path=pickle_file_path)\r\n\r\n# pickle_file_name = \"2022_pickle.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\"\r\n# graph_yields(pickle_file_name, pickle_file_path, 'Paid')\r\n\r\n# pickle_file_name = \"2022_pickle.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\"\r\n# get_tomato_yield_data(pickle_file_name, pickle_file_path, '2022 Tomato Yield.xlsx', 0, 263)\r\n# show_specific_pickle(pickle_file_name, specific_file_path=pickle_file_path)\r\n\r\n# pickle_file_name = \"2022_pickle.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\"\r\n# growers = open_specific_pickle(pickle_file_name, specific_file_path=pickle_file_path)\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         print(field.name, field.loggers[0].uninstall_date)\r\n#         field.crop_type = field.loggers[0].cropType\r\n#         field.net_yield = None\r\n#         field.paid_yield = None\r\n# write_specific_pickle(growers, pickle_file_name, specific_file_path=pickle_file_path)\r\n# show_specific_pickle(pickle_file_name, specific_file_path=pickle_file_path)\r\n\r\n# pickle_file_name = \"2022_pickle.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\"\r\n# growers = open_specific_pickle(pickle_file_name, specific_file_path=pickle_file_path)\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             if not hasattr(logger, 'rnd'):\r\n#                 logger.crop_type = logger.cropType\r\n#                 print(logger.grower.name, logger.field.name, logger.name, logger.crop_type)\r\n#                 logger.rnd = False\r\n#                 if logger.name == 'Development-C':\r\n#                     print(logger.grower.name, logger.field.name, logger.name, logger.crop_type)\r\n#                     logger.rnd = True\r\n#                 # logger.rnd = True\r\n# write_specific_pickle(growers, pickle_file_name, specific_file_path=pickle_file_path)\r\n# print(datetime.now().date())\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             if logger.name == 'MB-52-NE':\r\n#                 logger.consecutive_ir_values = deque()\r\n#                 logger.consecutive_ir_values.append((8.212098906263984, 26.622))\r\n#             elif logger.name == 'MB-52-SW':\r\n#                 logger.consecutive_ir_values = deque()\r\n#                 logger.consecutive_ir_values.append((4.40852468436712, 10.89))\r\n# write_pickle(growers)\r\n\r\n# show_pickle()\r\n\r\n# gpm = '1,200'\r\n# print(float(gpm))\r\n\r\n\r\n# def clean_list(list, remove_start, remove_end):\r\n#     clean = list[remove_start:len(list) - remove_end]\r\n#     print(clean)\r\n#\r\n# list = [1,2,3,4,5,6,7,8,9,10]\r\n# clean_list(list, 0, 0)\r\n\r\n# show_pickle()\r\n\r\n# only_certain_growers_field_logger_update('Matteoli Brothers', 'Matteoli Brothers50', 'MB-50-C', write_to_db=True)\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if field.name == 'Schreiner115':\r\n#             for logger in field.loggers:\r\n#                 print(logger.soil.soil_type)\r\n#                 print(logger.soil.field_capacity)\r\n#                 print(logger.soil.wilting_point)\r\n#                 logger.soil.set_soil_type('Silt Loam')\r\n#                 print(logger.soil.soil_type)\r\n#                 print(logger.soil.field_capacity)\r\n#                 print(logger.soil.wilting_point)\r\n# write_pickle(growers)\r\n# logger.to_string()\r\n# logger.ir_active = True\r\n# logger.to_string()\r\n# write_pickle(growers)\r\n# pickle_file_name = \"2022_pickle.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\"\r\n# field_capacities = []\r\n# field_capacities_data = []\r\n# growers = open_specific_pickle(pickle_file_name, specific_file_path=pickle_file_path)\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             logger.field_capacity = logger.fieldCapacity\r\n#             if logger.field_capacity not in field_capacities:\r\n#                 percent = 0.15\r\n#                 fc_upper = round(logger.field_capacity + (logger.field_capacity * percent), 1)\r\n#                 fc_lower = round(logger.field_capacity - (logger.field_capacity * percent), 1)\r\n#                 field_capacities.append(logger.field_capacity)\r\n#                 field_capacities_data.append((logger.field_capacity, fc_upper, fc_lower))\r\n#\r\n# for fc_data in field_capacities_data:\r\n#     fc, fc_u, fc_l = fc_data\r\n#     print(f'Upper: {fc_u}')\r\n#     print(f'FC: {fc}')\r\n#     print(f'Lower: {fc_l}')\r\n#     print()\r\n# print(field_capacities)\r\n\r\n# all_acres = []\r\n# total_acres = 0\r\n# number_of_fields = 0\r\n# price_per_station = []\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if field.crop_type in ['Tomatoes', 'Tomato', 'tomatoes', 'tomato']:\r\n#             if not field.loggers[0].rnd:\r\n#                 # print(type(field.acres))\r\n#                 total_acres += float(field.acres)\r\n#                 number_of_fields += 1\r\n#                 price_per_station.append(50 * float(field.acres) / len(field.loggers))\r\n#\r\n# # print(total_acres/number_of_fields)\r\n# print(price_per_station)\r\n# print(number_of_fields)\r\n#\r\n# print(sum(price_per_station)/len(price_per_station))\r\n\r\n\r\n# pickle_file_name = \"2022_pickle.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\"\r\n# # field_capacities = []\r\n# # field_capacities_data = []\r\n# growers = open_specific_pickle(pickle_file_name, specific_file_path=pickle_file_path)\r\n# all_acres = []\r\n# total_acres = 0\r\n# number_of_fields = 0\r\n# price_per_station = []\r\n# # growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if field.crop_type in ['Tomatoes', 'Tomato', 'tomatoes', 'tomato']:\r\n#             if not field.loggers[0].rnd:\r\n#                 total_acres += float(field.acres)\r\n#                 number_of_fields += 1\r\n#                 price_per_station.append(50 * float(field.acres) / len(field.loggers))\r\n#\r\n# # print(total_acres/number_of_fields)\r\n# print(price_per_station)\r\n# total_price = 0\r\n# for station in price_per_station:\r\n#     total_price += station\r\n# print(total_price/len(price_per_station))\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             st = Soil(field_capacity=logger.soil.field_capacity, wilting_point=logger.soil.wilting_point)\r\n#             logger.soil = st\r\n#\r\n#             print(field.name, logger.name)\r\n#             print(f'Soil type: {logger.soil.soil_type}')\r\n#             print(f'Ranges: {logger.soil.bounds}')\r\n# write_pickle(growers)\r\n# print(logger.field.name, logger.name, logger.field_capacity, logger.wilting_point)\r\n\r\n# pickle_file_name = \"2022_pickle.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\"\r\n# growers = open_pickle(filename=pickle_file_name, specific_file_path=pickle_file_path)\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             # logger.field_capacity = logger.fieldCapacity\r\n#             # logger.wilting_point = logger.wiltingPoint\r\n#             st = Soil(field_capacity=logger.soil.field_capacity, wilting_point=logger.soil.wilting_point)\r\n#             logger.soil = st\r\n# #\r\n#             print(field.name, logger.name)\r\n#             print(f'Soil type: {logger.soil.soil_type}')\r\n#             print(f'Ranges: {logger.soil.bounds}')\r\n# #             print()\r\n# write_pickle(growers, filename=pickle_file_name, specific_file_path=pickle_file_path)\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             soil_type = logger.soil.soil_type\r\n#             new_soil = Soil(soil_type=soil_type)\r\n#             logger.soil = new_soil\r\n# write_pickle(growers)\r\n\r\n# show_pickle()\r\n\r\n# pickle_file_name = \"2022_pickle.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\"\r\n# growers = open_specific_pickle(pickle_file_name, specific_file_path=pickle_file_path)\r\n# total_2022_fields = 0\r\n# total_2022_loggers = 0\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         total_2022_fields += 1\r\n#         for logger in field.loggers:\r\n#             total_2022_loggers += 1\r\n# print(f'Field #: {total_2022_fields}')\r\n# print(f'Logger #: {total_2022_loggers}')\r\n\r\n# pickle_file_name = \"2023_pickle.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2023\\\\Pickle\\\\\"\r\n# pickle_file_name = \"entry.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2021\\\\Pickle\\\\\"\r\n# pickle_file_name = \"2022_pickle.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\"\r\n# growers = open_specific_pickle(pickle_file_name, specific_file_path=pickle_file_path)\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             logger.install_date = None\r\n#             logger.broken = False\r\n#         field.crop_type = field.loggers[0].crop_type\r\n#         field.net_yield = None\r\n#         field.paid_yield = None\r\n# print('Done')\r\n# write_specific_pickle(growers, pickle_file_name, specific_file_path=pickle_file_path)\r\n# show_specific_pickle(pickle_file_name, specific_file_path=pickle_file_path)\r\n# show_pickle()\r\n# pickle_file_name = \"entry.pickle\"\r\n# pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2021\\\\Pickle\\\\\"\r\n# info = {}\r\n# growers = open_specific_pickle(pickle_file_name, specific_file_path=pickle_file_path)\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             if 'z6' in logger.id:\r\n#                 if logger.id not in info:\r\n#                     info[logger.id] = []\r\n#                 info[logger.id].append(logger.field.name + ' -> ' + logger.name)\r\n# pprint.pprint(info)\r\n# write_specific_pickle(growers, pickle_file_name, specific_file_path=pickle_file_path)\r\n# show_specific_pickle(pickle_file_name, specific_file_path=pickle_file_path)\r\n\r\n\r\n# turn_ai_game_data_into_csv(\"ai_game_data2.pickle\", \"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\\", 'ai_game_data_2022')\r\n# grower_pickle_file_name = \"2022_data.pickle\"\r\n# grower_pickle_file_path = \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\"\r\n# growers = open_specific_pickle(grower_pickle_file_name, specific_file_path=grower_pickle_file_path)\r\n# print()\r\n# setup_ai_game_data(\r\n#     \"2022_pickle.pickle\",\r\n#     \"H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\\",\r\n#     \"2022_data.pickle\",\r\n#     \"H:\\\\Shared drives\\\\Stomato\\\\2023\\\\Pickle\\\\\"\r\n# )\r\n\r\n\r\n# growers = open_specific_pickle('2022_pickle.pickle', 'H:\\\\Shared drives\\\\Stomato\\\\2022\\\\Pickle\\\\')\r\n# print(growers)\r\n\r\n# growers = open_specific_pickle('entry.pickle', 'H:\\\\Shared drives\\\\Stomato\\\\2021\\\\Pickle\\\\')\r\n# num_of_fields = 0\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         num_of_fields += 1\r\n# print(num_of_fields)\r\n#     grower.to_string()\r\n# print()\r\n\r\n# show_pickle()\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     tech = grower.technician\r\n#     print(tech.name)\r\n#     if tech.name == 'Vanessa' and len(tech.email) == 1:\r\n#         tech.email.append('gjazo@morningstarco.com')\r\n#     elif tech.name == 'Exsaelth' and len(tech.email) == 2:\r\n#         tech.email.append('jjimenez@morningstarco.com')\r\n#     print(tech.email)\r\n# write_pickle(growers)\r\n#     if isinstance(tech.email, str):\r\n#         tech.email = tech.email.split('; ')\r\n#     print(tech.email)\r\n# write_pickle(growers)\r\n# if tech.name == 'Development Test Tech':\r\n#     print(tech.email)\r\n#     tech.email = tech.email.split('; ')\r\n#     print(tech.email)\r\n\r\n\r\n#         grower.to_string()\r\n# recipients = ['jgarrido@morningstarco.com','jsalcedo@morningstarco.com']\r\n# print(', '.join(recipients))\r\n\r\n\r\n# dbw = DBWriter()\r\n# dbw.grab_bq_client(my_project='')\r\n# print()\r\n# cleanup_cimis_stations_pickle()\r\n# test_switch_cases()\r\n\r\n# update_information(get_data=True, write_to_db=True, write_to_portal=True)\r\n# show_pickle()\r\n# only_certain_growers_update(['Bullseye'])\r\n# only_certain_growers_field_update('Bullseye Farms', 'Bullseye FarmsYO2E', get_data=True, write_to_db=True, write_to_portal=True)\r\n# cimis_pickle = open_specific_pickle(\"cimisStation.pickle\")\r\n# print()\r\n\r\n# yesterdayRaw = date.today() - timedelta(1)\r\n# cimis = CIMIS()\r\n# print(cimis.get_list_of_active_eto_stations())\r\n# cimis.get_eto('169', str(yesterdayRaw), str(yesterdayRaw))\r\n\r\n# stations = {}\r\n# show_pickle()\r\n# dbw = DBWriter()\r\n# cwsi = CwsiProcessor()\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             if logger.ports:\r\n#                 for port in logger.ports:\r\n#                     sensor_type = logger.sensor_name(logger.ports[port])\r\n#                     logger.ports[port] = sensor_type\r\n#                 print(logger.ports)\r\n#             # ports[ind[\"port\"]] = ind[\"sensor_number\"]\r\n#             # ports[ind[\"port\"]] = sensor_type\r\n# write_pickle(growers)\r\n\r\n# show_pickle()\r\n# show_grower('Saul')\r\n\r\n# only_certain_growers_field_logger_update('Saul', 'Meza', 'Development-C', subtract_from_mrid=24)\r\n# only_certain_growers_field_update('Saul', 'Meza', get_weather=True)\r\n\r\n# weather = WeatherProcessor(37.052433, -120.811616)\r\n# weather_data = weather.time_machine_forecast(weather.lat, weather.long, datetime(2021, 1, 1), datetime(2021, 1, 10))\r\n# def print_pretty_weather_data(weather_data):\r\n#     print(\"Weather forecast:\\n\")\r\n#     for data in weather_data:\r\n#         date = data['datetime']\r\n#         temp_min = data['tempmin']\r\n#         temp_max = data['tempmax']\r\n#         conditions = data['conditions']\r\n#\r\n#         print(f\"{date}:\")\r\n#         print(f\"  Temperature: {temp_min}F - {temp_max}F\")\r\n#         print(f\"  Conditions: {conditions}\")\r\n#         print()\r\n# print_pretty_weather_data(weather_data['days'])\r\n\r\n# show_pickle()\r\n\r\n# print((logger.ports))\r\n#\r\n#             # print(f'GPM: {logger.gpm}')\r\n#             if not hasattr(logger, 'rnd'):\r\n#                 print(f'Logger: {logger.name}')\r\n#                 logger.rnd = False\r\n#             # print(f'R&D: {logger.rnd}')\r\n#             # logger.to_string()\r\n# write_pickle(growers)\r\n# show_pickle()\r\n# hi = 'LAKJ:LAKJ:LKJ:LKJA'\r\n# print(f'hi: {hi:5}')\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     print('************************GROWER***********************')\r\n#     pprint(vars(grower))\r\n#     print('***********************************************')\r\n#     for field in grower.fields:\r\n#         if hasattr(field, 'cimis'):\r\n#             delattr(field, 'cimis')\r\n#         print('===================FIELD=========================')\r\n#         pprint(vars(field))\r\n#         print('============================================')\r\n#         for logger in field.loggers:\r\n#             # logger.irrigation_set_acres = logger.acres\r\n#             if hasattr(logger, 'filename'):\r\n#                 delattr(logger, 'filename')\r\n#             if hasattr(logger, 'filepath'):\r\n#                 delattr(logger, 'filepath')\r\n#             print('--------------------LOGGER----------------------')\r\n#             pprint(vars(logger))\r\n#             print('------------------------------------------')\r\n# if hasattr(field, 'failed_cimis_update'):\r\n#     del field.failed_cimis_update\r\n# write_pickle(growers)\r\n# show_pickle()\r\n#         print(f'')\r\n#\r\n# reset_updated_all()\r\n# update_information(get_weather=True, write_to_db=True)\r\n# dbw = DBWriter()\r\n# cwsi = CwsiProcessor()\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         print(type(field.acres))\r\n#         print()\r\n#         if field.name == 'Bone Farms LLCF7' or field.name == 'Bone Farms LLCN42 N43':\r\n#             for logger in field.loggers:\r\n#                 result = dbw.add_up_whole_column('gdd', logger)\r\n#                 print(f'Name {logger.name}')\r\n#                 print(f'Gdd total: {result}')\r\n#                 logger.gdd_total = result\r\n#                 crop_stage = cwsi.get_crop_stage(result)\r\n#                 logger.crop_stage = crop_stage\r\n#                 print(f'Crop Stage: {crop_stage}')\r\n# write_pickle(growers)\r\n# print(logger.to_string())\r\n#             logger.crop_stage = 'NA'\r\n# write_pickle(growers)\r\n#         # field.cimis_station = field.cimisStation\r\n#         # if field.name == 'Bone Farms LLCF7':\r\n#         #     print()\r\n#         print(field.name, len(vars(field)))\r\n#         print()\r\n# print(field.name)\r\n# print()\r\n#         if field.cimisStation not in stations:\r\n#             stations[field.cimisStation] = 1\r\n#         else:\r\n#             stations[field.cimisStation] += 1\r\n# print(stations)\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         print(f'Field: {field.name} - Station: {field.cimisStation}')\r\n\r\n\r\n# onlyCertainGrowersUpdate(['KTN JV'], get_weather=True, write_to_db=True)\r\n# show_pickle()\r\n# write_pickle(growers)\r\n# show_pickle()\r\n# only_certain_growers_field_update('Bullseye Farms', 'Bullseye FarmsYO2E', write_to_portal=True, get_data=True)\r\n# remove_grower('Jesus')\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     if hasattr(grower, 'portalGSheetURL'):\r\n#         del grower.portalGSheetURL\r\n#     grower.email = ''\r\n# write_pickle(growers)\r\n#     print(grower.name, 'Email: ', grower.email)\r\n# for field in grower.fields:\r\n#     if hasattr(field, 'gSheetEtName'):\r\n#         del field.gSheetEtName\r\n#     if hasattr(field, 'gSheetIrrigationSchedulingName'):\r\n#         del field.gSheetIrrigationSchedulingName\r\n#     if hasattr(field, 'gSheetUrl'):\r\n#         del field.gSheetUrl\r\n#     if hasattr(field, 'gSheetWeatherIconName'):\r\n#         del field.gSheetWeatherIconName\r\n#     if hasattr(field, 'gSheetWeatherName'):\r\n#         del field.gSheetWeatherName\r\n#     if hasattr(field, 'portalGSheetName'):\r\n#         del field.portalGSheetName\r\n#     print()\r\n# for logger in field.loggers:\r\n#     if hasattr(logger, 'almondkc'):\r\n#         del logger.almondkc\r\n#     if hasattr(logger, 'pepperkc'):\r\n#         del logger.pepperkc\r\n#     if hasattr(logger, 'pistachiokc'):\r\n#         del logger.pistachiokc\r\n#     if hasattr(logger, 'tomatokc'):\r\n#         del logger.tomatokc\r\n#     if hasattr(logger, 'gsheetid'):\r\n#         del logger.gsheetid\r\n# write_pickle(growers)\r\n#         for logger in field.loggers:\r\n#             logger.logger_direction = logger.loggerDirection\r\n#             del logger.loggerDirection\r\n# logger.crop_type = logger.cropType\r\n# del logger.cropType\r\n# logger.field_capacity = logger.fieldCapacity\r\n# del logger.fieldCapacity\r\n# logger.wilting_point = logger.wiltingPoint\r\n# del logger.wiltingPoint\r\n\r\n# write_pickle(growers)\r\n# check_technician_clones()\r\n#         field.weather_crashed = False\r\n# remove_field()\r\n# update_information(get_weather=True, write_to_db=True)\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     new_fields = []\r\n#     print('Old Fields')\r\n#     for field in grower.fields:\r\n#         print(field.name, ' - ', field.active)\r\n#         if field.active:\r\n#             new_fields.append(field)\r\n#     print()\r\n#     print('New Fields')\r\n#     for f in new_fields:\r\n#         print(f.name, ' - ', f.active)\r\n#     print()\r\n#     grower.fields = new_fields\r\n# write_pickle(growers)\r\n\r\n\r\n# new_year_pickle_cleanup()\r\n# deactivate_grower('Javier')\r\n#     has_active_fields = False\r\n#     for field in grower.fields:\r\n#         if field.active:\r\n#             has_active_fields = True\r\n#     if has_active_fields:\r\n#         new_2023_growers.append(grower)\r\n#         # print(field.name, ' - ', field.active)\r\n# write_pickle(new_2023_growers)\r\n# print('Active Growers:')\r\n# for grower in new_2023_growers:\r\n#     print(grower.name)\r\n\r\n# for data in dict1:\r\n#     print(f'Length for {data} = {len(dict1[data])}')\r\n# print()\r\n# for data in dict2:\r\n#     print(f'Length for {data} = {len(dict2[data])}')\r\n\r\n\r\n# for data in multiple_days:\r\n#     print(f'Length for {data} = {len(multiple_days[data])}')\r\n\r\n# setup_ai_game_data()\r\n# cwsi = CwsiProcessor()\r\n# print('PSI ver1: ', cwsi.get_old_tomatoes_cwsi(-12.6,29.9,4.2,97.3,True))\r\n# print('PSI ver2: ', cwsi.get_old_tomatoes_cwsi_2(-12.6,29.9,4.2,97.3,True))\r\n# writeUninstallationProgresstoDB()\r\n\r\n# write_pickle(growers)\r\n# onlyCertainGrowersFieldUpdate('Bullseye Farms', 'Bullseye FarmsYO2W', get_data=True)\r\n# show_pickle()\r\n# onlyCertainGrowersFieldUpdate('Andrew', 'Andrew3107', get_weather=True, write_to_db=True)\r\n# reset_updated_all()\r\n# update_information(get_weather=True, write_to_db=True)\r\n# show_pickle()\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     if grower.active:\r\n#         for field in grower.fields:\r\n#             if field.active:\r\n#                 print(field.grower.name)\r\n#                 print(field.name)\r\n#                 print()\r\n# update_information(get_data=True, write_to_portal=True)\r\n\r\n# today = datetime.today()\r\n# print((today + timedelta(days=60)).month)\r\n# growers = open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         for l in f.loggers:\r\n#             print(l.name, l.model)\r\n\r\n# url = \"https://api.openweathermap.org/data/3.0/onecall?lat=37.053841&lon=-120.809556&appid=23e1e01a3d66fbd41154957a11dbe696\"\r\n#\r\n# headers = {\"accept\": \"application/json\"}\r\n# response = requests.get(url, headers=headers)\r\n# print(response.text)\r\n\r\n\r\n# ///////////////////////\r\n# api_key = \"91abc03a7e1748b767c16fccd701c7ec\"\r\n# lat = \"37.053841\"\r\n# lon = \"-120.809556\"\r\n# url = \"https://api.openweathermap.org/data/2.5/onecall?lat=%s&lon=%s&appid=%s&units=imperial&exclude=minutely,hourly\" % (lat, lon, api_key)\r\n#\r\n# response = requests.get(url)\r\n# data = json.loads(response.text)\r\n#\r\n# daily = data[\"daily\"]\r\n# for entry in daily:\r\n#     time = datetime.utcfromtimestamp(entry[\"dt\"])\r\n#     # time = datetime.fromtimestamp(entry[\"dt\"])\r\n#     date_string_format = time.strftime(\"%Y-%m-%d\")\r\n#     date_day = time.strftime('%a')\r\n#     maxTemp = entry[\"temp\"][\"max\"]\r\n#     humidity = entry[\"humidity\"]\r\n#     tempC = (maxTemp - 32) * 5.0 / 9.0\r\n#     saturation_vapor_pressure = 610.7 * 10 ** ((7.5 * tempC) / (237.7 + tempC))\r\n#     vpd = (((1 - humidity/100) * saturation_vapor_pressure) * 0.001)\r\n#     vpd = round(vpd, 1)\r\n#     icon = entry[\"weather\"][0][\"main\"]\r\n#     print(date_string_format, date_day, maxTemp, humidity, vpd, icon)\r\n# print(data)\r\n# ///////////////////////////////\r\n\r\n# show_pickle()\r\n# reset_updated_all()\r\n# update_information(get_weather=True, get_data=True)\r\n# onlyCertainGrowersUpdate(['Saul'], get_weather=True, get_data=True, write_to_db=True, write_to_portal=True)\r\n# only_certain_growers_field_logger_update('Saul', 'Meza', 'Development-C', subtract_from_mrid=48)\r\n\r\n# show_pickle()\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n\r\n#         if field.name == 'Andrew3101A':\r\n#             for logger in field.loggers:\r\n#                 print('HI')\r\n#                 logger.field_capacity = 18\r\n#                 logger.wilting_point = 8\r\n# write_pickle(growers)\r\n\r\n# show_pickle()\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if field.name == 'RG Farms LLC2':\r\n#             print()\r\n#             print(field.acres)\r\n#             field.acres = 30.35\r\n#             print(field.acres)\r\n# write_pickle(growers)\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             # print(f'Grower: {logger.grower.name} - Field: {logger.field.name}')\r\n#             # print(f'Logger name: {logger.name}')\r\n#             print(f'Logger ports: {logger.ports}')\r\n# print(f'Sensor data: {logger.get_sensor_index_data()}')\r\n# print(f'Logger keys: {logger.ports.keys()}')\r\n# print(f'Logger values: {logger.ports.values()}')\r\n# for key, value in sorted(logger.ports):\r\n#     print(f'Key: {key} - Value: {value}')\r\n#             irs = 0\r\n#             for ind, port in enumerate(logger.ports):\r\n# #                 port_sensor = logger.sensor_name(logger.ports[port])\r\n# #                 logger.ports[port] = port_sensor\r\n#                 print(f'Port: {port} - Sensor: {logger.ports[port]}')\r\n#                 if logger.ports[port] == 'Infra Red':\r\n#                     irs += 1\r\n#             print(f'IRs: {irs}')\r\n#             if irs > 1:\r\n#                 break\r\n#             print(f'Logger ports: {logger.ports}')\r\n# write_pickle(growers)\r\n# print()\r\n\r\n\r\n# setup_grower('Javier Test', 'a', 'a', 'North', True)\r\n\r\n# show_pickle()\r\n#         if field.active:\r\n#             print(field.name)\r\n# print(field.loggers[0].crop)\r\n# show_pickle()\r\n# ///////////////////////////////\r\n# METER API v1 Testing\r\n# GET READINGS\r\n# import requests\r\n# import json\r\n# import pprint\r\n# import pandas as pd\r\n# device_sn = \"z6-16138\"\r\n# device_pw = '65607-66874'\r\n# token = \"Token {TOKEN}\".format(TOKEN=\"6d1f65835ec6fd0c7ec77266d6a74d7f5a7be6b1\")\r\n# url = \"https://zentracloud.com/api/v1/readings\"\r\n# headers = {'content-type': 'application/json', 'Authorization': token}\r\n# output_format = \"json\"\r\n#\r\n# params = {'user': 'jgarrido@morningstarco.com', 'user_password': 'Mexico1012', 'sn': device_sn,\r\n#           'device_password': device_pw, 'start_mrid': 0}\r\n# # payload_str = urllib.parse.urlencode(params, safe='@')\r\n# response = requests.get(url, params=params)\r\n# # print(response.url)\r\n# print(f'Response ok: {response.ok}')\r\n# content = json.loads(response.content)\r\n# pprint.pprint(content)\r\n# df = pd.read_json(content['data'], convert_dates=True, orient='split')\r\n# print(df)\r\n# -->> Request URL: https://zentracloud.com/api/v1/readings?user=jgarrido@morningstarco.com&user_password=Mexico1012&sn=z6-07220&device_password=82901-36182&start_mrid=22204\r\n#                  'https://zentracloud.com/api/v1/readings/?user=jgarrido@morningstarco.com&user_password=Mexico1012&sn=z6-07275&device_password=65299-46534&start_mrid=0'\r\n# ///////////////////////////////\r\n\r\n\r\n\r\n# ///////////////////////////////\r\n# METER API v4 Testing\r\n# GET READINGS\r\n# import requests\r\n# import json\r\n# import pprint\r\n# import pandas as pd\r\n# device_sn = \"z6-16138\"\r\n# token = \"Token {TOKEN}\".format(TOKEN=\"8c5815c78e7dd349d77da4821db5e3ec2087c4a2\")\r\n# url = \"https://zentracloud.com/api/v4/get_readings/\"\r\n# headers = {'content-type': 'application/json', 'Authorization': token}\r\n# output_format = \"json\"\r\n# page_num = 1\r\n#\r\n# params = {'device_sn': device_sn, 'output_format': output_format, 'per_page': 2000,\r\n#           'sort_by': 'ascending'} #, 'start_date': '1-1-2023', 'end_date': '7-10-2023'}\r\n# response1 = requests.get(url, params=params, headers=headers)\r\n# content1 = json.loads(response1.content)\r\n# print()\r\n#\r\n# next_url = content1['pagination']['next_url']\r\n# print(next_url)\r\n# response2 = requests.get(next_url, headers=headers)\r\n# content2 = json.loads(response2.content)\r\n# print()\r\n# pprint.pprint(content)\r\n# df = pd.read_json(content['data'], convert_dates=True, orient='split')\r\n# print(df)\r\n# ///////////////////////////////\r\n\r\n\r\n\r\n# ///////////////////////////////\r\n# GET ENVIRONMENTAL\r\n# device_sn = \"z6-12376\"\r\n# token = \"Token {TOKEN}\".format(TOKEN=\"6d1f65835ec6fd0c7ec77266d6a74d7f5a7be6b1\")\r\n# url = \"https://zentracloud.com/api/v3/get_env_model_data/\"\r\n# headers = {'content-type': 'application/json', 'Authorization': token}\r\n# output_format = \"json\"\r\n#\r\n# params = {'device_sn': device_sn, 'model_type': 'ETo', 'port_num': 2, 'inputs': {\"elevation\": 3, \"latitude\": 38.6120803, \"wind_measurement_height\": 2}}\r\n# response = requests.get(url, params=params, headers=headers)\r\n# content = json.loads(response.content)\r\n# pprint.pprint(content)\r\n# df = pd.read_json(content['data'], convert_dates=True, orient='split')\r\n# print(df)\r\n# ///////////////////////////////\r\n\r\n\r\n# show_pickle()\r\n\r\n# apply_AI_recommendation_to_logger('Nees_AI', 'IRR-1-80-AI')\r\n# num_of_fields = 0\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             crop = logger.crop_type.lower()[0:4]\r\n#             print(crop)\r\n#         num_of_fields += 1\r\n#\r\n# print(num_of_fields)\r\n\r\n# show_pickle()\r\n# growers = open_pickle()\r\n# techs = get_all_technicians(growers)\r\n# for tech in techs:\r\n#     if tech.name == 'Exsaelth':\r\n#         tech.email = 'ejimenez@morningstarco.com; cvalcheck@morningstarco.com'\r\n#     print(tech.name)\r\n#     print(tech.email)\r\n# write_pickle(growers)\r\n# show_pickle()\r\n# tech = Technician('Vanessa_and_Exsaelth', 'vcastillo@morningstarco.com; ejimenez@morningstarco.com')\r\n#\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     print()\r\n#     print(grower.name)\r\n#     for field in grower.fields:\r\n#         print('\\t', field.name)\r\n#         for logger in field.loggers:\r\n#             print('\\t\\t', logger.name, ' R&D: ', logger.rnd)\r\n#     if grower.name == 'Lucero Watermark' or grower.name == 'Lucero Rio Vista' or grower.name == 'Lucero Morada':\r\n#         grower.technician = tech\r\n#         print(grower.technician.name)\r\n# write_pickle(growers)\r\n# update_information(get_data=True, check_for_notifications=True)\r\n# onlyCertainGrowersFieldLoggerUpdate('Saul', 'Meza', 'Development-C', subtract_from_mrid=48)\r\n# update_information(get_et=True, write_to_db=True)\r\n# cimisStationsPickle = CimisStation.open_cimis_station_pickle(CimisStation)\r\n# for stations in cimisStationsPickle:\r\n#     print(stations.station_number, ' : ', stations.latest_eto_value, ' : ', stations.updated)\r\n# cimisStations.showCimisStations()\r\n# show_pickle()\r\n\r\n\r\n# yesterdayRaw = date.today() - timedelta(1)\r\n# try:\r\n#     all_et_data_dicts = pull_all_et_values(str(yesterdayRaw), str(yesterdayRaw))\r\n# except Exception as error:\r\n#     print('ERROR in get_et')  # Used to just print ERROR\r\n#     print(error)\r\n#\r\n# try:\r\n#     write_all_et_values_to_db(all_et_data_dicts)\r\n# except Exception as error:\r\n#     print('ERROR in write_et_to_db')  # Used to just print ERROR\r\n#     print(error)\r\n\r\n# show_pickle()\r\n# remove_field('DCB', 'DCBCP:13,15')\r\n# update_information(get_data=True, write_to_db=True)\r\n# check_for_new_cimis_stations()\r\n# CimisStation.showCimisStations(CimisStation)\r\n# temp_ai_application()\r\n# print('BEFORE')\r\n# show_pickle()\r\n# onlyCertainGrowersFieldUpdate('Saul', 'Meza', get_data=True)\r\n# onlyCertainGrowersFieldLoggerUpdate('Hughes', 'Hughes233-4', 'HU-233-SW')\r\n\r\n\r\n# temp_ai_application()\r\n# show_pickle()\r\n# dbw = DBWriter()\r\n# dbw.add_gdd_columns_to_all_tables()\r\n# show_pickle()\r\n# dbwriter = DBWriter()\r\n# dbwriter.merge_all_tables_for_gdd()\r\n# show_pickle()\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             print(logger.cropType)\r\n#             if logger.lat == '':\r\n#                 logger.lat = None\r\n#             if logger.long == '':\r\n#                 logger.long = None\r\n#             if logger.name == 'HU-228-SW':\r\n#                 logger.lat = 36.5111213\r\n#             if logger.lat:\r\n#                 logger.lat = float(logger.lat)\r\n#             if logger.long:\r\n#                 logger.long = float(logger.long)\r\n#\r\n#             print(f'{logger.name} ---- Lat {logger.lat}, Long {logger.long}')\r\n# write_pickle(growers)\r\n#             print(logger.__dict__)\r\n# print(dir(logger))\r\n#     if grower.name == 'Saul':\r\n#         grower.deactivate()\r\n#     if 'Lucero' in grower.name:\r\n#         print(grower.name)\r\n#         for field in grower.fields:\r\n#             for logger in field.loggers:\r\n#                 print('\\t* factor for ', field.name, ' -- ', logger.name)\r\n#                 # print('(449 * ', logger.acres, ') / ')\r\n#                 # print('(', logger.gpm, ' * 0.85)')\r\n#                 print('\\t', round(((449*logger.acres)/(logger.gpm*0.85)),1))\r\n#             print()\r\n#         print()\r\n# temp_ai_application()\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     if grower.name == 'Javier':\r\n#         print(grower.fields[0].loggers[1].gpm)\r\n#         print(grower.fields[0].loggers[1].acres)\r\n# for field in grower.fields:\r\n#     for logger in field.loggers:\r\n#         logger.gpm = 3600\r\n#         logger.acres = 128\r\n#\r\n\r\n# show_pickle()\r\n\r\n# write_pickle(growers)\r\n# print(grower.fields[0].loggers[1].gpm)\r\n# print(grower.fields[0].loggers[1].acres)\r\n#     print('Grower Name: ', grower.name)\r\n#     print('Total Fields: ', len(grower.fields))\r\n#     for field in grower.fields:\r\n#         print('\\tField Name: ', field.name, ' - ')\r\n#         print('\\tTotal Loggers: ', len(field.loggers))\r\n#         for logger in field.loggers:\r\n#             print('\\t\\tLogger Name: ', logger.name)\r\n#     print()\r\n# show_pickle()\r\n\r\n# onlyCertainGrowersFieldLoggerUpdate('RnD','RnDStoler Rate Trial', 'CONTROL-W', write_to_db=True, subtract_from_mrid=500000)\r\n# onlyCertainGrowersFieldLoggerUpdate('RnD','RnDStoler Rate Trial', 'RATE-1-E', write_to_db=True, subtract_from_mrid=500000)\r\n# onlyCertainGrowersFieldLoggerUpdate('RnD','RnDStoler Rate Trial', 'RATE-1-W', write_to_db=True, subtract_from_mrid=500000)\r\n# onlyCertainGrowersFieldLoggerUpdate('RnD','RnDStoler Rate Trial', 'RATE-2-E', write_to_db=True, subtract_from_mrid=500000)\r\n# onlyCertainGrowersFieldLoggerUpdate('RnD','RnDStoler Rate Trial', 'RATE-2-W', write_to_db=True, subtract_from_mrid=500000)\r\n# onlyCertainGrowersFieldLoggerUpdate('Bullseye Farms','Bullseye FarmsYO2E', 'YO2E-WM2-S', write_to_db=True, subtract_from_mrid=500000)\r\n#\r\n# apply_AI_recommendation_to_logger('Nees_AI', 'IRR-1-80-AI')\r\n# apply_AI_recommendation_to_logger('Nees_AI', 'IRR-1-80-Ctrl')\r\n# apply_AI_recommendation_to_logger('Nees_AI', 'IRR-2-60-AI')\r\n# apply_AI_recommendation_to_logger('Nees_AI', 'IRR-2-60-Ctrl')\r\n# apply_AI_recommendation_to_logger('Nees_AI', 'IRR-3-80-AI')\r\n# apply_AI_recommendation_to_logger('Nees_AI', 'IRR-3-80-Ctrl')\r\n# apply_AI_recommendation_to_logger('Nees_AI', 'IRR-4-60-AI')\r\n# apply_AI_recommendation_to_logger('Nees_AI', 'IRR-4-60-Ctrl')\r\n# apply_AI_recommendation_to_logger('Nees_AI', 'IRR-5-80-AI')\r\n# apply_AI_recommendation_to_logger('Nees_AI', 'IRR-5-80-Ctrl')\r\n\r\n# check_technician_clones()\r\n#\r\n# temp_ai_application()\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         field.update_et_tables()\r\n#         for logger in field.loggers:\r\n#             print('Grower -> ', grower.name, '  ', logger.name, ' - R&D? ', logger.rnd)\r\n#     if grower.technician.name == 'Vanessa':\r\n#         print(grower.technician.email)\r\n#         grower.technician.email = 'vcastillo@morningstarco.com; jkent@morningstarco.com'\r\n#         # break\r\n# #\r\n# # for grower in growers:\r\n# #     if grower.technician.name == 'Adriana':\r\n# #         grower.technician = vane\r\n# write_pickle(growers)\r\n#\r\n# print('AFTER')\r\n# check_technician_clones()\r\n\r\n# ady = get_technician('Adriana')\r\n# print(round(5.5798723,2))\r\n\r\n# growers = open_pickle()\r\n# del growers[-1]\r\n# write_pickle(growers)\r\n# show_pickle()\r\n#\r\n# grower_javier = setupGrower('Javier', '', 'Development Test Tech')\r\n# field_javier = setupField('Nees AI', '', '36.8339015', '-120.7384265', 124)\r\n# field_javier.nickname = 'Nees AI'\r\n# logger1 = setup_logger('z6-12374', '39225-28564', 'IRR-1-80-AI', '', 'tomatoes', 42, 36, 1750, 152, 'N', planting_date='05/03/2022')\r\n# logger2 = setup_logger('z6-11584', '73659-11380', 'IRR-1-80-Ctrl', '', 'tomatoes', 42, 36, 1750, 152, 'N', planting_date='05/03/2022')\r\n# logger3 = setup_logger('z6-16148', '96777-21941', 'IRR-2-60-AI', '', 'tomatoes', 42, 36, 1750, 152, 'N', planting_date='05/03/2022')\r\n# logger4 = setup_logger('z6-16143', '41233-23875', 'IRR-2-60-Ctrl', '', 'tomatoes', 42, 36, 1750, 152, 'N', planting_date='05/03/2022')\r\n# logger5 = setup_logger('z6-13262', '76705-06865', 'IRR-3-80-AI', '', 'tomatoes', 42, 36, 1750, 152, 'N', planting_date='05/03/2022')\r\n# logger6 = setup_logger('z6-07231', '40779-55230', 'IRR-3-80-Ctrl', '', 'tomatoes', 42, 36, 1750, 152, 'N', planting_date='05/03/2022')\r\n# logger7 = setup_logger('z6-11553', '80480-15456', 'IRR-4-60-AI', '', 'tomatoes', 42, 36, 1750, 152, 'N', planting_date='05/03/2022')\r\n# logger8 = setup_logger('z6-01889', '24590-03289', 'IRR-4-60-Ctrl', '', 'tomatoes', 42, 36, 1750, 152, 'N', planting_date='05/03/2022')\r\n# logger9 = setup_logger('z6-12391', '57568-22189', 'IRR-5-80-AI', '', 'tomatoes', 42, 36, 1750, 152, 'N', planting_date='05/03/2022')\r\n# logger10 = setup_logger('z6-12368', '32338-34041', 'IRR-5-80-Ctrl', '', 'tomatoes', 42, 36, 1750, 152, 'N', planting_date='05/03/2022')\r\n\r\n# field_javier.addLoggers([logger1, logger2, logger3, logger4, logger5, logger6, logger7, logger8, logger9, logger10])\r\n# addFieldToGrower(grower_javier.name, field_javier)\r\n\r\n\r\n# grower = setupGrower('Saul', '1S8acM-DKwrMaxOZpEdndvHn59xij7OHxtB6ztErIxoY')\r\n# addGrowerToGrowers(grower)\r\n#\r\n# field = setupField('Meza', '1TtZQM1GU6h88P83U6EGEUojIResR5gSyBBC7SR6gQZc', '37.053941099999996', '-120.80917459999999', '56')\r\n# logger1 = setupLogger('z6-07275', '65299-46534', 'Development', 1665227864, 'Tomato', 36, 22, 1200, 100)\r\n# field.addLogger(logger1)\r\n# addFieldToGrower('Saul', field)\r\n\r\n# logger_list_javier = []\r\n# logger_list_jesus = open_specific_pickle(\"loggerList.pickle\")\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     print(grower.name)\r\n\r\n# del growers[-1]\r\n# write_pickle(growers)\r\n# for field in grower.fields:\r\n# print(field.name)\r\n#         for logger in field.loggers:\r\n#             logger_list_javier.append(logger)\r\n#\r\n# for logger in logger_list_javier:\r\n#     if logger.id not in logger_list_jesus:\r\n#         print(logger.id, ' not in')\r\n#         print(logger.name)\r\n#         print(logger.field.name)\r\n#         print(logger.active)\r\n#         print()\r\n\r\n\r\n# print(tech_dict)\r\n#     if grower.name == 'Ryan Jones':\r\n#         og_vanessa = grower.technician\r\n#\r\n# for grower in growers:\r\n#     if grower.name == 'Maricopa Orchards':\r\n#         grower.technician = og_vanessa\r\n#\r\n# for grower in growers:\r\n#     print(grower.name, ' - ', grower.technician.name, ' - ', id(grower.technician))\r\n\r\n\r\n# all_technicians = get_all_technicians(growers)\r\n# for tech in all_technicians:\r\n#     print(tech.name, ' - ', id(tech))\r\n\r\n# updated_run_report()\r\n# show_pickle()\r\n# g = growers[0]\r\n# # Multiple emails to each person with their own individual file\r\n# # for path in files:\r\n# #     g.all_notifications.email_tech_notifications(tech_notif_folder / path, path)\r\n# all_technicians = get_all_technicians(growers)\r\n# list_of_notifcation_files = []\r\n# for tech in all_technicians:\r\n#     list_of_notifcation_files.append(tech.notification_file_path)\r\n#\r\n# g.all_notifications.email_tech_notifications(list_of_notifcation_files, 'Tech Notifications')\r\n#\r\n# g.all_notifications.email_error_notifications()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         print(field.name, ' - ', field.preview_url)\r\n#             for logger in field.loggers:\r\n#                 if not logger.active:\r\n#                     print('Logger inactive', logger.id, ' - ', logger.name)\r\n# field.update(get_data=True, write_to_portal=True)\r\n# for grower in growers:\r\n#     if grower.name == 'Dougherty Bros':\r\n#         grower.to_string()\r\n#     if grower.technician is not None:\r\n#         print(grower.name, ' - ', grower.technician.name)\r\n#     # print(grower.name, ' - ', grower.technician.name)\r\n#     if grower.name == 'KTN JV':\r\n#         ex = grower.technician\r\n#     if grower.name == 'Mumma Bros':\r\n#         grower.technician = ex\r\n# if grower.name == 'Mumma Bros':\r\n#     grower.cwsi_processor = CwsiProcessor()\r\n# write_pickle(growers)\r\n#         for field in grower.fields:\r\n#             if field.name == 'La QuintaDates Block 36 DB':\r\n#                 field.loggers[0].update(subtract_from_mrid=48)\r\n# # #\r\n# for grower in growers:\r\n#     if grower.name == \"Mumma Bros\":\r\n#         print(grower.technician.name)\r\n#         vane = grower.technician\r\n#\r\n# for grower in growers:\r\n#     if grower.name == \"RKB\":\r\n#         grower.technician = vane\r\n#\r\n# #\r\n# # for grower in growers:\r\n# #     if grower.name == 'Maricopa Orchards':\r\n# #         grower.technician = ady\r\n# #\r\n# for grower in growers:\r\n#     if grower.technician.name == 'Vanessa':\r\n#         print(grower.name, '-', grower.technician.name, grower.technician)\r\n# techs = get_all_technicians(growers)\r\n# print()\r\n# for tech in techs:\r\n#     print(tech.name, '-', tech)\r\n# #\r\n# write_pickle(growers)\r\n\r\n# if os.path.exists('C:\\\\Users\\\\javie\\\\Projects\\\\S-TOMAto\\\\credentials.json'):\r\n#     os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/javie/Projects/S-TOMAto/credentials.json\"\r\n# elif os.path.exists('C:\\\\Users\\\\javie\\\\PycharmProjects\\\\Stomato\\\\credentials.json'):\r\n#     os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/javie/PycharmProjects/Stomato/credentials.json\"\r\n# elif os.path.exists('C:\\\\Users\\\\jsalcedo\\\\PycharmProjects\\\\Stomato\\\\credentials.json'):\r\n#     os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/jsalcedo/PycharmProjects/Stomato/credentials.json\"\r\n# elif os.path.exists('C:\\\\Users\\\\jesus\\\\PycharmProjects\\\\Stomato\\\\credentials.json'):\r\n#     os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/jesus/PycharmProjects/Stomato/credentials.json\"\r\n# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/javie/PycharmProjects/Stomato/credentials.json\"\r\n# dbw = DBWriter()\r\n# dbw.create_dataset('test2', project='growers-2022')\r\n# print('Hi')\r\n# growers = open_pickle()\r\n# # # #\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if field.cwsi_processor is None:\r\n#             print(field, ' has no cwsi processor')\r\n# #             if field.name == 'Dougherty BrosHB':\r\n# #                 field.update(get_data=True, write_to_portal=True)\r\n# for field in grower.fields:\r\n#     for logger in field.loggers:\r\n#         print(logger.loggerDirection)\r\n# if grower.name == 'Carvalho':\r\n#     grower.update(get_data=True, write_to_portal=True)\r\n# for field in grower.fields:\r\n#     for logger in field.loggers:\r\n#         print(logger.loggerDirection)\r\n# grower.to_string()\r\n# grower.update(get_data=True, write_to_portal=True)\r\n#         for field in grower.fields:\r\n#             if field.name == 'Carvalho302':\r\n#                 field.nickname = 'KC 302'\r\n#             if field.name == 'Carvalho307/307A':\r\n#                 field.nickname = 'KC 307/307A'\r\n# write_pickle(growers)\r\n#         field.update(get_data=True, write_to_portal=True)\r\n# grower.update(get_data=True, write_to_portal=True)\r\n\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             logger.fieldCapacity = int(logger.fieldCapacity)\r\n#             logger.wiltingPoint = int(logger.wiltingPoint)\r\n# write_pickle(growers)\r\n# if grower.name == 'Carvalho':\r\n# print('l;l')\r\n#     for field in grower.fields:\r\n#         if field.name == 'Carvalho302':\r\n#             field.update(get_data=True, write_to_portal=True)\r\n\r\n\r\n# grower.update(get_data=True, write_to_portal=True)\r\n# grower.fields[0].report_url = 'testing'\r\n# grower.to_string()\r\n# write_pickle(growers)\r\n\r\n# dbw = DBWriter()\r\n# dataset_id = 'growers-2022.Saul.field_averages'\r\n# dml = \"SELECT field FROM \" + dataset_id + \" WHERE field = 'Meza'\"\r\n# result = dbw.run_dml(dml, project='growers-2022')\r\n# if len(list(result)) >= 1:\r\n#     print('Found')\r\n# else:\r\n#     print('Not Found')\r\n\r\n#     # for field in grower.fields:\r\n#     #     # print(field.name)\r\n#     #     for logger in field.loggers:\r\n#     #         print(logger.name)\r\n#     # print(grower.name)\r\n#     if grower.name == 'David Santos':\r\n#         tech = grower.technician\r\n#     if grower.technician is None:\r\n#         print(grower.name, '-', 'NONE')\r\n#         grower.technician = tech\r\n#         print(grower.name, '-', grower.technician.name)\r\n\r\n# write_pickle(growers)\r\n# else:\r\n#     print(grower.name, '-',grower.technician.name)\r\n#     if grower.technician is not None:\r\n#         print(grower.name, '-', grower.technician.name)\r\n#     if grower.updated:\r\n#         pass\r\n#     else:\r\n#         for field in grower.fields:\r\n#             if field.updated:\r\n#                 pass\r\n#             else:\r\n#                 for logger in field.loggers:\r\n#                     if logger.updated:\r\n#                         pass\r\n#                     else:\r\n#                         print(grower.name, '-', field.name, '-', logger.name)\r\n#             if logger.crashed:\r\n#                 print(grower.name, '-', field.name, '-', logger.id)\r\n# # write_pickle(growers)\r\n\r\n# print(grower.technician.name)\r\n# print()\r\n# apply_cwsi_to_whole_table('Hughes301', 'z6-07274', 'pistachios')\r\n# apply_cwsi_to_whole_table('Bone_Farms_LLCR12_13', '5G129089', 'pistachios')\r\n# apply_cwsi_to_whole_table('Bone_Farms_LLCR12_13', '5G129217', 'pistachios')\r\n# apply_cwsi_to_whole_table('Bone_Farms_LLCR12_13', '5G129223', 'pistachios')\r\n\r\n# weather_schema = [\r\n#     bigquery.SchemaField(\"date\", \"DATE\"),\r\n#     bigquery.SchemaField(\"day\", \"STRING\"),\r\n#     bigquery.SchemaField(\"order\", \"FLOAT\"),\r\n#     bigquery.SchemaField(\"temp\", \"FLOAT\"),\r\n#     bigquery.SchemaField(\"rh\", \"FLOAT\"),\r\n#     bigquery.SchemaField(\"vpd\", \"FLOAT\"),\r\n#     bigquery.SchemaField(\"icon\", \"STRING\"),\r\n# ]\r\n#\r\n# dbw = DBWriter()\r\n# dbw.write_to_table_from_csv('OPC3_2', 'weather_forecast', 'Weather Forecast Test.csv', weather_schema, overwrite=True)\r\n# cimisStation = CimisStation()\r\n# print(cimisStation.return_list_of_stations())\r\n# cimisStationsPickle = cimisStation.open_cimis_station_pickle()\r\n# cimis = CIMIS()\r\n# print(cimis.get_closest_cimis_station(39.968252, -122.0956379))\r\n# for f in cimisStationsPickle:\r\n#     f.active = True\r\n# if f.station_number == '222':\r\n#     f.active = True\r\n# print(f\"{f.station_number}: {f.active}\")\r\n# write_specific_pickle(cimisStationsPickle, \"cimisStation.pickle\")\r\n# cimisStationsPickle = CimisStation.open_cimis_station_pickle(CimisStation)\r\n# for stations in cimisStationsPickle:\r\n#     stations.updated = False\r\n#     print(stations.station_number, \":\", stations.updated)\r\n# write_pickle(cimisStationsPickle, filename=\"cimisStation.pickle\")\r\n# d = pull_all_et_values('2022-01-01', '2022-12-01')\r\n# write_all_et_values_to_db(d)\r\n# print(d)\r\n# show_pickle()\r\n# deactivate_growers_with_all_inactive_fields()\r\n\r\n# write_et_values_specific_station('2022-01-01', '2023-01-01', '7')\r\n# count = 0\r\n# show_pickle()\r\n# growers = open_pickle()\r\n# removeGrower('a')\r\n# techs = get_all_technicians(growers)\r\n# print(techs)\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         for l in f.loggers:\r\n#             if l.cropType == 'pistachio' or l.cropType == 'Pistachios':\r\n#                 l.grower.to_string()\r\n#             if l.model == 'em50g':\r\n#                 count = count + 1\r\n#                 l.to_string()\r\n# print(count)\r\n\r\n# growers = open_pickle()\r\n# for g in growers:\r\n#     # if g.name == 'Andrew':\r\n#     for f in g.fields:\r\n#         for l in f.loggers:\r\n#                 # l.loggerD\r\n#     # irection = 'SE'\r\n#                 # print(l.loggerDirection)\r\n#                 # print(f.name)\r\n#                 # print(\"\\t\" + l.name)\r\n# write_pickle(growers)\r\n# showGrower('Andrew')\r\n# growers = open_pickle()\r\n# techs = get_all_technicians(growers)\r\n# print()\r\n# showGrower('Saul')\r\n# reassign_technician('Serafin', 'Vanessa')\r\n#\r\n# onlyCertainGrowersUpdate(['Saul'], get_weather=True, write_to_db=True)\r\n# onlyCertainGrowersFieldUpdate('Carvalho', 'Carvalho310/310A', get_weather=True, write_to_db=True)\r\n\r\n\r\n# show_pickle()\r\n\r\n# onlyCertainGrowersFieldLoggerUpdate('DCB', 'DCBHome', 'z6-06009', specific_mrid=12381, write_to_db=True)\r\n# count = 0\r\n# growers = open_pickle()\r\n# for g in growers:\r\n#     count = count + 1\r\n# print(count)\r\n#     if g.name == 'Saul':\r\n#         g.updated = False\r\n# write_pickle(growers)\r\n# onlyCertainGrowersUpdate(['Saul'], get_data=True, write_to_db=True)\r\n\r\n# onlyCertainGrowersFieldLoggerUpdate('La Quinta', 'La QuintaDates', 'z6-12396', subtract_from_mrid=36,\r\n# write_to_db=True)\r\n\r\n#         for f in g.fields:\r\n#             if f.name == 'Rossow13':\r\n#                 for l in f.loggers:\r\n#                     if l.id == 'z6-07261':\r\n#                         l.crashed = False\r\n# write_pickle(growers)\r\n# show_pickle()\r\n# total_growers = 0\r\n# update_information()\r\n# total_fields = 0\r\n# total_loggers = 0\r\n# #\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     print('\\t {}'.format(grower.name))\r\n#     total_growers = total_growers + 1\r\n#     for field in grower.fields:\r\n#         total_fields = total_fields + 1\r\n#         for logger in field.loggers:\r\n#             total_loggers = total_loggers + 1\r\n# print('Total Growers: {}'.format(total_growers))\r\n# print('Total Fields: {}'.format(total_fields))\r\n# print('Total Loggers: {}'.format(total_loggers))\r\n# for field in grower.fields:\r\n#     if not field.updated and field.active:\r\n#         for logger in field.loggers:\r\n#             print('Grower - {}\\t\\tField - {}\\t\\tLogger - {}'.format(grower.name, field.name, logger.id))\r\n\r\n# technicians = []\r\n# growers = open_pickle()\r\n# for g in growers:\r\n#     # g.technician.growers.append(g)\r\n#     if g.technician not in technicians:\r\n#         technicians.append(g.technician)\r\n#\r\n# for t in technicians:\r\n#     # t.growers = []\r\n#     t.to_string()\r\n# write_pickle(growers)\r\n\r\n# show_pickle()\r\n# onlyCertainGrowersFieldUpdate('David Santos', 'David SantosFA1', get_et=False, get_weather=True, get_data=True,\r\n#                                   write_to_sheet=True, write_to_portal_sheet=False, write_to_db=True,\r\n#                                   check_for_notifications=False)\r\n# onlyCertainGrowersFieldLoggerUpdate('David Santos', 'David SantosFA1', 'z6-01995', write_to_db=True)\r\n# onlyCertainGrowersFieldUpdate('David Santos', 'David SantosFA1', True, True, True, False, True, True, False)\r\n# update_et_tables()\r\n\r\n# list_of_db_fields = []\r\n# db = DBWriter()\r\n# datasets, project = db.get_datasets()\r\n# for d in datasets:\r\n#     # d.dataset_id.replace('_', ' ')\r\n#     # print(d.dataset_id.replace('_', ' '))\r\n#     list_of_db_fields.append(d.dataset_id)\r\n# print(\"\\tDB Fields ({})\".format(len(list_of_db_fields)))\r\n# for f in list_of_db_fields:\r\n#     print(f)\r\n# print(\"\\tDB Fields-----------\")\r\n#\r\n# list_of_pickle_fields = []\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         # print(field.name)\r\n#         field_name = field.name\r\n#         field_name = field_name.replace('-', '_')\r\n#         field_name = field_name.replace(' ', '_')\r\n#         field_name = field_name.replace('/', '_')\r\n#         list_of_pickle_fields.append(field_name)\r\n# list_of_pickle_fields.sort()\r\n# print(\"\\tPickle Fields ({})\".format(len(list_of_pickle_fields)))\r\n# for f in list_of_pickle_fields:\r\n#     print(f)\r\n# print(\"\\tPickle Fields------------\")\r\n#\r\n# set_difference = set(list_of_pickle_fields).symmetric_difference(set(list_of_db_fields))\r\n# list_difference = list(set_difference)\r\n#\r\n# list_difference.sort()\r\n# print(\"\\tDifferences ({})\".format(len(list_difference)))\r\n# for d in list_difference:\r\n#     print(d)\r\n# print(\"\\tDifferences------------\")\r\n\r\n# for item_db, item_pickle, item_diff in zip(list_of_db_fields, list_of_pickle_fields, list_difference):\r\n#     print('\\t - {} \\t\\t - {} \\t\\t - {}'.format(item_db, item_pickle, item_diff))\r\n# # print(list_difference)\r\n\r\n# for logger in field.loggers:\r\n\r\n# if path.exists(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\"):\r\n#     with open(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\", 'rb') as f:\r\n#         ai_game_data_all = pickle.load(f)\r\n# ai_game_data_all.model_vs_human_comparison()\r\n\r\n# ai_game_data_all.old_ai_game_data = []\r\n# new_ai_game_data = []\r\n# count = 0\r\n# for i in ai_game_data_all.ai_game_data:\r\n#     print('Game Date: {}'.format(i.game_date))\r\n#     if  i.game_date < datetime(2021,10,20):\r\n#         print('OLD')\r\n#         # new_ai_game_data.append(i)\r\n#         # ai_game_data_all.old_ai_game_data.append(i)\r\n#         # ai_game_data_all.remove_data_point(i)\r\n# # ai_game_data_all.ai_game_data = new_ai_game_data\r\n# if path.exists(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\"):\r\n#     with open(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\", 'wb') as f:\r\n#         pickle.dump(ai_game_data_all, f)\r\n\r\n#     print('Planting Date: {}'.format(i.planting_date))\r\n#     print('Harvest Date: {}'.format(i.harvest_date))\r\n#     print('Crop Stage: {}'.format(i.crop_stage))\r\n#     print()\r\n\r\n# if path.exists(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\"):\r\n#     with open(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\", 'rb') as f:\r\n#         ai_game_data_all = pickle.load(f)\r\n# # ai_game_data.model_vs_human_comparison()\r\n# growers = open_pickle()\r\n# for dp in ai_game_data_all.ai_game_data:\r\n#     if not hasattr(dp, 'crop stage'):\r\n#         print('Field: {}            Logger: {}'.format(dp.field, dp.logger))\r\n#         print('\\t Grabbing planting date-------------')\r\n#         for g in growers:\r\n#             for f in g.fields:\r\n#                 if dp.field == 'MatteoliG10B':\r\n#                     dp.planting_date = date(2021, 4, 6)\r\n#                 if f.name == dp.field:\r\n#                     print('Found field: {}'.format(dp.field))\r\n#                     for l in f.loggers:\r\n#                         print('Planting date: {}'.format(l.planting_date))\r\n#                         dp.planting_date = l.planting_date\r\n#         print('\\t Grabbing harvest date-------------')\r\n#         dataset = dp.field\r\n#         logger_id = dp.logger\r\n#\r\n#         dataset = dataset.replace(' ', '_')\r\n#         dataset = dataset.replace('-', '_')\r\n#         dataset = dataset.replace('/', '_')\r\n#         dml = 'SELECT *' \\\r\n#               'FROM `stomato.' + dataset + '.' + logger_id + '` ' \\\r\n#               'WHERE et_hours is not NULL AND logger_id is not NULL ORDER BY date ASC'\r\n#         dbwriter = DBWriter()\r\n#         result = dbwriter.run_dml(dml)\r\n#         db_results = {\"logger_id\": [], \"date\": [], \"time\": [], \"canopy_temperature\": [], \"ambient_temperature\": [],\r\n#                       \"vpd\": [], \"vwc_1\": [], \"vwc_2\": [], \"vwc_3\": [], \"field_capacity\": [], \"wilting_point\": [],\r\n#                       \"daily_gallons\": [], \"daily_switch\": [], \"daily_hours\": [], \"daily_pressure\": [],\r\n#                       \"daily_inches\": [], \"psi\": [], \"psi_threshold\": [], \"psi_critical\": [],\r\n#                       \"sdd\": [], \"rh\": [], 'eto': [], 'kc': [], 'etc': [], 'et_hours': [],\r\n#                       \"phase1_adjustment\": [], \"phase1_adjusted\": [], \"phase2_adjustment\": [], \"phase2_adjusted\": []}\r\n#\r\n#         for r in result:\r\n#             logger_id = r[0]\r\n#             rdate = r[1]\r\n#         #     time = r[2]\r\n#         #     canopy_temperature = r[3]\r\n#         #     ambient_temperature = r[4]\r\n#         #     vpd = r[5]\r\n#         #     vwc_1 = r[6]\r\n#         #     vwc_2 = r[7]\r\n#         #     vwc_3 = r[8]\r\n#         #     field_capacity = r[9]\r\n#         #     wilting_point = r[10]\r\n#         #     daily_gallons = r[11]\r\n#         #     daily_switch = r[12]\r\n#         #     daily_hours = r[13]\r\n#         #     daily_pressure = r[14]\r\n#         #     daily_inches = r[15]\r\n#         #     psi = r[16]\r\n#         #     psi_threshold = r[17]\r\n#         #     psi_critical = r[18]\r\n#         #     sdd = r[19]\r\n#         #     rh = r[20]\r\n#         #     eto = r[21]\r\n#         #     kc = r[22]\r\n#         #     etc = r[23]\r\n#         #     et_hours = r[24]\r\n#         #\r\n#             db_results['logger_id'].append(logger_id)\r\n#             db_results['date'].append(rdate)\r\n#         #     db_results['time'].append(time)\r\n#         #     db_results['canopy_temperature'].append(canopy_temperature)\r\n#         #     db_results['ambient_temperature'].append(ambient_temperature)\r\n#         #     db_results['vpd'].append(vpd)\r\n#         #     db_results['vwc_1'].append(vwc_1)\r\n#         #     db_results['vwc_2'].append(vwc_2)\r\n#         #     db_results['vwc_3'].append(vwc_3)\r\n#         #     db_results['field_capacity'].append(field_capacity)\r\n#         #     db_results['wilting_point'].append(wilting_point)\r\n#         #     db_results['daily_gallons'].append(daily_gallons)\r\n#         #     db_results['daily_switch'].append(daily_switch)\r\n#         #     db_results['daily_hours'].append(daily_hours)\r\n#         #     db_results['daily_pressure'].append(daily_pressure)\r\n#         #     db_results['daily_inches'].append(daily_inches)\r\n#         #     db_results['psi'].append(psi)\r\n#         #     db_results['psi_threshold'].append(psi_threshold)\r\n#         #     db_results['psi_critical'].append(psi_critical)\r\n#         #     db_results['sdd'].append(sdd)\r\n#         #     db_results['rh'].append(rh)\r\n#         #     db_results['eto'].append(eto)\r\n#         #     db_results['kc'].append(kc)\r\n#         #     db_results['etc'].append(etc)\r\n#         #     db_results['et_hours'].append(et_hours)\r\n#\r\n#         dp.harvest_date = db_results['date'][-1]\r\n#         print('\\t Grabbing crop stage-------------')\r\n#         crop_stage = get_crop_stage(dp.date, dp.harvest_date, dp.planting_date)\r\n#         dp.crop_stage = crop_stage\r\n#         print('\\t DONE-----------------------------------')\r\n#         print()\r\n#\r\n# if path.exists(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\"):\r\n#     with open(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\", 'wb') as f:\r\n#         pickle.dump(ai_game_data_all, f)\r\n\r\n\r\n# show_pickle()\r\n\r\n#\r\n# data_fixed = 0\r\n# for data_point in ai_game_data.ai_game_data:\r\n#     ran = data_point.fix_recommendations()\r\n#     if ran:\r\n#         data_fixed = data_fixed + 1\r\n#\r\n# print('Data Fixed: {}'.format(data_fixed))\r\n#\r\n# if path.exists(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\"):\r\n#     with open(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\", 'wb') as f:\r\n#         pickle.dump(ai_game_data, f)\r\n\r\n# #\r\n# ai_game_data.add_to_north_pool('Dougherty BrosD3', 'z6-11982')\r\n# ai_game_data.add_to_north_pool('MatteoliG10B', 'z6-02039')\r\n# del ai_game_data.north_pool[-1]\r\n# ai_game_data.show_content()\r\n\r\n# if path.exists(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\"):\r\n#     with open(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\", 'wb') as f:\r\n#         pickle.dump(ai_game_data, f)\r\n\r\n# show_pickle()\r\n# growers = open_pickle()\r\n# for g in growers:\r\n#     if g.name == 'Bullseye_Farms':\r\n#         g.to_string()\r\n# for f in g.fields:\r\n#     if g.name == 'MatteoliG10B':\r\n\r\n\r\n# showGrower('TP')\r\n\r\n# for dp in data.ai_game_data:\r\n#     dp.human_p1 = float(dp.human_p1)\r\n#     dp.human_p2 = float(dp.human_p2)\r\n#     dp.human_p3 = float(dp.human_p3)\r\n#\r\n# data = None\r\n# if path.exists(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\"):\r\n#     with open(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\", 'rb') as f:\r\n#         pickle.dump(data, f)\r\n\r\n# data.show_content\r\n# data.clear_all_data()\r\n# data.show_content()\r\n#\r\n# if path.exists(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\"):\r\n#     with open(\"G:\\\\My Drive\\\\S-TOMAto\\\\2021\\\\Pickle\\\\ai_game_data.pickle\", 'wb') as f:\r\n#         pickle.dump(data, f)\r\n\r\n# show_pickle()\r\n\r\n# content.south_pool.remove(content.south_pool[-1])\r\n# print(content.south_pool)\r\n# for data_point in content.ai_game_data:\r\n#     print('Field-{}  Logger-{}  Game Date-{}'.format(data_point.field, data_point.logger, data_point.game_date))\r\n#     print('Data Point-{}'.format(data_point.date))\r\n\r\n# apply_cwsi_to_whole_table('LemonicaLemon_E', 'z6-02020', 'Lemons')\r\n# apply_cwsi_to_whole_table('LemonicaLemon_E', 'z6-07266', 'Lemons')\r\n# apply_cwsi_to_whole_table('LemonicaLemon_E', 'z6-07272', 'Lemons')\r\n# apply_cwsi_to_whole_table('LemonicaLemon_E', 'z6-12420', 'Lemons')\r\n# apply_cwsi_to_whole_table('Hughes301', 'z6-07165', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Hughes301', 'z6-07274', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Maricopa_Orchards1831', 'z6-12298', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Maricopa_Orchards1831', 'z6-12209', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Maricopa_Orchards1831', 'z6-12332', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Maricopa_Orchards1831', 'z6-12338', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Bullseye_FarmsMB6', 'z6-02181', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Bullseye_FarmsMB6', 'z6-02018', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Bullseye_FarmsMB6', 'z6-05983', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Bullseye_FarmsMB6', 'z6-06004', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Bullseye_FarmsYO2E_West', 'z6-11527', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Bullseye_FarmsYO2E_West', 'z6-11528', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Bullseye_FarmsYO2E_East', 'z6-11519', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Bullseye_FarmsYO2E_East', 'z6-11516', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Shiraz_RanchS6_Pistachios', 'z6-11487', 'Pistachios')\r\n# apply_cwsi_to_whole_table('Shiraz_RanchS6_Pistachios', 'z6-11520', 'Pistachios')\r\n\r\n# growers = open_pickle() for grower in growers: for field in grower.fields: for logger in field.loggers: print(\r\n# 'Grower {}\\tField {}\\tLogger {}\\tLat {}\\tLong {}'.format(grower.name, field.name, logger.id, field.lat,\r\n# field.long)) write_pickle(growers)\r\n\r\n\r\n# onlyCertainGrowersFieldLoggerUpdate('OPC', 'OPC3-3', 'z6-07268', specific_mrid=0)\r\n\r\n# growers = open_pickle() for grower in growers: for field in grower.fields: for logger in field.loggers: if\r\n# logger.cropType == 'Pistachios': print('Grower {}\\tField {}\\tLogger {}\\tLat {}\\tLong {}'.format(grower.name,\r\n# field.name, logger.id, field.lat, field.long)) write_pickle(growers)\r\n\r\n# growers = open_pickle() for grower in growers: for field in grower.fields: for logger in field.loggers: if\r\n# logger.id == 'z6-11936': file_name = logger.jesus_output_folder + logger.id + '.dxd' battery_level =\r\n# logger.read_battery_level(file_name) print('Grower-{}\\tField-{}\\tLogger-{}\\tBattery Level-{}'.format(grower.name,\r\n# field.name, logger.id, battery_level))\r\n\r\n\r\n# show_pickle()\r\n# showGrower('OPC Independece Project')\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if field.name == ''\r\n#         for logger in field.loggers:\r\n\r\n# reset_updated_all() onlyCertainGrowersFieldUpdate('OPC', 'OPC3-2', get_weather=True, get_data=True,\r\n# write_to_db=True, write_to_portal_sheet=True, write_to_sheet=True, check_for_notifications=True)\r\n# update_information(get_et=True, write_to_db=True)\r\n\r\n# growers = open_pickle() for grower in growers: for field in grower.fields: for logger in field.loggers: print(\r\n# 'Grower {}\\tField {}\\tLogger {}\\tCrop {}'.format(grower.name, field.name, logger.id, logger.cropType))\r\n# write_pickle(growers)\r\n\r\n# updatedRunReport()\r\n# show_pickle()\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if not field.active:\r\n#             print('Field active? {}'.format(field.active))\r\n#             # field.deactivate()\r\n#             for l in field.loggers:\r\n#                 print(l.active)\r\n# write_pickle(growers)\r\n# apply_AI_recommendation_to_logger('DCBDT', 'z6-05993')\r\n# growers = open_pickle()\r\n# for g in growers:\r\n#     if g.name == 'TP':  # or g.name == 'Dougherty' or g.name == 'Bullseye':\r\n#         for f in g.fields:\r\n#             if f.name == 'TPMM3':\r\n#                 for l in f.loggers:\r\n#                     print('Field Name - {} | Logger - {}'.format(f.name, l.id))\r\n#                     apply_AI_recommendation_to_logger(f.name, l.id)\r\n\r\n# growers = open_pickle()\r\n# for g in growers:\r\n#     g.active = True\r\n#     for f in g.fields:\r\n#         f.active = True\r\n#         for l in f.loggers:\r\n#             l.active = True\r\n# write_pickle(growers)\r\n\r\n# show_pickle()\r\n# showGrower('Bullseye')\r\n\r\n# dbwriter = DBWriter()\r\n# dbwriter.add_AI_columns_to_all_tables()\r\n\r\n# updatedRunReport()\r\n# showField('David SantosFA1')\r\n\r\n# show_pickle()\r\n\r\n# updatedRunReport() Technician lists Vanessa = [Zuckerman Farms, FS , Ryan Jones, JJB Farms, BT, Hughes, Carvalho,\r\n# Rossow, Andrew, Lucero Hanford, Lucero Morada, Lucero 8 Mile] Serafin = [OPC, David Santos, JHP, RKB Ranch, DCB,\r\n# Bone Farms LLC]\r\n\r\n# growers = open_pickle()\r\n# # # loggerCount = 0\r\n# # # # rndLoggerCount = 0\r\n# vanessasGrowerList = ['Zuckerman Farms', 'FS' , 'Ryan Jones', 'JJB Farms', 'BT', 'Hughes', 'Carvalho', 'Rossow',\r\n#                       'Andrew', 'Lucero Hanford', 'Lucero Morada', 'Lucero 8 Mile', 'Oasis Organics']\r\n# serafinsGrowerList = ['OPC', 'David Santos', 'JHP', 'RKB Ranch', 'DCB', 'Bone Farms LLC']\r\n# adrianasGrowerList = ['Maricopa Orchards', 'OPC Independece Project', 'David Santos Independece Project', 'Lemonica',\r\n#                       'La Quinta']\r\n# northGrowerList = ['Matteoli', 'Tim Kalfsbeek', 'Barrios Farms', 'CM Ochoa', 'Schreiner Bros', 'Sam Reynolds',\r\n#                    'Faxon Farms' , 'Mumma Bros', 'Bullseye Farms' , 'CICC', 'Sean Doherty', 'Sycamore Marsh Farms',\r\n#                    'KTN JV', 'Knight Farms' , 'Dougherty Bros', 'JK Vineyards' , 'Kidwell Farms',\r\n#                    'UC Davis', 'TP', 'Quad H', 'Muller Ag LLC', 'Shiraz Ranch']\r\n# developmentList = ['Saul']\r\n#\r\n# vanessa = Technician('Vanessa', 'vcastillo@morningstarco.com')\r\n# serafin = Technician('Serafin', 'scolse@morningstarco.com')\r\n# adriana = Technician('Adriana', 'garciaa@morningstarco.com')\r\n# exsaelth = Technician('Exsaelth', 'ejimenez@morningstarco.com')\r\n# development_test_tech = Technician('Development Test Tech', 'jgarrido@morningstarco.com')\r\n#\r\n# for g in growers:\r\n#     print(g.name)\r\n#     if g.name in vanessasGrowerList:\r\n#         print('Assigned to Vanessa')\r\n#         g.technician = vanessa\r\n#         g.region = 'South'\r\n# #\r\n#     elif g.name in serafinsGrowerList:\r\n#         print('Assigned to Serafin')\r\n#         g.technician = serafin\r\n#         g.region = 'South'\r\n#\r\n#     elif g.name in adrianasGrowerList:\r\n#         print('Assigned to Adriana')\r\n#         g.technician = adriana\r\n#         g.region = 'South'\r\n#\r\n#     elif g.name in northGrowerList:\r\n#         print('Assigned to Exsaelth')\r\n#         g.technician = exsaelth\r\n#         g.region = 'North'\r\n#\r\n#     elif g.name in developmentList:\r\n#         print('Assigned to Dev')\r\n#         g.technician = development_test_tech\r\n#         g.region = 'South'\r\n# #\r\n#     else:\r\n#         print(\"{0} has no tech assigned\".format(g.name))\r\n#     print()\r\n# write_pickle(growers)\r\n# counter = 0\r\n# growers = open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         for l in f.loggers:\r\n#             counter = counter + 1\r\n#     # print(f'Grower: {g.name}')\r\n#     # print(f'Tech: {g.technician}')\r\n#     # print()\r\n#     # counter = counter + 1\r\n# print(counter)\r\n#\r\n#     if g.name == 'Lucero 8 Mile':\r\n#         g.technician = 'Vanessa'\r\n# write_pickle(growers)\r\n\r\n\r\n# showGrower('OPC')\r\n\r\n\r\n# setCimisStation('DCBChapman', 148)\r\n# setPlantingDate('Lucero 8 Mile', 'Lucero 8 Mile12-13', 2021, 6, 30)\r\n# growers = open_pickle()\r\n# for g in growers:\r\n#     print(\"{0} is covered by {1}\".format(g.name, g.technician))\r\n#     print(\"{0} region is {1}\".format(g.name, g.region))\r\n\r\n\r\n#     for f in g.fields:\r\n#         for l in f.loggers:\r\n#             if hasattr(l, \"crashed\"):\r\n#                 if l.crashed == True:\r\n#                     print(\"Crashed: {0}\".format(l.id))\r\n#                     loggerCount = loggerCount + 1\r\n#             if l.updated == False:\r\n#                 print(\"Not updated: {0}\".format(l.id))\r\n#                 loggerCount = loggerCount + 1\r\n# showGrower('BT')\r\n# growers = open_pickle()\r\n# for g in growers:\r\n#     if g.name == 'La Quinta':\r\n#         for f in g.fields:\r\n#             print('Field name:{0}'.format(f.name))\r\n#             print('Cimis station: {0}'.format(f.cimisStation))\r\n#             f.cimisStation = '218'\r\n# #             for l in f.loggers:\r\n# #                 print('Crop type: {0}'.format(l.cropType))\r\n# write_pickle(growers)\r\n# get_all_current_cimis_stations()\r\n# writeETValuesSpecificStation('12/31/2021','12/31/2021','148')\r\n# write_all_et_values_to_db('07/20/2022', '08/15/2022')\r\n# startDate = '01/01/2021'\r\n# endDate = '05/17/2021'\r\n\r\n# removeField('BT', 'BTSL01 ')\r\n#\r\n\r\n# showGrower('BT')\r\n# show_pickle()\r\n# print('Total commercial loggers installed: {0}'.format(loggerCount))\r\n# print('Total R&D loggers installed: {0}'.format(rndLoggerCount))\r\n\r\n# list = [\r\n#     'z6-01857',\r\n#     'z6-07165',\r\n#     'z6-01900',\r\n#     'z6-02017',\r\n#     'z6-07112',\r\n#     'z6-03443',\r\n#     'z6-01860',\r\n#     'z6-06002',\r\n#     'z6-05999',\r\n#     'z6-01898',\r\n#     'z6-03539',\r\n#     'z6-07265',\r\n#     'z6-07171',\r\n#     'z6-07270',\r\n# ]\r\n# reset_updated_all()\r\n# showGrower(\"La Quinta\")\r\n# show_pickle()\r\n# show_pickle()\r\n\r\n# growers = open_pickle()\r\n# print('Test')\r\n# for g in growers:\r\n#     if g.name == \"David Santos\":\r\n#         for f in g.fields:\r\n#             if f.name == 'David SantosFA1':\r\n#                 for l in f.loggers:\r\n#                     print('here')\r\n\r\n# onlyCertainGrowersFieldLoggerUpdate(\"David Santos\", \"David SantosFA1\", \"z6-01995\", specific_mrid=10803)\r\n# onlyCertainGrowersFieldLoggerUpdate(\"Bullseye Farms\", \"Bullseye FarmsMB6\", \"z6-02018\",  write_to_sheet=True,\r\n# write_to_db=True, write_to_portal_sheet=True) onlyCertainGrowersUpdate(['La Quinta'], get_weather=True,\r\n# get_data=True, write_to_db=True, write_to_sheet=True, write_to_portal_sheet=True)\r\n#\r\n# updatePrevSwitch(list, 60)\r\n# get_all_current_cimis_stations()\r\n# show_pickle()\r\n# showGrower('Knight Farms')\r\n# growers = open_pickle()\r\n# for g in growers:\r\n#     if g.updated == False:\r\n#         print(\"Grower {0} updated: {1}\".format(g.name, g.updated))\r\n#     for f in g.fields:\r\n#         if f.updated == False:\r\n#             print(\"\\tField {0} updated: {1}\".format(f.name, f.updated))\r\n#         for l in f.loggers:\r\n#             if l.updated == False:\r\n#                 print(\"\\t\\tLogger {0} updated: {1}\".format(l.name, l.updated))\r\n\r\n# write_pickle(growers)\r\n#                 if hasattr(l, \"crashed\"):\r\n#                     print(\"Logger: {0} has crashed: {1}\".format(l.id, l.crashed))\r\n#                 else:\r\n#                     print(\"Logger: {0} has no crashed attribute\")\r\n#\r\n#\r\n# if g.name == 'Sean Doherty':\r\n#     print(\"Grower: {0}\".format(g.name))\r\n#     for f in g.fields:\r\n#         # if f.name == 'Sean DohertyE1':\r\n#         print(\"\\tField {0} updated successfully? {1}\".format(f.name, f.updated))\r\n#         print(\"\\tNumber of loggers: {0}\".format(len(f.loggers)))\r\n#         f.checkSuccessfulUpdatedLoggers()\r\n#         print(\"\\tField {0} updated successfully? {1}\".format(f.name, f.updated))\r\n#         print()\r\n#     print(\"Grower {0} updated successfully? {1}\".format(g.name, g.updated))\r\n#     print(\"Number of fields: {0}\".format(len(g.fields)))\r\n#     g.checkSuccessfulUpdatedFields()\r\n#     print(\"Grower {0} updated successfully? {1}\".format(g.name, g.updated))\r\n#     print()\r\n# write_pickle(growers)\r\n\r\n\r\n# f.set_updated(False)\r\n# for l in f.loggers:\r\n#     l.set_updated(False)\r\n# write_pickle(growers)\r\n\r\n# onlyCertainGrowersFieldUpdate(\"DCB\", \"DCBNees 7-8\", get_et=False, get_weather=True, get_data=True,\r\n#                                       write_to_sheet=True, write_to_portal_sheet=True, write_to_db=True)\r\n# show_pickle()\r\n# showField('Bullseye FarmsFY1')\r\n\r\n# write_new_csv_to_db(\"Historical_ET\", \"114\", \"historicalET.csv\")\r\n# write_new_historical_et_to_db(\"114\", \"historicalET.csv\")\r\n\r\n# getMRID(\"2021-05-07\")\r\n# getPreviousDataField(\"Carvalho\", \"Carvalho304\", \"2021-05-07\", write_to_sheet=True)\r\n\r\n# onlyCertainGrowersFieldLoggerUpdate('Hughes', 'Hughes309-4', 'z6-07220', write_to_sheet=True, write_to_db=True,\r\n# subtract_from_mrid=96)\r\n\r\n# showField('Hughes309-4')\r\n\r\n# removeField('Hughes', 'Hughes234-2') removeGrower('LA QUINTA') removeField('Rossow', 'RossowWeholt')\r\n# onlyCertainGrowersUpdate(['KTN JV','Knight Farms','Andrew','Dougherty Bros','JK Vineyards','Kidwell Farms',\r\n# 'UC Davis', 'Zuckerman Farms', ], get_weather=True, get_data=True, write_to_db=True, write_to_portal_sheet=True,\r\n# write_to_sheet=True) onlyCertainGrowersFieldLoggerUpdate('JK Vineyards', 'JK VineyardsGemmer North', 'z6-02143',\r\n# write_to_sheet=True, write_to_portal_sheet=True, write_to_db=True) onlyCertainGrowersFieldLoggerUpdate('JHP',\r\n# 'JHPOakland 4', 'z6-01871', write_to_sheet=True, write_to_portal_sheet=True, write_to_db=True,\r\n# subtract_from_mrid=260) onlyCertainGrowersFieldLoggerUpdate('JHP', 'JHPOakland 4', 'z6-02026', write_to_sheet=True,\r\n# write_to_portal_sheet=True, write_to_db=True, subtract_from_mrid=260) onlyCertainGrowersFieldLoggerUpdate('JHP',\r\n# 'JHPOakland 4', 'z6-05964', write_to_sheet=True, write_to_portal_sheet=True, write_to_db=True,\r\n# subtract_from_mrid=260) onlyCertainGrowersFieldLoggerUpdate('JHP', 'JHPOakland 4', 'z6-03419', write_to_sheet=True,\r\n# write_to_portal_sheet=True, write_to_db=True, subtract_from_mrid=260)\r\n\r\n# onlyCertainGrowersFieldLoggerUpdate('Rossow', 'RossowWeholt', 'z6-12308', write_to_sheet=True,\r\n# write_to_portal_sheet=True, write_to_db=True, subtract_from_mrid=340) onlyCertainGrowersFieldLoggerUpdate('Bone\r\n# Farms LLC', 'Bone Farms LLCF7', 'z6-03447', write_to_sheet=True, write_to_portal_sheet=True, write_to_db=True,\r\n# subtract_from_mrid=340)\r\n\r\n# onlyCertainGrowersFieldLoggerUpdate('Oasis Organics', 'Oasis OrganicsDessert Ranch 34', 'z6-01690',\r\n# write_to_sheet=True, write_to_portal_sheet=True, write_to_db=True, subtract_from_mrid=550)\r\n# onlyCertainGrowersFieldLoggerUpdate('Oasis Organics', 'Oasis OrganicsDessert Ranch 34', 'z6-02020',\r\n# write_to_sheet=True, write_to_portal_sheet=True, write_to_db=True, subtract_from_mrid=550)\r\n# onlyCertainGrowersFieldLoggerUpdate('OPC', 'OPC11-2', 'z6-07267', write_to_sheet=True, write_to_portal_sheet=True,\r\n# write_to_db=True, subtract_from_mrid=96)\r\n\r\n\r\n# getAcres('OPC4-1', 'z6-06002')\r\n\r\n# onlyCertainGrowersFieldUpdate(\"Schreiner Bros\", \"Schreiner Bros121\", get_weather=True, get_data=True,\r\n# write_to_sheet=True, write_to_portal_sheet=True, write_to_db=True) onlyCertainGrowersFieldLoggerUpdate(\"Andrew\",\r\n# \"Andrew3104\", \"z6-12300\", write_to_sheet=True, write_to_portal_sheet=True, write_to_db=True)\r\n# onlyCertainGrowersFieldLoggerUpdate(\"KTN JV\", \"KTN JVYA1\", \"z6-11489\", write_to_sheet=True)\r\n# onlyCertainGrowersFieldLoggerUpdate(\"KTN JV\", \"KTN JVYA1\", \"z6-11562\", write_to_sheet=True)\r\n# onlyCertainGrowersFieldLoggerUpdate(\"KTN JV\", \"KTN JVYA1\", \"z6-02049\", write_to_sheet=True)\r\n# onlyCertainGrowersFieldLoggerUpdate(\"KTN JV\", \"KTN JVYA1\", \"z6-01887\", write_to_sheet=True)\r\n# onlyCertainGrowersUpdate([\"Bullseye Farms\", \"CICC\", \"Sean Doherty\", \"Sycamore Marsh Farms\", \"FS\", \"KTN JV\",\r\n# \"Knight Farms\", \"Andrew\", \"Dougherty Bros\", \"JK Vineyards\", \"Kidwell Farms\", \"UC Davis\", \"Zuckerman Farms\"],\r\n# get_data=True,  write_to_sheet=True, write_to_db=True, get_weather=True, write_to_portal_sheet=True)\r\n# onlyCertainGrowersFieldUpdate('Knight Farms', 'ntosDS1', get_weather=True, get_data=True, write_to_db=True,\r\n# write_to_sheet=True, write_to_portal_sheet=True) write_new_csv_to_db() show_pickle()\r\n\r\n# onlyCertainGrowersFieldUpdate() onlyCertainGrowersFieldLoggerUpdate('OPC', \"OPC14-1\", \"z6-02024\",\r\n# write_to_portal_sheet=True, write_to_sheet=True, write_to_db=True)\r\n\r\n# grower = setupGrower('Saul', '1S8acM-DKwrMaxOZpEdndvHn59xij7OHxtB6ztErIxoY')\r\n# addGrowerToGrowers(grower)\r\n#\r\n# field = setupField('Meza', '1TtZQM1GU6h88P83U6EGEUojIResR5gSyBBC7SR6gQZc', '37.053941099999996',\r\n# '-120.80917459999999', '56') logger1 = setupLogger('z6-07275', '65299-46534', 'Development', 1665227864, 'Tomato',\r\n# 36, 22, 1200, 100) field.addLogger(logger1) addFieldToGrower('Saul', field)\r\n#\r\n# grower = setupGrower('Casey', '1S8acM-DKwrMaxOZpEdndvHn59xij7OHxtB6ztErIxoY')\r\n# addGrowerToGrowers(grower)\r\n#\r\n# field = setupField('Pistachios', '1TtZQM1GU6h88P83U6EGEUojIResR5gSyBBC7SR6gQZc', '37.053941099999996',\r\n# '-120.80917459999999', '56') logger1 = setupLogger('z6-02181', '18379-27319', 'Development2', 1096363282,\r\n# 'Pistachios', 36, 22) field.addLogger(logger1) addFieldToGrower('Casey', field)\r\n#\r\n# show_pickle()\r\n\r\n# c = CIMIS()\r\n# et = c.get_eto('15', '01/01/2021', '04/16/2021')\r\n# print(et)\r\n\r\n# update_information(get_weather=True, write_to_sheet=True)\r\n\r\n# removeGrower(\"Dougherty Bros\")\r\n# update_information()\r\n# removeGrower('Casey')\r\n# onlyCertainGrowersFieldsUpdate(['Hughes304-3'], get_et=True, write_to_db=True)\r\n# onlyCertainGrowersUpdate(['Saul'], get_data=True, write_to_sheet=True, write_to_db=True)\r\n# update_information(get_data=True, write_to_db=True)\r\n# update_information(get_et=True)\r\n#\r\n# show_pickle()\r\n# update_information(get_data=True, write_to_db=True)\r\n# growers = open_pickle()\r\n# for g in growers:\r\n#     if g.name == \"Oasis Organics\":\r\n#         for f in g.fields:\r\n#             for l in f.loggers:\r\n# newDate = datetime.datetime(2021, 3, 1).date()\r\n# l.planting_date = newDate\r\n# print(l.planting_date)\r\n# print(type(l.planting_date))\r\n# if f.name == \"Bullseye FarmsST2\":\r\n#     print(\"Old cimis staiton: \" + f.cimisStation)\r\n# f.cimisStation = \"226\"\r\n# print(\"New cimis station: \" + f.cimisStation)\r\n# write_pickle(growers)\r\n\r\n# for l in f.loggers:\r\n#     print(l.planting_date)\r\n#     if hasattr(l, 'gpm'):\r\n#         print('GPM: ' + str(l.gpm))\r\n#     else:\r\n#         print('No GPM')\r\n#     if hasattr(l, 'acres'):\r\n#         print('Acres: ' + str(l.acres))\r\n#     else:\r\n#         print('No Acres')\r\n# print()\r\n# update_information(get_et=True, write_to_db=True)\r\n# for g in growers:\r\n#     if g.name != 'Matteoli':\r\n#         g.region = \"South\"\r\n#     elif g.name  == 'Matteoli':\r\n#         g.region = \"North\"\r\n#     else:\r\n#         g.region = ''\r\n# write_pickle(growers)\r\n# show_pickle()\r\n#     for f in g.fields:\r\n#         for l in f.loggers:\r\n#             print(\"New Logger\")\r\n#             print(l.name)\r\n#             print(l.cropType)\r\n#             if l.fieldCapacity:\r\n#                 print(l.fieldCapacity)\r\n#             else:\r\n#                 print('            No FC')\r\n#             if l.wiltingPoint:\r\n#                 print(l.wiltingPoint)\r\n#             else:\r\n#                 print('           No WP')\r\n#             print()\r\n# if g.name == \"Hughes\":\r\n#         g.fields[0].loggers[0].setCropType(\"Pistachios\")\r\n#         g.fields[0].loggers[1].setCropType(\"Pistachios\")\r\n# write_pickle(growers)\r\n# show_pickle()\r\n# onlyCertainGrowersUpdate('Saul', get_data=True, write_to_db=True)\r\n# update_information(get_data=True, write_to_db=True)\r\n# update_information(all_params=True)\r\n\r\n# setup_grower('Javier Test', 'aaa', 'aaa', 'aaa', True)\r\n# show_pickle()\r\n\r\n# only_certain_growers_field_logger_update('Riley Chaney Farms', 'Riley Chaney Farms16', 'RC-16-E')\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     print(grower.name)\r\n#     for field in grower.fields:\r\n#         if field.name == 'Bone FarmsN42 N43':\r\n#             for logger in field.loggers:\r\n#                 logger.gpm = float(1490)\r\n# write_pickle(growers)\r\n# remove_field('KTN JV', 'KTN JVYA1')\r\n# remove_field('CM Ochoa', 'CM OchoaL37')\r\n# remove_field('CM Ochoa', 'CM OchoaL35')\r\n#\r\n# new_year_pickle_cleanup()\r\n\r\n\r\n# deactivate_grower('S&S Ranch'\r\n# dbw = DBWriter()\r\n# dbw.list_datasets('growers-2024')\r\n# client = dbw.grab_bq_client('growers-2024')\r\n# service_email = client.get_service_account_email()\r\n# print(service_email)\r\n# deactivate_grower('S&S Ranch')\r\n\r\n\r\n# remove_inactive_growers_from_pickle()\r\n# remove_inactive_fields_from_growers_from_pickle()\r\n\r\n# only_certain_growers_update(['Bone Farms'], get_weather=True, get_data=True, write_to_portal=True, write_to_db=True, subtract_from_mrid=216)\r\n# remove_grower('Bone Farms')\r\n# only_certain_growers_field_update('Barrios Farms', 'Barrios Farms25W', True, True, True, True)\r\n\r\n# show_pickle()\r\n\r\n\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             print(f'Field {field.name}')\r\n#             print('BEFORE')\r\n#             logger.show_irrigation_ledger()\r\n#             print('CLEANING...')\r\n#             logger.cwsi_processor.clean_irrigation_ledger(logger.irrigation_ledger)\r\n#             print('AFTER')\r\n#             logger.show_irrigation_ledger()\r\n#             print()\r\n# write_pickle(growers)\r\n\r\n# show_pickle()\r\n\r\n# only_certain_growers_field_update('Barrios Farms', 'Barrios Farms25W', get_data=True, write_to_db=True, write_to_portal=True, subtract_from_mrid=48)\r\n# only_certain_growers_update(['Lucero Kern'], get_weather=True, get_data=True, write_to_db=True, write_to_portal=True)\r\n\r\n# setup_logger()\r\n# growers = open_pickle()\r\n# cimis_stations_pickle = open_pickle(filename=\"cimisStation.pickle\")\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         for logger in field.loggers:\r\n#             if logger.name == 'BF-25W-C':\r\n#                 print(logger)\r\n#                 logger.id = 'z6-11954'\r\n#                 logger.password = '91051-01535'\r\n#                 logger.updated = False\r\n#                 logger.update(cimis_stations_pickle, write_to_db=True)\r\n\r\n# show_pickle()\r\n# only_certain_growers_update(['Seasholtz'], get_weather=True, get_data=True, write_to_portal=True, write_to_db=True, subtract_from_mrid=200)\r\n# show_field('Barrios Farms25W')\r\n# remove_grower('Mike Silva Farms')\r\n# only_certain_growers_field_logger_update('Barrios Farms', 'Barrios Farms36W', 'BF-36W-C', write_to_db=True)\r\n# pull_all_et_values('2024-01-01', '2024-04-01')\r\ncimis = CIMIS()\r\n# cimis.get_eto(['105', '105','105','105','105','105','105','105','105','105','105','105','105','105','105','105','105','105'],'2024-01-01', '2024-04-01')\r\n# cimis.get_eto(['105'],'2024-01-01', '2024-04-01')\r\nupdate_all_eto_values('2024-01-01', '2024-04-01')\r\nprint()\r\n# remove_grower('Seasholtz')\r\n# growers = open_pickle()\r\n# for grower in growers:\r\n#     if grower.technician.name == 'Vanessa':\r\n#         print()\r\n#         # grower.technician.email.append('acaposella@morningstarco.com')\r\n#         # grower.technician.email.append('frankielozano89@gmail.com')\r\n#         break\r\n#\r\n# print()\r\n# write_pickle(growers)\r\n\r\n\r\n\r\n# all_techs = get_all_technicians(growers)\r\n# print()\r\n\r\n# only_certain_growers_field_update('Lucero Kern', 'Lucero Kern212', get_weather=True, get_data=True, write_to_db=True, write_to_portal=True)\r\n\r\n# start_date = datetime(2024, 3, 26).date()\r\n# end_date = datetime(2024, 3, 28).date()\r\n# update_et_information(get_et=True, write_to_db=True, start_date=start_date, end_date=end_date)\r\n\r\n# show_pickle()\r\n# only_certain_growers_field_logger_update('Seasholtz', 'SeasholtzOnion', 'SH-ON-NE', write_to_db=True, subtract_from_mrid=48)\r\n\r\n\r\n# cimis = CIMIS()\r\n# cimis.get_eto(['105'],'2024-01-01', '2024-04-01')\r\n\r\n# cimis_stations_pickle = open_pickle(filename=\"cimisStation.pickle\")\r\n# print()
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Decagon.py b/Decagon.py
--- a/Decagon.py	
+++ b/Decagon.py	
@@ -978,13 +978,13 @@
     dbwriter.write_to_table_from_csv(historicalET, table, filename, schema, project, overwrite=overwrite)
 
 
-def write_new_historical_et_to_db_2(dataset_id, table, data, filename="newhistoricalET.csv", overwrite=False):
+def write_new_historical_et_to_db_2(dataset_id, table, data, filename="HistoricalET.csv", overwrite=False):
     """
-    Function writes irr scheduling data into csv then creates a db table from csv
+    Function writes irr scheduling data into csv then creates a db table from csv given a data table of dates and etos
 
     :param dataset_id:
-    :param table:
-    :param data:
+    :param table: The station number
+    :param data: Dictionary of dates and etos
     :param filename:
     :param overwrite:
     """
@@ -992,28 +992,30 @@
     with open(filename, "w", newline='') as outfile:
         writer = csv.writer(outfile)
         writer.writerow(data.keys())
-        # Using zip_longest because dict rows are uneven length due to daily_switch algo issue
-        # This will add full null rows for any additional daily_switch list values
         writer.writerows(zip_longest(*data.values()))
     print('...Done - file: ' + filename)
-
+    keys_list = list(data.keys())
     schema = [
-        bigquery.SchemaField("Year_2022", "DATE", mode="NULLABLE"),
-        bigquery.SchemaField("Year_2022_ET", "Float", mode="NULLABLE"),
-        bigquery.SchemaField("Year_2021", "DATE", mode="NULLABLE"),
-        bigquery.SchemaField("Year_2021_ET", "Float", mode="NULLABLE"),
-        bigquery.SchemaField("Year_2020", "DATE", mode="NULLABLE"),
-        bigquery.SchemaField("Year_2020_ET", "Float", mode="NULLABLE"),
-        bigquery.SchemaField("Year_2019", "DATE", mode="NULLABLE"),
-        bigquery.SchemaField("Year_2019_ET", "Float", mode="NULLABLE"),
-        bigquery.SchemaField("Year_2018", "DATE", mode="NULLABLE"),
-        bigquery.SchemaField("Year_2018_ET", "Float", mode="NULLABLE"),
-        bigquery.SchemaField("Average", "Float", mode="NULLABLE")
+        bigquery.SchemaField(keys_list[0], "DATE", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[1], "Float", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[2], "DATE", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[3], "Float", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[4], "DATE", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[5], "Float", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[6], "DATE", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[7], "Float", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[8], "DATE", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[9], "Float", mode="NULLABLE"),
     ]
     dbwriter = DBWriter()
     print("Writing Data to DB")
     project = 'stomato-info'
+    full_table_id = f'{project}.{dataset_id}.{table}'
     dbwriter.write_to_table_from_csv(dataset_id, table, filename, schema, project, overwrite=overwrite)
+    dml_statement1 = f'ALTER TABLE {full_table_id} ADD COLUMN Average FLOAT64'
+    dbwriter.run_dml(dml_statement1)
+    dml_statement2 = f'UPDATE {full_table_id} SET Average = ({keys_list[1]} + {keys_list[3]} + {keys_list[5]} + {keys_list[7]} + {keys_list[9]} ) / 5 WHERE True'
+    dbwriter.run_dml(dml_statement2)
 
 
 def update_irr_scheduling(table, fieldName, data, filename="irrScheduling.csv", overwrite=False, logger=None):
@@ -5778,19 +5780,8 @@
 # remove_grower('Mike Silva Farms')
 # only_certain_growers_field_logger_update('Barrios Farms', 'Barrios Farms36W', 'BF-36W-C', write_to_db=True)
 # pull_all_et_values('2024-01-01', '2024-04-01')
-cimis = CIMIS()
-# cimis.get_eto(['105', '105','105','105','105','105','105','105','105','105','105','105','105','105','105','105','105','105'],'2024-01-01', '2024-04-01')
-# cimis.get_eto(['105'],'2024-01-01', '2024-04-01')
-update_all_eto_values('2024-01-01', '2024-04-01')
-print()
 # remove_grower('Seasholtz')
-# growers = open_pickle()
-# for grower in growers:
-#     if grower.technician.name == 'Vanessa':
-#         print()
-#         # grower.technician.email.append('acaposella@morningstarco.com')
-#         # grower.technician.email.append('frankielozano89@gmail.com')
-#         break
+
 #
 # print()
 # write_pickle(growers)
@@ -5807,11 +5798,21 @@
 # update_et_information(get_et=True, write_to_db=True, start_date=start_date, end_date=end_date)
 
 # show_pickle()
-# only_certain_growers_field_logger_update('Seasholtz', 'SeasholtzOnion', 'SH-ON-NE', write_to_db=True, subtract_from_mrid=48)
-
+# only_certain_growers_field_logger_update('Riley Chaney Farms', 'Riley Chaney FarmsRN 2 LLC', 'RN-2LLC-N', write_to_db=True)
+# only_certain_growers_field_update("Riley Chaney Farms", 'Riley Chaney Farms16', write_to_db=True, get_data=True, write_to_portal=True)
 
 # cimis = CIMIS()
 # cimis.get_eto(['105'],'2024-01-01', '2024-04-01')
 
-# cimis_stations_pickle = open_pickle(filename="cimisStation.pickle")
-# print()
\ No newline at end of file
+
+# remove_grower('Steve Etchegary')
+# remove_field()
+
+# growers = open_pickle()
+# for g in growers:
+#     if g.name == 'Lucero Bakersfield':
+#         for f in g.fields:
+#             if f.name == 'Lucero BakersfieldTowerline':
+#                 print('Field {} found:'.format(f.name))
+#                 f.activate()
+# write_pickle(growers)
\ No newline at end of file
Index: Field.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import csv\r\nimport uuid\r\nfrom datetime import datetime\r\nfrom datetime import timedelta\r\nfrom itertools import zip_longest\r\n\r\nimport numpy as numpy\r\nfrom google.cloud import bigquery\r\n\r\n# import Decagon\r\nfrom CwsiProcessor import CwsiProcessor\r\nfrom DBWriter import DBWriter\r\nfrom Grower import Grower\r\nfrom Notifications import AllNotifications\r\nfrom Thresholds import Thresholds\r\nfrom WeatherProcessor import WeatherProcessor\r\n\r\nDATABASE_YEAR = '2024'\r\nFIELD_PORTALS_BIGQUERY_PROJECT = 'growers-' + DATABASE_YEAR\r\n\r\n\r\nclass Field(object):\r\n    \"\"\"\r\n    Class to hold information for 1 field where we have a water management trial.\r\n\r\n    Attributes:\r\n        cimis_station: String with the value of the CIMIS station that\r\n            corresponds to the field and from which we will get ET info\r\n        name: String of the field name\r\n        grower: String of the grower name for the field\r\n        weather_processor: WeatherProcessor object used to call\r\n            weather API's to get the forecast and icons\r\n    \"\"\"\r\n\r\n    def __init__(self,\r\n                 name: str,\r\n                 loggers: list,\r\n                 lat: str,\r\n                 long: str,\r\n                 cimis_station: str,\r\n                 acres: float,\r\n                 crop_type: str,\r\n                 grower: Grower = None,\r\n                 active: bool = True,\r\n                 report_url: str = 'https://i.imgur.com/04UdmBH.png',\r\n                 preview_url: str = 'https://i.imgur.com/04UdmBH.png',\r\n                 nickname: str = '',\r\n                 field_type: str = 'Commercial',\r\n                 ):\r\n        \"\"\"\r\n        Inits Field class with the following parameters:\r\n\r\n        :param acres:\r\n        :param preview_url:\r\n        :param report_url:\r\n        :param name:\r\n        :param loggers:\r\n        :param lat:\r\n        :param long:\r\n        :param cimis_station:\r\n        :param grower:\r\n        \"\"\"\r\n\r\n        self.loggers = loggers\r\n        self.id = uuid.uuid4()\r\n        self.lat = lat\r\n        self.long = long\r\n        self.cimis_station = cimis_station\r\n        self.name = name\r\n        self.grower = grower\r\n        self.dbwriter = DBWriter()\r\n        self.cwsi_processor = CwsiProcessor()\r\n        # if grower.name == 'Sugal Chile':\r\n        #     self.weather_processor = WeatherProcessor(self.lat, self.long, use_celsius=True)\r\n        # else:\r\n        self.weather_processor = WeatherProcessor(self.lat, self.long)\r\n        self.all_notifications = AllNotifications()\r\n        self.updated = False\r\n        self.weather_crashed = False\r\n        self.active = active\r\n        self.report_url = report_url\r\n        self.preview_url = preview_url\r\n        self.acres = acres\r\n        self.crop_type = crop_type\r\n        self.net_yield = None\r\n        self.paid_yield = None\r\n        self.field_type = field_type\r\n\r\n        if len(nickname) > 0:\r\n            self.nickname = nickname\r\n        else:\r\n            self.nickname = name\r\n        if grower is not None:\r\n            self.field_string = self.grower.name + \" - \" + self.name\r\n\r\n    def __repr__(self):\r\n        return f'Field: {self.nickname}, Active: {self.active}, # of Loggers: {len(self.loggers)}'\r\n\r\n    def check_successful_updated_loggers(self):\r\n        successful_loggers = 0\r\n        number_of_active_loggers, number_of_inactive_loggers = self.get_number_of_active_loggers()\r\n        for logger in self.loggers:\r\n            if logger.active and logger.updated:\r\n                successful_loggers += 1\r\n        if successful_loggers == number_of_active_loggers:\r\n            print(f\"\\t\\tAll loggers for Field {self.name} successful! \")\r\n            print(f\"\\t\\tSuccess: {successful_loggers}/ Active: {number_of_active_loggers}\")\r\n            self.updated = True\r\n        else:\r\n            print(\"\\t\\t{0}/{1} loggers updated successfully\".format(successful_loggers, number_of_active_loggers))\r\n            self.updated = False\r\n\r\n    def add_logger(self, logger):\r\n        self.loggers.append(logger)\r\n\r\n    def add_loggers(self, loggers: list):\r\n        for logger in loggers:\r\n            self.loggers.append(logger)\r\n\r\n    def to_string(self, include_loggers: bool = True):\r\n        \"\"\"\r\n        Function used to print out output to screen. Prints out the field name, grower,\r\n            location GSheetURL, gSheetEtName, gSheetWeatherName, gSheetWeatherIconName,\r\n            cimisStation.\r\n            Then it calls on its plots list and has each object in the list call its own toString function\r\n        :return:\r\n        \"\"\"\r\n        if not hasattr(self, 'cimis_station'):\r\n            if hasattr(self, 'cimisStation'):\r\n                self.cimis_station = self.cimisStation\r\n\r\n        if not hasattr(self, 'report_url'):\r\n            self.report_url = 'No URL'\r\n\r\n        if not hasattr(self, 'crop_type'):\r\n            self.crop_type = self.loggers[0].crop_type\r\n\r\n        field_str = f'Field: {str(self.name)}'\r\n        location_str = f'Location: ({str(self.lat)},{str(self.long)})'\r\n        active_str = f'Active: {str(self.active)}'\r\n        crop_type_str = f'Crop Type: {str(self.crop_type)}'\r\n        net_yield_str = f'Yield --> Net T/A: {str(self.net_yield)}'\r\n\r\n\r\n        print('---------------------------------------------------------------------------------------------------')\r\n        print(f'\\t{field_str:40} | Grower: {str(self.grower.name)}')\r\n        print(f'\\t{location_str:40} | CimisStation: {str(self.cimis_station)}')\r\n        print(f'\\t{active_str:40} | Updated: {str(self.updated)}')\r\n        print(f'\\t{crop_type_str:40} | Field Type: {self.field_type}')\r\n        print(f'\\t{net_yield_str:40} | Paid T/A: {str(self.paid_yield)}')\r\n        print(f'\\tReport URL: {str(self.report_url)}')\r\n        print()\r\n        if include_loggers:\r\n            for logger in self.loggers:\r\n                logger.to_string()\r\n        print('---------------------------------------------------------------------------------------------------')\r\n\r\n    def update(\r\n            self,\r\n            cimis_stations_pickle,\r\n            get_weather: bool = False,\r\n            get_data: bool = False,\r\n            write_to_portal: bool = False,\r\n            write_to_db: bool = False,\r\n            check_for_notifications: bool = False,\r\n            check_updated: bool = False,\r\n            subtract_from_mrid: int = 0\r\n    ):\r\n        \"\"\"\r\n        Function used to update each fields information. This function will be called every day.\r\n        This function then calls the update function on each of its plots[]\r\n\r\n        :param subtract_from_mrid: Int used to subtract a specific amount from the logger MRIDs for API calls\r\n        :param cimis_stations_pickle:\r\n        :param get_weather: Boolean that dictates if we want to get the fields weather forecast\r\n        :param get_data: Boolean that dictates if we want to get the logger data\r\n        :param write_to_portal:\r\n        :param write_to_db:\r\n        :param check_for_notifications:\r\n        :param check_updated:\r\n        :return:\r\n        \"\"\"\r\n        if self.active:\r\n            # self.field_string = self.grower.name + \" - \" + self.name\r\n            print()\r\n\r\n            if self.updated and not self.weather_crashed:\r\n                print('\\tField: ' + self.name + '  already updated. Skipping...')\r\n            else:\r\n                print(f'FIELD updating: {str(self.grower.name)} - {self.name} ->')\r\n\r\n                # UPDATE WEATHER\r\n                if get_weather:\r\n                    try:\r\n                        forecast = self.get_weather_forecast()\r\n                        self.weather_crashed = False\r\n                        # weatherData, weatherIconData = self.get_weather_forecast()\r\n                    except Exception as error:\r\n                        print(\"\\tError in Field get_weather - \" + self.name)\r\n                        print(\"\\tError type: \" + str(error))\r\n                        forecast = []\r\n                        self.weather_crashed = True\r\n                else:\r\n                    print('\\tNot doing Weather')\r\n\r\n                # Write weather data to DB\r\n                if write_to_db and get_weather:\r\n                    if not forecast:\r\n                        print('\\tNo weather data')\r\n                    else:\r\n                        try:\r\n                            print('\\tPreparing weather data to be written to DB-')\r\n                            # Prep data for writing to DB\r\n                            weather_schema, weather_filename = self.prep_weather_data_for_writing_to_db(forecast)\r\n\r\n                            # Prep DB\r\n                            self.prep_db_for_weather(forecast)\r\n\r\n                            # Write to DB\r\n                            print()\r\n                            print('\\tWriting weather data to DB')\r\n                            field_name = self.dbwriter.remove_unwanted_chars_for_db_dataset(self.name)\r\n                            project = self.dbwriter.get_db_project(self.loggers[0].crop_type)\r\n                            self.dbwriter.write_to_table_from_csv(\r\n                                field_name, 'weather_forecast', weather_filename, weather_schema, project\r\n                            )\r\n                        except Exception as error:\r\n                            print(\"Error in Field Weather DB Write - \" + self.name)\r\n                            print(\"Error type: \" + str(error))\r\n\r\n                if not self.updated:\r\n                    # Get data\r\n                    if get_data:\r\n                        #\r\n                        # For each logger, call its update function\r\n\r\n                        field_loggers_portal_data = {}\r\n                        for logger in self.loggers:\r\n                            logger_portal_data = logger.update(cimis_stations_pickle, write_to_db=write_to_db,\r\n                                                               check_for_notifications=check_for_notifications,\r\n                                                               check_updated=check_updated,\r\n                                                               subtract_from_mrid=subtract_from_mrid)  # do logger updates\r\n                            if logger_portal_data is not None:\r\n                                field_loggers_portal_data[logger.id] = logger_portal_data\r\n                        self.check_successful_updated_loggers()\r\n                    else:\r\n                        print('\\tNot doing Data')\r\n                        print()\r\n\r\n                    # Handling all portal data (Field Portal and Logger Portal) - Processing and writing to portal\r\n                    if write_to_portal and get_data:\r\n                        try:\r\n                            self.cwsi_processor = CwsiProcessor()\r\n                            if field_loggers_portal_data:\r\n                                new_data_to_write_to_portal = False\r\n                                for logger in self.loggers:\r\n                                    if logger.active and logger.id in field_loggers_portal_data:\r\n                                        if field_loggers_portal_data[logger.id]['dates']:\r\n                                            # Intentional way of setting new_data_to_write_to_portal that sets it to True if\r\n                                            # any of the loggers do have data that needs to be written, even if loggers after\r\n                                            # that don't have new data\r\n                                            new_data_to_write_to_portal = new_data_to_write_to_portal or True\r\n                                        else:\r\n                                            new_data_to_write_to_portal = new_data_to_write_to_portal or False\r\n\r\n                                if new_data_to_write_to_portal:\r\n                                    print()\r\n                                    print('\\t>>> Handling ', self.name, ' Portal Data')\r\n\r\n                                    field_averages_table_schema = [bigquery.SchemaField(\"order\", \"FLOAT\"),\r\n                                                                   bigquery.SchemaField(\"field\", \"STRING\"),\r\n                                                                   bigquery.SchemaField(\"crop_type\", \"STRING\"),\r\n                                                                   bigquery.SchemaField(\"crop_image\", \"STRING\"),\r\n                                                                   bigquery.SchemaField(\"soil_moisture_num\", \"FLOAT\"),\r\n                                                                   bigquery.SchemaField(\"soil_moisture_desc\", \"STRING\"),\r\n                                                                   bigquery.SchemaField(\"si_num\", \"FLOAT\"),\r\n                                                                   bigquery.SchemaField(\"si_desc\", \"STRING\"),\r\n                                                                   bigquery.SchemaField(\"report\", \"STRING\"),\r\n                                                                   bigquery.SchemaField(\"preview\", \"STRING\")]\r\n\r\n                                    logger_portal_table_schema = field_averages_table_schema.copy()\r\n                                    logger_portal_table_schema.append(\r\n                                        bigquery.SchemaField(\"logger_name\", \"STRING\")\r\n                                    )\r\n                                    logger_portal_table_schema.append(\r\n                                        bigquery.SchemaField(\"logger_direction\", \"STRING\")\r\n                                    )\r\n\r\n                                    #  Grab field portal data average\r\n                                    print('\\t\\tGrabbing field average data...')\r\n                                    average_field_portal_data = self.average_field_portal_data(field_loggers_portal_data)\r\n\r\n                                    # Process field portal data average\r\n                                    print('\\t\\tProcessing field portal data...')\r\n                                    processed_average_field_portal_data = self.cwsi_processor.process_data_for_writing_db_portal(\r\n                                        average_field_portal_data, self\r\n                                    )\r\n\r\n                                    # Write field portal data\r\n                                    print('\\t\\tWriting field portal data...')\r\n                                    grower_name = self.dbwriter.remove_unwanted_chars_for_db_dataset(self.grower.name)\r\n                                    field_averages_portal_dataset_id = FIELD_PORTALS_BIGQUERY_PROJECT + '.' + grower_name + '.field_averages'\r\n                                    logger_portal_dataset_id = FIELD_PORTALS_BIGQUERY_PROJECT + '.' + grower_name + '.loggers'\r\n\r\n                                    # Check field portal table for field\r\n                                    value_exists = self.check_if_row_value_exists_in_table(\r\n                                        field_averages_portal_dataset_id, 'field', self.nickname, FIELD_PORTALS_BIGQUERY_PROJECT\r\n                                    )\r\n                                    # If it's there, replace specific column values\r\n                                    if value_exists:\r\n                                        # update_portal_table_value(self, dbw, dataset_id, column_name, value_name, processed_portal_data)\r\n                                        self.update_portal_table_value(\r\n                                            field_averages_portal_dataset_id, 'field', self.nickname,\r\n                                            processed_average_field_portal_data\r\n                                        )\r\n                                    else:\r\n                                        # If not, write new row for field\r\n                                        self.write_portal_row(\r\n                                            field_averages_table_schema, grower_name, processed_average_field_portal_data,\r\n                                            'field_averages'\r\n                                        )\r\n\r\n                                    # Process logger portal data\r\n                                    print()\r\n                                    print('\\t\\tProcessing logger portal data...')\r\n                                    processed_logger_portal_data = []\r\n                                    for logger in self.loggers:\r\n                                        if logger.id in field_loggers_portal_data:\r\n                                            processed_logger_portal_data.append(\r\n                                                self.cwsi_processor.process_data_for_writing_db_portal(\r\n                                                    field_loggers_portal_data[logger.id],\r\n                                                    self,\r\n                                                    logger_name=logger.name,\r\n                                                    logger_direction=logger.logger_direction\r\n                                                )\r\n                                            )\r\n                                    print('\\t\\tWriting logger portal data...')\r\n                                    for logger_processed_data in processed_logger_portal_data:\r\n                                        value_exists = self.check_if_row_value_exists_in_table(\r\n                                            logger_portal_dataset_id, 'logger_name', logger_processed_data[\"logger_name\"],\r\n                                            FIELD_PORTALS_BIGQUERY_PROJECT\r\n                                        )\r\n                                        # If it's there, replace specific column values\r\n                                        if value_exists:\r\n                                            # update_portal_table_value(self, dbw, dataset_id, column_name, value_name, processed_portal_data)\r\n                                            self.update_portal_table_value(\r\n                                                logger_portal_dataset_id, 'logger_name', logger_processed_data[\"logger_name\"],\r\n                                                logger_processed_data\r\n                                            )\r\n                                        else:\r\n                                            # If not, write new row for field\r\n                                            self.write_portal_row(\r\n                                                logger_portal_table_schema, grower_name, logger_processed_data, 'loggers'\r\n                                            )\r\n                                    print('\\t<<< Done with ', self.name, ' Portal Data')\r\n                                else:\r\n                                    print('\\tNothing new to write to portal')\r\n                        except Exception as error:\r\n                            print(\"Error in field portal data - \" + self.name)\r\n                            print(\"Error type: \" + str(error))\r\n                    print(str(self.grower.name) + ' - ' + str(self.name) + ' Done Updating-')\r\n                    print()\r\n        else:\r\n            print('Field - {} not active'.format(self.name))\r\n\r\n    def write_portal_row(self, table_schema, grower_name: str, processed_portal_data: dict, table_name: str):\r\n        print('\\t\\t\\tdata not already in table')\r\n        print('\\t\\t\\tWriting new row')\r\n        filename = 'portal_data.csv'\r\n        print('\\t\\t\\t- writing data to csv')\r\n        with open(filename, \"w\", newline='') as outfile:\r\n            writer = csv.writer(outfile)\r\n            writer.writerow(processed_portal_data.keys())\r\n            # Using zip_longest because dict rows are uneven length due to daily_switch algo issue\r\n            # This will add full null rows for any additional daily_switch list values\r\n            writer.writerow(processed_portal_data.values())\r\n        print('\\t\\t\\t...Done - file: ' + filename)\r\n        self.dbwriter.write_to_table_from_csv(\r\n            grower_name, table_name, filename, table_schema, project=FIELD_PORTALS_BIGQUERY_PROJECT\r\n        )\r\n\r\n    def update_portal_table_value(self, dataset_id: str, column_name: str, value_name: str,\r\n                                  processed_portal_data: dict):\r\n        print('\\t\\t\\tData already found in table')\r\n        print('\\t\\t\\tUpdating table values')\r\n\r\n        # DML statement doesn't like None for update, so we changed to 'null'\r\n        if processed_portal_data[\"si_num\"] is None:\r\n            processed_portal_data[\"si_num\"] = 'null'\r\n        if processed_portal_data[\"soil_moisture_num\"] is None:\r\n            processed_portal_data[\"soil_moisture_num\"] = 'null'\r\n        dml = \"UPDATE \" + dataset_id + \" as t SET t.order = \" + str(processed_portal_data[\"order\"]) \\\r\n              + \", t.soil_moisture_num = \" + str(processed_portal_data[\"soil_moisture_num\"]) \\\r\n              + \", t.soil_moisture_desc = '\" + str(processed_portal_data[\"soil_moisture_desc\"]) + \"'\" \\\r\n              + \", t.si_num = \" + str(processed_portal_data[\"si_num\"]) \\\r\n              + \", t.si_desc = '\" + str(processed_portal_data[\"si_desc\"]) + \"'\" \\\r\n              + \", t.crop_image = '\" + str(processed_portal_data[\"crop_image\"]) + \"'\" \\\r\n              + \", t.report = '\" + str(processed_portal_data[\"report\"]) + \"'\" \\\r\n              + \", t.preview = '\" + str(processed_portal_data[\"preview\"]) + \"'\" \\\r\n              + \", t.field = '\" + str(processed_portal_data[\"field\"]) + \"'\" \\\r\n              + \" WHERE t.\" + column_name + \" = '\" + str(value_name) + \"'\"\r\n        # print('\\t\\t\\t  - ' + str(dml))\r\n        self.dbwriter.run_dml(dml, project=FIELD_PORTALS_BIGQUERY_PROJECT)\r\n\r\n    def check_if_row_value_exists_in_table(self, dataset_id: str, column_name: str, value_name: str,\r\n                                           project: str) -> bool:\r\n        dml = \"SELECT \" + column_name + \" FROM \" + dataset_id + \" WHERE \" + column_name + \" = '\" + value_name + \"'\"\r\n        result = self.dbwriter.run_dml(dml, project=project)\r\n        if len(list(result)) >= 1:\r\n            return True\r\n        return False\r\n\r\n    def average_field_portal_data(self, all_loggers_portal_data: dict) -> dict:\r\n        field_loggers = list(all_loggers_portal_data.keys())\r\n        data_keys = list(all_loggers_portal_data[field_loggers[0]].keys())\r\n        average_field_portal_data = dict.fromkeys(data_keys)\r\n\r\n        for each_logger in all_loggers_portal_data:\r\n            if all_loggers_portal_data[each_logger]['dates'] is not None:\r\n                average_field_portal_data['dates'] = all_loggers_portal_data[each_logger]['dates']\r\n            break\r\n\r\n        canopy_temps = []\r\n        ambient_temps = []\r\n        cwsis = []\r\n        sdds = []\r\n        rhs = []\r\n        vpds = []\r\n        vwc_1s = []\r\n        vwc_2s = []\r\n        vwc_3s = []\r\n        vwc_1_ecs = []\r\n        vwc_2_ecs = []\r\n        vwc_3_ecs = []\r\n        daily_switchs = []\r\n        kcs = []\r\n\r\n        for logger_data in all_loggers_portal_data:\r\n            canopy_temperature = all_loggers_portal_data[logger_data]['canopy temperature']\r\n            ambient_temperature = all_loggers_portal_data[logger_data]['ambient temperature']\r\n            cwsi = all_loggers_portal_data[logger_data]['cwsi']\r\n            sdd = all_loggers_portal_data[logger_data]['sdd']\r\n            rh = all_loggers_portal_data[logger_data]['rh']\r\n            vpd = all_loggers_portal_data[logger_data]['vpd']\r\n            vwc_1 = all_loggers_portal_data[logger_data]['vwc_1']\r\n            vwc_2 = all_loggers_portal_data[logger_data]['vwc_2']\r\n            vwc_3 = all_loggers_portal_data[logger_data]['vwc_3']\r\n            vwc_1_ec = all_loggers_portal_data[logger_data]['vwc_1_ec']\r\n            vwc_2_ec = all_loggers_portal_data[logger_data]['vwc_2_ec']\r\n            vwc_3_ec = all_loggers_portal_data[logger_data]['vwc_3_ec']\r\n            daily_switch = all_loggers_portal_data[logger_data]['daily switch']\r\n            if 'kc' in all_loggers_portal_data[logger_data].keys():\r\n                kc = all_loggers_portal_data[logger_data]['kc']\r\n            else:\r\n                kc = None\r\n\r\n            if canopy_temperature is not None:\r\n                canopy_temps.append(canopy_temperature)\r\n            if ambient_temperature is not None:\r\n                ambient_temps.append(ambient_temperature)\r\n            if cwsi is not None:\r\n                cwsis.append(cwsi)\r\n            if sdd is not None:\r\n                sdds.append(sdd)\r\n            if rh is not None:\r\n                rhs.append(rh)\r\n            if vpd is not None:\r\n                vpds.append(vpd)\r\n            if vwc_1 is not None:\r\n                vwc_1s.append(vwc_1)\r\n            if vwc_2 is not None:\r\n                vwc_2s.append(vwc_2)\r\n            if vwc_3 is not None:\r\n                vwc_3s.append(vwc_3)\r\n            if vwc_1_ec is not None:\r\n                vwc_1_ecs.append(vwc_1_ec)\r\n            if vwc_2_ec is not None:\r\n                vwc_2_ecs.append(vwc_2_ec)\r\n            if vwc_3_ec is not None:\r\n                vwc_3_ecs.append(vwc_3_ec)\r\n            if daily_switch is not None:\r\n                daily_switchs.append(daily_switch)\r\n            if kc is not None:\r\n                kcs.append(kc)\r\n\r\n        if len(canopy_temps) > 0:\r\n            average_field_portal_data['canopy temperature'] = numpy.mean(canopy_temps)\r\n        if len(ambient_temps) > 0:\r\n            average_field_portal_data['ambient temperature'] = numpy.mean(ambient_temps)\r\n        if len(cwsis) > 0:\r\n            average_field_portal_data['cwsi'] = numpy.mean(cwsis)\r\n        if len(sdds) > 0:\r\n            average_field_portal_data['sdd'] = numpy.mean(sdds)\r\n        if len(rhs) > 0:\r\n            average_field_portal_data['rh'] = numpy.mean(rhs)\r\n        if len(vpds) > 0:\r\n            average_field_portal_data['vpd'] = numpy.mean(vpds)\r\n        if len(vwc_1s) > 0:\r\n            average_field_portal_data['vwc_1'] = numpy.mean(vwc_1s)\r\n        if len(vwc_2s) > 0:\r\n            average_field_portal_data['vwc_2'] = numpy.mean(vwc_2s)\r\n        if len(vwc_3s) > 0:\r\n            average_field_portal_data['vwc_3'] = numpy.mean(vwc_3s)\r\n        if len(vwc_1_ecs) > 0:\r\n            average_field_portal_data['vwc_1_ec'] = numpy.mean(vwc_1_ecs)\r\n        if len(vwc_2_ecs) > 0:\r\n            average_field_portal_data['vwc_2_ec'] = numpy.mean(vwc_2_ecs)\r\n        if len(vwc_3_ecs) > 0:\r\n            average_field_portal_data['vwc_3_ec'] = numpy.mean(vwc_3_ecs)\r\n        if len(daily_switchs) > 0:\r\n            average_field_portal_data['daily switch'] = numpy.mean(daily_switchs)\r\n        if len(kcs) > 0:\r\n            average_field_portal_data['kc'] = numpy.mean(kcs)\r\n\r\n        return average_field_portal_data\r\n\r\n    def get_weather_forecast(self) -> list:\r\n        \"\"\"\r\n        Function used to get the weather forecast. Uses the weatherProcessor class to call the yahoo\r\n            weather API and get the forecast for the next 5 days\r\n        :return:\r\n            weatherMatrix: Matrix with weather forecast ready to be written to GSheet\r\n            weatherIconMatrix: Matrix with corresponding weather icons for forecast ready to be written to GSheet\r\n        \"\"\"\r\n        print()\r\n        # ## Uncomment to use Open Weather API\r\n        # print('\\tGetting weather forecast using Open Weather-')\r\n        # forecast = self.weatherProcessor.open_weather_forecast()\r\n        # ##\r\n\r\n        ## Uncomment to use Apple Weather Kit API\r\n        print('\\tGetting weather forecast using Apple Weather Kit-')\r\n        forecast = self.weather_processor.apple_forecast()\r\n        ##\r\n\r\n        print()\r\n\r\n        return forecast\r\n\r\n    def prep_weather_data_for_writing_to_db(self, forecast: list[dict]) -> (list, str):\r\n        weather_schema = [\r\n            bigquery.SchemaField(\"date\", \"DATE\"),\r\n            bigquery.SchemaField(\"day\", \"STRING\"),\r\n            bigquery.SchemaField(\"order\", \"FLOAT\"),\r\n            bigquery.SchemaField(\"temp\", \"FLOAT\"),\r\n            bigquery.SchemaField(\"rh\", \"FLOAT\"),\r\n            bigquery.SchemaField(\"vpd\", \"FLOAT\"),\r\n            bigquery.SchemaField(\"icon\", \"STRING\"),\r\n        ]\r\n        weather_filename = 'weather forecast.csv'\r\n        order = 0\r\n\r\n        weather_data = {\"date\": [], \"day\": [], \"order\": [], \"temp\": [], \"rh\": [], \"vpd\": [], \"icon\": []}\r\n        for ind, data_point in enumerate(forecast):\r\n            date = data_point['time']\r\n            date_string_format = date.strftime(\"%Y-%m-%d\")\r\n            date_day = date.strftime('%a')\r\n            max_temp = data_point['max_temp']\r\n            relative_humidity = data_point['humidity']\r\n            vpd = data_point['vpd']\r\n            forecastText = data_point['icon']\r\n            relative_humidity_percentage = relative_humidity * 100\r\n            order = ind + 1\r\n\r\n            weather_data[\"date\"].append(date_string_format)\r\n            weather_data[\"day\"].append(date_day)\r\n            weather_data[\"order\"].append(order)\r\n            weather_data[\"temp\"].append(round(max_temp, 1))\r\n            weather_data[\"rh\"].append(round(relative_humidity_percentage, 1))\r\n            weather_data[\"vpd\"].append(round(vpd, 1))\r\n            weather_data[\"icon\"].append(forecastText)\r\n\r\n        weather_data = self.add_extra_blank_days(forecast, order, weather_data)\r\n\r\n        print('\\t\\tWriting weather data to csv')\r\n        with open(weather_filename, \"w\", newline='') as outfile:\r\n            writer = csv.writer(outfile)\r\n            writer.writerow(weather_data.keys())\r\n            # Using zip_longest because dict rows are uneven length due to daily_switch algo issue\r\n            # This will add full null rows for any additional daily_switch list values\r\n            writer.writerows(zip_longest(*weather_data.values()))\r\n        print('\\t\\tDone - file: ' + weather_filename)\r\n        print()\r\n\r\n        return weather_schema, weather_filename\r\n\r\n    def add_extra_blank_days(self, forecast: list, order: int, weather_data: dict):\r\n\r\n        current_forecast_days = len(weather_data[\"date\"])\r\n        days_to_add = 10 - current_forecast_days\r\n\r\n        if days_to_add > 0:\r\n            for x in range(days_to_add):\r\n                extra_day = (forecast[-1]['time']) + timedelta(days=x + 1)\r\n                extra_day_string = extra_day.strftime(\"%Y-%m-%d\")\r\n                weather_data[\"date\"].extend([extra_day_string])\r\n                weather_data[\"day\"].extend([None])\r\n                weather_data[\"order\"].extend([order + x + 1])\r\n                weather_data[\"temp\"].extend([None])\r\n                weather_data[\"rh\"].extend([None])\r\n                weather_data[\"vpd\"].extend([None])\r\n                weather_data[\"icon\"].extend([None])\r\n\r\n        return weather_data\r\n\r\n    def prep_db_for_weather(self, forecast: list):\r\n        dbw = DBWriter()\r\n        field_name = dbw.remove_unwanted_chars_for_db_dataset(self.name)\r\n        project = dbw.get_db_project(self.loggers[0].crop_type)\r\n        table_exsists = dbw.check_if_table_exists(field_name, 'weather_forecast', project=project)\r\n        if table_exsists:\r\n            # Change the order of the previous day to 99\r\n            print('\\t\\tChanging weather order from prev day to 99')\r\n            self.change_order_from_previous_day(forecast)\r\n            # Delete all data that is between the new ranges for forecast\r\n            print('\\t\\tRemoving redundant data')\r\n            self.remove_data_that_is_about_to_be_updated(forecast)\r\n\r\n    def change_order_from_previous_day(self, forecast: list):\r\n        dbw = DBWriter()\r\n        field = dbw.remove_unwanted_chars_for_db_dataset(self.name)\r\n        first_date = (forecast[0]['time'])\r\n        # first_date_string = first_date.strftime(\"%Y-%m-%d\")\r\n        previous_date = first_date - timedelta(days=1)\r\n        previous_date_string = previous_date.strftime(\"%Y-%m-%d\")\r\n        project = dbw.get_db_project(self.loggers[0].crop_type)\r\n        dml = \"UPDATE `\" + project + \".\" + field + \".weather_forecast` as t SET t.order = 99.0 WHERE date = '\" + previous_date_string + \"'\"\r\n        dbw.run_dml(dml, project=project)\r\n\r\n    def remove_data_that_is_about_to_be_updated(self, forecast: list):\r\n        dbw = DBWriter()\r\n        field = dbw.remove_unwanted_chars_for_db_dataset(self.name)\r\n        first_date = (forecast[0]['time'])\r\n        last_date = (forecast[-1]['time']) + timedelta(days=2)\r\n        first_date_string = first_date.strftime(\"%Y-%m-%d\")\r\n        last_date_string = last_date.strftime(\"%Y-%m-%d\")\r\n        project = dbw.get_db_project(self.loggers[0].crop_type)\r\n        dml = \"DELETE `\" + project + \".\" + field + \".weather_forecast` \" \\\r\n                                                   \"WHERE date BETWEEN DATE('\" + first_date_string + \"') AND DATE('\" + last_date_string + \"') \"\r\n        # print(dml)\r\n        dbw.run_dml(dml, project=project)\r\n\r\n    def update_et_tables(self):\r\n        # latest_et = self.get_latest_et()\r\n        for logger in self.loggers:\r\n            print('\\tUpdating et values in Logger table...')\r\n            try:\r\n                logger.merge_et_db_with_logger_db_values()\r\n            except Exception as err:\r\n                print(\"ET Did not update for this logger\")\r\n                print(err)\r\n\r\n    def get_number_of_active_loggers(self) -> (int, int):\r\n        active_loggers = 0\r\n        inactive_loggers = 0\r\n        for logger in self.loggers:\r\n            if logger.active:\r\n                active_loggers += 1\r\n            else:\r\n                inactive_loggers += 1\r\n        return active_loggers, inactive_loggers\r\n\r\n    def check_for_notifications(self, weather_data):\r\n        \"\"\"\r\n        Function to check for notifications related to the weather forecast data.\r\n\r\n        :param weather_data:\r\n            2-dimensional list of the weather forecast data before it is written to GSheets. Format of the list is:\r\n            [\r\n                [day],\r\n                [temperature highs],\r\n                [temperature lows]\r\n            ]\r\n\r\n        :return:\r\n        \"\"\"\r\n        thresholds = Thresholds()\r\n        weather_threshold = thresholds.weather_threshold\r\n        consecutive_temps = thresholds.consecutive_temps\r\n        all_weather_results = {\"days\": [],\r\n                               \"temps\": []}\r\n        consecutive_weather_results = {\"days\": [],\r\n                                       \"temps\": []}\r\n\r\n        i = 0\r\n        j = 0\r\n        length = len(weather_data[1])\r\n        while i < length:\r\n            if int(weather_data[1][i]) >= weather_threshold:\r\n                all_weather_results[\"temps\"].insert(j, [int(weather_data[1][i])])\r\n                all_weather_results[\"days\"].insert(j, [weather_data[0][i]])\r\n                i += 1\r\n                while i < len(weather_data[1]):\r\n                    if int(weather_data[1][i]) >= weather_threshold:\r\n                        all_weather_results[\"temps\"][j].append(int(weather_data[1][i]))\r\n                        all_weather_results[\"days\"][j].append(weather_data[0][i])\r\n                        i += 1\r\n                    else:\r\n                        break\r\n                j += 1\r\n            i += 1\r\n        for ind, i in enumerate(all_weather_results[\"temps\"]):\r\n            if len(i) >= consecutive_temps:\r\n                consecutive_weather_results[\"temps\"].append(all_weather_results[\"temps\"][ind])\r\n                consecutive_weather_results[\"days\"].append(all_weather_results[\"days\"][ind])\r\n\r\n        if consecutive_weather_results[\"temps\"]:\r\n            self.all_notifications.add_notification(\r\n                datetime.now(), str(self.grower.name) + \" - \" + self.name,\r\n                self.field_string, \"Weather\", consecutive_weather_results,\r\n                weather_threshold, \"were greater than\"\r\n            )\r\n\r\n    def deactivate(self):\r\n        print('Deactivating Field {}...'.format(self.name))\r\n        self.active = False\r\n        for logger in self.loggers:\r\n            logger.deactivate()\r\n        print('Done')\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Field.py b/Field.py
--- a/Field.py	
+++ b/Field.py	
@@ -231,7 +231,6 @@
                 if not self.updated:
                     # Get data
                     if get_data:
-                        #
                         # For each logger, call its update function
 
                         field_loggers_portal_data = {}
@@ -717,3 +716,11 @@
         for logger in self.loggers:
             logger.deactivate()
         print('Done')
+
+
+    def activate(self):
+        print('Deactivating Field {}...'.format(self.name))
+        self.active = True
+        for logger in self.loggers:
+            logger.activate()
+        print('Done')
Index: CwsiProcessor.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import csv\r\nimport uuid\r\nfrom datetime import datetime\r\nfrom datetime import timedelta\r\nfrom itertools import zip_longest\r\n\r\nimport numpy as numpy\r\n\r\nfrom DBWriter import DBWriter\r\nfrom IrrigationRecommendationExpert import IrrigationRecommendationExpert\r\nfrom Soils import Soil\r\n\r\n\r\nclass CwsiProcessor(object):\r\n    def __init__(self):\r\n        pass\r\n\r\n    def convert_farenheit_list_to_celsius_list(self, fahrenheit: list[float]) -> list[float] or None:\r\n        \"\"\"\r\n        Function to convert Fahrenheit to Celsius\r\n        :param fahrenheit: Fahrenheit in float\r\n        :return: celsius in float\r\n        \"\"\"\r\n        celsius_list = []\r\n        for fahrenheit_data_point in fahrenheit:\r\n            if fahrenheit_data_point is None:\r\n                celsius_list.append(None)\r\n            else:\r\n                c = (fahrenheit_data_point - 32) * 5 / 9\r\n                celsius_list.append(c)\r\n        return celsius_list\r\n\r\n    def get_highest_and_lowest_temperature_indexes(self, all_results_converted, mute_prints = False):\r\n        \"\"\"\r\n        Function to loop through the converted results and return the indexes corresponding to\r\n        the hottest air temperature each day. If there are multiple hottest air temperatures with the same\r\n        value, check their corresponding vpd's and pick the one with the higher vpd\r\n\r\n        :param all_results_converted:\r\n        :return:\r\n        \"\"\"\r\n        i = 0\r\n\r\n        day_data_points = 0  # New variable needed to check how many data points are in each day before checking for the hottest time\r\n        # If there are not enough data points, it will ignore that day\r\n        data_points_required_for_full_day = 10  # Data points required for processing. 10 by default\r\n        highest_temp_values_indexes = []\r\n        highest_temp_values = []\r\n        lowest_temp_values_indexes = []\r\n        lowest_temp_values = []\r\n        day_break_indexes = [0]\r\n        length_of_list = len(all_results_converted['dates'])\r\n\r\n        while i < length_of_list:\r\n            # Loop through list of ambient temps from start until we find value that isn't None\r\n            # This was needed because occasionally the first value of the ambient temp list is None\r\n            if all_results_converted['ambient temperature'][i] is None:\r\n                highest_temp_value = 0\r\n                lowest_temp_value = 999\r\n            else:\r\n                highest_temp_value = all_results_converted['ambient temperature'][i]\r\n                lowest_temp_value = all_results_converted['ambient temperature'][i]\r\n\r\n            highest_temp_index = lowest_temp_index = i\r\n\r\n            if i == length_of_list - 1:\r\n                if day_data_points > data_points_required_for_full_day:  # There are at least 10 data points in that day\r\n                    if not mute_prints:\r\n                        print('Data points: ' + str(day_data_points))\r\n                    highest_temp_index = i\r\n                    lowest_temp_index = i\r\n                    highest_temp_values_indexes.append(int(highest_temp_index))\r\n                    lowest_temp_values_indexes.append(int(lowest_temp_index))\r\n                    if all_results_converted['ambient temperature'][highest_temp_index] is not None:\r\n                        highest_temp_values.append(\r\n                            round(all_results_converted['ambient temperature'][highest_temp_index], 1)\r\n                        )\r\n                    else:\r\n                        highest_temp_values.append(None)\r\n                    if all_results_converted['ambient temperature'][lowest_temp_index] is not None:\r\n                        lowest_temp_values.append(\r\n                            round(all_results_converted['ambient temperature'][lowest_temp_index], 1)\r\n                        )\r\n                    else:\r\n                        lowest_temp_values.append(None)\r\n                else:\r\n                    if not mute_prints:\r\n                        print('\\t\\tMRID ISSUES - Only ' + str(day_data_points) + ' data points')\r\n                highest_temp_value = all_results_converted['ambient temperature'][i]\r\n\r\n                break\r\n            while all_results_converted['dates'][i].day == \\\r\n                    all_results_converted['dates'][i + 1].day:\r\n                day_data_points = day_data_points + 1\r\n                next_ambient_temp = all_results_converted['ambient temperature'][i + 1]\r\n                if next_ambient_temp is not None:\r\n                    if next_ambient_temp > highest_temp_value:\r\n                        highest_temp_value = next_ambient_temp\r\n                        highest_temp_index = i + 1\r\n\r\n                    if next_ambient_temp < lowest_temp_value:\r\n                        lowest_temp_value = next_ambient_temp\r\n                        lowest_temp_index = i + 1\r\n\r\n                i += 1\r\n                if i == length_of_list - 1:\r\n                    break\r\n            i += 1\r\n            if i < length_of_list - 1:\r\n                # print(f'New day: {all_results_converted[\"dates\"][i]}')\r\n                day_break_indexes.append(i)\r\n            if day_data_points > data_points_required_for_full_day:  # There are at least 10 data points in that day\r\n                if not mute_prints:\r\n                    print('\\t\\tData points: ' + str(day_data_points))\r\n                highest_temp_values_indexes.append(int(highest_temp_index))\r\n                lowest_temp_values_indexes.append(int(lowest_temp_index))\r\n                if all_results_converted['ambient temperature'][highest_temp_index] is not None:\r\n                    highest_temp_values.append(\r\n                        round(all_results_converted['ambient temperature'][highest_temp_index], 1)\r\n                    )\r\n                else:\r\n                    highest_temp_values.append(None)\r\n                if all_results_converted['ambient temperature'][lowest_temp_index] is not None:\r\n                    lowest_temp_values.append(\r\n                        round(all_results_converted['ambient temperature'][lowest_temp_index], 1))\r\n                else:\r\n                    lowest_temp_values.append(None)\r\n            else:\r\n                if not mute_prints:\r\n                    print('\\t\\tMRID ISSUES - Only ' + str(day_data_points) + ' data points')\r\n            day_data_points = 0\r\n        # print(f'New day: {all_results_converted[\"dates\"][len(all_results_converted[\"dates\"]) - 1]}')\r\n        day_break_indexes.append(len(all_results_converted[\"dates\"]) - 1)\r\n        if not mute_prints:\r\n            print()\r\n            print('\\t\\tResults from Hottest / Coldest Temps Alg')\r\n            print(f'\\t\\t\\tHighest Temp Val Ind: {highest_temp_values_indexes}')\r\n            print(f'\\t\\t\\tHighest Temp Val: {highest_temp_values}')\r\n            print(f'\\t\\t\\tLowest Temp Val Ind: {lowest_temp_values_indexes}')\r\n            print(f'\\t\\t\\tLowest Temp Val: {lowest_temp_values}')\r\n            print()\r\n        return highest_temp_values_indexes, lowest_temp_values_indexes, day_break_indexes\r\n\r\n    def get_gallons(self, all_results_converted, prev_gallons):\r\n        i = 0\r\n        daily_gallons = []\r\n        previous_gallons = prev_gallons\r\n        day_gallons = 0\r\n        length_of_list = len(all_results_converted['dates'])\r\n\r\n        day_break_points = [0]\r\n        j = 0\r\n        while i < length_of_list - 1:\r\n            if all_results_converted['dates'][i].day == \\\r\n                    all_results_converted['dates'][i + 1].day:\r\n                i += 1\r\n            else:\r\n                day_break_points.append(i + 1)\r\n                i += 1\r\n        if i != day_break_points[len(day_break_points) - 1]:\r\n            day_break_points.append(i)\r\n        while j < len(day_break_points) - 1:\r\n            my_list = all_results_converted['daily gallons'][day_break_points[j]:day_break_points[j + 1]]\r\n            day_gallons = sum(my_list)\r\n            daily_gallons.append(day_gallons)\r\n            j += 1\r\n\r\n        return daily_gallons, previous_gallons\r\n\r\n\r\n    def update_irrigation_ledger(self, all_results_converted, irrigation_ledger):\r\n        # Todo -support measurement configurations other than 1 Hour. Currently, if the measurement configuration is\r\n        #  not 1 Hour, the values for the switch come totaled for w/e the measurement configuration is. Meaning, if\r\n        #  the measurement configuration is 15 minutes, a switch that is on would show 15 minutes for each 15 minute\r\n        #  interval.\r\n        dates_list = all_results_converted['dates']\r\n        switch_minutes_list = all_results_converted['daily switch']\r\n\r\n        for date, switch_minutes in zip(dates_list, switch_minutes_list):\r\n            date_key = date.date()\r\n\r\n            if date_key not in irrigation_ledger:\r\n                irrigation_ledger[date_key] = [None] * 24\r\n\r\n            hour_index = date.hour\r\n\r\n            if irrigation_ledger[date_key][hour_index] is None:\r\n                irrigation_ledger[date_key][hour_index] = switch_minutes\r\n\r\n\r\n    def clean_irrigation_ledger(self, irrigation_ledger):\r\n        \"\"\"\r\n        Function to remove old dates from the irrigation ledger that are no longer relevant and may have been left\r\n        behind from previous manual or automatic runs\r\n        :param irrigation_ledger:\r\n        \"\"\"\r\n        # Calculate the cutoff date\r\n        cutoff_date = datetime.now().date() - timedelta(days=35)\r\n\r\n        # Grab keys older than cutoff date to be removed\r\n        dates_to_remove = [date for date in irrigation_ledger if date < cutoff_date]\r\n\r\n        for key in dates_to_remove:\r\n            del irrigation_ledger[key]\r\n\r\n\r\n\r\n    def get_switch(self, all_results_converted, prev_switch):\r\n        i = 0\r\n        daily_switch = []\r\n        daily_switch2 = []\r\n        previous_switch = prev_switch\r\n        day_switch = 0\r\n        length_of_list = len(all_results_converted['dates'])\r\n        print('\\tProcessing Switch')\r\n        print(f'\\t\\tPrevious switch: {str(prev_switch)}')\r\n\r\n        day_data_points = 0\r\n        left_over_switch = prev_switch\r\n        # day_break_points = [0]\r\n        # j = 0\r\n        water = 0\r\n        # These following lines are causing us to double count the irrigation hours that overlaps in\r\n        #   the API call returns\r\n        # if all_results_converted['daily switch'][0]:\r\n        #     water = all_results_converted['daily switch'][0]\r\n\r\n        for index, switchData in enumerate(all_results_converted['daily switch']):\r\n            if index == length_of_list - 1:\r\n                # Only append value if the last value's day is different from the previous\r\n                # Fixes issue on initialization\r\n                daily_switch.append(water)\r\n                # if all_results_converted['dates'][index].day != all_results_converted['dates'][index - 1].day:\r\n                #     daily_switch.append(water)\r\n                break\r\n\r\n            today = all_results_converted['dates'][index].day\r\n            next_day = all_results_converted['dates'][index + 1].day\r\n            switch_today_data = all_results_converted['daily switch'][index]\r\n            next_day_switch_data = all_results_converted['daily switch'][index + 1]\r\n\r\n            if today == next_day:\r\n                day_data_points = day_data_points + 1\r\n                if next_day_switch_data is None or next_day_switch_data == 'None':\r\n                    water = water + 0\r\n                else:\r\n                    water = water + next_day_switch_data\r\n            else:\r\n                if next_day_switch_data is None or next_day_switch_data == 'None':\r\n                    water = 0\r\n                else:\r\n                    daily_switch.append(water)\r\n                    water = next_day_switch_data\r\n                    day_data_points = 0\r\n\r\n        if not len(daily_switch) == 0 and left_over_switch > 0:\r\n            print('\\t\\tModifying daily switch[0] to compensate overnight irrigation from previous night')\r\n            print('\\t\\tfrom: ' + str(daily_switch[0]))\r\n            print(\r\n                '\\t\\tto: ' + str(daily_switch[0]) + ' + ' + str(left_over_switch) + ' = ' + str(\r\n                    daily_switch[0] + left_over_switch\r\n                )\r\n            )\r\n            # should the index here be -2 instead of 0?\r\n            daily_switch[0] = daily_switch[0] + left_over_switch\r\n            previous_switch = 0\r\n\r\n        if len(daily_switch) > 1 and day_data_points < 10:\r\n            print('\\t\\tAssigning previous switch to: ' + str(daily_switch[-1]))\r\n            previous_switch = daily_switch[-1]\r\n            del daily_switch[-1]\r\n\r\n        return daily_switch, previous_switch\r\n\r\n    def final_results(self, all_results_converted, highest_temp_values_index, lowest_temp_values_index, logger):\r\n        \"\"\"\r\n        Function to assemble final results dict that contains only info for hottest time of the day for each day\r\n        This dict will be used to populate the Google Sheets\r\n        Use for multiple days of processing info\r\n\r\n        :param logger:\r\n        :param lowest_temp_values_index:\r\n        :param all_results_converted:\r\n        :param highest_temp_values_index:\r\n        :return:\r\n        \"\"\"\r\n        final_results_converted = {\r\n            \"dates\": [],\r\n            \"canopy temperature\": [],\r\n            \"ambient temperature\": [],\r\n            \"lowest ambient temperature\": [],\r\n            \"gdd\": [],\r\n            \"crop stage\": [],\r\n            \"vpd\": [],\r\n            \"vwc_1\": [],\r\n            \"vwc_2\": [],\r\n            \"vwc_3\": [],\r\n            \"vwc_1_ec\": [],\r\n            \"vwc_2_ec\": [],\r\n            \"vwc_3_ec\": [],\r\n            \"daily gallons\": [],\r\n            \"daily switch\": [],\r\n            \"cwsi\": [],\r\n            \"sdd\": [],\r\n            \"rh\": []\r\n        }\r\n\r\n        # print()\r\n        # print('\\tAll Results Converted -> Before Processing: ')\r\n        # for key, values in all_results_converted.items():\r\n        #     print('\\t', key, \" : \", values)\r\n\r\n        for index, i in enumerate(highest_temp_values_index):\r\n            # if all_results_converted[\"dates\"][i].year == this_year:\r\n            date = all_results_converted[\"dates\"][i]\r\n            tc = all_results_converted[\"canopy temperature\"][i]\r\n            ta = all_results_converted[\"ambient temperature\"][i]\r\n            lta = all_results_converted[\"ambient temperature\"][lowest_temp_values_index[index]]\r\n            rh = all_results_converted[\"rh\"][i]\r\n            vpd = all_results_converted[\"vpd\"][i]\r\n            vwc_1 = all_results_converted[\"vwc_1\"][i]\r\n            vwc_2 = all_results_converted[\"vwc_2\"][i]\r\n            vwc_3 = all_results_converted[\"vwc_3\"][i]\r\n            vwc_1_ec = all_results_converted[\"vwc_1_ec\"][i]\r\n            vwc_2_ec = all_results_converted[\"vwc_2_ec\"][i]\r\n            vwc_3_ec = all_results_converted[\"vwc_3_ec\"][i]\r\n\r\n            '''\r\n                Calling functions to calculate SDD, and CWSI with each specific days values\r\n                '''\r\n            sdd = self.get_sdd(tc, ta)\r\n            cwsi = self.get_cwsi(tc, vpd, ta, logger.crop_type, rh=rh)\r\n            gdd = self.get_gdd(ta, lta, logger.crop_type)\r\n\r\n            logger.update_ir_consecutive_data(cwsi, sdd)\r\n\r\n            final_results_converted[\"dates\"].append(date)\r\n            final_results_converted[\"ambient temperature\"].append(ta)\r\n            final_results_converted[\"lowest ambient temperature\"].append(lta)\r\n            final_results_converted[\"gdd\"].append(gdd)\r\n            # final_results_converted[\"crop stage\"].append(crop_stage)\r\n            final_results_converted[\"vpd\"].append(vpd)\r\n            final_results_converted[\"vwc_1\"].append(vwc_1)\r\n            final_results_converted[\"vwc_2\"].append(vwc_2)\r\n            final_results_converted[\"vwc_3\"].append(vwc_3)\r\n            final_results_converted[\"vwc_1_ec\"].append(vwc_1_ec)\r\n            final_results_converted[\"vwc_2_ec\"].append(vwc_2_ec)\r\n            final_results_converted[\"vwc_3_ec\"].append(vwc_3_ec)\r\n            final_results_converted[\"rh\"].append(rh)\r\n\r\n            # If logger.ir_active is False\r\n\r\n            if not logger.ir_active or logger.crop_type.lower() in ['almonds', 'almond', 'pistachios', 'pistachio']:\r\n                date_to_check = date.date()\r\n                logger.ir_active = logger.should_ir_be_active(date_to_check=date_to_check)\r\n\r\n            if logger.ir_active:\r\n                final_results_converted[\"canopy temperature\"].append(tc)\r\n                final_results_converted[\"sdd\"].append(sdd)\r\n                final_results_converted[\"cwsi\"].append(cwsi)\r\n            else:\r\n                final_results_converted[\"canopy temperature\"].append(None)\r\n                final_results_converted[\"sdd\"].append(None)\r\n                final_results_converted[\"cwsi\"].append(None)\r\n\r\n        # NEW WAY OF GETTING SWITCH DATA\r\n        for date in final_results_converted[\"dates\"]:\r\n            if date.date() in logger.irrigation_ledger:\r\n                no_none_switch_values = [val for val in logger.irrigation_ledger[date.date()] if val is not None]\r\n                irrigation_minutes = sum(no_none_switch_values)\r\n                final_results_converted['daily switch'].append(irrigation_minutes)\r\n\r\n                if None not in logger.irrigation_ledger[date.date()]:\r\n                    del logger.irrigation_ledger[date.date()]\r\n\r\n        return final_results_converted\r\n\r\n    def get_sdd(self, canopy_temp, ambient_temp):\r\n        \"\"\"\r\n        Function to calculate SDD given Canopy Temperature\r\n        and Ambient Temperature\r\n\r\n        :param canopy_temp:\r\n        :param ambient_temp:\r\n        :return:\r\n        \"\"\"\r\n        if ambient_temp is None or canopy_temp is None:\r\n            return None\r\n        return canopy_temp - ambient_temp\r\n\r\n    def get_rh(self, vpd, ta):\r\n        \"\"\"\r\n        Function to calculate Relative Humidity given VPD\r\n        and Ambient Temperature\r\n\r\n        :param vpd:\r\n        :param ta:\r\n        :return:\r\n        \"\"\"\r\n        rh = 100 - ((100 * vpd) / (\r\n                0.001 * (610.7 * 10 ** ((7.5 * ((5 * (ta - 32)) / 9)) / (237.7 + ((5 * (ta - 32)) / 9))))))\r\n        return rh\r\n\r\n    def get_gdd(self, high_temp, low_temp, crop_type, algorithm='base'):\r\n        if crop_type.lower() == 'tomatoes' or crop_type.lower() == 'tomato':\r\n            if algorithm == 'base':\r\n                gdd = self.get_tomato_gdd_base(high_temp, low_temp)\r\n                return gdd\r\n            elif algorithm == 'limited':\r\n                gdd = self.get_tomato_gdd_limited(high_temp, low_temp)\r\n                return gdd\r\n            elif algorithm == 'limited2':\r\n                gdd = self.get_tomato_gdd_limited_2(high_temp, low_temp)\r\n                return gdd\r\n        else:\r\n            return None\r\n\r\n    def get_tomato_gdd_base(self, high_temp, low_temp):\r\n        TOMATO_BASE_VALUE = 50\r\n        if high_temp is None or low_temp is None:\r\n            return 0\r\n        gdd = ((high_temp + low_temp) / 2) - TOMATO_BASE_VALUE\r\n        if gdd < 0:\r\n            return 0\r\n        return gdd\r\n\r\n    def get_tomato_gdd_limited(self, high_temp, low_temp):\r\n        TOMATO_BASE_VALUE = 50\r\n        TOMATO_HIGH_TEMP_LIMIT = 86\r\n        if high_temp is None or low_temp is None:\r\n            return 0\r\n        if high_temp > TOMATO_HIGH_TEMP_LIMIT:\r\n            high_temp = TOMATO_HIGH_TEMP_LIMIT\r\n        if low_temp < TOMATO_BASE_VALUE:\r\n            low_temp = TOMATO_BASE_VALUE\r\n        gdd = ((high_temp + low_temp) / 2) - TOMATO_BASE_VALUE\r\n        if gdd < 0:\r\n            return 0\r\n        return gdd\r\n\r\n    def get_tomato_gdd_limited_2(self, high_temp, low_temp):\r\n        TOMATO_BASE_VALUE = 50\r\n        TOMATO_HIGH_TEMP_LIMIT = 86\r\n        if high_temp is None or low_temp is None:\r\n            return 0\r\n        average_temp = (high_temp + low_temp) / 2\r\n        if average_temp < TOMATO_HIGH_TEMP_LIMIT and average_temp > TOMATO_BASE_VALUE:\r\n            gdd = average_temp - TOMATO_BASE_VALUE\r\n        elif average_temp >= TOMATO_HIGH_TEMP_LIMIT:\r\n            gdd = TOMATO_HIGH_TEMP_LIMIT - TOMATO_BASE_VALUE\r\n        elif average_temp <= TOMATO_BASE_VALUE:\r\n            gdd = 0\r\n        if gdd < 0:\r\n            return 0\r\n        return gdd\r\n\r\n    def get_cwsi(self, tc, vpd, ta, cropType, rh=0, return_negative=False, with_adjustment=True):\r\n        \"\"\"\r\n        Function to calculate Crop Water Stress Index given\r\n        SDD, RH, VPD, and TA\r\n\r\n        :param tc:\r\n        :param vpd:\r\n        :param ta:\r\n        :param cropType:\r\n        :param rh:\r\n        :param return_negative:\r\n        :return:\r\n        \"\"\"\r\n        if tc is None or ta is None or vpd is None or cropType is None or tc < -50:\r\n            return None\r\n\r\n        ta_celsius = (ta - 32) * 5 / 9\r\n        tc_celsius = (tc - 32) * 5 / 9\r\n        sdd = tc - ta\r\n        sdd_celsius = tc_celsius - ta_celsius\r\n\r\n        # Converting cropType to all lowercase to avoid case isssues\r\n        if cropType.lower() == 'tomatoes' or cropType.lower() == 'tomato':\r\n            # Using Farenheit sdd this 2021 year, changing to Celsius in the future\r\n            # Using old school formula for psi for 2021 that goes from 0-2.2, switching to new formula in the future\r\n            cwsi = self.get_old_tomatoes_cwsi(sdd, rh, vpd, ta, with_adjustment)\r\n            # cwsi = self.get_tomatoes_cwsi(sdd, vpd)\r\n        elif cropType.lower() == 'almonds':\r\n            cwsi = self.get_almonds_cwsi(sdd_celsius, vpd)\r\n        elif cropType.lower() == 'pistachios':\r\n            cwsi = self.get_pistachios_cwsi(sdd_celsius, vpd)\r\n        elif cropType.lower() == 'grapes':\r\n            cwsi = self.get_grapes_cwsi(sdd_celsius, vpd)\r\n        elif cropType.lower() == 'garlic':\r\n            cwsi = self.get_garlic_cwsi(sdd_celsius, vpd)\r\n        elif cropType.lower() == 'lemons':\r\n            cwsi = self.get_lemons_cwsi(sdd_celsius, vpd)\r\n        elif cropType.lower() == 'tangerines':\r\n            cwsi = self.get_tangerines_cwsi(sdd_celsius, vpd)\r\n        else:\r\n            # print(\"Crop Type: \" + str(cropType) + ' not supported')\r\n            return None\r\n\r\n        if cwsi is not None and cwsi < 0:\r\n            if return_negative:\r\n                pass\r\n            else:\r\n                cwsi = 0\r\n\r\n        return cwsi\r\n\r\n    def get_old_tomatoes_cwsi(self, sdd, rh, vpd, ta, with_adjustment=True):\r\n        if sdd is None or ta is None or rh is None or vpd is None or sdd < -50:\r\n            return None\r\n\r\n        # if rh > 0 and ta > 0:\r\n        # if ta < 85:\r\n        #     cwsi = ((sdd + (ta - 85) + (sdd * (rh / 100))) - ((-2.5086 * vpd) + 0.8639)) / (\r\n        #             2.7 - ((-2.5086 * vpd) + 0.8639)) + 2\r\n        # else:\r\n        #     cwsi = ((sdd + (sdd * (rh / 100))) - ((-2.5086 * vpd) + 0.8639)) / (\r\n        #             2.7 - ((-2.5086 * vpd) + 0.8639)) + 2\r\n\r\n        # OLD FORMULA without adjustments\r\n        # cwsi = ((sdd ) - ((-2.5086 * vpd) + 0.8639)) / (2.7 - ((-2.5086 * vpd) + 0.8639)) + 2\r\n\r\n        water_stress_baseline = 2.7\r\n        non_water_stress_baseline = ((-2.5086 * vpd) + 0.8639)\r\n        if with_adjustment:\r\n            if rh > 0 and ta > 0:\r\n                if ta < 85:\r\n                    temp_adjustment = ta - 85\r\n                    rh_adjustment = sdd * (rh / 100)\r\n                    adjustments = temp_adjustment + rh_adjustment\r\n\r\n                    top = (sdd + adjustments - non_water_stress_baseline)\r\n                    bot = (water_stress_baseline - non_water_stress_baseline)\r\n\r\n                    cwsi = top / bot + 2\r\n                else:\r\n                    temp_adjustment = 0\r\n                    rh_adjustment = sdd * (rh / 100)\r\n                    adjustments = temp_adjustment + rh_adjustment\r\n\r\n                    top = (sdd + adjustments - non_water_stress_baseline)\r\n                    bot = (water_stress_baseline - non_water_stress_baseline)\r\n\r\n                    cwsi = top / bot + 2\r\n        else:\r\n            top = (sdd - non_water_stress_baseline)\r\n            bot = (water_stress_baseline - non_water_stress_baseline)\r\n\r\n            cwsi = top / bot + 2\r\n\r\n        return cwsi\r\n\r\n    def get_tomatoes_cwsi(self, sdd, vpd):\r\n        '''\r\n        CWSI = SDD - NWSB / WSB - NWSB\r\n\r\n        :param sdd:\r\n        :param vpd:\r\n        :return:\r\n        '''\r\n        water_stress_baseline = 2.7\r\n        non_water_stress_baseline = ((-2.5086 * vpd) + 0.8639)\r\n\r\n        top = (sdd - non_water_stress_baseline)\r\n        bot = (water_stress_baseline - non_water_stress_baseline)\r\n\r\n        cwsi = top / bot\r\n\r\n        return cwsi\r\n\r\n    def get_almonds_cwsi(self, sdd_celsius, vpd):\r\n        '''\r\n        CWSI = SDD - NWSB / WSB - NWSB\r\n\r\n        :param sdd:\r\n        :param vpd:\r\n        :return:\r\n        '''\r\n\r\n        # =(J25 - ((-2.8311 * L25) + 1.5071)) / (1.5 - ((-2.8311 * L25) + 1.5071))\r\n        # Need to get WSB and NWSB from 2020 data using Celsius and update below\r\n        # since we are using all Celsius info for almonds going forward\r\n        # Current algo using Farenheit for WSB, NWSB and vpd\r\n        water_stress_baseline = 1.5\r\n        non_water_stress_baseline = ((-2.8311 * vpd) + 1.5071)\r\n\r\n        top = (sdd_celsius - non_water_stress_baseline)\r\n        bot = (water_stress_baseline - non_water_stress_baseline)\r\n\r\n        cwsi = top / bot\r\n\r\n        return cwsi\r\n        # Turned on 3/28/2022\r\n        # After the season CWSI for almonds doesn't make sense because there are no leaves to read the IR for\r\n        # so disabling it for now\r\n        # return None\r\n\r\n    def get_pistachios_cwsi(self, sdd_celsius, vpd):\r\n        '''\r\n        CWSI = SDD - NWSB / WSB - NWSB\r\n\r\n        :param sdd:\r\n        :param vpd:\r\n        :return:\r\n        '''\r\n\r\n        # Algo still in development\r\n        water_stress_baseline = 0.9\r\n        non_water_stress_baseline = ((-2.4216 * vpd) + 0.7034)\r\n\r\n        top = (sdd_celsius - non_water_stress_baseline)\r\n        bot = (water_stress_baseline - non_water_stress_baseline)\r\n\r\n        cwsi = top / bot\r\n\r\n        return cwsi\r\n        # return None\r\n\r\n    def get_grapes_cwsi(self, sdd_celsius, vpd):\r\n        '''\r\n        CWSI = SDD - NWSB / WSB - NWSB\r\n\r\n        :param sdd:\r\n        :param vpd:\r\n        :return:\r\n        '''\r\n\r\n        # Algo still in development\r\n        # water_stress_baseline = 2.7\r\n        # non_water_stress_baseline = ((-2.5086 * vpd) + 0.8639)\r\n        #\r\n        # top = (sdd_celsius - non_water_stress_baseline)\r\n        # bot = (water_stress_baseline - non_water_stress_baseline)\r\n        #\r\n        # cwsi = top / bot\r\n        #\r\n        # return cwsi\r\n        return None\r\n\r\n    def get_garlic_cwsi(self, sdd_celsius, vpd):\r\n        '''\r\n        CWSI = SDD - NWSB / WSB - NWSB\r\n\r\n        :param sdd:\r\n        :param vpd:\r\n        :return:\r\n        '''\r\n\r\n        # Algo still in development\r\n        # water_stress_baseline = 2.7\r\n        # non_water_stress_baseline = ((-2.5086 * vpd) + 0.8639)\r\n        #\r\n        # top = (sdd_celsius - non_water_stress_baseline)\r\n        # bot = (water_stress_baseline - non_water_stress_baseline)\r\n        #\r\n        # cwsi = top / bot\r\n        #\r\n        # return cwsi\r\n        return None\r\n\r\n    def get_lemons_cwsi(self, sdd_celsius, vpd):\r\n        '''\r\n                CWSI = SDD - NWSB / WSB - NWSB\r\n\r\n                :param sdd:\r\n                :param vpd:\r\n                :return:\r\n                '''\r\n\r\n        # Algo still in development\r\n        # water_stress_baseline = 0.8\r\n        # non_water_stress_baseline = ((-1.1938 * vpd) + 2.8598)\r\n        #\r\n        # top = (sdd_celsius - non_water_stress_baseline)\r\n        # bot = (water_stress_baseline - non_water_stress_baseline)\r\n        #\r\n        # cwsi = top / bot\r\n        #\r\n        # return cwsi\r\n        return None\r\n\r\n    def get_tangerines_cwsi(self, sdd_celsius, vpd):\r\n        '''\r\n                CWSI = SDD - NWSB / WSB - NWSB\r\n\r\n                :param sdd:\r\n                :param vpd:\r\n                :return:\r\n                '''\r\n\r\n        # Algo still in development\r\n        # water_stress_baseline = 0.9\r\n        # non_water_stress_baseline = ((-1.8129 * vpd) + 1.0770)\r\n        #\r\n        # top = (sdd_celsius - non_water_stress_baseline)\r\n        # bot = (water_stress_baseline - non_water_stress_baseline)\r\n        #\r\n        # cwsi = top / bot\r\n        #\r\n        # return cwsi\r\n        return None\r\n\r\n    def prep_data_for_writting_db(self, final_results, logger, db_dates):\r\n        final_results_no_dups = self.remove_duplicates_already_in_db(db_dates, final_results)\r\n\r\n        gpm = 0\r\n        logger_model = logger.model\r\n        logger_id = logger.id\r\n        # logger_direction = logger.loggerDirection\r\n\r\n        field_capacity = logger.soil.field_capacity\r\n        wilting_point = logger.soil.wilting_point\r\n\r\n        psi_critical, psi_threshold = self.get_psi_thresholds(logger.crop_type)\r\n\r\n        final_results_db = {\"logger_id\": [], \"date\": [], \"time\": [], \"canopy_temperature\": [], \"canopy_temperature_celsius\": [],\r\n                            \"ambient_temperature\": [], \"ambient_temperature_celsius\": [], \"vpd\": [],\r\n                            \"vwc_1\": [], \"vwc_2\": [], \"vwc_3\": [],\r\n                            \"field_capacity\": [], \"wilting_point\": [], \"daily_gallons\": [], \"daily_switch\": [],\r\n                            \"daily_hours\": [], \"daily_pressure\": [], \"daily_inches\": [], \"psi\": [], \"psi_threshold\": [],\r\n                            \"psi_critical\": [], \"sdd\": [], \"sdd_celsius\": [], \"rh\": [], 'eto': [], 'kc': [], 'etc': [], 'et_hours': [],\r\n                            \"phase1_adjustment\": [], \"phase1_adjusted\": [], \"phase2_adjustment\": [],\r\n                            \"phase2_adjusted\": [], \"phase3_adjustment\": [], \"phase3_adjusted\": [], \"vwc_1_ec\": [],\r\n                            \"vwc_2_ec\": [], \"vwc_3_ec\": [],\r\n                            \"lowest_ambient_temperature\": [], \"lowest_ambient_temperature_celsius\":[], \"gdd\": [], \"crop_stage\": [], \"id\": [],\r\n                            \"planting_date\": [], \"variety\": []}\r\n        if hasattr(logger, 'gpm'):\r\n            if type(logger.gpm) == str:\r\n                gpm = logger.gpm.replace(',', '')\r\n            else:\r\n                gpm = logger.gpm\r\n            if logger.gpm == None:\r\n                gpm = 0\r\n            i = 0\r\n        else:\r\n            gpm = 0\r\n        if hasattr(logger, 'irrigation_set_acres'):\r\n            if type(logger.irrigation_set_acres) == str:\r\n                acres = logger.irrigation_set_acres.replace(',', '')\r\n            else:\r\n                acres = logger.irrigation_set_acres\r\n            if logger.irrigation_set_acres == 0:\r\n                acres = 1\r\n        else:\r\n            acres = 1\r\n\r\n        for ind, val in enumerate(final_results_no_dups[\"dates\"]):\r\n            final_results_db[\"logger_id\"].append(logger_id)\r\n            # final_results_db[\"logger_direction\"].append(logger_direction)\r\n            final_results_db[\"field_capacity\"].append(field_capacity)\r\n            final_results_db[\"wilting_point\"].append(wilting_point)\r\n            final_results_db[\"psi_threshold\"].append(psi_threshold)\r\n            final_results_db[\"psi_critical\"].append(psi_critical)\r\n            final_results_db[\"date\"].append(val.strftime(\"%Y-%m-%d\"))\r\n            final_results_db[\"time\"].append(val.strftime(\"%I:%M %p\"))\r\n            final_results_db[\"id\"].append(uuid.uuid4())\r\n            if logger.planting_date:\r\n                final_results_db[\"planting_date\"].append(logger.planting_date)\r\n            if ind < len(final_results_no_dups[\"daily switch\"]):\r\n                final_results_db[\"daily_hours\"].append(round(final_results_no_dups[\"daily switch\"][ind] / 60, 1))\r\n                final_results_db[\"daily_inches\"].append(\r\n                    round((final_results_no_dups[\"daily switch\"][ind] * float(gpm)) / (float(acres) * 27154), 1)\r\n                )\r\n        final_results_db[\"canopy_temperature\"] = final_results_no_dups[\"canopy temperature\"]\r\n        final_results_db[\"canopy_temperature_celsius\"] = self.convert_farenheit_list_to_celsius_list(final_results_no_dups[\"canopy temperature\"])\r\n        final_results_db[\"ambient_temperature\"] = final_results_no_dups[\"ambient temperature\"]\r\n        final_results_db[\"ambient_temperature_celsius\"] = self.convert_farenheit_list_to_celsius_list(final_results_no_dups[\"ambient temperature\"])\r\n        final_results_db[\"lowest_ambient_temperature\"] = final_results_no_dups[\"lowest ambient temperature\"]\r\n        final_results_db[\"lowest_ambient_temperature\"] = self.convert_farenheit_list_to_celsius_list(final_results_no_dups[\"lowest ambient temperature\"])\r\n        final_results_db[\"gdd\"] = final_results_no_dups[\"gdd\"]\r\n        final_results_db[\"vpd\"] = final_results_no_dups[\"vpd\"]\r\n        final_results_db[\"crop_stage\"] = final_results_no_dups['crop stage']\r\n        # while len(final_results_no_dups[\"daily switch\"]) > len(final_results_no_dups[\"dates\"]):\r\n        if len(final_results_no_dups[\"daily switch\"]) > len(final_results_no_dups[\"dates\"]):\r\n            print('\\t---Mismatch length of dates and switch arrays---')\r\n            print('\\t# of Date values: ' + str(len(final_results_no_dups[\"dates\"])))\r\n            print('\\t# of Switch values: ' + str(len(final_results_no_dups[\"daily switch\"])))\r\n            # if final_results_no_dups[\"daily switch\"][-1] == 0:\r\n            # del final_results_no_dups[\"daily switch\"][-1]\r\n            # elif final_results_no_dups[\"daily switch\"][-2] == 0:\r\n            #     del final_results_no_dups[\"daily switch\"][-2]\r\n            # else:\r\n            #     del final_results_no_dups[\"daily switch\"][-1]\r\n        final_results_db[\"daily_switch\"] = final_results_no_dups[\"daily switch\"]\r\n        final_results_db[\"psi\"] = final_results_no_dups[\"cwsi\"]\r\n        final_results_db[\"sdd\"] = final_results_no_dups[\"sdd\"]\r\n        final_results_db[\"sdd_celsius\"] = self.convert_farenheit_list_to_celsius_list(final_results_no_dups[\"sdd\"])\r\n        final_results_db[\"rh\"] = final_results_no_dups[\"rh\"]\r\n        if \"kc\" in final_results_no_dups:\r\n            final_results_db[\"kc\"] = final_results_no_dups[\"kc\"]\r\n        if \"eto\" in final_results_no_dups:\r\n            final_results_db[\"eto\"] = final_results_no_dups[\"eto\"]\r\n        if \"etc\" in final_results_no_dups:\r\n            final_results_db[\"etc\"] = final_results_no_dups[\"etc\"]\r\n        if \"et_hours\" in final_results_no_dups:\r\n            final_results_db[\"et_hours\"] = final_results_no_dups[\"et_hours\"]\r\n\r\n        final_results_db[\"vwc_1\"] = final_results_no_dups[\"vwc_1\"]\r\n        final_results_db[\"vwc_2\"] = final_results_no_dups[\"vwc_2\"]\r\n        final_results_db[\"vwc_3\"] = final_results_no_dups[\"vwc_3\"]\r\n        final_results_db[\"vwc_1_ec\"] = final_results_no_dups[\"vwc_1_ec\"]\r\n        final_results_db[\"vwc_2_ec\"] = final_results_no_dups[\"vwc_2_ec\"]\r\n        final_results_db[\"vwc_3_ec\"] = final_results_no_dups[\"vwc_3_ec\"]\r\n\r\n        filename = 'data.csv'\r\n        print(f'\\tWriting data to csv file: {filename}')\r\n        with open(filename, \"w\", newline='') as outfile:\r\n            writer = csv.writer(outfile)\r\n            writer.writerow(final_results_db.keys())\r\n            # Using zip_longest because dict rows are uneven length due to daily_switch algo issue\r\n            # This will add full null rows for any additional daily_switch list values\r\n            writer.writerows(zip_longest(*final_results_db.values()))\r\n\r\n        return None\r\n\r\n    def remove_duplicates_already_in_db(self, db_dates, final_results):\r\n        print('\\t\\tChecking for and removing duplicate data')\r\n        final_results_dates = [date.date() for date in final_results['dates']]\r\n        no_db_repeat_final_results = {}\r\n\r\n        for key in final_results:\r\n            no_db_repeat_final_results[key] = []\r\n\r\n        found_duplicates = False\r\n        duplicate_dates = []\r\n        for results_date in final_results_dates:\r\n            if results_date not in db_dates:\r\n                final_results_date_index = final_results_dates.index(results_date)\r\n                for key in final_results:\r\n                    if key != 'daily gallons' and len(final_results[key]) > final_results_date_index:\r\n                        no_db_repeat_final_results[key].append(final_results[key][final_results_date_index])\r\n            else:\r\n                found_duplicates = True\r\n                duplicate_dates.append(results_date)\r\n\r\n        if found_duplicates:\r\n            print(f'\\t\\tFound some duplicates and skipped from writing those to db - {duplicate_dates}')\r\n            #TODO Check duplicate values and take the one that has the hottest ambient temp\r\n\r\n        return no_db_repeat_final_results\r\n\r\n    def process_data_for_writing_db_portal(self, final_results, field, logger_name='', logger_direction=''):\r\n        \"\"\"\r\n\r\n        :param logger_direction:\r\n        :param logger_name:\r\n        :param final_results: {\"dates\": [], \"canopy temperature\": [], \"ambient temperature\": [], \"vpd\": [],\r\n        #                            \"vwc_1\": [], \"vwc_2\": [], \"vwc_3\": [], \"vwc_1_ec\": [], \"vwc_2_ec\": [],\r\n        #                            \"vwc_3_ec\": [],\r\n        #                            \"daily gallons\": [], \"daily switch\": [], \"cwsi\": [], \"sdd\": [], \"rh\": []}\r\n        :param field: Field object\r\n        :return:\r\n        \"\"\"\r\n        individual_logger = False\r\n        if len(logger_name) > 0:\r\n            individual_logger = True\r\n        vwc_1 = final_results['vwc_1']\r\n        vwc_2 = final_results['vwc_2']\r\n        vwc_3 = final_results['vwc_3']\r\n        si_num = final_results['cwsi']\r\n        if si_num is not None:\r\n            si_num = round(si_num, 1)\r\n        crop_type = field.loggers[0].crop_type\r\n        planting_date = field.loggers[0].planting_date\r\n        field_name = field.nickname\r\n        report_url = field.report_url\r\n        preview_url = field.preview_url\r\n\r\n        # Check to make work in progress be the crop image for the individual loggers portal else it would be the crop\r\n        # type image\r\n        if individual_logger and preview_url == 'https://i.imgur.com/04UdmBH.png':\r\n            crop_image = 'https://i.imgur.com/04UdmBH.png'\r\n        else:\r\n            crop_image = self.get_crop_image(crop_type)\r\n\r\n        field_capacities = []\r\n        wilting_points = []\r\n\r\n        for logger in field.loggers:\r\n            if not individual_logger:\r\n                field_capacities.append(float(logger.soil.field_capacity))\r\n                wilting_points.append(float(logger.soil.wilting_point))\r\n            else:\r\n                if logger.name == logger_name:\r\n                    field_capacity_avg = logger.soil.field_capacity\r\n                    wilting_point_avg = logger.soil.wilting_point\r\n        if not individual_logger:\r\n            field_capacity_avg = numpy.mean(field_capacities)\r\n            wilting_point_avg = numpy.mean(wilting_points)\r\n\r\n        soil_moisture_num = self.calculate_portal_soil_moisture_num(vwc_1, vwc_2, vwc_3, planting_date, crop_type)\r\n        soil_moisture_desc = self.calculate_portal_soil_moisture_desc(\r\n            soil_moisture_num,\r\n            field_capacity_avg,\r\n            wilting_point_avg\r\n        )\r\n        si_desc = self.calculate_portal_si_desc(crop_type, si_num)\r\n\r\n        order = self.calculate_portal_order(crop_type, soil_moisture_desc, si_desc)\r\n\r\n        final_results_portal_db = {\"order\": order, \"field\": field_name, \"crop_type\": crop_type,\r\n                                   \"crop_image\": crop_image,\r\n                                   \"soil_moisture_num\": soil_moisture_num, \"soil_moisture_desc\": soil_moisture_desc,\r\n                                   \"si_num\": si_num, \"si_desc\": si_desc, \"report\": report_url, \"preview\": preview_url}\r\n\r\n        if not field.active:\r\n            # Writing uninstall in field portal\r\n            final_results_portal_db = {\r\n                \"order\": 999, \"field\": field_name, \"crop_type\": crop_type, \"crop_image\": crop_image,\r\n                \"soil_moisture_num\": 'null', \"soil_moisture_desc\": \"Uninstalled\",\r\n                \"si_num\": 'null', \"si_desc\": \"Uninstalled\", \"report\": report_url, \"preview\": preview_url\r\n            }\r\n\r\n        # Adding logger name when processing individual logger data\r\n        if individual_logger:\r\n            final_results_portal_db['logger_name'] = logger_name\r\n            final_results_portal_db['logger_direction'] = logger_direction\r\n\r\n        return final_results_portal_db\r\n\r\n    def get_psi_thresholds(self, crop_type):\r\n        if crop_type.lower() == \"tomato\" or crop_type.lower() == \"tomatoes\":\r\n            psi_threshold = 1.6\r\n            psi_critical = 2.2\r\n        elif crop_type.lower() == \"almond\" or crop_type.lower() == \"almonds\" \\\r\n                or crop_type.lower() == 'pistachio' or crop_type.lower() == 'pistachios':\r\n            psi_threshold = 0.5\r\n            psi_critical = 1.0\r\n        else:\r\n            psi_threshold = None\r\n            psi_critical = None\r\n        return psi_critical, psi_threshold\r\n\r\n    def calculate_portal_soil_moisture_num(self, vwc_1, vwc_2, vwc_3, planting_date, crop_type):\r\n        vwc_list = []\r\n        if crop_type.lower() == 'tomato' or crop_type.lower() == 'tomatoes':\r\n            today = datetime.today().date()\r\n            day_delta = today - planting_date\r\n\r\n            if day_delta.days > 30:\r\n                if vwc_2 is None and vwc_3 is None:\r\n                    return None\r\n                elif vwc_2 is None:\r\n                    return round(vwc_3, 1)\r\n                elif vwc_3 is None:\r\n                    return round(vwc_2, 1)\r\n                vwc_list.append(vwc_2)\r\n                vwc_list.append(vwc_3)\r\n                soil_moisture_num = numpy.mean(vwc_list)\r\n                return round(soil_moisture_num, 1)\r\n\r\n        # crop isn't tomato or its tomato within 30 days after planting\r\n\r\n        if vwc_1 is None and vwc_2 is None:\r\n            return None\r\n        elif vwc_1 is None:\r\n            return round(vwc_2, 1)\r\n        elif vwc_2 is None:\r\n            return round(vwc_1, 1)\r\n        vwc_list.append(vwc_1)\r\n        vwc_list.append(vwc_2)\r\n        soil_moisture_num = numpy.mean(vwc_list)\r\n        return round(soil_moisture_num, 1)\r\n\r\n    def calculate_portal_soil_moisture_desc(self, soil_moisture_num: float, field_capacity_avg: float,\r\n                                            wilting_point_avg: float) -> str:\r\n        \"\"\"\r\n        Create a soil with the field capacity and wilting point we were given and then get the appropriate\r\n        description for the soil_moisture_num based on that soil type's vwc ranges (Function already provided for\r\n        in the Soil class)\r\n\r\n        :param soil_moisture_num: Float of the soil moisture value we want to calculate the description for\r\n        :param field_capacity_avg: Float of the field capacity for the soil type\r\n        :param wilting_point_avg: Float of the wilting point for the soil type\r\n        :return: String of the appropriate description\r\n        \"\"\"\r\n        soil = Soil(field_capacity=field_capacity_avg, wilting_point=wilting_point_avg)\r\n        description = soil.find_vwc_range_description(soil_moisture_num)\r\n        return description\r\n\r\n    def calculate_portal_si_desc(self, crop_type, si_num):\r\n        optimum = 'Optimum'\r\n        low = 'Low'\r\n        medium = 'Medium'\r\n        high = 'High'\r\n        very_high = 'Very High'\r\n        no_si = 'No Stress Index'\r\n        if si_num is None:\r\n            return no_si\r\n        if crop_type.lower() == 'tomato' or crop_type.lower() == 'tomatoes':\r\n            if 0 <= si_num < 0.6:\r\n                return optimum\r\n            elif 0.6 <= si_num < 1.2:\r\n                return low\r\n            elif 1.2 <= si_num < 1.6:\r\n                return medium\r\n            elif 1.6 <= si_num < 2.2:\r\n                return high\r\n            elif 2.2 <= si_num:\r\n                return very_high\r\n        else:\r\n            if 0 <= si_num < 0.2:\r\n                return optimum\r\n            elif 0.2 <= si_num < 0.4:\r\n                return low\r\n            elif 0.4 <= si_num < 0.6:\r\n                return medium\r\n            elif 0.6 <= si_num < 0.8:\r\n                return high\r\n            elif 0.8 <= si_num:\r\n                return very_high\r\n\r\n    def calculate_portal_order(self, crop_type, soil_moisture_desc, si_desc):\r\n        order = 0\r\n        special_start = 100\r\n        tomato_start = 90\r\n        almond_start = 80\r\n        pistachio_start = 70\r\n\r\n        # Crop type start\r\n        if crop_type.lower() == 'tomato' or crop_type.lower() == 'tomatoes':\r\n            order = tomato_start\r\n        elif crop_type.lower() == 'almond' or crop_type.lower() == 'almonds':\r\n            order = almond_start\r\n        elif crop_type.lower() == 'pistachio' or crop_type.lower() == 'pistachios':\r\n            order = pistachio_start\r\n\r\n        # VWC Level\r\n        '''\r\n        VERY_LOW = 'Very Low Moisture'\r\n        LOW = 'Low Moisture Levels'\r\n        BELOW_OPT = 'Below Optimum'\r\n        OPTIMUM = 'Optimum Moisture'\r\n        HIGH = 'High Soil Moisture'\r\n        VERY_HIGH = 'Very High Soil Moisture'\r\n        INCORRECT = 'Incorrect Value'\r\n        '''\r\n        if soil_moisture_desc == 'Optimum Moisture':\r\n            order = order + 0\r\n        elif soil_moisture_desc == 'Below Optimum':\r\n            order = order + 0.5\r\n        elif soil_moisture_desc == 'Low Moisture Levels' or soil_moisture_desc == 'High Soil Moisture':\r\n            order = order + 1\r\n        elif soil_moisture_desc == 'Very Low Moisture' or soil_moisture_desc == 'Very High Soil Moisture':\r\n            order = order + 2\r\n\r\n        # Stress Level\r\n        if si_desc == 'Optimum':\r\n            order = order + 0\r\n        elif si_desc == 'Low':\r\n            order = order + 0.5\r\n        elif si_desc == 'Medium':\r\n            order = order + 1\r\n        elif si_desc == 'High':\r\n            order = order + 1.5\r\n        elif si_desc == 'Very High':\r\n            order = order + 2\r\n\r\n        return order\r\n\r\n    def get_crop_image(self, crop_type):\r\n        # Currently hosting off of Imgur\r\n        crop_type = crop_type.lower()\r\n\r\n        defUrl = 'https://i.imgur.com/'\r\n        tomato = defUrl + 'yqTglkD.png'\r\n        almond = defUrl + '2wkD3SR.png'\r\n        pistachio = defUrl + 'Gl3UuEe.png'\r\n        lemon = defUrl + 'NFkOMUu.png'\r\n        grape = defUrl + '7bRDO3t.png'\r\n        pepper = defUrl + 'h5aOCK3.png'\r\n        garlic = defUrl + 'hPjyLfU.png'\r\n        date = defUrl + '5yyz4dJ.png'\r\n        hemp = defUrl + 'mvdZtjV.png'\r\n        tangerines = defUrl + 'Fs8edNK.png'\r\n        squash = defUrl + 'siBofu6.png'\r\n        cherry = defUrl + 'LqbA0Ie.png'\r\n        onion = defUrl + '8wCFjgF.png'\r\n        onion_joke = defUrl + 'eHCMbOl.png'\r\n        default = defUrl + 'B2coKxO.png'\r\n\r\n        return {\r\n            'tomato': tomato,\r\n            'tomatoes': tomato,\r\n            'almond': almond,\r\n            'almonds': almond,\r\n            'pistachio': pistachio,\r\n            'pistachios': pistachio,\r\n            'lemon': lemon,\r\n            'lemons': lemon,\r\n            'grape': grape,\r\n            'grapes': grape,\r\n            'pepper': pepper,\r\n            'peppers': pepper,\r\n            'garlic': garlic,\r\n            'date': date,\r\n            'dates': date,\r\n            'hemp': hemp,\r\n            'tangerines': tangerines,\r\n            'squash': squash,\r\n            'cherry': cherry,\r\n            'cherries': cherry,\r\n            'onion': onion_joke,\r\n            'onions': onion_joke,\r\n            # 'onion': onion,\r\n            # 'onions': onion\r\n        }.get(crop_type, default)\r\n\r\n    def irrigation_ai_processing(self, data, logger):\r\n\r\n        # print(f'Grabbing data from {dataset} for logger {logger_id} - ')\r\n        # dml = 'SELECT *' \\\r\n        #       'FROM `stomato.' + dataset + '.' + logger_id + '` ' \\\r\n        #                                                      'WHERE et_hours is not NULL ORDER BY date DESC'\r\n        #\r\n        # dbwriter = DBWriter()\r\n        expertSys = IrrigationRecommendationExpert()\r\n        # result = dbwriter.run_dml(dml)\r\n\r\n        # FORMAT OF DATA\r\n        # final_results_converted = {\"dates\": [], \"canopy temperature\": [], \"ambient temperature\": [], \"vpd\": [],\r\n        #                            \"vwc_1\": [], \"vwc_2\": [], \"vwc_3\": [], \"vwc_1_ec\": [], \"vwc_2_ec\": [],\r\n        #                            \"vwc_3_ec\": [],\r\n        #                            \"daily gallons\": [], \"daily switch\": [], \"cwsi\": [], \"sdd\": [], \"rh\": [], \"kc\": []}\r\n\r\n        # applied_finals = {}\r\n        ai_results = {\"logger_id\": [], \"date\": [], \"time\": [], \"canopy_temperature\": [], \"ambient_temperature\": [],\r\n                      \"vpd\": [], \"vwc_1\": [], \"vwc_2\": [], \"vwc_3\": [], \"field_capacity\": [], \"wilting_point\": [],\r\n                      \"daily_gallons\": [], \"daily_switch\": [], \"daily_hours\": [], \"daily_pressure\": [],\r\n                      \"daily_inches\": [], \"psi\": [], \"psi_threshold\": [], \"psi_critical\": [],\r\n                      \"sdd\": [], \"rh\": [], 'eto': [], 'kc': [], 'etc': [], 'et_hours': [],\r\n                      \"phase1_adjustment\": [], \"phase1_adjusted\": [], \"phase2_adjustment\": [], \"phase2_adjusted\": []}\r\n\r\n        # applied_finals['date'] = []\r\n        # applied_finals['base'] = []\r\n        # applied_finals['final_rec'] = []\r\n        # applied_finals['adjustment_values'] = []\r\n        # applied_finals['adjustment_steps'] = []\r\n\r\n        planting_date = logger.planting_date\r\n        # growers = open_pickle()\r\n        # for grower in growers:\r\n        #     for field in grower.fields:\r\n        #         field_name = dbwriter.remove_unwanted_chars_for_db(field.name)\r\n        #         if dataset in field_name:\r\n        #             for logger in field.loggers:\r\n        #                 planting_date = logger.planting_date\r\n\r\n        # harvest_date = result[-1][1]\r\n        harvest_date = '2022-06-06'\r\n\r\n        # final_results_converted = {\"dates\": [], \"canopy temperature\": [], \"ambient temperature\": [], \"vpd\": [],\r\n        #                            \"vwc_1\": [], \"vwc_2\": [], \"vwc_3\": [], \"vwc_1_ec\": [], \"vwc_2_ec\": [],\r\n        #                            \"vwc_3_ec\": [],\r\n        #                            \"daily gallons\": [], \"daily switch\": [], \"cwsi\": [],\r\n        #                            \"sdd\": [], \"rh\": [], \"kc\": []}\r\n\r\n        field_capacity = logger.soil.field_capacity\r\n        wilting_point = logger.soil.wilting_point\r\n        ai_results_phase1_adjustment = []\r\n        ai_results_phase1_adjusted = []\r\n        ai_results_phase2_adjustment = []\r\n        ai_results_phase2_adjusted = []\r\n\r\n        for data_point in data:\r\n            date = data_point['date']\r\n            vwc_1 = data_point['vwc_1']\r\n            vwc_2 = data_point['vwc_2']\r\n            vwc_3 = data_point['vwc_3']\r\n            psi = data_point['cwsi']\r\n            et_hours = data_point['et_hours']\r\n\r\n            rec = expertSys.make_recommendation(\r\n                psi, field_capacity, wilting_point, vwc_1, vwc_2, vwc_3,\r\n                crop='Tomatoes', date=date, planting_date=planting_date,\r\n                harvest_date=harvest_date\r\n            )\r\n            applied_final, applied_steps = expertSys.apply_recommendations(et_hours, rec)\r\n\r\n            ai_results_phase1_adjustment.append(rec.recommendation_info[0])\r\n            ai_results_phase1_adjusted.append(applied_steps[0])\r\n            ai_results_phase2_adjustment.append(rec.recommendation_info[1])\r\n            ai_results_phase2_adjusted.append(applied_steps[1])\r\n\r\n        data['phase1_adjustment'] = ai_results_phase1_adjustment\r\n        data['phase1_adjusted'] = ai_results_phase1_adjusted\r\n        data['phase2_adjustment'] = ai_results_phase2_adjustment\r\n        data['phase2_adjusted'] = ai_results_phase2_adjusted\r\n\r\n        # print(f'Adding AI info to DB {dataset} - {logger_id} ')\r\n        #\r\n        # filename = 'ai_data.csv'\r\n        # print('\\t- writing data to csv')\r\n        # with open(filename, \"w\", newline='') as outfile:\r\n        #     writer = csv.writer(outfile)\r\n        #     writer.writerow(ai_results.keys())\r\n        #     # Using zip_longest because dict rows are uneven length due to daily_switch algo issue\r\n        #     # This will add full null rows for any additional daily_switch list values\r\n        #     writer.writerows(zip_longest(*ai_results.values()))\r\n        # print('...Done - file: ' + filename)\r\n\r\n        # schema = [\r\n        #     bigquery.SchemaField(\"logger_id\", \"STRING\"),\r\n        #     bigquery.SchemaField(\"date\", \"DATE\"),\r\n        #     bigquery.SchemaField(\"time\", \"STRING\"),\r\n        #     bigquery.SchemaField(\"canopy_temperature\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"ambient_temperature\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"vpd\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"vwc_1\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"vwc_2\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"vwc_3\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"field_capacity\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"wilting_point\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"daily_gallons\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"daily_switch\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"daily_hours\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"daily_pressure\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"daily_inches\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"psi\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"psi_threshold\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"psi_critical\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"sdd\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"rh\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"eto\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"kc\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"etc\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"et_hours\", \"FLOAT\"),\r\n        #     bigquery.SchemaField('phase1_adjustment', 'FLOAT'),\r\n        #     bigquery.SchemaField('phase1_adjusted', 'FLOAT'),\r\n        #     bigquery.SchemaField('phase2_adjustment', 'FLOAT'),\r\n        #     bigquery.SchemaField('phase2_adjusted', 'FLOAT'),\r\n        #     bigquery.SchemaField('phase3_adjustment', 'FLOAT'),\r\n        #     bigquery.SchemaField('phase3_adjusted', 'FLOAT'),\r\n        #     bigquery.SchemaField('vwc_1_ec', 'FLOAT'),\r\n        #     bigquery.SchemaField('vwc_2_ec', 'FLOAT'),\r\n        #     bigquery.SchemaField('vwc_3_ec', 'FLOAT'),\r\n        # ]\r\n        # dbwriter.write_to_table_from_csv(dataset, logger_id, filename, schema, overwrite=True)\r\n        print()\r\n\r\n        print('Fully Done')\r\n        return ai_results\r\n\r\n    def temp_irrigation_ai(self, logger):\r\n\r\n        \"\"\"\r\n            Apply the AI Irrigation recommendation to a specific logger's data\r\n\r\n            :type logger: Logger object\r\n            :param logger: Logger object\r\n            \"\"\"\r\n        dataset = logger.field.name\r\n        logger_name = logger.name\r\n\r\n        print(f'Grabbing data from {dataset} for logger {logger_name} - ')\r\n        dml = 'SELECT date, cwsi, vwc_1, vwc_2, vwc_3, et_hours' \\\r\n              'FROM `stomato.' + dataset + '.' + logger_name + '` ' \\\r\n                                                               'WHERE et_hours is not NULL' \\\r\n                                                               ' AND WHERE phase1_adjustment is NULL ORDER BY date DESC'\r\n\r\n        dbwriter = DBWriter()\r\n        expertSys = IrrigationRecommendationExpert()\r\n        result = dbwriter.run_dml(dml, project='stomato')\r\n        applied_finals = {}\r\n        ai_results = {\"logger_id\": [], \"date\": [], \"time\": [], \"canopy_temperature\": [], \"ambient_temperature\": [],\r\n                      \"vpd\": [], \"vwc_1\": [], \"vwc_2\": [], \"vwc_3\": [], \"field_capacity\": [], \"wilting_point\": [],\r\n                      \"daily_gallons\": [], \"daily_switch\": [], \"daily_hours\": [], \"daily_pressure\": [],\r\n                      \"daily_inches\": [], \"psi\": [], \"psi_threshold\": [], \"psi_critical\": [],\r\n                      \"sdd\": [], \"rh\": [], 'eto': [], 'kc': [], 'etc': [], 'et_hours': [],\r\n                      \"phase1_adjustment\": [], \"phase1_adjusted\": [], \"phase2_adjustment\": [], \"phase2_adjusted\": []}\r\n        applied_finals['date'] = []\r\n        applied_finals['base'] = []\r\n        applied_finals['final_rec'] = []\r\n        applied_finals['adjustment_values'] = []\r\n        applied_finals['adjustment_steps'] = []\r\n\r\n        planting_date = logger.planting_date\r\n\r\n        # harvest_date = result[-1][1]\r\n        harvest_date = planting_date + timedelta(days=120)\r\n\r\n        field_capacity = logger.soil.field_capacity\r\n        wilting_point = logger.soil.wilting_point\r\n\r\n        for r in result:\r\n            date = r[1]\r\n            psi = r[2]\r\n            vwc_1 = r[3]\r\n            vwc_2 = r[4]\r\n            vwc_3 = r[5]\r\n            et_hours = r[6]\r\n\r\n            rec = expertSys.make_recommendation(\r\n                psi, field_capacity, wilting_point, vwc_1, vwc_2, vwc_3,\r\n                crop='Tomatoes', date=date, planting_date=planting_date,\r\n                harvest_date=harvest_date\r\n            )\r\n            applied_final, applied_steps = expertSys.apply_recommendations(et_hours, rec)\r\n\r\n            phase1_adjustment = rec.recommendation_info[0]\r\n            phase1_adjusted = applied_steps[0]\r\n            phase2_adjustment = rec.recommendation_info[1]\r\n            phase2_adjusted = applied_steps[1]\r\n\r\n            print(f'Got AI Results:')\r\n            print(f'Date: {date}   ET: {et_hours}')\r\n            print(f'Phase 1 Results - Adjustment: {phase1_adjustment}  Adjusted: {phase1_adjusted}')\r\n            print(f'Phase 2 Results - Adjustment: {phase2_adjustment}  Adjusted: {phase2_adjusted}')\r\n            print()\r\n            print(f'Adding AI info to DB {dataset} - {logger_name} ')\r\n\r\n            dml = 'UPDATE `stomato.' + dataset + '.' + logger_name + '` ' \\\r\n                                                                     'SET  phase1_adjustment = ' + phase1_adjustment + ', ' \\\r\n                                                                                                                       'phase1_adjusted = ' + phase1_adjusted + ', ' \\\r\n                                                                                                                                                                'phase2_adjustment = ' + phase2_adjustment + ', ' \\\r\n                                                                                                                                                                                                             'phase2_adjusted = ' + phase2_adjusted + ', ' \\\r\n                                                                                                                                                                                                                                                      'WHERE et_hours is not NULL' \\\r\n                                                                                                                                                                                                                                                      ' AND WHERE phase1_adjustment is NULL' \\\r\n                                                                                                                                                                                                                                                      ' AND WHERE date = ' + date\r\n\r\n            result = dbwriter.run_dml(dml, project='stomato')\r\n\r\n        # filename = 'ai_data.csv'\r\n        # print('\\t- writing data to csv')\r\n        # with open(filename, \"w\", newline='') as outfile:\r\n        #     writer = csv.writer(outfile)\r\n        #     writer.writerow(ai_results.keys())\r\n        #     # Using zip_longest because dict rows are uneven length due to daily_switch algo issue\r\n        #     # This will add full null rows for any additional daily_switch list values\r\n        #     writer.writerows(zip_longest(*ai_results.values()))\r\n        # print('...Done - file: ' + filename)\r\n\r\n        # schema = [\r\n        #     bigquery.SchemaField(\"logger_id\", \"STRING\"),\r\n        #     bigquery.SchemaField(\"date\", \"DATE\"),\r\n        #     bigquery.SchemaField(\"time\", \"STRING\"),\r\n        #     bigquery.SchemaField(\"canopy_temperature\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"ambient_temperature\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"vpd\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"vwc_1\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"vwc_2\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"vwc_3\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"field_capacity\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"wilting_point\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"daily_gallons\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"daily_switch\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"daily_hours\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"daily_pressure\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"daily_inches\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"psi\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"psi_threshold\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"psi_critical\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"sdd\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"rh\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"eto\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"kc\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"etc\", \"FLOAT\"),\r\n        #     bigquery.SchemaField(\"et_hours\", \"FLOAT\"),\r\n        #     bigquery.SchemaField('phase1_adjustment', 'FLOAT'),\r\n        #     bigquery.SchemaField('phase1_adjusted', 'FLOAT'),\r\n        #     bigquery.SchemaField('phase2_adjustment', 'FLOAT'),\r\n        #     bigquery.SchemaField('phase2_adjusted', 'FLOAT'),\r\n        #     bigquery.SchemaField('phase3_adjustment', 'FLOAT'),\r\n        #     bigquery.SchemaField('phase3_adjusted', 'FLOAT'),\r\n        #     bigquery.SchemaField('vwc_1_ec', 'FLOAT'),\r\n        #     bigquery.SchemaField('vwc_2_ec', 'FLOAT'),\r\n        #     bigquery.SchemaField('vwc_3_ec', 'FLOAT'),\r\n        # ]\r\n        # dbwriter.write_to_table_from_csv(dataset, logger_id, filename, schema, overwrite=True)\r\n        print()\r\n\r\n        print('Fully Done')\r\n\r\n        pass\r\n\r\n    def get_crop_stage_level(self, accumulated_gdds):\r\n        # Preliminary Crop Stage GDD ranges from\r\n        # \"Predicitng Phenological Event of California Tomatoes\" by Zalom and Wilson (1999)\r\n        if accumulated_gdds == 0:\r\n            crop_stage_level = 0\r\n        elif 0 < accumulated_gdds <= 185:\r\n            crop_stage_level = 1\r\n        elif 185 < accumulated_gdds <= 427:\r\n            crop_stage_level = 2\r\n        elif 427 < accumulated_gdds <= 495:\r\n            crop_stage_level = 3\r\n        elif 495 < accumulated_gdds <= 557:\r\n            crop_stage_level = 4\r\n        elif 557 < accumulated_gdds <= 770:\r\n            crop_stage_level = 5\r\n        elif 770 < accumulated_gdds <= 909:\r\n            crop_stage_level = 6\r\n        elif 909 < accumulated_gdds <= 996:\r\n            crop_stage_level = 7\r\n        elif 996 < accumulated_gdds <= 1101:\r\n            crop_stage_level = 8\r\n        elif 1101 < accumulated_gdds <= 1214:\r\n            crop_stage_level = 9\r\n        elif 1214 < accumulated_gdds:\r\n            crop_stage_level = 10\r\n        else:\r\n            crop_stage_level = accumulated_gdds\r\n\r\n        return crop_stage_level\r\n\r\n    def get_crop_stage(self, accumulated_gdds):\r\n        crop_stage_level = self.get_crop_stage_level(accumulated_gdds)\r\n\r\n        # Preliminary Crop Stage GDD ranges from\r\n        # \"Predicitng Phenological Event of California Tomatoes\" by Zalom and Wilson (1999)\r\n        return {\r\n            0: 'NA',\r\n            1: 'Bloom',\r\n            2: '0.5-0.75 inch Green',\r\n            3: '1.25-1.5 inch Green',\r\n            4: 'Mature Green Fruit',\r\n            5: 'Pink Fruit',\r\n            6: '10-30% Red',\r\n            7: '30-50% Red',\r\n            8: '50-75% Red',\r\n            9: '75-90% Red',\r\n            10: '90-100% Red',\r\n        }.get(crop_stage_level, 'Error - GDDs:' + str(crop_stage_level))\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/CwsiProcessor.py b/CwsiProcessor.py
--- a/CwsiProcessor.py	
+++ b/CwsiProcessor.py	
@@ -37,6 +37,7 @@
         value, check their corresponding vpd's and pick the one with the higher vpd
 
         :param all_results_converted:
+        :param mute_prints:
         :return:
         """
         i = 0
Index: Logger.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import datetime\r\nimport json\r\nimport time\r\nimport xml.etree.ElementTree as ET\r\nfrom collections import defaultdict\r\nfrom collections import deque\r\nfrom datetime import date, timedelta, datetime\r\nfrom os import path\r\n\r\nimport requests\r\nfrom dateutil import tz\r\nfrom google.cloud import bigquery\r\nfrom requests.adapters import HTTPAdapter, Retry\r\n\r\nfrom CropCoefficient import CropCoefficient\r\nfrom CwsiProcessor import CwsiProcessor\r\nfrom DBWriter import DBWriter\r\nfrom Field import Field\r\nfrom Grower import Grower\r\nfrom Notifications import Notification_SensorError, Notification_TechnicianWarning\r\nfrom Soils import Soil\r\nfrom Technician import Technician\r\nfrom Thresholds import Thresholds\r\n\r\nDIRECTORY_YEAR = \"2024\"\r\nDXD_DIRECTORY = \"H:\\\\Shared drives\\\\Stomato\\\\\" + DIRECTORY_YEAR + \"\\\\Dxd Files\\\\\"\r\n\r\n\r\n####################################################################\r\n# Base Class for a logger in a field                               #\r\n####################################################################\r\ndef read_last_time(dxd_file: str):\r\n    \"\"\"\r\n    Read and return the last time information was pulled from a dxd file.\r\n\r\n    The Last Time information was pulled indicates when the last time the API was used to pull information\r\n\r\n    :param dxd_file:\r\n        File we want to get the last time from\r\n    :return:\r\n        if found return:\r\n            last_time - datetime obj\r\n            last_timestamp - timestamp\r\n        else 0\r\n    \"\"\"\r\n    txt = \"no data found\"\r\n    with open(dxd_file) as file:\r\n        data = json.load(file)\r\n        if \"created\" in data:\r\n            last_time_ts = data['device']['timeseries'][-1]['configuration']['values'][-1][0]\r\n            return last_time_ts\r\n\r\n    return 0\r\n\r\n\r\nclass Logger(object):\r\n    \"\"\"\r\n    Class to hold information for 1 logger installed in the field.\r\n\r\n    This class will encompass everything a logger needs to do to update its information. That includes\r\n        downloading the new dxds, converting them, processing the information, and then writing it out\r\n        to its Google Sheet.\r\n\r\n    Attributes:\r\n        id: String to hold the logger's ID\r\n        password: String to hold the logger's password\r\n        prev_day_gallons: Number to hold the previous day gallons. This value is needed and used to calculate what\r\n            the next day's gallons are\r\n        prev_day_switch: Number to hold the previous day switch minutes. This value is needed and used to calculate\r\n            what the next day's switch minutes are\r\n        daily_switch: List to hold values for daily switch\r\n        ports: Dictionary to hold the different port values\r\n        cwsi_processor: CwsiProcessor Object used to process the information from the logger\r\n    \"\"\"\r\n\r\n    def __init__(\r\n            self,\r\n            id: str,\r\n            password: str,\r\n            name: str,\r\n            crop_type: str,\r\n            soil_type: str,\r\n            gpm: float,\r\n            irrigation_set_acres: float,\r\n            logger_direction: str,\r\n            install_date: datetime.date,\r\n            lat: str = '',\r\n            long: str = '',\r\n            grower: Grower = None,\r\n            field: Field = None,\r\n            planting_date: datetime.date = None,\r\n            rnd: bool = False,\r\n            active: bool = True\r\n    ) -> object:\r\n        \"\"\"\r\n\r\n        :param install_date:\r\n        :param id:\r\n        :param password:\r\n        :param name:\r\n        :param crop_type:\r\n        :param field_capacity:\r\n        :param wilting_point:\r\n        :param gpm:\r\n        :param irrigation_set_acres:\r\n        :param grower:\r\n        :param field:\r\n        :param planting_date:\r\n        :param rnd:\r\n        \"\"\"\r\n\r\n        self.id = id\r\n        self.password = password\r\n        self.name = name\r\n        self.grower = grower\r\n        self.field = field\r\n        self.cwsi_processor = CwsiProcessor()\r\n        self.dbwriter = DBWriter()\r\n        self.prev_day_switch = 0\r\n        self.prev_day_gallons = 0\r\n        self.updated = False\r\n        self.crashed = False\r\n        self.crop_coefficient = CropCoefficient()\r\n        if self.id[0] == 'z':\r\n            self.model = 'z6'\r\n        else:\r\n            self.model = 'unknown'\r\n        if isinstance(planting_date, str):\r\n            ptdate = datetime.strptime(planting_date, '%m/%d/%Y').date()\r\n            self.planting_date = ptdate\r\n        else:\r\n            self.planting_date = planting_date\r\n        self.crop_type = crop_type\r\n        self.soil = Soil(soil_type)\r\n        if gpm is not None:\r\n            self.gpm = float(gpm)\r\n        if irrigation_set_acres is not None:\r\n            self.irrigation_set_acres = float(irrigation_set_acres)\r\n        self.prev_mrid = 0\r\n        self.rnd = rnd\r\n        self.active = active\r\n        self.lat = lat\r\n        self.long = long\r\n        self.logger_direction = logger_direction\r\n        self.gdd_total = 0\r\n        self.crop_stage = 'NA'\r\n        self.ir_active = False\r\n        self.ports = {}\r\n        self.install_date = install_date\r\n        self.broken = False\r\n        self.uninstall_date = None\r\n        self.consecutive_ir_values = deque()\r\n        self.irrigation_ledger = {}\r\n\r\n    def __repr__(self):\r\n        return f'Logger: {self.name}, Active: {self.active}, Crop Type: {self.crop_type}, Soil: {self.soil.soil_type}, IR Active: {self.ir_active}'\r\n\r\n    def to_string(self):\r\n        \"\"\"\r\n        Function used to print out output to screen.\r\n\r\n        Print out the Logger sheet name, id, password, sheet url,\r\n            sheet id, prev day gallons, prev day switch\r\n        :return:\r\n        \"\"\"\r\n        name_str = f'Name: {str(self.name)}'\r\n        grower_str = f'Grower: {str(self.grower.name)}'\r\n        id_str = f'ID: {str(self.id)}'\r\n        active_str = f'Active: {str(self.active)}'\r\n        if not hasattr(self, 'crop_type'):\r\n            if hasattr(self, 'cropType'):\r\n                self.crop_type = self.cropType\r\n        crop_str = f'Crop: {str(self.crop_type)}'\r\n        prev_day_switch_str = f'Prev Day Switch: {str(self.prev_day_switch)}'\r\n        if not hasattr(self, 'gdd_total'):\r\n            self.gdd_total = 'No GDD'\r\n        gdd_str = f'GDD Total: {str(self.gdd_total)}'\r\n        gpm_str = f'GPM: {str(self.gpm)}'\r\n        soil_type_str = f'Soil Type: {str(self.soil.soil_type)}'\r\n        updated_str = f'Updated: {str(self.updated)}'\r\n        if not hasattr(self, 'crop_stage'):\r\n            self.crop_stage = 'No Crop Stage'\r\n        if not hasattr(self, 'irrigation_set_acres'):\r\n            if hasattr(self, 'acres'):\r\n                self.irrigation_set_acres = self.acres\r\n        if not hasattr(self, 'crashed'):\r\n            self.crashed = False\r\n        if not hasattr(self, 'rnd'):\r\n            self.rnd = False\r\n        if not hasattr(self, 'ir_active'):\r\n            self.ir_active = None\r\n        install_date_str = f'Install Date: {str(self.install_date)}'\r\n        formatted_consecutive_psi = [round(tup[0], 2) for tup in self.consecutive_ir_values]\r\n        formatted_consecutive_sdd = [round(tup[1], 2) for tup in self.consecutive_ir_values]\r\n        # formatted_consecutive_psi = [t[0] for t in self.consecutive_ir_values]\r\n        consect_psi_str = f'Consec PSI: {formatted_consecutive_psi}'\r\n\r\n        print('....................................................................')\r\n        print(f'\\t{name_str:30} | Model: {str(self.model)}')\r\n        print(f'\\t{grower_str:30} | Field: {str(self.field.name)}')\r\n        print(f'\\t{id_str:30} | Password: {str(self.password)}')\r\n        print(f'\\t{active_str:30} | Broken: {str(self.broken)}')\r\n        print(f'\\t{install_date_str:30} | Planting Date: {str(self.planting_date)}')\r\n        print(f'\\t{crop_str:30} | R&D: {str(self.rnd)}')\r\n        print(f'\\t{prev_day_switch_str:30} | IR Active: {self.ir_active}')\r\n        print(f'\\t{consect_psi_str:30} | Consect SDD: {formatted_consecutive_sdd}')\r\n        print(f'\\t{gdd_str:30} | Crop Stage: {self.crop_stage}')\r\n        print(f'\\t{gpm_str:30} | Acres: {str(self.irrigation_set_acres)}')\r\n        print(f'\\t{soil_type_str:30} | FC: {str(self.soil.field_capacity)}   WP: {str(self.soil.wilting_point)}')\r\n        print(f'\\t{updated_str:30} | Crashed: {str(self.crashed)}')\r\n        print('....................................................................')\r\n\r\n    def get_logger_data(\r\n            self,\r\n            specific_mrid: int = None,\r\n            subtract_from_mrid: int = 0,\r\n            mr_id_location: str = DXD_DIRECTORY,\r\n            dxd_save_location: str = DXD_DIRECTORY,\r\n            file_name: str = None,\r\n    ) -> bool:\r\n        \"\"\"\r\n        Download dxd files from decagon API containing all the logger information and store them.\r\n        Call on the corresponding API for z6 loggers. Using zentra API v1.0\r\n\r\n        Access information for the API is hard coded - email, user_password, url\r\n        Files are stored in the OutputFolder with the Logger ID as the name. For example:\r\n            5G0B0420.dxd\r\n        :return:\r\n        \"\"\"\r\n        response_success = False\r\n        # file_path = ''\r\n        mr_id_file_path = ''\r\n        dxd_save_location_file_path = ''\r\n        if file_name is None:\r\n            file_name = self.id + '.dxd'\r\n        else:\r\n            file_name = file_name + '.dxd'\r\n        if path.exists(mr_id_location):\r\n            mr_id_file_path = mr_id_location + file_name\r\n        if path.exists(dxd_save_location):\r\n            dxd_save_location_file_path = dxd_save_location + file_name\r\n\r\n        # if path.exists(DXD_DIRECTORY):\r\n        #     file_path = DXD_DIRECTORY + file_name\r\n        if specific_mrid is not None:\r\n            mr_id = specific_mrid\r\n        else:\r\n            mr_id = self.get_mrid(mr_id_file_path, subtract_from_mrid)\r\n            self.prev_mrid = mr_id\r\n\r\n        response = self.zentra_api_call(mr_id)\r\n\r\n        if response.ok:\r\n            response_success = True\r\n            self.write_dxd_file(dxd_save_location_file_path, response)\r\n        else:\r\n            print('\\tResponse not OK')\r\n            response_success = False\r\n\r\n        return response_success\r\n\r\n    def write_dxd_file(self, file_path, response):\r\n        try:\r\n            write_dxd_start_time = time.time()\r\n            print('\\tWriting dxd file...')\r\n            parsed_json = json.loads(response.content)\r\n            with open(file_path, 'w', encoding=\"utf8\") as fd:\r\n                json.dump(parsed_json, fd, indent=4, sort_keys=True, default=str)\r\n            write_dxd_end_time = time.time()\r\n            print(\"----------FINISHED----------\")\r\n            write_dxd_elapsed_time_seconds = write_dxd_end_time - write_dxd_start_time\r\n\r\n            write_dxd_elapsed_time_hours = int(write_dxd_elapsed_time_seconds // 3600)\r\n            write_dxd_elapsed_time_minutes = int((write_dxd_elapsed_time_seconds % 3600) // 60)\r\n            write_dxd_elapsed_time_seconds = int(write_dxd_elapsed_time_seconds % 60)\r\n            print(f\"\\tWrite DXD execution time: {write_dxd_elapsed_time_hours}:\"\r\n                  + f\"{write_dxd_elapsed_time_minutes}:\"\r\n                  + f\"{write_dxd_elapsed_time_seconds} (hours:minutes:seconds)\")\r\n            print()\r\n        except Exception as error:\r\n            print('\\tERROR in writing dxd file for json data for z6')\r\n            self.updated = False\r\n            print(error)\r\n\r\n    def zentra_api_call(self, mr_id):\r\n        print('\\tCalling Zentra API...')\r\n        url = 'https://zentracloud.com/api/v1/readings'\r\n        params = {'user': 'jgarrido@morningstarco.com', 'user_password': 'Mexico1012', 'sn': self.id,\r\n                  'device_password': self.password, 'start_mrid': mr_id}\r\n        # OLD METHOD BUILDING WHOLE STRING BY HAND\r\n        # email_lead = '?user='\r\n        # email = 'jgarrido@morningstarco.com'\r\n        # user_password_lead = '&user_password='\r\n        # user_password = 'Mexico1012'\r\n        # id_lead = '&sn='\r\n        # id = self.id\r\n        # password_lead = '&device_password='\r\n        # password = self.password\r\n        # mrid_lead = '&start_mrid='\r\n        # built_url = url + email_lead + email + \\\r\n        #             user_password_lead + user_password + \\\r\n        #             id_lead + id + \\\r\n        #             password_lead + password\r\n        # if mr_id > 0:\r\n        #     built_url = built_url + mrid_lead + str(mr_id)\r\n        try:\r\n            retry_strategy = Retry(\r\n                total=7,\r\n                backoff_factor=2,\r\n                status_forcelist=[429, 443, 500, 502, 503, 504]\r\n            )\r\n            adapter = HTTPAdapter(max_retries=retry_strategy)\r\n            http = requests.Session()\r\n            http.mount(\"https://\", adapter)\r\n            http.mount(\"http://\", adapter)\r\n\r\n            print(f\"\\tMRID from DXD: {mr_id}\")\r\n\r\n            response = http.get(url, params=params)\r\n            print(\"\\t-->> Request URL: \" + str(response.url))\r\n\r\n            # OLD METHOD WITHOUT RETRY OR BACKOFF\r\n            # response = requests.get(url, timeout=120)\r\n\r\n            if response.ok:\r\n                print(f'\\tSuccessful METER API')\r\n\r\n        except Exception as error:\r\n            print('\\tERROR in making z6 data request to METER')\r\n            self.updated = False\r\n            print(error)\r\n        except requests.exceptions.Timeout:\r\n            print('\\tTimeout in making z6 data request to METER')\r\n            self.updated = False\r\n        except requests.exceptions.TooManyRedirects:\r\n            print('\\tToo many redirects in making z6 data request to METER')\r\n            self.updated = False\r\n        except requests.exceptions.RequestException as e:\r\n            print('\\tERROR in making z6 data request to METER')\r\n            self.updated = False\r\n            print(e)\r\n        return response\r\n\r\n    def get_mrid(self, file_path, subtract_from_mrid):\r\n        mr_id = 0\r\n        if self.crashed:\r\n            print(\"\\tCrashed so running with previous MRID: {0}\".format(self.prev_mrid))\r\n            mr_id = self.prev_mrid\r\n            # Resetting the crashed boolean\r\n            self.crashed = False\r\n        else:\r\n            if self.is_file(file_path):\r\n                mr_id = self.read_mrid(file_path)\r\n                if subtract_from_mrid > 0:\r\n                    sub_mr_id = mr_id - subtract_from_mrid\r\n                    if sub_mr_id < 0:\r\n                        sub_mr_id = 0\r\n                    print(\r\n                        f\"\\t-->> Subtracting from MRID: {str(mr_id)} - {str(subtract_from_mrid)} = {str(sub_mr_id)}\"\r\n                    )\r\n                    mr_id = sub_mr_id\r\n            else:\r\n                mr_id = 0\r\n        return mr_id\r\n\r\n    def is_file(self, file: str) -> bool:\r\n        \"\"\"\r\n        Check if a file is a file or not.\r\n\r\n        :param file:\r\n        :return:\r\n            True if it is a file\r\n            None if it is not\r\n        \"\"\"\r\n        try:\r\n            with open(file):\r\n                pass\r\n            return True\r\n        except IOError as e:\r\n            print(\"Unable to open file %s\" % file)\r\n            return None\r\n\r\n    def read_mrid(self, file_path: str):\r\n        \"\"\"\r\n        Read and return the MRID from a dxd file.\r\n\r\n        MRID is a number that indicates how current the information in the dxd is. Everytime a download occurs,\r\n        the MRID is set to a newer number. Each new download just requires the MRID + 1 to get the latest info\r\n        since the last download.\r\n\r\n        :param file_path:\r\n            File we want to get the MRID from\r\n        :return:\r\n            MRID if found, 0 if not\r\n        \"\"\"\r\n        with open(file_path) as file:\r\n            data = json.load(file)\r\n            if \"created\" in data:\r\n                mrid = data['device']['timeseries'][-1]['configuration']['values'][-1][1]\r\n                self.prev_mrid = mrid\r\n                return mrid\r\n        return 0\r\n\r\n    def read_ereset(self, dxd_file):\r\n        \"\"\"\r\n        Read and return the eReset from a dxd file.\r\n\r\n        eReset is a number that indicates how many times the logger has been reset. This is useful information\r\n        because each time a logger is reset, the gallons and switch counters get reset to 0 as well which can affect\r\n        the total tallies.\r\n\r\n        :param dxd_file:\r\n            File we want to get the eReset from\r\n        :return:\r\n            eReset if found, 0 if not\r\n        \"\"\"\r\n        txt = \"no data found\"\r\n        doc = ET.parse(dxd_file)\r\n        root = doc.getroot()\r\n        for element in root.iter():\r\n            if 'Status' in element.tag:\r\n                ereset = int(element.get('eReset'))\r\n                return ereset\r\n        return 0\r\n\r\n    def read_battery_level(self, dxd_file: str):\r\n        \"\"\"\r\n        Read and return the Battery level from a dxd file.\r\n\r\n        Battery is a number that indicates how much battery is left in the logger batteries.\r\n\r\n        :param dxd_file:\r\n            File we want to get the Battery level from\r\n        :return:\r\n            Battery level if found, None if not\r\n        \"\"\"\r\n\r\n        with open(dxd_file) as file:\r\n            data = json.load(file)\r\n            if \"created\" in data:\r\n                battery_level = data['device']['timeseries'][-1]['configuration']['values'][-1][-2][0]['value']\r\n                return battery_level\r\n        return None\r\n\r\n    def read_dxd(self, dxd_save_location: str = DXD_DIRECTORY, file_name: str = None, ):\r\n        \"\"\"\r\n        Read the dxd file and check the response.\r\n\r\n        :return:\r\n            Dictionary with raw dates and raw values\r\n        \"\"\"\r\n        result = None\r\n        if file_name is None:\r\n            file_name = self.id + '.dxd'\r\n        else:\r\n            file_name = file_name + '.dxd'\r\n\r\n        if path.exists(dxd_save_location):\r\n            file_path = dxd_save_location + file_name\r\n\r\n        raw_dxd = \"no data found\"\r\n        with open(file_path) as file:\r\n            raw_dxd = json.load(file)\r\n        if raw_dxd == \"no data found\":\r\n            return None\r\n        return raw_dxd\r\n\r\n    def get_all_ports_information(self, raw_dxd: dict, specific_year: int = datetime.now().year) -> dict:\r\n        \"\"\"\r\n        Read the dxd file and returns the information in all ports.\r\n\r\n        :param specific_year:\r\n        :param raw_dxd:\r\n            Dxd file to read\r\n        :return:\r\n            Dictionary holding the raw values in each port\r\n        \"\"\"\r\n        raw_dxd_dict = None\r\n        converted_results = {\"dates\": [], \"canopy temperature\": [], \"ambient temperature\": [], \"rh\": [], \"vpd\": [],\r\n                             \"vwc_1\": [], \"vwc_2\": [], \"vwc_3\": [], \"vwc_1_ec\": [], \"vwc_2_ec\": [], \"vwc_3_ec\": [],\r\n                             \"daily gallons\": [], \"daily switch\": []}\r\n        data_from_previous_years = False\r\n        min_number_of_values_for_timeseries = 5\r\n\r\n        if \"device\" in raw_dxd:\r\n            all_data_series = []\r\n            for ind, timeseries in enumerate(raw_dxd['device']['timeseries']):\r\n                # Check that the timeseries has at least 5 values\r\n                if len(timeseries['configuration']['values']) >= min_number_of_values_for_timeseries:\r\n                    # Grab start and end of timeseries\r\n                    timeseries_start_date_timestamp = timeseries['configuration']['values'][0][0]\r\n                    timeseries_end_date_timestamp = timeseries['configuration']['values'][-1][0]\r\n\r\n                    # Special check because some timeseries seem to get 1 random value at the very end from an\r\n                    # early year. When this happens, we just grab the date for the 2nd to last value instead of\r\n                    # the last\r\n                    if timeseries_end_date_timestamp < timeseries_start_date_timestamp:\r\n                        # start = self.convert_timestamp_to_local_datetime(timeseries_start_date_timestamp)\r\n                        # end = self.convert_timestamp_to_local_datetime(timeseries_end_date_timestamp)\r\n                        #\r\n                        # print('Error: END DATE < START DATE')\r\n                        # print(self.field.name)\r\n                        # print(self.name)\r\n                        # print(f'{end} < {start}')\r\n                        # print()\r\n                        timeseries_end_date_timestamp = timeseries['configuration']['values'][-2][0]\r\n\r\n                    # Convert those start and end timestamps to datetimes\r\n                    timeseries_start_date_datetime = self.convert_timestamp_to_local_datetime(\r\n                        timeseries_start_date_timestamp)\r\n                    timeseries_start_date_datetime_year = timeseries_start_date_datetime.year\r\n\r\n                    timeseries_end_date_datetime = self.convert_timestamp_to_local_datetime(\r\n                        timeseries_end_date_timestamp)\r\n                    timeseries_end_date_datetime_year = timeseries_end_date_datetime.year\r\n\r\n                    if timeseries_start_date_datetime_year <= specific_year <= timeseries_end_date_datetime_year:\r\n                        # Grab the port configuration of this particular timeseries\r\n                        ports = self.get_ports(timeseries['configuration']['sensors'])\r\n\r\n                        # Check if ports.keys() has every one of the required ports\r\n                        required_ports = [1, 2, 3, 4, 5, 6]\r\n                        has_all_ports = True\r\n\r\n                        for port_num in required_ports:\r\n                            if port_num not in ports.keys():\r\n                                has_all_ports = False\r\n                                break\r\n\r\n                        # If it has all required ports and each port is set to the correct sensor:\r\n                        if (has_all_ports and\r\n                            ports[1] in ['Infra Red'] and\r\n                            ports[2] in ['VP4', 'Atmos 14'] and\r\n                            ports[3] in ['GS1', 'Terros 10', 'GS3', 'Terros 12'] and\r\n                            ports[4] in ['GS1', 'Terros 10', 'GS3', 'Terros 12'] and\r\n                            ports[5] in ['GS1', 'Terros 10', 'GS3', 'Terros 12'] and\r\n                            ports[6] in ['Switch']):\r\n\r\n                            # If we passed all our checks, this is a valid timeseries we care about so append it along with\r\n                            # its ports to all_data_series as a tuple (timeseries['configuration], ports)\r\n                            all_data_series.append((timeseries['configuration'], ports))\r\n                        else:\r\n                            print(f\"Error not a standard configuration: {ports}\")\r\n\r\n            # For each tuple (chapter, ports) in all the chapters and ports that have data we care about\r\n            for data_series, ports in all_data_series:\r\n                # print(ports)\r\n                data_index_offset, ir_port, vp4_port, vwc1_port, vwc2_port, vwc3_port, switch_port = self.get_sensor_port_indexes(ports)\r\n                sensor_data_indexes = self.get_sensor_individual_data_indexes()\r\n\r\n                # Grab data\r\n                for data_point in data_series['values']:\r\n                    data_from_previous_years = False\r\n\r\n                    timestamp = (data_point[0])\r\n\r\n                    # Bandaid fix for Meter randomly giving us data from 1970 and crashing our local timestamp conversion. wtf\r\n                    if timestamp > 0:\r\n                        datapoint_datetime = self.convert_timestamp_to_local_datetime(timestamp)\r\n\r\n                        # Check and only add data that is from current year going forward\r\n                        d_year = datapoint_datetime.year\r\n                        if d_year == specific_year or (datetime.now().month == 1 and datetime.now().day == 1):\r\n\r\n                            # Check and only grab data from install date going forward\r\n                            # This is to avoid grabbing data from a logger that was moved to another field from the\r\n                            # previous field it was installed in\r\n                            if self.install_date <= datapoint_datetime.date():\r\n                                converted_results[\"dates\"].append(datapoint_datetime)\r\n\r\n                                # Grabbing IR data\r\n                                if ir_port is not None:\r\n                                    ir_temp_value = data_point[ir_port][sensor_data_indexes['ir temp']]['value']\r\n                                    if ir_temp_value == 'None' or ir_temp_value == '':\r\n                                        ir_temp_value = None\r\n                                    converted_results[\"canopy temperature\"].append(ir_temp_value)\r\n                                else:\r\n                                    converted_results[\"canopy temperature\"].append(None)\r\n\r\n                                # Grabbing VP4/Atmos 14 data\r\n                                if vp4_port is not None:\r\n                                    vp4_air_temp_value = data_point[vp4_port][sensor_data_indexes['vp4 air temp']]['value']\r\n                                    if vp4_air_temp_value == 'None' or vp4_air_temp_value == '':\r\n                                        vp4_air_temp_value = None\r\n                                    converted_results[\"ambient temperature\"].append(vp4_air_temp_value)\r\n\r\n                                    vp_rh_value = data_point[vp4_port][sensor_data_indexes['vp4 rh']]['value']\r\n                                    if vp_rh_value == 'None' or vp_rh_value == '':\r\n                                        vp_rh_value = None\r\n                                    converted_results[\"rh\"].append(vp_rh_value)\r\n\r\n                                    vp_vpd_value = data_point[vp4_port][sensor_data_indexes['vp4 vpd']]['value']\r\n                                    if vp_vpd_value == 'None' or vp_vpd_value == '':\r\n                                        vp_vpd_value = None\r\n                                    converted_results[\"vpd\"].append(vp_vpd_value)\r\n                                else:\r\n                                    converted_results[\"ambient temperature\"].append(None)\r\n                                    converted_results[\"rh\"].append(None)\r\n                                    converted_results[\"vpd\"].append(None)\r\n\r\n                                # Grabbing VWC 1 data\r\n                                if vwc1_port is not None:\r\n                                    vwc1_value = data_point[vwc1_port][sensor_data_indexes['vwc volumetric']]['value']\r\n                                    if vwc1_value == 'None' or vwc1_value == '':\r\n                                        vwc1_value = None\r\n                                    converted_results[\"vwc_1\"].append(vwc1_value)\r\n\r\n                                    if ports[vwc1_port - data_index_offset] in ['GS3', 'Terros 12']:\r\n                                        vwc1_ec_value = data_point[vwc1_port][sensor_data_indexes['vwc ec']]['value']\r\n                                        if vwc1_ec_value == 'None' or vwc1_ec_value == '':\r\n                                            vwc1_ec_value = None\r\n                                        converted_results[\"vwc_1_ec\"].append(vwc1_ec_value)\r\n                                    else:\r\n                                        converted_results[\"vwc_1_ec\"].append(None)\r\n                                else:\r\n                                    converted_results[\"vwc_1\"].append(None)\r\n\r\n                                # Grabbing VWC 2 data\r\n                                if vwc2_port is not None:\r\n                                    vwc2_value = data_point[vwc2_port][sensor_data_indexes['vwc volumetric']]['value']\r\n                                    if vwc2_value == 'None' or vwc2_value == '':\r\n                                        vwc2_value = None\r\n                                    converted_results[\"vwc_2\"].append(vwc2_value)\r\n\r\n                                    if ports[vwc2_port - data_index_offset] in ['GS3', 'Terros 12']:\r\n                                        vwc2_ec_value = data_point[vwc2_port][sensor_data_indexes['vwc ec']]['value']\r\n                                        if vwc2_ec_value == 'None' or vwc2_ec_value == '':\r\n                                            vwc2_ec_value = None\r\n                                        converted_results[\"vwc_2_ec\"].append(vwc2_ec_value)\r\n                                    else:\r\n                                        converted_results[\"vwc_2_ec\"].append(None)\r\n                                else:\r\n                                    converted_results[\"vwc_2\"].append(None)\r\n\r\n                                # Grabbing VWC 3 data\r\n                                if vwc3_port is not None:\r\n                                    vwc3_value = data_point[vwc3_port][sensor_data_indexes['vwc volumetric']]['value']\r\n                                    if vwc3_value == 'None' or vwc3_value == '':\r\n                                        vwc3_value = None\r\n                                    converted_results[\"vwc_3\"].append(vwc3_value)\r\n\r\n                                    if ports[vwc3_port - data_index_offset] in ['GS3', 'Terros 12']:\r\n                                        vwc3_ec_value = data_point[vwc3_port][sensor_data_indexes['vwc ec']]['value']\r\n                                        if vwc3_ec_value == 'None' or vwc3_ec_value == '':\r\n                                            vwc3_ec_value = None\r\n                                        converted_results[\"vwc_3_ec\"].append(vwc3_ec_value)\r\n                                    else:\r\n                                        converted_results[\"vwc_3_ec\"].append(None)\r\n                                else:\r\n                                    converted_results[\"vwc_3\"].append(None)\r\n\r\n                                # Grabbing Switch data\r\n                                if switch_port is not None:\r\n                                    switch_value = data_point[switch_port][sensor_data_indexes['switch minutes']]['value']\r\n                                    if switch_value == 'None' or switch_value == '':\r\n                                        switch_value = None\r\n                                    converted_results[\"daily switch\"].append(switch_value)\r\n                                else:\r\n                                    converted_results[\"daily switch\"].append(None)\r\n                            # else:\r\n                            #     print('Ignored some data from earlier in the year')\r\n                        else:\r\n                            data_from_previous_years = True\r\n\r\n            if data_from_previous_years:\r\n                print(\"Ignored some data from previous years\")\r\n        return converted_results\r\n\r\n    def get_all_ports_information_weather_stations(self, raw_dxd: dict,\r\n                                                   specific_year: int = datetime.now().year) -> dict:\r\n        \"\"\"\r\n        Read the dxd file and returns the information in all ports.\r\n\r\n        :param specific_year:\r\n        :param raw_dxd:\r\n            Dxd file to read\r\n        :return:\r\n            Dictionary holding the raw values in each port\r\n        \"\"\"\r\n        raw_dxd_dict = None\r\n        converted_results = {\"dates\": [], \"solar radiation\": [], \"precipitation\": [], \"lightning activity\": [],\r\n                             \"lightning distance\": [],\r\n                             \"wind direction\": [], \"wind speed\": [], \"gust speed\": [], \"ambient temperature\": [],\r\n                             \"relative humidity\": [], \"atmospheric pressure\": [],\r\n                             \"x axis level\": [], \"y axis level\": [], \"vpd\": []}\r\n        data_from_previous_years = False\r\n        min_number_of_values_for_timeseries = 5\r\n\r\n        if \"device\" in raw_dxd:\r\n            all_data_series = []\r\n            for ind, timeseries in enumerate(raw_dxd['device']['timeseries']):\r\n                # Check that the timeseries has at least 5 values\r\n                if len(timeseries['configuration']['values']) >= min_number_of_values_for_timeseries:\r\n                    # Grab start and end of timeseries\r\n                    timeseries_start_date_timestamp = timeseries['configuration']['values'][0][0]\r\n                    timeseries_end_date_timestamp = timeseries['configuration']['values'][-1][0]\r\n\r\n                    # Special check because some timeseries seem to get 1 random value at the very end from an\r\n                    # early year. When this happens, we just grab the date for the 2nd to last value instead of\r\n                    # the last\r\n                    if timeseries_end_date_timestamp < timeseries_start_date_timestamp:\r\n                        # start = self.convert_timestamp_to_local_datetime(timeseries_start_date_timestamp)\r\n                        # end = self.convert_timestamp_to_local_datetime(timeseries_end_date_timestamp)\r\n                        #\r\n                        # print('Error: END DATE < START DATE')\r\n                        # print(self.field.name)\r\n                        # print(self.name)\r\n                        # print(f'{end} < {start}')\r\n                        # print()\r\n                        timeseries_end_date_timestamp = timeseries['configuration']['values'][-2][0]\r\n\r\n                    # Convert those start and end timestamps to datetimes\r\n                    timeseries_start_date_datetime = self.convert_timestamp_to_local_datetime(\r\n                        timeseries_start_date_timestamp)\r\n                    timeseries_start_date_datetime_year = timeseries_start_date_datetime.year\r\n\r\n                    timeseries_end_date_datetime = self.convert_timestamp_to_local_datetime(\r\n                        timeseries_end_date_timestamp)\r\n                    timeseries_end_date_datetime_year = timeseries_end_date_datetime.year\r\n\r\n                    if timeseries_start_date_datetime_year <= specific_year <= timeseries_end_date_datetime_year:\r\n                        # Grab the port configuration of this particular timeseries\r\n                        ports = self.get_ports(timeseries['configuration']['sensors'])\r\n\r\n                        # Check if ports.keys() has every one of the required ports\r\n                        required_ports = [2]\r\n                        has_all_ports = True\r\n\r\n                        for port_num in required_ports:\r\n                            if port_num not in ports.keys():\r\n                                has_all_ports = False\r\n                                break\r\n\r\n                        # If it has all required ports and each port is set to the correct sensor:\r\n                        if has_all_ports and ports[2] in ['Atmos 41']:\r\n\r\n                            # If we passed all our checks, this is a valid timeseries we care about so append it along with\r\n                            # its ports to all_data_series as a tuple (timeseries['configuration], ports)\r\n                            all_data_series.append((timeseries['configuration'], ports))\r\n                        else:\r\n                            print(f\"Error not a standard configuration: {ports}\")\r\n\r\n            # For each tuple (chapter, ports) in all the chapters and ports that have data we care about\r\n            for data_series, ports in all_data_series:\r\n                # print(ports)\r\n                data_index_offset, atmos_41_port = self.get_sensor_port_indexes_weather_stations(ports)\r\n                sensor_data_indexes = self.get_sensor_individual_data_indexes_weather_stations()\r\n\r\n                # Grab data\r\n                for data_point in data_series['values']:\r\n\r\n                    data_from_previous_years = False\r\n\r\n                    timestamp = (data_point[0])\r\n\r\n                    # Bandaid fix for Meter randomly giving us data from 1970 and crashing our local timestamp conversion. wtf\r\n                    if timestamp > 0:\r\n                        datapoint_datetime = self.convert_timestamp_to_local_datetime(timestamp)\r\n\r\n                        # Check and only add data that is from current year going forward\r\n                        d_year = datapoint_datetime.year\r\n                        if d_year == specific_year or (datetime.now().month == 1 and datetime.now().day == 1):\r\n\r\n                            '''\r\n                            {\"dates\": [], \"solar radiation\": [], \"precipitation\": [], \"lightning activity\": [],\r\n                             \"lightning distance\": [],\r\n                             \"wind direction\": [], \"wind speed\": [], \"gust speed\": [], \"ambient temperature\": [],\r\n                             \"relative humidity\": [], \"atmospheric pressure\": [],\r\n                             \"x axis level\": [], \"y axis level\": [], \"vpd\": []}\r\n                            '''\r\n                            # Check and only grab data from install date going forward\r\n                            # This is to avoid grabbing data from a logger that was moved to another field from the\r\n                            # previous field it was installed in\r\n                            try:\r\n                                if self.install_date <= datapoint_datetime.date():\r\n                                    converted_results[\"dates\"].append(datapoint_datetime)\r\n\r\n                                    if atmos_41_port is not None:\r\n                                        solar_radiation_value = data_point[atmos_41_port][sensor_data_indexes[\r\n                                            'solar radiation']]['value']\r\n                                        precipitation_value = data_point[atmos_41_port][sensor_data_indexes[\r\n                                            'precipitation']]['value']\r\n                                        lightning_activity_value = data_point[atmos_41_port][sensor_data_indexes[\r\n                                            'lightning activity']]['value']\r\n                                        lightning_distance_value = data_point[atmos_41_port][sensor_data_indexes[\r\n                                            'lightning distance']]['value']\r\n                                        wind_direction_value = data_point[atmos_41_port][sensor_data_indexes[\r\n                                            'wind direction']]['value']\r\n                                        wind_speed_value = data_point[atmos_41_port][sensor_data_indexes[\r\n                                            'wind speed']]['value']\r\n                                        gust_speed_value = data_point[atmos_41_port][sensor_data_indexes[\r\n                                            'gust speed']]['value']\r\n                                        ambient_temperature_value = data_point[atmos_41_port][sensor_data_indexes[\r\n                                            'air temperature']][\r\n                                            'value']\r\n                                        relative_humidity_value = data_point[atmos_41_port][sensor_data_indexes[\r\n                                            'relative humidity']][\r\n                                            'value']\r\n                                        atmospheric_pressure_value = data_point[atmos_41_port][sensor_data_indexes[\r\n                                            'atmospheric pressure']][\r\n                                            'value']\r\n                                        x_axis_level_value = data_point[atmos_41_port][sensor_data_indexes[\r\n                                            'x axis level']]['value']\r\n                                        y_axis_level_value = data_point[atmos_41_port][sensor_data_indexes[\r\n                                            'y axis level']]['value']\r\n                                        vpd_value = data_point[atmos_41_port][sensor_data_indexes['vpd']]['value']\r\n\r\n                                        if solar_radiation_value == 'None' or solar_radiation_value == '':\r\n                                            solar_radiation_value = None\r\n                                        if precipitation_value == 'None' or precipitation_value == '':\r\n                                            precipitation_value = None\r\n                                        if lightning_activity_value == 'None' or lightning_activity_value == '':\r\n                                            lightning_activity_value = None\r\n                                        if lightning_distance_value == 'None' or lightning_distance_value == '':\r\n                                            lightning_distance_value = None\r\n                                        if wind_direction_value == 'None' or wind_direction_value == '':\r\n                                            wind_direction_value = None\r\n                                        if wind_speed_value == 'None' or wind_speed_value == '':\r\n                                            wind_speed_value = None\r\n                                        if gust_speed_value == 'None' or gust_speed_value == '':\r\n                                            gust_speed_value = None\r\n                                        if ambient_temperature_value == 'None' or ambient_temperature_value == '':\r\n                                            ambient_temperature_value = None\r\n                                        if relative_humidity_value == 'None' or relative_humidity_value == '':\r\n                                            relative_humidity_value = None\r\n                                        if atmospheric_pressure_value == 'None' or atmospheric_pressure_value == '':\r\n                                            atmospheric_pressure_value = None\r\n                                        if x_axis_level_value == 'None' or x_axis_level_value == '':\r\n                                            x_axis_level_value = None\r\n                                        if y_axis_level_value == 'None' or y_axis_level_value == '':\r\n                                            y_axis_level_value = None\r\n                                        if vpd_value == 'None' or vpd_value == '':\r\n                                            vpd_value = None\r\n\r\n                                        converted_results[\"solar radiation\"].append(solar_radiation_value)\r\n                                        converted_results[\"precipitation\"].append(precipitation_value)\r\n                                        converted_results[\"lightning activity\"].append(lightning_activity_value)\r\n                                        converted_results[\"lightning distance\"].append(lightning_distance_value)\r\n                                        converted_results[\"wind direction\"].append(wind_direction_value)\r\n                                        converted_results[\"wind speed\"].append(wind_speed_value)\r\n                                        converted_results[\"gust speed\"].append(gust_speed_value)\r\n                                        converted_results[\"ambient temperature\"].append(ambient_temperature_value)\r\n                                        converted_results[\"relative humidity\"].append(relative_humidity_value)\r\n                                        converted_results[\"atmospheric pressure\"].append(atmospheric_pressure_value)\r\n                                        converted_results[\"x axis level\"].append(x_axis_level_value)\r\n                                        converted_results[\"y axis level\"].append(y_axis_level_value)\r\n                                        converted_results[\"vpd\"].append(vpd_value)\r\n                                    else:\r\n                                        converted_results[\"solar radiation\"].append(None)\r\n                                        converted_results[\"precipitation\"].append(None)\r\n                                        converted_results[\"lightning activity\"].append(None)\r\n                                        converted_results[\"lightning distance\"].append(None)\r\n                                        converted_results[\"wind direction\"].append(None)\r\n                                        converted_results[\"wind speed\"].append(None)\r\n                                        converted_results[\"gust speed\"].append(None)\r\n                                        converted_results[\"ambient temperature\"].append(None)\r\n                                        converted_results[\"relative humidity\"].append(None)\r\n                                        converted_results[\"atmospheric pressure\"].append(None)\r\n                                        converted_results[\"x axis level\"].append(None)\r\n                                        converted_results[\"y axis level\"].append(None)\r\n                                        converted_results[\"vpd\"].append(None)\r\n                            except Exception as e:\r\n                                print(f\"Error: {e}\")\r\n                                print()\r\n                        else:\r\n                            data_from_previous_years = True\r\n\r\n            if data_from_previous_years:\r\n                print(\"Ignored some data from previous years\")\r\n        return converted_results\r\n\r\n    def get_sensor_port_indexes(self, ports):\r\n        ir_port = None\r\n        vp4_port = None\r\n        vwc1_port = None\r\n        vwc2_port = None\r\n        vwc3_port = None\r\n        switch_port = None\r\n        vwc_ports = []\r\n        # Offset to account for Zentra data return having a timestamp in index 0, mrid in index 1,\r\n        # and 1 extra value in index 2. Actual sensors don't start until index 3. Using an offset of 2\r\n        # since the port data starts at 1 already, not from 0. So 1 + 2 = 3 as the first sensor data index.\r\n        data_index_offset = 2\r\n        for key in ports:\r\n            value = ports[key]\r\n            if ir_port is None and value == 'Infra Red':\r\n                ir_port = key + data_index_offset\r\n            elif vp4_port is None and value in ['VP4', 'Atmos 14']:\r\n                vp4_port = key + data_index_offset\r\n            elif value in ['GS1', 'GS3', 'Terros 10', 'Terros 12']:\r\n                vwc_ports.append(key)\r\n            elif switch_port is None and value == 'Switch':\r\n                switch_port = key + data_index_offset\r\n\r\n        # VWC ports grabbed after in a sorted list to ensure we assign them in the correct order. The first port with\r\n        # a VWC sensor will be vwc1_port, the second will be vwc2_port, and so on until we have 3 ports for VWCs\r\n        for key in sorted(vwc_ports):\r\n            if vwc1_port is None:\r\n                vwc1_port = key + data_index_offset\r\n            elif vwc2_port is None:\r\n                vwc2_port = key + data_index_offset\r\n            elif vwc3_port is None:\r\n                vwc3_port = key + data_index_offset\r\n\r\n        return data_index_offset, ir_port, vp4_port, vwc1_port, vwc2_port, vwc3_port, switch_port\r\n\r\n    def get_sensor_port_indexes_weather_stations(self, ports):\r\n        atmos_41_port = None\r\n        # Offset to account for Zentra data return having a timestamp in index 0, mrid in index 1,\r\n        # and 1 extra value in index 2. Actual sensors don't start until index 3. Using an offset of 2\r\n        # since the port data starts at 1 already, not from 0. So 1 + 2 = 3 as the first sensor data index.\r\n        data_index_offset = 2\r\n        for ind, key in enumerate(ports):\r\n            value = ports[key]\r\n            if atmos_41_port is None and value == 'Atmos 41':\r\n                # Can't use key as the value to designate the atmos_41_port because the API doesn't respect that.\r\n                # It uses the index to position the values, not the key for some stupid reason\r\n                # atmos_41_port = key + data_index_offset\r\n                atmos_41_port = ind + 1 + data_index_offset\r\n\r\n        return data_index_offset, atmos_41_port\r\n\r\n    def get_ports(self, time_series, dxd_save_location: str = DXD_DIRECTORY) -> dict:\r\n        \"\"\"\r\n        Read the dxd file and return information on what sensor is connected to each port.\r\n\r\n        :return:\r\n            Dictionary with the port and what sensor is connected to each port\r\n                {'number': value, ...}\r\n        \"\"\"\r\n        ports = {}\r\n        for sensor in time_series:\r\n            sensor_type = self.sensor_name(sensor[\"sensor_number\"])\r\n            # ports[sensor[\"port\"]] = sensor[\"sensor_number\"]\r\n            ports[sensor[\"port\"]] = sensor_type\r\n\r\n        return ports\r\n\r\n    def remove_duplicate_data(self, raw_data: dict, ports: dict) -> dict:\r\n        print('Looking for duplicates-')\r\n        duplicates = []\r\n        duplicate_dates = []\r\n        converted_results = {\"dates\": [], \"canopy temperature\": [], \"ambient temperature\": [], \"rh\": [], \"vpd\": [],\r\n                             \"vwc 8\": [], \"vwc 16\": [], \"vwc 24\": [], \"daily gallons\": [], \"daily switch\": []}\r\n        for ind, val in enumerate(raw_data[\"dates\"]):\r\n            # print('Checking' + str(val))\r\n            if val in converted_results[\"dates\"]:\r\n                duplicates.append(ind)\r\n                duplicate_dates.append(val)\r\n            else:\r\n                converted_results[\"dates\"].append(raw_data[\"dates\"][ind])\r\n                converted_results[\"canopy temperature\"].append(raw_data[\"canopy temperature\"][ind])\r\n                converted_results[\"ambient temperature\"].append(raw_data[\"ambient temperature\"][ind])\r\n                converted_results[\"rh\"].append(raw_data[\"rh\"][ind])\r\n                converted_results[\"vpd\"].append(raw_data[\"vpd\"][ind])\r\n                converted_results[\"vwc 8\"].append(raw_data[\"vwc 8\"][ind])\r\n                converted_results[\"vwc 16\"].append(raw_data[\"vwc 16\"][ind])\r\n                converted_results[\"vwc 24\"].append(raw_data[\"vwc 24\"][ind])\r\n                if self.switch_connected(ports):\r\n                    converted_results[\"daily switch\"].append(raw_data[\"daily switch\"][ind])\r\n\r\n        if duplicates:\r\n            print(\"-Duplicates found at:\")\r\n            print(duplicates)\r\n        else:\r\n            print(\"-No duplicates found\")\r\n        # print(duplicate_dates)        #To show duplicate dates\r\n        print()\r\n        return converted_results\r\n\r\n    def remove_duplicate_data_2(self, raw_data: dict):\r\n        duplicates = []\r\n        duplicate_dates = []\r\n\r\n        tally = defaultdict(list)\r\n        for i, item in enumerate(raw_data):\r\n            tally[item].append(i)\r\n        returned = ((key, locs) for key, locs in tally.items()\r\n                    if len(locs) > 1)\r\n\r\n        for dup in returned:\r\n            print(dup)\r\n            duplicate_dates.append(dup[-1][-1])\r\n        print(duplicate_dates)\r\n\r\n    def remove_out_of_order_data(self, raw_data: dict, ports: dict) -> dict:\r\n        print('Looking for out of order data-')\r\n        mark_for_removal = []\r\n        out_of_order = []\r\n        latest = raw_data[\"dates\"][0]\r\n        for ind, i in enumerate(raw_data[\"dates\"]):\r\n            if latest > i:\r\n                mark_for_removal.append(ind)\r\n                out_of_order.append(i)\r\n            else:\r\n                latest = i\r\n\r\n        if mark_for_removal:\r\n            print(\"-Out of order data found at:\")\r\n            print(mark_for_removal)\r\n            print(out_of_order)\r\n            print(\"--Removing out of order data\")\r\n\r\n            # Reversing the list that is marked for removal so that when we start removing those indeces we don't\r\n            # have issues with later indeces being changed from the deletion of earlier ones\r\n            mark_for_removal.reverse()\r\n            for ind in mark_for_removal:\r\n                del raw_data[\"dates\"][ind]\r\n                del raw_data[\"canopy temperature\"][ind]\r\n                del raw_data[\"ambient temperature\"][ind]\r\n                del raw_data[\"rh\"][ind]\r\n                del raw_data[\"vpd\"][ind]\r\n                del raw_data[\"vwc 8\"][ind]\r\n                del raw_data[\"vwc 16\"][ind]\r\n                del raw_data[\"vwc 24\"][ind]\r\n                if self.switch_connected(ports):\r\n                    del raw_data[\"daily switch\"][ind]\r\n\r\n            print(\"--Removed\")\r\n        else:\r\n            print(\"-No out of order data found\")\r\n        print()\r\n\r\n        return raw_data\r\n\r\n    def sensor_name(self, sensor: int) -> str:\r\n        \"\"\"\r\n        Function to return the sensor name given its numeric value.\r\n\r\n        Used for printing what sensor we are working on.\r\n        :param sensor: Number assigned to the type of sensor\r\n        :return:\r\n            String with the sensor name\r\n        \"\"\"\r\n        return {\r\n            64: 'Infra Red',\r\n            67: 'Infra Red',\r\n            68: 'Infra Red',\r\n            102: 'VP4',\r\n            123: 'Atmos 14',\r\n            241: 'GS1',\r\n            238: 'Terros 10',\r\n            119: 'GS3',\r\n            103: 'Terros 12',\r\n            180: 'Flow Meter',\r\n            183: 'Flow Meter',\r\n            220: 'Switch',\r\n            221: 'Switch',\r\n            133: 'Battery',\r\n            134: 'Logger',\r\n            93: 'Atmos 41'\r\n        }.get(sensor, 'Other')\r\n\r\n    ##########################################################\r\n    # Converts decagon date into standard date               #\r\n    ##########################################################\r\n    def convert_dates(self, raw_date):\r\n        \"\"\"\r\n        Function to convert decagon date into standard date.\r\n\r\n        :param raw_date:\r\n        :return:\r\n            datetime_val: datetime object with the converted date\r\n        \"\"\"\r\n\r\n        converted_date = time.gmtime(raw_date + 946684800)\r\n        datetime_val = datetime(*converted_date[:6])\r\n        return datetime_val\r\n\r\n    def convert_datetime_to_timestamp(self, raw_datetime):\r\n        return datetime.timestamp(raw_datetime)\r\n\r\n    def convert_last_download_time_to_datetime(self, raw_time):\r\n        return datetime.strptime(raw_time, '%Y-%m-%dT%H:%M:%SZ')\r\n\r\n    def convert_utc_timestamp_to_utc_datetime(self, raw_timestamp):\r\n        utc_dt = datetime.utcfromtimestamp(raw_timestamp)\r\n        return utc_dt\r\n\r\n    def convert_utc_datetime_to_local_datetime(self, utc_raw_time):\r\n        from_zone = tz.tzutc()\r\n        to_zone = tz.tzlocal()\r\n\r\n        utc = utc_raw_time.replace(tzinfo=from_zone)\r\n        pacific = utc.astimezone(to_zone)\r\n        return pacific\r\n\r\n    def convert_timestamp_to_local_datetime(self, timestamp):\r\n        time_start = self.convert_utc_timestamp_to_utc_datetime(timestamp)\r\n        time_local_start = self.convert_utc_datetime_to_local_datetime(time_start)\r\n        dt = time_local_start.replace(tzinfo=None)\r\n        return dt\r\n\r\n    def flow_meter_connected(self, raw_ports: dict) -> bool:\r\n        \"\"\"\r\n        Function to determine whether a Flow Meter is connected based on its sensor number.\r\n\r\n        :param raw_ports: Dictionary with the ports information for the logger. We want to check port 5 for\r\n            a flow meter\r\n        :return:\r\n            Boolean indicating if a flow meter is connected\r\n        \"\"\"\r\n\r\n        # 180 and 183 are the sensor numbers for flow meters\r\n        if 6 in raw_ports.keys():\r\n            if raw_ports[6] == 180 or raw_ports[6] == 183:\r\n                return True\r\n            else:\r\n                return False\r\n        else:\r\n            return False\r\n\r\n    def switch_connected(self, raw_ports: dict) -> bool:\r\n        \"\"\"\r\n        Function to determine whether a Pressure Switch is connected based on its sensor number.\r\n\r\n        :param raw_ports: Dictionary with the ports information for the logger. We want to check port 5 for\r\n            a pressure switch\r\n        :return:\r\n            Boolean indicating if a pressure switch is connected\r\n        \"\"\"\r\n\r\n        # 220 and 221 are the sensor numbers for pressure switches\r\n        if 6 in raw_ports.keys():\r\n            if raw_ports[6] == 'Switch':\r\n                return True\r\n            else:\r\n                return False\r\n        else:\r\n            return False\r\n\r\n    def vp4_connected(self, raw_ports: dict) -> bool:\r\n        \"\"\"\r\n        Function to determine whether a VP4 is connected based on its sensor number.\r\n\r\n        :param raw_ports: Dictionary with the ports information for the logger. We want to check port 2 for a VP4\r\n        :return:\r\n            Boolean indicating if a vp4 is connected\r\n        \"\"\"\r\n        ## Bandaid for Casey\r\n        if 2 not in raw_ports:\r\n            if raw_ports[3] == 102 or 123:\r\n                return True\r\n        if raw_ports[2] == 102 or 123:\r\n            return True\r\n        else:\r\n            return False\r\n\r\n    def delete_last_day(self, data: dict) -> dict:\r\n        \"\"\"\r\n        Function to delete the last row of data if it is from today.\r\n\r\n        We only want to write information from the previous day. If some information is in the DXD from today because\r\n            download is at midnight, that data needs to be deleted and not written into the GSheet.\r\n        Since we only care about data at the hottest time of the day, we won't lose any important data by doing this\r\n            deletion other than possibly losing gallons or switch minutes if irrigation was on at midnight.\r\n        In this case, we will simply subtract the gallons or minutes from the previous values in the logger so the next\r\n            time it check if the new value is higher it is artificially inflated with the gallons lost in the midnight data\r\n            deletion\r\n        :param data:\r\n        :return:\r\n        \"\"\"\r\n\r\n        print('\\tDelete Last Day')\r\n        todayRaw = date.today()\r\n        lastElement = len(data[\"dates\"]) - 1\r\n        if lastElement >= 0:\r\n            if data[\"dates\"][lastElement].date() == todayRaw:\r\n                print(\"\\tDeleting extra same day data\")\r\n                # try:\r\n                #     if self.switch_connected(self.ports):\r\n                #         print('Switch totals: ')\r\n                #         print(self.daily_switch)\r\n                #         if len(self.daily_switch) >= 1:\r\n                #             last_swi = self.daily_switch[-1]\r\n                #             del self.daily_switch[-1]\r\n                #         else:\r\n                #             last_swi = 0\r\n                #         print('Leftover switch total: ' + str(last_swi))\r\n                #\r\n                #         self.prev_day_switch = last_swi\r\n                # except Exception as error:\r\n                #     print('\\tSome error in delete_last_day - water part')\r\n                #     print(error)\r\n\r\n                try:\r\n                    for key in data.keys():\r\n                        if data[key]:\r\n                            del data[key][lastElement]\r\n                except Exception as error:\r\n                    print('\\tSome error in delete_last_day - results part Z6')\r\n                    print(error)\r\n        return data\r\n\r\n    def get_kc(self, data: dict) -> dict:\r\n        \"\"\"\r\n        Function to get the kc for a crop\r\n\r\n        :param data: Dictionary holding all the data that is still missing kc info\r\n        :return: data with kc information added\r\n        \"\"\"\r\n        self.crop_coefficient = CropCoefficient()\r\n        data['kc'] = []\r\n        for data_point in data[\"dates\"]:\r\n            kc = self.crop_coefficient.get_kc(\r\n                self.crop_type.lower(), data_point.date(),\r\n                planting_date=self.planting_date\r\n            )\r\n            if kc is None:\r\n                data['kc'].append(0)\r\n            else:\r\n                data['kc'].append(kc)\r\n\r\n        print()\r\n        print('\\tGot KC data:')\r\n        print('\\t', data['kc'])\r\n        print()\r\n        return data\r\n\r\n    def update_eto(self, latest_et: float):\r\n        print('   Updating eto for logger:' + str(self.id))\r\n        self.dbwriter = DBWriter()\r\n        yesterdayRaw = date.today() - timedelta(1)\r\n        yesterday = '{0}-{1}-{2}'.format(yesterdayRaw.year, yesterdayRaw.month, yesterdayRaw.day)\r\n        yesterday = \"'\" + yesterday + \"'\"\r\n        # print(yesterday)\r\n        # print(latest_et)\r\n        logger_name = self.name\r\n        field_name = self.field.name\r\n        field_name = self.dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n        project = self.dbwriter.get_db_project(self.crop_type)\r\n        dataset_id = project + '.' + field_name + '.' + logger_name\r\n        dataset_id = \"`\" + dataset_id + \"`\"\r\n        if latest_et == None:\r\n            latest_et = 0\r\n        dml_statement = \"UPDATE \" + str(dataset_id) + ' SET eto = ' + str(latest_et) + ' WHERE date = ' + yesterday \\\r\n            # '@yesterday'\r\n\r\n        self.dbwriter.run_dml(dml_statement, project=project)\r\n\r\n    def update_etc(self):\r\n        print('   Updating etc for logger:' + str(self.id))\r\n        self.dbwriter = DBWriter()\r\n        yesterdayRaw = date.today() - timedelta(1)\r\n        yesterday = '{0}-{1}-{2}'.format(yesterdayRaw.year, yesterdayRaw.month, yesterdayRaw.day)\r\n        yesterday = \"'\" + yesterday + \"'\"\r\n        logger_name = self.name\r\n        field_name = self.field.name\r\n        field_name = self.dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n        project = self.dbwriter.get_db_project(self.crop_type)\r\n        dataset_id = project + '.' + field_name + '.' + logger_name\r\n        dataset_id = \"`\" + dataset_id + \"`\"\r\n\r\n        # TODO check if kc is null\r\n        kc = self.get_kc_from_db()\r\n        if kc != None:\r\n            dml_statement = \"UPDATE \" + dataset_id + 'SET etc = eto * kc WHERE date = ' + yesterday\r\n            self.dbwriter.run_dml(dml_statement, project=project)\r\n        else:\r\n            print(\"       No kc, can't calculate ETc\")\r\n        return kc\r\n\r\n    def update_et_hours(self):\r\n        self.dbwriter = DBWriter()\r\n        yesterdayRaw = date.today() - timedelta(1)\r\n        yesterday = '{0}-{1}-{2}'.format(yesterdayRaw.year, yesterdayRaw.month, yesterdayRaw.day)\r\n        yesterday = \"'\" + yesterday + \"'\"\r\n        logger_name = self.name\r\n        field_name = self.field.name\r\n        field_name = self.dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n        project = self.dbwriter.get_db_project(self.crop_type)\r\n        dataset_id = project + '.' + field_name + '.' + logger_name\r\n        dataset_id = \"`\" + dataset_id + \"`\"\r\n        # etc_dml_statement = \"SELECT etc FROM \" + dataset_id + ' WHERE date = ' + yesterday\r\n        # etc_dml_statement = \"SELECT etc FROM \" + dataset_id + ' WHERE etc is not NULL ORDER BY date DESC LIMIT 1'\r\n        # print('Getting etc from DB')\r\n        # etc_response = self.dbwriter.run_dml(etc_dml_statement)\r\n        # for e in etc_response:\r\n        #     etc = e[\"etc\"]\r\n        #     print(etc)\r\n        if isinstance(self.irrigation_set_acres, str):\r\n            acres = float(self.irrigation_set_acres.replace(',', ''))\r\n        elif isinstance(self.irrigation_set_acres, int):\r\n            acres = float(self.irrigation_set_acres)\r\n        elif isinstance(self.irrigation_set_acres, float):\r\n            acres = self.irrigation_set_acres\r\n        else:\r\n            acres = 0\r\n        if isinstance(self.gpm, str):\r\n            gpm = float(self.gpm.replace(',', ''))\r\n        elif isinstance(self.gpm, int):\r\n            gpm = float(self.gpm)\r\n        elif isinstance(self.gpm, float):\r\n            gpm = self.gpm\r\n        else:\r\n            gpm = 0\r\n\r\n        if gpm != 0:\r\n            et_hours_pending_etc_mult = ((449 * acres) / (gpm * 0.85))\r\n\r\n            print(\"Updating et_hours data for table: \" + dataset_id)\r\n\r\n            dml_statement = \"UPDATE \" + dataset_id + \" SET et_hours = ROUND(\" \\\r\n                            + str(et_hours_pending_etc_mult) + \" * etc) \" \\\r\n                            + \" WHERE date = \" + yesterday\r\n\r\n            self.dbwriter.run_dml(dml_statement, project=project)\r\n        else:\r\n            print('   GPM is 0')\r\n\r\n    def get_kc_from_db(self) -> float:\r\n        print('   Checking kc for logger:' + str(self.id))\r\n        self.dbwriter = DBWriter()\r\n        yesterdayRaw = date.today() - timedelta(1)\r\n        yesterday = '{0}-{1}-{2}'.format(yesterdayRaw.year, yesterdayRaw.month, yesterdayRaw.day)\r\n        yesterday = \"'\" + yesterday + \"'\"\r\n        logger_name = self.name\r\n        field_name = self.field.name\r\n        field_name = self.dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n        project = self.dbwriter.get_db_project(self.crop_type)\r\n        dataset_id = project + '.' + field_name + '.' + logger_name\r\n        dataset_id = \"`\" + dataset_id + \"`\"\r\n\r\n        dml_statement = \"SELECT kc FROM \" + dataset_id + ' WHERE date = ' + yesterday\r\n        kc_response = self.dbwriter.run_dml(dml_statement, project=project)\r\n        kc = 0\r\n        for e in kc_response:\r\n            # print(e[\"eto\"])\r\n            kc = e[\"kc\"]\r\n        print('   Got KC = ' + str(kc))\r\n        print()\r\n        return kc\r\n\r\n    def merge_et_db_with_logger_db_values(self):\r\n        self.dbwriter = DBWriter()\r\n        logger_name = self.name\r\n        field_name = self.field.name\r\n        field_name = self.dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n        project = self.dbwriter.get_db_project(self.crop_type)\r\n        dataset_id = project + '.' + field_name + '.' + logger_name\r\n        dataset_id = \"`\" + dataset_id + \"`\"\r\n        et_id = \"stomato-info.ET.\" + str(self.field.cimis_station)\r\n        et_id = \"`\" + et_id + \"`\"\r\n\r\n        acres = self.irrigation_set_acres\r\n        gpm = self.gpm\r\n\r\n        if gpm != 0:\r\n            et_hours_pending_etc_mult = ((449 * acres) / (gpm * 0.85))\r\n\r\n            print(\"\\t\\tUpdating all et data for table: \" + dataset_id)\r\n\r\n            dml_statement = \"MERGE \" + dataset_id + \" T \" \\\r\n                            + \"USING \" + et_id + \" S \" \\\r\n                            + \"ON (T.date = S.date AND T.eto IS NULL)  \" \\\r\n                            + \"WHEN MATCHED THEN \" \\\r\n                            + \"UPDATE SET eto = s.eto, etc = s.eto * t.kc, et_hours = ROUND(\" + str(\r\n                et_hours_pending_etc_mult) + \" * s.eto * t.kc)\"\r\n        else:\r\n            print('   GPM is 0')\r\n            dml_statement = \"MERGE \" + dataset_id + \" T \" \\\r\n                            + \"USING \" + et_id + \" S \" \\\r\n                            + \"ON (T.date = S.date AND T.eto IS NULL)  \" \\\r\n                            + \"WHEN MATCHED THEN \" \\\r\n                            + \"UPDATE SET eto = s.eto, etc = s.eto * t.kc \"\r\n        self.dbwriter.run_dml(dml_statement, project=project)\r\n\r\n    def grab_portal_data(self, data: dict) -> dict:\r\n        \"\"\"\r\n        Function to grab just the last day of data from the dictionary data\r\n         and assign it to a new dictionary called portal_data_dict and return that\r\n\r\n        :param data: dict (str, list)\r\n        :return portal_data_dict: dict (str, value)\r\n        \"\"\"\r\n        data_keys = list(data.keys())\r\n        portal_data_dict = dict.fromkeys(data_keys)\r\n        for key in data_keys:\r\n            if len(data[key]) > 0:\r\n                portal_data_dict[key] = data[key][-1]\r\n        return portal_data_dict\r\n\r\n    def check_for_notifications_final_results(self, final_results_converted: dict, warnings: bool = True,\r\n                                              errors: bool = True):\r\n        \"\"\"\r\n        Function to check the daily values after conversion and processing to see if any of the numbers are\r\n        outside of the thresholds\r\n\r\n        :param errors:\r\n        :param warnings:\r\n        :param field_name:\r\n        :param final_results_converted: Dictionary holding the values for the previous day\r\n            final_results_converted = {\"dates\": [], \"canopy temperature\": [], \"ambient temperature\": [], \"relative_humidity\": [],\r\n            \"vpd\": [], \"vwc 18\": [], \"vwc 36\": [], \"sdd\": [], \"cwsi\": [], \"daily gallons\": [], \"daily switch\": []}\r\n        :return:\r\n        \"\"\"\r\n        technician = self.field.grower.technician\r\n        field_name = self.field.name\r\n\r\n        thresholds = Thresholds()\r\n\r\n        if path.exists(DXD_DIRECTORY):\r\n            file_name = DXD_DIRECTORY + self.id + '.dxd'\r\n\r\n        battery_level = self.read_battery_level(file_name)\r\n\r\n        if errors:\r\n            if battery_level < thresholds.battery_threshold and battery_level is not None:\r\n                technician.all_notifications.add_notification(\r\n                    Notification_SensorError(\r\n                        datetime.now(),\r\n                        field_name,\r\n                        self,\r\n                        \"Battery\",\r\n                        \"Battery Level of: \" + str(battery_level) + \" is less than \" + str(thresholds.battery_threshold)\r\n                    )\r\n                )\r\n\r\n        if final_results_converted[\"dates\"]:\r\n            for ind, date in enumerate(final_results_converted[\"dates\"]):\r\n                cwsi = final_results_converted[\"cwsi\"][ind]\r\n                vwc_1 = final_results_converted[\"vwc_1\"][ind]\r\n                vwc_2 = final_results_converted[\"vwc_2\"][ind]\r\n                vwc_3 = final_results_converted[\"vwc_3\"][ind]\r\n                sdd = final_results_converted[\"sdd\"][ind]\r\n                air_temperature = final_results_converted[\"ambient temperature\"][ind]\r\n                # TODO Check lowest temperature values\r\n                canopy_temperature = final_results_converted[\"canopy temperature\"][ind]\r\n                relative_humidity = final_results_converted[\"rh\"][ind]\r\n                vpd = final_results_converted[\"vpd\"][ind]\r\n\r\n                if self.field.field_type != 'R&D':\r\n\r\n                    self.vp4_notifications(field_name, date, air_temperature, relative_humidity, vpd, technician,\r\n                                           thresholds, warnings=warnings, errors=errors)\r\n\r\n                    if self.ir_active:\r\n                        self.canopy_temperature_notifications(field_name, date, canopy_temperature, technician,\r\n                                                              thresholds, warnings=warnings, errors=errors)\r\n\r\n                        self.psi_notifications(field_name, date, cwsi, technician, thresholds, warnings=warnings,\r\n                                               errors=errors)\r\n                    else:\r\n                        self.psi_not_active_notification(field_name, date, technician, warnings=warnings, errors=errors)\r\n\r\n                    self.vwc_notifications(field_name, self.soil, date, vwc_1, vwc_2, vwc_3, technician, thresholds,\r\n                                           warnings=warnings, errors=errors)\r\n\r\n    def check_for_notifications_all_data(self, all_data: dict):\r\n        \"\"\"\r\n        Function to check the daily values after conversion and before processing to see if any of the numbers are\r\n        None for the whole day. If they are, create a notification for the sensor\r\n\r\n        :param all_data: Dictionary holding the values for all data from the API call for all hours\r\n        \"\"\"\r\n        technician = self.field.grower.technician\r\n\r\n        canopy_temperature_issue = False\r\n        vp4_issue = False\r\n        vwc_1_issue = False\r\n        vwc_2_issue = False\r\n        vwc_3_issue = False\r\n\r\n        # Check if logger is sending data\r\n        required_data_points = 2\r\n        if len(all_data['dates']) < required_data_points:\r\n            if all_data['dates']:\r\n                dates_date = all_data['dates'][-1]\r\n            else:\r\n                dates_date = datetime.now() - timedelta(days=1)\r\n            technician.all_notifications.add_notification(\r\n                Notification_SensorError(\r\n                    dates_date,\r\n                    self.field.name,\r\n                    self,\r\n                    \"Z6 Logger\",\r\n                    \"We did not get any data for this logger. Signal issue? Connection issue? Got hit by a tractor issue?\"\r\n                )\r\n            )\r\n\r\n        # Loop through all values and check for None values\r\n        for ind, dp in enumerate(all_data['dates']):\r\n            if all_data['canopy temperature'][ind] is None:\r\n                canopy_temperature_issue = True\r\n                canopy_temperature_date = dp\r\n            if (all_data['ambient temperature'][ind] is None or\r\n                    all_data['rh'][ind] is None or\r\n                    all_data['vpd'][ind] is None):\r\n                vp4_issue = True\r\n                vp4_date = dp\r\n            if all_data['vwc_1'][ind] is None:\r\n                vwc_1_issue = True\r\n                vwc_1_date = dp\r\n            if all_data['vwc_2'][ind] is None:\r\n                vwc_2_issue = True\r\n                vwc_2_date = dp\r\n            if all_data['vwc_3'][ind] is None:\r\n                vwc_3_issue = True\r\n                vwc_3_date = dp\r\n\r\n        # Canopy Temp\r\n        if canopy_temperature_issue:\r\n            technician.all_notifications.add_notification(\r\n                Notification_SensorError(\r\n                    canopy_temperature_date,\r\n                    self.field.name,\r\n                    self,\r\n                    \"Canopy Temp\",\r\n                    \"Canopy Temp is showing None at some point in the day (Not necessarily at the hottest time). Connection issue?\"\r\n                )\r\n            )\r\n\r\n        # VP4\r\n        if vp4_issue:\r\n            technician.all_notifications.add_notification(\r\n                Notification_SensorError(\r\n                    vp4_date,\r\n                    self.field.name,\r\n                    self,\r\n                    \"VP4\",\r\n                    \"VP4 is showing None at some point in the day (Not necessarily at the hottest time). Connection issue?\"\r\n                )\r\n            )\r\n\r\n        # VWC_1\r\n        if vwc_1_issue:\r\n            technician.all_notifications.add_notification(\r\n                Notification_SensorError(\r\n                    vwc_1_date,\r\n                    self.field.name,\r\n                    self,\r\n                    \"VWC_1\",\r\n                    \"VWC_1 is showing None at some point in the day (Not necessarily at the hottest time). Connection issue?\"\r\n                )\r\n            )\r\n\r\n        # VWC_2\r\n        if vwc_2_issue:\r\n            technician.all_notifications.add_notification(\r\n                Notification_SensorError(\r\n                    vwc_2_date,\r\n                    self.field.name,\r\n                    self,\r\n                    \"VWC_2\",\r\n                    \"VWC_2 is showing None at some point in the day (Not necessarily at the hottest time). Connection issue?\"\r\n                )\r\n            )\r\n\r\n        # VWC_3\r\n        if vwc_3_issue:\r\n            technician.all_notifications.add_notification(\r\n                Notification_SensorError(\r\n                    vwc_3_date,\r\n                    self.field.name,\r\n                    self,\r\n                    \"VWC_3\",\r\n                    \"VWC_3 is showing None at some point in the day (Not necessarily at the hottest time). Connection issue?\"\r\n                )\r\n            )\r\n\r\n    def vwc_notifications(\r\n            self,\r\n            field_name: str,\r\n            soil,\r\n            date: datetime,\r\n            vwc_1: float,\r\n            vwc_2: float,\r\n            vwc_3: float,\r\n            technician: Technician,\r\n            thresholds: Thresholds,\r\n            warnings: bool = True,\r\n            errors: bool = True\r\n    ):\r\n        if vwc_1 is not None:\r\n            if vwc_1 < thresholds.error_vwc_lower or vwc_1 > thresholds.error_vwc_upper:\r\n                if errors:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_SensorError(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VWC_1\",\r\n                            f\"VWC_1 is out of reasonable bounds: {vwc_1}. Connection issue?\"\r\n                        )\r\n                    )\r\n            elif vwc_1 < soil.very_low_upper:\r\n                if warnings:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_TechnicianWarning(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VWC_1\",\r\n                            f\"!!!! VWC_1 in VERY LOW levels: {str(round(vwc_1, 1))} < {str(soil.very_low_upper)} for soil type: {soil.soil_type}\"\r\n                        )\r\n                    )\r\n            elif vwc_1 < soil.low_upper:\r\n                if warnings:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_TechnicianWarning(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VWC_1\",\r\n                            f\"!! VWC_1 in LOW levels: {str(round(vwc_1, 1))} < {str(soil.low_upper)} for soil type: {soil.soil_type}\"\r\n                        )\r\n                    )\r\n            elif vwc_1 > soil.very_high_lower:\r\n                if warnings:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_TechnicianWarning(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VWC_1\",\r\n                            f\"!!!! VWC_1 in VERY HIGH levels: {str(round(vwc_1, 1))} > {str(soil.very_high_lower)} for soil type: {soil.soil_type}\"\r\n                        )\r\n                    )\r\n\r\n        if vwc_2 is not None:\r\n            if vwc_2 < thresholds.error_vwc_lower or vwc_2 > thresholds.error_vwc_upper:\r\n                if errors:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_SensorError(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VWC_2\",\r\n                            f\"VWC_2 is out of reasonable bounds: {vwc_2}. Connection issue?\"\r\n                        )\r\n                    )\r\n            elif vwc_2 < soil.very_low_upper:\r\n                if warnings:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_TechnicianWarning(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VWC_2\",\r\n                            f\"!!!! VWC_2 in VERY LOW levels: {str(round(vwc_2, 1))} < {str(soil.very_low_upper)} for soil type: {soil.soil_type}\"\r\n                        )\r\n                    )\r\n            elif vwc_2 < soil.low_upper:\r\n                if warnings:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_TechnicianWarning(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VWC_2\",\r\n                            f\"!! VWC_2 in LOW levels: {str(round(vwc_2, 1))} < {str(soil.low_upper)} for soil type: {soil.soil_type}\"\r\n                        )\r\n                    )\r\n            elif vwc_2 > soil.very_high_lower:\r\n                if warnings:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_TechnicianWarning(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VWC_2\",\r\n                            f\"!!!! VWC_2 in VERY HIGH levels: {str(round(vwc_2, 1))} > {str(soil.very_high_lower)} for soil type: {soil.soil_type}\"\r\n                        )\r\n                    )\r\n\r\n        if vwc_3 is not None:\r\n            if vwc_3 < thresholds.error_vwc_lower or vwc_3 > thresholds.error_vwc_upper:\r\n                if errors:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_SensorError(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VWC_3\",\r\n                            f\"VWC_3 is out of reasonable bounds: {vwc_3}. Connection issue?\"\r\n                        )\r\n                    )\r\n            elif vwc_3 < soil.very_low_upper:\r\n                if warnings:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_TechnicianWarning(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VWC_3\",\r\n                            f\"!!!! VWC_3 in VERY LOW levels: {str(round(vwc_3, 1))} < {str(soil.very_low_upper)} for soil type: {soil.soil_type}\"\r\n                        )\r\n                    )\r\n            elif vwc_3 < soil.low_upper:\r\n                if warnings:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_TechnicianWarning(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VWC_3\",\r\n                            f\"!! VWC_3 in LOW levels: {str(round(vwc_3, 1))} < {str(soil.low_upper)} for soil type: {soil.soil_type}\"\r\n                        )\r\n                    )\r\n            elif vwc_3 > soil.very_high_lower:\r\n                if warnings:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_TechnicianWarning(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VWC_3\",\r\n                            f\"!!!! VWC_3 in VERY HIGH levels: {str(round(vwc_3, 1))} > {str(soil.very_high_lower)} for soil type: {soil.soil_type}\"\r\n                        )\r\n                    )\r\n\r\n    def vp4_notifications(\r\n            self,\r\n            field_name: str,\r\n            date: datetime,\r\n            air_temp: float,\r\n            relative_humidity: float,\r\n            vpd: float,\r\n            technician: Technician,\r\n            thresholds: Thresholds,\r\n            warnings: bool = True,\r\n            errors: bool = True\r\n    ):\r\n        # VP4 NOTIFICATIONS ----\r\n        if errors:\r\n            # COMMENTING THIS OUT FOR NOW SINCE WE CHECK FOR NONES IN ALL VALUES BEFORE THIS AND THIS WAS CAUSING\r\n            # DUPLICATE NOTIFICATIONS\r\n            # Check for None values\r\n            # vp4_values = [air_temp, relative_humidity, vpd]\r\n            # vp4_error = False\r\n            # if any(value is None or value == 'None' for value in vp4_values):\r\n            #     vp4_error = True\r\n            #     technician.all_notifications.add_notification(\r\n            #         Notification_SensorError(\r\n            #             date,\r\n            #             field_name,\r\n            #             self,\r\n            #             \"VP4\",\r\n            #             \"VP4 is showing None. Connection issue?\"\r\n            #         )\r\n            #     )\r\n\r\n            # If we didn't get a None on the VP4 values, check for threshold errors\r\n            # if not vp4_error:\r\n            if air_temp is not None:\r\n                if air_temp < thresholds.error_temp_lower:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_SensorError(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VP4\",\r\n                            f\"Air Temp of: {str(air_temp)} is < {str(thresholds.error_temp_lower)}\"\r\n                        )\r\n                    )\r\n                elif air_temp > thresholds.error_temp_upper:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_SensorError(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VP4\",\r\n                            f\"Air Temp of: {str(air_temp)} is > {str(thresholds.error_temp_upper)}\"\r\n                        )\r\n                    )\r\n\r\n            if relative_humidity is not None:\r\n                if relative_humidity < thresholds.error_rh_lower:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_SensorError(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VP4\",\r\n                            f\"Relative Humidity of: {str(relative_humidity)} is < {str(thresholds.error_rh_lower)}\"\r\n                        )\r\n                    )\r\n                elif relative_humidity > thresholds.error_rh_upper:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_SensorError(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VP4\",\r\n                            f\"Relative Humidity of: {str(relative_humidity)} is > {str(thresholds.error_rh_upper)}\"\r\n                        )\r\n                    )\r\n\r\n            if vpd is not None:\r\n                if vpd < thresholds.error_vpd_lower:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_SensorError(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VP4\",\r\n                            f\"VPD of: {str(vpd)} is < {str(thresholds.error_vpd_lower)}\"\r\n                        )\r\n                    )\r\n                elif vpd > thresholds.error_vpd_upper:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_SensorError(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"VP4\",\r\n                            f\"VPD of: {str(vpd)} is > {str(thresholds.error_vpd_upper)}\"\r\n                        )\r\n                    )\r\n\r\n    def canopy_temperature_notifications(\r\n            self,\r\n            field_name: str,\r\n            date: datetime,\r\n            canopy_temp: float,\r\n            technician: Technician,\r\n            thresholds: Thresholds,\r\n            warnings: bool = True,\r\n            errors: bool = True\r\n    ):\r\n        if errors:\r\n            if canopy_temp is None:\r\n                # Not reporting this anymore since its caught by the Notification checks in for All Data, not just\r\n                # hottest time of day\r\n                # technician.all_notifications.add_notification(\r\n                #     Notification_SensorError(\r\n                #         date,\r\n                #         field_name,\r\n                #         self,\r\n                #         \"Canopy Temp\",\r\n                #         \"Canopy Temp is showing None. Connection issue?\"\r\n                #     )\r\n                # )\r\n                pass\r\n            elif canopy_temp < thresholds.error_temp_lower:\r\n                technician.all_notifications.add_notification(\r\n                    Notification_SensorError(\r\n                        date,\r\n                        field_name,\r\n                        self,\r\n                        \"Canopy Temp\",\r\n                        f\"Canopy Temp of: {str(canopy_temp)} is < {str(thresholds.error_temp_lower)}\"\r\n                    )\r\n                )\r\n            elif canopy_temp > thresholds.error_temp_upper:\r\n                technician.all_notifications.add_notification(\r\n                    Notification_SensorError(\r\n                        date,\r\n                        field_name,\r\n                        self,\r\n                        \"Canopy Temp\",\r\n                        f\"Canopy Temp of: {str(canopy_temp)} is > {str(thresholds.error_temp_upper)}\"\r\n                    )\r\n                )\r\n\r\n    def psi_notifications(\r\n            self,\r\n            field_name: str,\r\n            date: datetime,\r\n            psi: float,\r\n            technician: Technician,\r\n            thresholds: Thresholds,\r\n            warnings: bool = True,\r\n            errors: bool = True\r\n    ):\r\n        if psi is None:\r\n            # Not reporting this anymore since its caught by the Notification checks in for All Data, not just\r\n            # hottest time of day\r\n            # if errors:\r\n            #     technician.all_notifications.add_notification(\r\n            #         Notification_SensorError(\r\n            #             date,\r\n            #             field_name,\r\n            #             self,\r\n            #             \"PSI\",\r\n            #             \"PSI is showing None. Connection issue?\"\r\n            #         )\r\n            #     )\r\n            pass\r\n        elif self.field.crop_type in ['Tomatoes', 'Tomato', 'tomatoes', 'tomato']:\r\n            # Tomato PSI Notifications\r\n            if warnings:\r\n                if psi > thresholds.tomato_psi_danger:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_TechnicianWarning(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"PSI\",\r\n                            f\"!!!! PSI in CRITICAL HIGH levels: {str(round(psi, 1))} > {str(thresholds.tomato_psi_danger)}\"\r\n                        )\r\n                    )\r\n        else:\r\n            # Permanent Crop PSI Notifications\r\n            if warnings:\r\n                if psi > thresholds.permanent_psi_danger:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_TechnicianWarning(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"PSI\",\r\n                            f\"!!!! PSI in CRITICAL HIGH levels: {str(round(psi, 1))} > {str(thresholds.permanent_psi_danger)}\"\r\n                        )\r\n                    )\r\n\r\n    def psi_not_active_notification(\r\n            self,\r\n            field_name: str,\r\n            date: datetime,\r\n            technician: Technician,\r\n            warnings: bool = True,\r\n            errors: bool = True\r\n    ):\r\n        if errors:\r\n            if self.field.crop_type in ['Tomatoes', 'Tomato', 'tomatoes', 'tomato']:\r\n                # Tomato PSI Notifications\r\n                planting_date_plus_70 = self.planting_date + timedelta(days=70)\r\n                formatted_consecutive_psi = [round(tup[0], 2) for tup in self.consecutive_ir_values]\r\n                formatted_consecutive_sdd = [round(tup[1], 2) for tup in self.consecutive_ir_values]\r\n                if date.date() >= planting_date_plus_70:\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_SensorError(\r\n                            date,\r\n                            field_name,\r\n                            self,\r\n                            \"PSI\",\r\n                            f\"It's been more than 70 days from planting date and IR is not active. Date: {date.date()} >= Planting + 70: {planting_date_plus_70}. Should it be on? The last 3 psi values were: {formatted_consecutive_psi}. Last 3 sdd values were: {formatted_consecutive_sdd}\"\r\n                        )\r\n                    )\r\n            else:\r\n                # Permanent Crop PSI Notifications\r\n                pass\r\n\r\n    def update(\r\n            self,\r\n            cimis_stations_pickle,\r\n            write_to_db: bool = False,\r\n            check_for_notifications: bool = False,\r\n            specific_mrid: int = None,\r\n            subtract_from_mrid: int = 0,\r\n            check_updated: bool = False\r\n    ) -> dict:\r\n        \"\"\"\r\n        Function to update the information from each Logger\r\n\r\n        :param write_to_db:\r\n        :param check_for_notifications:\r\n        :param specific_mrid:\r\n        :param subtract_from_mrid:\r\n        :param check_updated:\r\n        :param subtract_from_mrid: Int used to subtract a specific amount from the logger MRIDs for API calls\r\n        :return:\r\n        \"\"\"\r\n        if self.active:\r\n            try:\r\n                portal_data = None\r\n                if self.updated:\r\n                    print('\\tLogger: ' + self.id + '  already updated. Skipping...')\r\n                    return portal_data\r\n                else:\r\n                    print(\r\n                        '========================================================================================================================'\r\n                    )\r\n                    print('LOGGER updating: ')\r\n                    self.to_string()\r\n                    print(\r\n                        '------------------------------------------------------------------------------------------------------------------------'\r\n                    )\r\n                    # Download dxd files from Decaon API\r\n                    print()\r\n                    print('Downloading Data into DXD files-')\r\n                    response_success = self.get_logger_data(\r\n                        specific_mrid=specific_mrid,\r\n                        subtract_from_mrid=subtract_from_mrid\r\n                    )\r\n                    # print('-METER API Quota Delay')\r\n                    # time.sleep(20)\r\n                    print('-Finished')\r\n                    print()\r\n\r\n                    # Read data in dxd files\r\n                    if response_success:\r\n                        print('Reading data-')\r\n                        raw_dxd = self.read_dxd()\r\n                        raw_data = self.get_all_ports_information(raw_dxd)\r\n                        print('-Finished')\r\n                        print()\r\n                        converted_raw_data = raw_data  # NO DUPLICATE REMOVAL\r\n                        # converted_raw_data = self.remove_duplicate_data(raw_data)         #DUPLICATE REMOVAL\r\n                        # self.remove_duplicate_data_2(raw_data)\r\n                        # Testing removal of duplicate data algorithm\r\n                        # converted_raw_data = self.remove_out_of_order_data(converted_raw_data)          #OUT OF ORDER DATA REMOVAL\r\n\r\n                        if check_for_notifications:\r\n                            # Check for notifications\r\n                            try:\r\n                                print('Checking for notifications on all data-')\r\n                                self.check_for_notifications_all_data(converted_raw_data)\r\n                                print('\\t-Finished')\r\n                            except Exception as e:\r\n                                print(\"Error in Logger check_for_notifications_all_data - \" + self.name)\r\n                                print(\"Error type: \" + str(e))\r\n\r\n                        # Process data\r\n                        print('Processing data-')\r\n                        print()\r\n                        print('\\tAll Results Converted -> Before Processing: ')\r\n                        for key, values in converted_raw_data.items():\r\n                            print('\\t', key, \" : \", values)\r\n                            if len(values) > 5:\r\n                                print()\r\n\r\n                        # Update irrigation ledger\r\n                        print('\\tCleaning irrigation ledger')\r\n                        self.cwsi_processor.clean_irrigation_ledger(self.irrigation_ledger)\r\n\r\n                        print('\\tUpdating irrigation ledger')\r\n                        self.cwsi_processor.update_irrigation_ledger(converted_raw_data, self.irrigation_ledger)\r\n                        print('\\t Ledger after update:')\r\n                        self.show_irrigation_ledger()\r\n                        print('\\t ...done')\r\n                        print()\r\n\r\n                        print('\\tGetting hottest and coldest temperatures')\r\n                        highest_temp_values_ind, lowest_temp_values_ind, _ = \\\r\n                            self.cwsi_processor.get_highest_and_lowest_temperature_indexes(converted_raw_data)\r\n\r\n                        print('\\tFinal Results processing')\r\n                        final_results_converted = self.cwsi_processor.final_results(\r\n                            converted_raw_data, highest_temp_values_ind, lowest_temp_values_ind, self\r\n                        )\r\n\r\n                        print('\\tLedger after final results:')\r\n                        self.show_irrigation_ledger()\r\n\r\n                        print()\r\n                        print(\"\\tFinal Results Converted -> After Processing:\")\r\n                        for key, values in final_results_converted.items():\r\n                            print('\\t', key, \" : \", values)\r\n                            if len(values) > 5:\r\n                                print()\r\n\r\n                        # Check irrigation_ledger for delayed completed ledger date switch lists and update db\r\n                        self.check_and_update_delayed_ledger_filled_lists()\r\n                        print()\r\n                        print('\\tLedger after delayed update:')\r\n                        self.show_irrigation_ledger()\r\n\r\n                        # Getting kc\r\n                        final_results_converted = self.get_kc(final_results_converted)\r\n\r\n                        # Get ET data\r\n                        final_results_converted = self.get_et(final_results_converted, cimis_stations_pickle)\r\n\r\n                        # Delete last row of data if it is from today\r\n                        final_results_converted = self.delete_last_day(final_results_converted)\r\n\r\n                        if self.crop_type.lower() == 'tomatoes' or self.crop_type.lower() == 'tomato':\r\n                            final_results_converted = self.calculate_total_gdd_and_crop_stage(final_results_converted)\r\n                        print('-Finished')\r\n                        print()\r\n\r\n                        # PLUG IN AI ENGINE THROUGH CWSI PROCESSOR\r\n                        # final_results_converted = self.cwsi_processor.irrigation_ai_processing(final_results_converted, self)\r\n\r\n                        print()\r\n                        print('\\tFinal Results before DB write-')\r\n                        for key, values in final_results_converted.items():\r\n                            print('\\t', key, \" : \", values)\r\n                            if len(values) > 5:\r\n                                print()\r\n\r\n                        # Grab only last day data for portal\r\n                        print()\r\n                        print('\\tGrab Portal Data:')\r\n                        portal_data = self.grab_portal_data(final_results_converted)\r\n                        print('\\t-Finished')\r\n\r\n                        if check_for_notifications:\r\n                            # Check for notifications\r\n                            try:\r\n                                print()\r\n                                print('\\tChecking for Notifications on final results')\r\n                                self.check_for_notifications_final_results(final_results_converted, warnings=False)\r\n                                print('\\t-Finished')\r\n                            except Exception as e:\r\n                                print(\"Error in Logger check_for_notifications_final_results - \" + self.name)\r\n                                print(\"Error type: \" + str(e))\r\n\r\n                        # Write data to DB\r\n                        if write_to_db:\r\n                            # self.dbwriter = DBWriter()\r\n                            # self.dbwriter.create_dataset(self.grower.name + '_' + self.field.name)\r\n\r\n                            # the database writes for logger\r\n                            try:\r\n                                if final_results_converted[\"dates\"]:\r\n                                    print()\r\n                                    print('\\tWriting to DB-')\r\n                                    # Get project, dataset and table names\r\n                                    project = self.dbwriter.get_db_project(self.crop_type)\r\n                                    dataset_id = self.field.name\r\n                                    table_id = self.name\r\n\r\n                                    schema = [\r\n                                        bigquery.SchemaField(\"logger_id\", \"STRING\"),\r\n                                        bigquery.SchemaField(\"date\", \"DATE\"),\r\n                                        bigquery.SchemaField(\"time\", \"STRING\"),\r\n                                        bigquery.SchemaField(\"canopy_temperature\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"canopy_temperature_celsius\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"ambient_temperature\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"ambient_temperature_celsius\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"vpd\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"vwc_1\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"vwc_2\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"vwc_3\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"field_capacity\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"wilting_point\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"daily_gallons\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"daily_switch\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"daily_hours\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"daily_pressure\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"daily_inches\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"psi\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"psi_threshold\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"psi_critical\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"sdd\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"sdd_celsius\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"rh\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"eto\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"kc\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"etc\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"et_hours\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"phase1_adjustment\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"phase1_adjusted\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"phase2_adjustment\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"phase2_adjusted\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"phase3_adjustment\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"phase3_adjusted\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"vwc_1_ec\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"vwc_2_ec\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"vwc_3_ec\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"lowest_ambient_temperature\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"lowest_ambient_temperature_celsius\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"gdd\", \"FLOAT\"),\r\n                                        bigquery.SchemaField(\"crop_stage\", \"STRING\"),\r\n                                        bigquery.SchemaField(\"id\", \"STRING\"),\r\n                                        bigquery.SchemaField(\"planting_date\", \"DATE\"),\r\n                                        bigquery.SchemaField(\"variety\", \"STRING\"),\r\n                                    ]\r\n\r\n                                    # Check if the data we have is new or already exists in the DB\r\n                                    db_dates = self.dbwriter.grab_specific_column_table_data(\r\n                                        dataset_id,\r\n                                        table_id,\r\n                                        project,\r\n                                        'date'\r\n                                    )\r\n                                    if db_dates is not None:\r\n                                        db_dates_list = [row[0] for row in db_dates]\r\n                                    else:\r\n                                        db_dates_list = []\r\n\r\n                                    # Prepping data to be written\r\n                                    self.cwsi_processor.prep_data_for_writting_db(final_results_converted, self, db_dates_list)\r\n\r\n                                    self.dbwriter.write_to_table_from_csv(\r\n                                        dataset_id, table_id, 'data.csv', schema, project\r\n                                    )\r\n                                    print('\\t-Finished')\r\n\r\n                                else:\r\n                                    print('\\tNothing new to write to DB')\r\n                            except Exception as e:\r\n                                print(\"\\tError in logger db write - \" + self.id)\r\n                                print(\"\\tError type: \" + str(e))\r\n                        self.updated = True\r\n                    else:\r\n                        print('\\tResponse not successful')\r\n                        self.updated = False\r\n\r\n                    print()\r\n                    print(\r\n                        '-------------------------------------Logger ' + self.id + ' Done------------------------------------------------------------'\r\n                    )\r\n                    print()\r\n                    self.to_string()\r\n                    print(\r\n                        '========================================================================================================================'\r\n                    )\r\n                    print()\r\n                    print()\r\n                    print()\r\n                    print()\r\n\r\n                    return portal_data\r\n\r\n                # ------------------------------------HERE uncomment for trycatch\r\n            except Exception as e:\r\n                print(\"Error in logger update - \" + self.id)\r\n                print(\"Error type: \" + str(e))\r\n                self.crashed = True\r\n                # -----------------------------------HERE uncomment for trycatch\r\n        else:\r\n            print('Logger - {} not active'.format(self.id))\r\n\r\n    def show_irrigation_ledger(self):\r\n        print('\\tIrrigation Ledger: ')\r\n        for date_key, switch_list in self.irrigation_ledger.items():\r\n            print(f'\\t\\t{date_key} -> {switch_list}')\r\n\r\n    def check_and_update_delayed_ledger_filled_lists(self):\r\n        dates_to_remove = []\r\n        technician = self.field.grower.technician\r\n        for date, switch_list in self.irrigation_ledger.items():\r\n            if None not in switch_list:\r\n                switch_sum = sum(switch_list)\r\n                dates_to_remove.append(date)\r\n                if switch_sum > 0:\r\n                    print(f'\\tDelayed switch data for date: {date}...updating DB')\r\n                    print(f'\\tSwitch sum: {switch_sum}')\r\n                    self.dbwriter.update_overflow_switch_irr_hours_for_date_by_replacing(\r\n                        self,\r\n                        switch_sum,\r\n                        date\r\n                    )\r\n\r\n                    technician.all_notifications.add_notification(\r\n                        Notification_SensorError(\r\n                            date,\r\n                            self.field.name,\r\n                            self,\r\n                            \"Delayed Irrigation Hours Updated\",\r\n                            f\"Updated irrigation hours for date {date}. There may have been a lack of data reported for\"\r\n                            + f\" this date when originally processed so hours have been updated now that the full 24\"\r\n                            + f\" hours of irrigation are accounted for.\"\r\n                        )\r\n                    )\r\n\r\n        for date in dates_to_remove:\r\n            del self.irrigation_ledger[date]\r\n\r\n    def should_ir_be_active(self, date_to_check: datetime.date = datetime.today().date()) -> bool:\r\n        # date_to_check = datetime.today().date()\r\n\r\n        # print()\r\n        # print('\\tChecking if IR should be active:')\r\n        if self.crop_type.lower() in ['tomato', 'tomatoes']:\r\n            psi_threshold_high = 1.6\r\n            sdd_threshold = -5.0\r\n            planting_date_plus_30 = self.planting_date + timedelta(days=30)\r\n            if date_to_check > planting_date_plus_30 and len(self.consecutive_ir_values) >= 3:\r\n                for psi_val, sdd_val in self.consecutive_ir_values:\r\n                    if psi_val > psi_threshold_high or sdd_val > sdd_threshold:\r\n                        return False\r\n                else:\r\n                    return True\r\n        elif self.crop_type.lower() in ['almond', 'almonds']:\r\n            # If date_to_check's date is between March and October (Active tree cycle)\r\n            psi_threshold_high = 0.5\r\n            # sdd_threshold = -3.0\r\n            if 2 < date_to_check.month < 10:\r\n                # if within months check if IR is On\r\n                if self.ir_active:\r\n                    return True\r\n                # if IR has not been turned on see if it passes checks\r\n                else:\r\n                    for psi_val, _ in self.consecutive_ir_values:\r\n                        if psi_val > psi_threshold_high:  # or sdd_val > sdd_threshold:\r\n                            return False\r\n                    # if IR is off and did not fail checks turn IR ON\r\n                    else:\r\n                        return True\r\n            # if outside the months turn IR off always\r\n            else:\r\n                return False\r\n            # suggested by ChatGPT 4\r\n            # elif self.crop_type.lower() in ['almonds', 'almond']:\r\n            # if 3 <= date_to_check.month <= 9 and not self.ir_active:\r\n            #     return all(psi_val <= 0.5 for psi_val, _ in self.consecutive_ir_values)\r\n            # return self.ir_active or 3 <= date_to_check.month <= 9\r\n\r\n        elif self.crop_type.lower() in ['pistachio', 'pistachios']:\r\n            # If date_to_check's date is between May and November (Active tree cycle)\r\n            if 4 < date_to_check.month < 11:\r\n                # Band-Aid Fix. Pistachios are not ready for stress monitoring\r\n                print('\\t\\tIR Active')\r\n                return True\r\n            else:\r\n                print('\\t\\tIR NOT Active')\r\n                return False\r\n\r\n\r\n        elif self.crop_type.lower() == 'dates' or self.crop_type.lower() == 'date':\r\n            # La Quinta requested to always see canopy temp and SDD\r\n            print('\\t\\tIR Active')\r\n            return True\r\n        return False\r\n\r\n    def deactivate(self):\r\n        print('Deactivating Logger {}...'.format(self.id))\r\n        self.active = False\r\n        print('Done')\r\n\r\n    def calculate_total_gdd_and_crop_stage(self, final_results_converted: dict) -> dict:\r\n        print('\\tCalculating GDDS and Crop Stage:')\r\n        accumulated_gdd = previous_gdd = self.gdd_total\r\n\r\n        crop_stage = 'NA'\r\n        for gdd in final_results_converted['gdd']:\r\n            accumulated_gdd += gdd\r\n            crop_stage = self.cwsi_processor.get_crop_stage(accumulated_gdd)\r\n            final_results_converted['crop stage'].append(crop_stage)\r\n        self.gdd_total = accumulated_gdd\r\n        self.crop_stage = crop_stage\r\n        print(\r\n            f'\\t GDD before: {str(previous_gdd)} -> GDD after: {str(self.gdd_total)} -> Crop Stage: {self.crop_stage}'\r\n        )\r\n        print()\r\n        return final_results_converted\r\n\r\n    def recalculate_total_gdd(self):\r\n        pass\r\n\r\n    def get_sensor_individual_data_indexes(self):\r\n\r\n        get_sensor_individual_data_indexes = {}\r\n        # Dictionary to hold what index the data is being stored in from the API return for Zentra v1\r\n        get_sensor_individual_data_indexes['ir temp'] = 0\r\n        get_sensor_individual_data_indexes['ir body temp'] = 1\r\n        get_sensor_individual_data_indexes['vp4 air temp'] = 0\r\n        get_sensor_individual_data_indexes['vp4 rh'] = 1\r\n        get_sensor_individual_data_indexes['vp4 pressure'] = 2\r\n        get_sensor_individual_data_indexes['vp4 vpd'] = 3\r\n        get_sensor_individual_data_indexes['vwc volumetric'] = 0\r\n        get_sensor_individual_data_indexes['vwc soil temp'] = 1\r\n        get_sensor_individual_data_indexes['vwc ec'] = 2\r\n        get_sensor_individual_data_indexes['switch minutes'] = 0\r\n\r\n        return get_sensor_individual_data_indexes\r\n\r\n    def get_sensor_individual_data_indexes_weather_stations(self):\r\n        \"\"\"\r\n\r\n        :return:\r\n        \"\"\"\r\n\r\n        get_sensor_individual_data_indexes = {}\r\n        # Dictionary to hold what index the data is being stored in from the API return for Zentra v1\r\n        get_sensor_individual_data_indexes['solar radiation'] = 0\r\n        get_sensor_individual_data_indexes['precipitation'] = 1\r\n        get_sensor_individual_data_indexes['lightning activity'] = 2\r\n        get_sensor_individual_data_indexes['lightning distance'] = 3\r\n        get_sensor_individual_data_indexes['wind direction'] = 4\r\n        get_sensor_individual_data_indexes['wind speed'] = 5\r\n        get_sensor_individual_data_indexes['gust speed'] = 6\r\n        get_sensor_individual_data_indexes['air temperature'] = 7\r\n        get_sensor_individual_data_indexes['relative humidity'] = 8\r\n        get_sensor_individual_data_indexes['atmospheric pressure'] = 9\r\n        get_sensor_individual_data_indexes['x axis level'] = 10\r\n        get_sensor_individual_data_indexes['y axis level'] = 11\r\n        get_sensor_individual_data_indexes['max precip rate'] = 12\r\n        get_sensor_individual_data_indexes['rh sensor temp'] = 13\r\n        get_sensor_individual_data_indexes['vpd'] = 14\r\n\r\n        return get_sensor_individual_data_indexes\r\n\r\n    def set_broken(self):\r\n        self.broken = True\r\n        self.active = False\r\n        self.uninstall_date = datetime.now().date()\r\n\r\n    def update_ir_consecutive_data(self, cwsi: float, sdd: float):\r\n        \"\"\"\r\n\r\n        :param sdd:\r\n        :param cwsi: Float of the CWSI we want to append to the que\r\n        \"\"\"\r\n        if cwsi is not None and sdd is not None:\r\n            self.consecutive_ir_values.append((cwsi, sdd))\r\n        if len(self.consecutive_ir_values) > 3:\r\n            self.consecutive_ir_values.popleft()\r\n\r\n    def get_et(self, final_results_converted, cimis_stations_pickle):\r\n        # Check - If we only need yesterday's value, we can grab it from the cimis station pickle. If we need more than\r\n        # yesterday's value, we need grab it from the database.\r\n        final_results_converted['eto'] = []\r\n        final_results_converted['etc'] = []\r\n        final_results_converted['et_hours'] = []\r\n        if len(final_results_converted['dates']) == 1:\r\n            # Grab et data from latest cimis station pickle\r\n            final_results_converted = self.update_et_values_from_cimis_pickle(cimis_stations_pickle,\r\n                                                                              final_results_converted)\r\n        elif len(final_results_converted['dates']) > 1:\r\n            # Grab et data from et db\r\n            final_results_converted = self.update_et_values_from_et_db(final_results_converted)\r\n        return final_results_converted\r\n\r\n    def update_et_values_from_cimis_pickle(self, cimis_stations_pickle, final_results_converted):\r\n        # Grab data from latest cimis station pickle\r\n        print(\"\\tUpdating ET data from pickle\")\r\n        try:\r\n            cimis_station = self.field.cimis_station\r\n            latest_eto = 0\r\n            for station in cimis_stations_pickle:\r\n                if station.station_number == cimis_station:\r\n                    latest_eto = station.latest_eto_value\r\n                    break\r\n            # calculate etc from eto * kc\r\n            acres = self.irrigation_set_acres\r\n            gpm = self.gpm\r\n\r\n            kc = final_results_converted['kc'][0]\r\n            latest_eto = float(latest_eto)\r\n            etc = latest_eto * kc  # etc = eto * kc\r\n            et_hours = None\r\n            # calculate et_hours\r\n            if gpm != 0:\r\n                # et_hours_pending_etc_mult = ((449 * acres) / (gpm * 0.85))\r\n                # et_hours = round(et_hours_pending_etc_mult * latest_eto * kc)\r\n                et_hours = round(etc * ((449 * acres) / (gpm * 0.85)))\r\n            final_results_converted['eto'].append(latest_eto)\r\n            final_results_converted['etc'].append(etc)\r\n            final_results_converted['et_hours'].append(et_hours)\r\n            print(f\"\\tGot ET data from pickle: ETo: {latest_eto}, kc: {kc}, ETc: {etc}, ET Hours: {et_hours}, Acres: {acres}, GPM: {gpm}\")\r\n        except Exception as error:\r\n            print(\"Error in logger ET data grab from pickle - \" + self.name)\r\n            print(\"Error type: \" + str(error))\r\n            print(f\"ET data from pickle: ETo: {latest_eto}, kc: {kc}, ETc: {etc}, ET Hours: {et_hours}, Acres: {acres}, GPM: {gpm}\")\r\n        return final_results_converted\r\n\r\n    def update_et_values_from_et_db(self, final_results_converted):\r\n        print(\"\\tUpdating ET data from DB\")\r\n        try:\r\n            field_name = self.field.name\r\n            field_name = self.dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n            project = 'stomato-info'\r\n            dataset_id = f\"{project}.ET.{str(self.field.cimis_station)}\"\r\n            dataset_id = \"`\" + dataset_id + \"`\"\r\n\r\n            acres = self.irrigation_set_acres\r\n            gpm = self.gpm\r\n\r\n            start_date = final_results_converted['dates'][0].strftime('%Y-%m-%d')\r\n            end_date = final_results_converted['dates'][-1].strftime('%Y-%m-%d')\r\n\r\n            dml_statement = f\"SELECT * FROM {dataset_id} WHERE date BETWEEN DATE(\\'{start_date}\\') AND DATE(\\'{end_date}\\') ORDER BY date ASC\"\r\n            result = self.dbwriter.run_dml(dml_statement, project=project)\r\n\r\n            et_db_dates = []\r\n            et_db_etos = []\r\n            for row in result:\r\n                et_db_dates.append(row['date'])\r\n                et_db_etos.append(row['eto'])\r\n\r\n            for ind, data_date in enumerate(final_results_converted['dates']):\r\n                eto = None\r\n                etc = None\r\n                et_hours = None\r\n\r\n                if data_date.date() in et_db_dates:\r\n                    eto = et_db_etos[et_db_dates.index(data_date.date())]\r\n                    kc = final_results_converted['kc'][ind]\r\n                    etc = eto * kc  # etc = eto * kc\r\n                    if gpm != 0:\r\n                        et_hours_pending_etc_mult = ((449 * acres) / (gpm * 0.85))\r\n                        et_hours = round(et_hours_pending_etc_mult * eto * kc)\r\n                    else:\r\n                        et_hours = None\r\n\r\n                final_results_converted['eto'].append(eto)\r\n                final_results_converted['etc'].append(etc)\r\n                final_results_converted['et_hours'].append(et_hours)\r\n            print(f\"\\tGot ET data from DB:\")\r\n            print(f\"\\t\\tETO: {final_results_converted['eto']}\")\r\n            print(f\"\\t\\tETC: {final_results_converted['etc']}\")\r\n            print(f\"\\t\\tET Hours: {final_results_converted['et_hours']}\")\r\n        except Exception as error:\r\n            print(\"Error in logger ET data grab from DB - \" + self.name)\r\n            print(\"Error type: \" + str(error))\r\n        return final_results_converted\r\n\r\n\r\ndef convert_datetime_to_timestamp(raw_datetime):\r\n    return datetime.timestamp(raw_datetime)\r\n\r\n\r\ndef convert_utc_timestamp_to_utc_datetime(raw_timestamp):\r\n    utc_dt = datetime.utcfromtimestamp(raw_timestamp)\r\n    return utc_dt\r\n\r\n\r\ndef convert_utc_datetime_to_local_datetime(utc_raw_time):\r\n    from_zone = tz.tzutc()\r\n    to_zone = tz.tzlocal()\r\n\r\n    utc = utc_raw_time.replace(tzinfo=from_zone)\r\n    pacific = utc.astimezone(to_zone)\r\n    return pacific\r\n\r\n# timestamp = 1659988800\r\n# timestamp = 1659985200 #8-8-22\r\n# timestamp = 1655154000 #6-13-22\r\n# meter_time = convert_utc_timestamp_to_utc_datetime(timestamp)\r\n# time_local = convert_utc_datetime_to_local_datetime(meter_time)\r\n# time_local = time_local.replace(tzinfo=None)\r\n# print(time_local.date())\r\n# print(type(time_local.date()))\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Logger.py b/Logger.py
--- a/Logger.py	
+++ b/Logger.py	
@@ -2303,6 +2303,11 @@
         self.active = False
         print('Done')
 
+    def activate(self):
+        print('Activating Logger {}...'.format(self.id))
+        self.active = True
+        print('Done')
+
     def calculate_total_gdd_and_crop_stage(self, final_results_converted: dict) -> dict:
         print('\tCalculating GDDS and Crop Stage:')
         accumulated_gdd = previous_gdd = self.gdd_total
Index: SQLScripts.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import itertools\r\nimport pickle\r\nimport pprint\r\nfrom datetime import datetime, timedelta, date\r\nfrom os import path\r\nfrom statistics import mean\r\n\r\nimport google.api_core.exceptions\r\nimport numpy\r\nfrom dateutil.relativedelta import relativedelta\r\nfrom google.api_core import exceptions\r\nfrom google.cloud import bigquery\r\n\r\nimport Decagon\r\nfrom CIMIS import CIMIS\r\nfrom CimisStation import CimisStation\r\nfrom CwsiProcessor import CwsiProcessor\r\nfrom DBWriter import DBWriter\r\n\r\ndbwriter = DBWriter()\r\nDIRECTORY_YEAR = \"2023\"\r\nPICKLE_DIRECTORY = \"H:\\\\Shared drives\\\\Stomato\\\\\" + DIRECTORY_YEAR + \"\\\\Pickle\\\\\"\r\n\r\ndef update_value_for_date(project, field_name, logger_name, date, value_name, value):\r\n    dml = 'UPDATE `' + str(project) + '.' + str(field_name) + '.' + str(logger_name) + '`' \\\r\n          + ' SET ' + str(value_name) + ' = ' + str(value) \\\r\n          + \" WHERE date = '\" + str(date) + \"'\"\r\n    print(dml)\r\n\r\n    dbwriter.run_dml(dml, project=project)\r\n\r\n\r\ndef delete_null_rows(project, field, logger, row_value='', start_date='', end_date=''):\r\n    print('Deleting nulls in: ' + str(field) + ' ' + str(logger))\r\n    if start_date == '' and end_date == '':\r\n        if row_value == '':\r\n            dml = \"DELETE   FROM \" \\\r\n                  + \"`\" + project + \".\" + str(field) + \".\" + str(logger) + \"`\" \\\r\n                  + \" WHERE logger_id is NULL\"\r\n        else:\r\n            dml = \"DELETE   FROM \" \\\r\n                  + \"`\" + project + \".\" + str(field) + \".\" + str(logger) + \"`\" \\\r\n                  + \" WHERE \" + row_value + \" is NULL\"\r\n    else:\r\n        if row_value == '':\r\n            dml = \"DELETE   FROM \" \\\r\n                  + \"`\" + project + \".\" + str(field) + \".\" + str(logger) + \"`\" \\\r\n                  + \" WHERE logger_id is NULL AND date BETWEEN DATE('\" + start_date + \"') AND DATE('\" + end_date + \"') \"\r\n        else:\r\n            dml = \"DELETE   FROM \" \\\r\n                  + \"`\" + project + \".\" + str(field) + \".\" + str(logger) + \"`\" \\\r\n                  + \" WHERE \" + row_value + \" is NULL AND date BETWEEN DATE('\" + start_date + \"') AND DATE('\" + end_date + \"') \"\r\n    dbwriter.run_dml(dml, project=project)\r\n\r\n\r\ndef delete_all_null_rows(project, row_value='', start_date='', end_date=''):\r\n    datasets = dbwriter.get_datasets(project=project)\r\n    for d in datasets[0]:\r\n        if d.dataset_id == 'ET' or d.dataset_id == 'Historical_ET':\r\n            continue\r\n        tables = dbwriter.get_tables(d.dataset_id, project=project)\r\n        for t in tables:\r\n            if t.table_id == 'Lat Long Trial':\r\n                continue\r\n            delete_null_rows(project, d.dataset_id, t.table_id, row_value, start_date, end_date)\r\n\r\n\r\ndef update_irrigation_hours_for_date(project, field_name, logger_name, daily_hours, date):\r\n    # Get gpm and acres\r\n    gpm = Decagon.get_gpm(field_name, logger_name)\r\n    acres = Decagon.get_acres(field_name, logger_name)\r\n    field_db = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n    # Calculate daily hours, flow, and inches using Switch Data\r\n    switch_data = daily_hours * 60\r\n    daily_inches = round((switch_data * float(gpm)) / (float(acres) * 27154), 1)\r\n    # Set up and run Query\r\n    dml = \"UPDATE `\" + str(project) + \".\" + str(field_db) + \".\" + str(logger_name) + \"`\" \\\r\n          + \" SET daily_switch = \" + str(switch_data) + \", daily_hours = \" + str(daily_hours) + \", daily_inches = \" \\\r\n          + str(daily_inches) + \" WHERE date = '\" + str(date) + \"'\"\r\n    # print(dml)\r\n    dbwriter.run_dml(dml, project=project)\r\n    print(\"Done Updating Irr. Hours\")\r\n\r\n# update_irrigation_hours_for_date('stomato-2023', 'Lucero Mandeville17 I J', 'LM-17J-S', 4.2, '2023-08-08')\r\n# update_irrigation_hours_for_date('stomato-2023', 'Lucero Mandeville17 I J', 'LM-17J-S', 5.1, '2023-08-10')\r\n# update_irrigation_hours_for_date('stomato-2023', 'Lucero Mandeville17 I J', 'LM-17J-S', 3.5, '2023-08-12')\r\n# update_irrigation_hours_for_date('stomato-2023', 'Lucero Mandeville17 I J', 'LM-17J-S', 13.8, '2023-08-15')\r\n# update_irrigation_hours_for_date('stomato-2023', 'Lucero Mandeville17 I J', 'LM-17J-S', 6.8, '2023-08-16')\r\n\r\ndef update_irrigation_inches_for_whole_table(project, field_name, logger_name):\r\n    # Useful when gpm or acres change and you want to recalculate all the inches\r\n    gpm = Decagon.get_gpm(field_name, logger_name)\r\n    acres = Decagon.get_acres(field_name, logger_name)\r\n    field_db = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n    # Calculate inches using Switch Data\r\n    # daily_inches = round((switch_data * float(gpm)) / (float(acres) * 27154), 1)\r\n    # Set up and run Query\r\n    dml = f\"UPDATE `{str(project)}.{str(field_db)}.{str(logger_name)}`\" \\\r\n          + f\" SET  daily_inches = ((daily_switch * {float(gpm)}) / ({float(acres)} * 27154))\" \\\r\n          + f\" WHERE logger_id is not null\"\r\n    # print(dml)\r\n    dbwriter.run_dml(dml, project=project)\r\n    print(\"Done Updating Irr. Inches\")\r\n# update_irr_inches_for_date('stomato-2023', 'Lucero Dillard RoadD4', 'DI-D4-W')\r\n\r\n\r\ndef update_irrigation_hours_for_date_range(project, field_name, logger_name, daily_hours, start_date, end_date):\r\n    # Get gpm and acres\r\n    gpm = Decagon.get_gpm(field_name, logger_name)\r\n    acres = Decagon.get_acres(field_name, logger_name)\r\n\r\n    field_db = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n\r\n    # Turn date string into datetimes\r\n    start_date_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\r\n    end_date_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\r\n    delta = end_date_dt - start_date_dt + timedelta(days=1)\r\n\r\n    # Calculate daily hours, flow, and inches using Switch Data\r\n    switch_data = daily_hours * 60\r\n    flow = round((switch_data * float(gpm)) / float(acres))\r\n    daily_inches = flow / 27154\r\n    # Set up and run Query\r\n    dml = \"UPDATE `\" + str(project) + \".\" + str(field_db) + \".\" + str(logger_name) + \"`\" \\\r\n          + \" SET daily_switch = \" + str(switch_data) + \", daily_hours = \" + str(daily_hours) + \", daily_inches = \" \\\r\n          + str(daily_inches) + \" WHERE date BETWEEN DATE('\" + start_date + \"') AND DATE('\" + end_date + \"') \"\r\n    dbwriter.run_dml(dml, project=project)\r\n    print(\"Done Updating Irr. Hours\")\r\n\r\ndef update_eto_etc(project, field_name, logger_name, list_etos, start_date, end_date):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n    list_etos = list_etos\r\n\r\n    # Setup dataset_id from passed in field_name and logger_name parameters\r\n    dataset_id = project + '.' + field_name + '.' + logger_name\r\n    dataset_id = \"`\" + dataset_id + \"`\"\r\n\r\n    # Turn date string into datetimes\r\n    start_date_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\r\n    end_date_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\r\n    delta = end_date_dt - start_date_dt + timedelta(days=1)\r\n\r\n    # check that length of listETos = endDate - startDate\r\n    if len(list_etos) == delta.days:\r\n        for eto in list_etos:\r\n            # startDateS = datetime.strftime(start_date_dt, \"%Y-%m-%d\")\r\n            startDateS = '{0}-{1}-{2}'.format(start_date_dt.year, start_date_dt.month, start_date_dt.day)\r\n            startDateS = \"'\" + startDateS + \"'\"\r\n            kc_dml_statement = \"SELECT kc FROM \" + dataset_id + ' WHERE date = ' + startDateS\r\n            print('Getting kc from DB')\r\n            kc_response = dbwriter.run_dml(kc_dml_statement, project=project)\r\n            kc = 0\r\n            for e in kc_response:\r\n                kc = e[\"kc\"]\r\n                print(kc)\r\n            print(' Done. Got kc: ' + str(kc))\r\n            etc = kc * eto\r\n            print()\r\n            print('etc: ' + str(etc))\r\n            print('Updating etc and eto in DB')\r\n            etc_dml_statement = \"UPDATE \" + dataset_id + ' SET etc = ' + str(etc) + ', eto = ' + str(\r\n                eto) + ' WHERE date = ' + startDateS\r\n            dbwriter.run_dml(etc_dml_statement, project=project)\r\n            start_date_dt = start_date_dt + timedelta(days=1)\r\n            print()\r\n\r\n            if start_date_dt == end_date_dt + timedelta(1):\r\n                print('Start date = End date')\r\n                break\r\n\r\n\r\ndef update_kcs(project, field_name, logger_name, list_kcs, start_date, end_date):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n\r\n    # Setup dataset_id from passed in field and logger_id parameters\r\n    dataset_id = project + '.' + field_name + '.' + logger_name\r\n    dataset_id = \"`\" + dataset_id + \"`\"\r\n\r\n    # Turn date string into datetimes\r\n    start_date_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\r\n    end_date_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\r\n    delta = end_date_dt - start_date_dt + timedelta(days=1)\r\n\r\n    # check that length of listETos = endDate - startDate\r\n    if len(list_kcs) == delta.days:\r\n        for kc in list_kcs:\r\n            # startDateS = datetime.strftime(start_date_dt, \"%Y-%m-%d\")\r\n            startDateS = '{0}-{1}-{2}'.format(start_date_dt.year, start_date_dt.month, start_date_dt.day)\r\n            startDateS = \"'\" + startDateS + \"'\"\r\n\r\n            print('Updating kc DB for date: ' + startDateS)\r\n            kc_dml_statement = \"UPDATE \" + dataset_id + ' SET kc = ' + str(kc) + ' WHERE date = ' + startDateS\r\n            dbwriter.run_dml(kc_dml_statement, project=project)\r\n            start_date_dt = start_date_dt + timedelta(days=1)\r\n            print()\r\n\r\n            if start_date_dt == end_date_dt + timedelta(1):\r\n                print('Start date = End date')\r\n                break\r\n\r\n\r\ndef update_values_for_date_range(project, field_name, logger_name, value_name, values_list, start_date, end_date):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n\r\n    # Setup dataset_id from passed in field and logger_id parameters\r\n    dataset_id = project + '.' + field_name + '.' + logger_name\r\n    dataset_id = \"`\" + dataset_id + \"`\"\r\n\r\n    # Turn date string into datetimes\r\n    start_date_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\r\n    end_date_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\r\n    delta = end_date_dt - start_date_dt + timedelta(days=1)\r\n\r\n    # check that length of listETos = endDate - startDate\r\n    if len(values_list) == delta.days:\r\n        for val in values_list:\r\n            # start_date_s = datetime.strftime(start_date_dt, \"%Y-%m-%d\")\r\n            start_date_s = '{0}-{1}-{2}'.format(start_date_dt.year, start_date_dt.month, start_date_dt.day)\r\n            start_date_s = \"'\" + start_date_s + \"'\"\r\n\r\n            print('Updating val DB for date: ' + start_date_s)\r\n            dml = \"UPDATE \" + dataset_id + ' SET ' + str(value_name) + ' = ' + str(\r\n                val) + ' WHERE date = ' + start_date_s\r\n            dbwriter.run_dml(dml, project=project)\r\n            start_date_dt = start_date_dt + timedelta(days=1)\r\n            print()\r\n\r\n            if start_date_dt == end_date_dt + timedelta(1):\r\n                print('Start date = End date')\r\n                break\r\n    else:\r\n        print('Values and dates dont match')\r\n        print('Values: ' + str(len(values_list)))\r\n        print(\"Days: \" + str(delta.days))\r\n\r\n\r\ndef copy_values_from_table_to_table():\r\n    dml = \"SELECT date, daily_inches, daily_hours, daily_switch FROM `stomato.Andrew3104.z6-12421` ORDER BY date ASC\"\r\n    result = dbwriter.run_dml(dml, project='stomato')\r\n    for e in result:\r\n        date = e[\"date\"]\r\n        if date is not None:\r\n            inches = e[\"daily_inches\"]\r\n            hours = e[\"daily_hours\"]\r\n            switch = e[\"daily_switch\"]\r\n\r\n            dml = \"UPDATE `stomato.Andrew3104.z6-12300` \" \\\r\n                  + \" SET daily_switch = \" + str(switch) + \\\r\n                  \", daily_hours = \" + str(hours) + \\\r\n                  \", daily_inches = \" + str(inches) + \\\r\n                  \" WHERE date = '\" + str(date) + \"'\"\r\n            dbwriter.run_dml(dml, project='stomato')\r\n    print('done')\r\n\r\n\r\ndef copy_gdd_values_from_temp_table_to_table(project, field, original_table, temp_table):\r\n    dml_statement = \"MERGE `\" + project + \".\" + field + \".\" + original_table + \"` T \" \\\r\n                    + \"USING `\" + project + \".\" + field + \".\" + temp_table + \"` S \" \\\r\n                    + \"ON T.date = S.date \" \\\r\n                    + \"WHEN MATCHED THEN \" \\\r\n                    + \"UPDATE SET \" \\\r\n                      \"lowest_ambient_temperature = s.lowest_ambient_temperature, \" \\\r\n                      \"gdd = s.gdd,\" \\\r\n                      \"crop_stage = s.crop_stage, \" \\\r\n                      \"id = s.id, \" \\\r\n                      \"planting_date = s.planting_date\"\r\n\r\n    result = dbwriter.run_dml(dml_statement, project=project)\r\n    print('done')\r\n\r\n\r\ndef copy_vp4_vals_from_table_to_table(project, fieldName, source, target, date):\r\n    fieldName = dbwriter.remove_unwanted_chars_for_db_dataset(fieldName)\r\n    # print(date)\r\n    dml = \"SELECT date, ambient_temperature, rh, vpd FROM `\" + project + \".\" + fieldName + \".\" + source + \\\r\n          \"` ORDER BY date ASC\"\r\n    print(dml)\r\n    result = dbwriter.run_dml(dml, project=project)\r\n    for e in result:\r\n        # print(e)\r\n        dbDate = e[\"date\"]\r\n        # print(dbDate)\r\n        if str(dbDate) == date:\r\n            ambient_temperature = e[\"ambient_temperature\"]\r\n            rh = e[\"rh\"]\r\n            vpd = e[\"vpd\"]\r\n\r\n            dml = \"UPDATE `\" + project + \".\" + fieldName + \".\" + target + \"`\" \\\r\n                  + \" SET ambient_temperature = \" + str(ambient_temperature) + \\\r\n                  \", rh = \" + str(rh) + \\\r\n                  \", vpd = \" + str(vpd) + \\\r\n                  \" WHERE date = '\" + str(date) + \"'\"\r\n            print(dml)\r\n            dbwriter.run_dml(dml, project=project)\r\n    print('done updating VP4 Data')\r\n\r\n\r\ndef daterange(start_date, end_date):\r\n    for n in range(int((end_date - start_date).days)):\r\n        yield start_date + timedelta(n)\r\n\r\n\r\ndef keep_db_days(field_name, startDate, endDate):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.name == field_name:\r\n                for log in f.loggers:\r\n                    logger_id = log.id\r\n                    # Setup dataset_id from passed in field and logger_id parameters\r\n                    project = dbwriter.get_db_project(log.crop_type)\r\n                    dataset_id = project + '.' + field_name + '.' + logger_id\r\n                    dataset_id = \"`\" + dataset_id + \"`\"\r\n\r\n                    # Keep dates specified by user Start and End Date\r\n                    val_dml_statement = \"CREATE OR REPLACE TABLE \" + dataset_id + \" AS \" + \"SELECT * FROM \" + dataset_id \\\r\n                                        + \"WHERE date BETWEEN DATE('\" + startDate + \"') AND DATE('\" + endDate + \"') \"\r\n                    print(val_dml_statement)\r\n                    dbwriter.run_dml(val_dml_statement, project=project)\r\n\r\n\r\ndef delete_and_update_db(grower, field, db_end_date, start_date):\r\n    keep_db_days(field, '2021-01-01', db_end_date)\r\n    Decagon.get_previous_data_field(grower, field, start_date, write_to_sheet=True, write_to_db=True)\r\n\r\n\r\ndef delete_and_update_db_grower(grower, db_end_date, start_date):\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        if g.name == grower:\r\n            print(\"Found grower, these are his fields: \")\r\n            for f in g.fields:\r\n                field = f.name\r\n                print(f.name)\r\n                keep_db_days(field, '2021-01-01', db_end_date)\r\n                # Todo pass in field and grower objects to parameters\r\n                Decagon.get_previous_data_field(grower, field, start_date, write_to_sheet=True, write_to_db=True)\r\n\r\n\r\ndef remove_psi_specific(project, field_name, logger_name, start_date, end_date):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n    dataset_id = project + '.' + field_name + '.' + logger_name\r\n    dataset_id = \"`\" + dataset_id + \"`\"\r\n    val_dml_statement = \"Update \" + dataset_id + \" Set \" + \" psi = null, sdd = null, canopy_temperature = null \" \\\r\n                        + \"WHERE date BETWEEN DATE('\" + start_date + \"') AND DATE('\" + end_date + \"') \"\r\n    # print(val_dml_statement)\r\n    print(\"Removing PSI from field pages\")\r\n    dbwriter.run_dml(val_dml_statement, project=project)\r\n\r\n\r\ndef remove_psi(field_name_pickle, start_date, end_date, portal_year):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field_name_pickle)\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.name == field_name_pickle:\r\n                grower_name = dbwriter.remove_unwanted_chars_for_db_dataset(g.name)\r\n                print(\"Removing PSI from field pages\")\r\n                for log in f.loggers:\r\n                    logger_name = log.name\r\n                    project = dbwriter.get_db_project(log.crop_type)\r\n                    dataset_id = project + '.' + field_name + '.' + logger_name\r\n                    dataset_id = \"`\" + dataset_id + \"`\"\r\n                    val_dml_statement = \"Update \" + dataset_id + \" Set \" + \" psi = null, sdd = null, canopy_temperature = null \" \\\r\n                                        + \"WHERE date BETWEEN DATE('\" + start_date + \"') AND DATE('\" + end_date + \"') \"\r\n                    # print(val_dml_statement)\r\n                    dbwriter.run_dml(val_dml_statement, project=project)\r\n                print(\"Removing PSI from portal\")\r\n                dataset_id_portal_field_averages = 'growers-' + portal_year + '.' + grower_name + '.field_averages'\r\n                dataset_id_portal_field_averages = \"`\" + dataset_id_portal_field_averages + \"`\"\r\n                dataset_id_portal_loggers = 'growers-' + portal_year + '.' + grower_name + '.loggers'\r\n                dataset_id_portal_loggers = \"`\" + dataset_id_portal_loggers + \"`\"\r\n\r\n                val_dml_statement = \"Update \" + dataset_id_portal_field_averages + \" Set\" + \" si_num = null, si_desc = null \" \\\r\n                                    + \"Where field = '\" + f.nickname + \"'\"\r\n                print(\"Removing PSI from field_averages\")\r\n                dbwriter.run_dml(val_dml_statement, project='growers-' + portal_year)\r\n                val_dml_statement = \"Update \" + dataset_id_portal_loggers + \" Set\" + \" si_num = null, si_desc = null \" \\\r\n                                    + \"Where field = '\" + f.nickname + \"'\"\r\n                print(\"Removing PSI from loggers\")\r\n                dbwriter.run_dml(val_dml_statement, project='growers-' + portal_year)\r\n\r\n\r\ndef update_missing_et_data(logger):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(logger.field.name)\r\n    project = dbwriter.get_db_project(logger.crop_type)\r\n    dataset_id = project + \".\" + field_name + \".\" + logger.name\r\n    et_id = \"stomato-info.ET.\" + str(logger.field.cimis_station)\r\n\r\n    if isinstance(logger.irrigation_set_acres, str):\r\n        acres = float(logger.irrigation_set_acres.replace(',', ''))\r\n    elif isinstance(logger.irrigation_set_acres, int):\r\n        acres = float(logger.irrigation_set_acres)\r\n    elif isinstance(logger.irrigation_set_acres, float):\r\n        acres = logger.irrigation_set_acres\r\n    else:\r\n        acres = 0\r\n    if isinstance(logger.gpm, str):\r\n        gpm = float(logger.gpm.replace(',', ''))\r\n    elif isinstance(logger.gpm, int):\r\n        gpm = float(logger.gpm)\r\n    elif isinstance(logger.gpm, float):\r\n        gpm = logger.gpm\r\n    else:\r\n        gpm = 0\r\n\r\n    if gpm != 0:\r\n        et_hours_pending_etc_mult = ((449 * acres) / (gpm * 0.85))\r\n\r\n        print(\"Updating eto data for table: \" + dataset_id)\r\n        print(\" from\")\r\n        print(\"ET table: \" + et_id)\r\n        # Use when eto is NULL\r\n        # dml_statement = \"MERGE `\" + dataset_id + \"` T \" \\\r\n        #                 + \"USING `\" + et_id + \"` S \" \\\r\n        #                 + \"ON T.date = S.date \" \\\r\n        #                 + \"WHEN MATCHED AND t.eto is NULL THEN \" \\\r\n        #                 + \"UPDATE SET eto = s.eto, etc = s.eto * t.kc, et_hours = ROUND(\" + str(\r\n        #     et_hours_pending_etc_mult) + \" * s.eto * t.kc)\"\r\n\r\n        # Use when eto is not NULL\r\n\r\n        dml_statement = \"MERGE `\" + dataset_id + \"` T \" \\\r\n                        + \"USING `\" + et_id + \"` S \" \\\r\n                        + \"ON (T.date = S.date AND T.eto IS NULL)  \" \\\r\n                        + \"WHEN MATCHED THEN \" \\\r\n                        + \"UPDATE SET eto = s.eto, etc = s.eto * t.kc, et_hours = ROUND(\" + str(\r\n            et_hours_pending_etc_mult) + \" * s.eto * t.kc)\"\r\n        # print(dml_statement)\r\n        dbwriter.run_dml(dml_statement, project=project)\r\n\r\n\r\ndef update_missing_et_hours(logger):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(logger.field.name)\r\n    project = dbwriter.get_db_project(logger.crop_type)\r\n    dataset_id = project + \".\" + field_name + \".\" + logger.name\r\n\r\n    if isinstance(logger.irrigation_set_acres, str):\r\n        acres = float(logger.irrigation_set_acres.replace(',', ''))\r\n    elif isinstance(logger.irrigation_set_acres, int):\r\n        acres = float(logger.irrigation_set_acres)\r\n    else:\r\n        acres = 0\r\n    if isinstance(logger.gpm, str):\r\n        gpm = float(logger.gpm.replace(',', ''))\r\n    elif isinstance(logger.gpm, int):\r\n        gpm = float(logger.gpm)\r\n    else:\r\n        gpm = 0\r\n\r\n    if gpm != 0:\r\n        et_hours_pending_etc_mult = ((449 * acres) / (gpm * 0.85))\r\n\r\n        print(\"Updating et_hours data for table: \" + dataset_id)\r\n\r\n        dml_statement = \"UPDATE `\" + dataset_id + \"` SET et_hours = ROUND(\" + str(\r\n            et_hours_pending_etc_mult) + \" * eto * kc) \" + \" WHERE et_hours is NULL\"\r\n\r\n        dbwriter.run_dml(dml_statement, project=project)\r\n    else:\r\n        print('Cannot calculate ET Hours. GPM is: ' + str(gpm))\r\n\r\n\r\ndef add_column_to_db_specific_field(field_name: str, column_name_and_type_dict: dict, project='stomato'):\r\n    \"\"\"\r\n\r\n    :param field_name:\r\n    :param column_name_and_type_dict: Dict[column_name] = column_type\r\n    :return:\r\n    \"\"\"\r\n    fieldName = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.name == field_name:\r\n                for log in f.loggers:\r\n                    logger_id = log.id\r\n                    for val in column_name_and_type_dict:\r\n                        try:\r\n                            dbwriter.add_new_column_to_table(fieldName, logger_id, val, column_name_and_type_dict[val], project=project)\r\n                        except:\r\n                            print(\"Exception\")\r\n\r\n\r\ndef add_column_to_db(column_name_and_type_dict: dict, project='stomato'):\r\n    \"\"\"\r\n\r\n    :param column_name_and_type_dict: Dict[column_name] = column_type\r\n    :return:\r\n    \"\"\"\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            fieldName = dbwriter.remove_unwanted_chars_for_db_dataset(f.name)\r\n            print(fieldName)\r\n            for log in f.loggers:\r\n                logger_id = log.id\r\n                for val in column_name_and_type_dict:\r\n                    try:\r\n                        dbwriter.add_new_column_to_table(fieldName, logger_id, val, column_name_and_type_dict[val], project=project)\r\n                    except:\r\n                        print(\"Field:\" + fieldName + \" already has ET Hours\")\r\n\r\n\r\ndef remove_duplicate_rows(project, dataset, table, rowName):\r\n    dmlStatement = \"create or replace table `\" + str(project) + \".\" + str(dataset) + \".\" + str(table) + \"` as ( \\\r\n    select * except(row_num) from (SELECT *, ROW_NUMBER() OVER (PARTITION BY \" + str(rowName) + \" ORDER BY \" + str(\r\n        rowName) + \" desc) row_num \\\r\n    FROM `\" + project + \".\" + str(dataset) + \".\" + str(table) + \"`) t \\\r\n    WHERE row_num=1)\"\r\n\r\n    dbwriter.run_dml(dmlStatement, project=project)\r\n\r\n\r\ndef removeDuplicateET():\r\n    cimisStations = Decagon.get_all_current_cimis_stations()\r\n    project = 'stomato-info'\r\n    dataset = \"ET\"\r\n    rowName = \"date\"\r\n    for station in cimisStations:\r\n        print(\"Removing dupes in station \" + str(station))\r\n        remove_duplicate_rows(project, dataset, station, rowName)\r\n\r\n\r\ndef remove_double_data_late_hours(field_name, logger_name):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n    growers = Decagon.open_pickle()\r\n    dataset_id = \"stomato.\" + field_name + \".\" + logger_name\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.name == field_name:\r\n                for log in f.loggers:\r\n                    if logger_name == log.name:\r\n                        project = dbwriter.get_db_project(log.crop_type)\r\n                        dml_statement = \"DELETE `\" + project + \".\" + dataset_id + \"` where time = '11:00 PM' or time = '10:00 PM'\"\r\n                        dbwriter.run_dml(dml_statement, project=project)\r\n\r\n\r\ndef update_kc_values_with_a_max_including_etc_etc_hours(logger):\r\n    if isinstance(logger.irrigation_set_acres, str):\r\n        acres = float(logger.irrigation_set_acres.replace(',', ''))\r\n    elif isinstance(logger.irrigation_set_acres, int):\r\n        acres = float(logger.irrigation_set_acres)\r\n    else:\r\n        acres = 0\r\n    if isinstance(logger.gpm, str):\r\n        gpm = float(logger.gpm.replace(',', ''))\r\n    elif isinstance(logger.gpm, int):\r\n        gpm = float(logger.gpm)\r\n    else:\r\n        gpm = 0\r\n\r\n    if gpm != 0:\r\n        et_hours_pending_etc_mult = ((449 * acres) / (gpm * 0.85))\r\n\r\n        field_name = dbwriter.remove_unwanted_chars_for_db_dataset(logger.field.name)\r\n        project = dbwriter.get_db_project(logger.crop_type)\r\n        dataset_id = project + \".\" + field_name + \".\" + logger.id\r\n        print(\"Updating field: {0} and logger {1}\".format(field_name, logger.id))\r\n        dmlStatement = \"UPDATE `\" + dataset_id + \"` as t \\\r\n        SET t.kc = 1.1, t.etc = t.eto * 1.1, et_hours = ROUND(\" + str(et_hours_pending_etc_mult) + \" * eto * kc) \\\r\n        WHERE t.kc > 1.1\"\r\n        dbwriter.run_dml(dmlStatement, project=project)\r\n\r\n\r\ndef update_kc_values_with_a_max(logger):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(logger.field.name)\r\n    project = dbwriter.get_db_project(logger.crop_type)\r\n    dataset_id = project + \".\" + field_name + \".\" + logger.name\r\n    print(\"Updating field: {0} and logger {1}\".format(field_name, logger.name))\r\n    dml_statement = \"UPDATE `\" + dataset_id + \"` as t \\\r\n    SET t.kc = 1.1, t.etc = t.eto * 1.1 \\\r\n    WHERE t.kc > 1.1\"\r\n    dbwriter.run_dml(dml_statement, project=project)\r\n\r\n\r\ndef delete_last_day(project: str, field_name: str, logger_name: str, day=''):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n    if day == '':\r\n        today = date.today() - timedelta(days=1)\r\n    else:\r\n        today = day\r\n    dataset_id = project + \".\" + field_name + \".\" + logger_name\r\n    dmlStatement = \"Delete `\" + dataset_id + \"` where date = '\" + str(today) + \"'\"\r\n    print(dmlStatement)\r\n    try:\r\n        dbwriter.run_dml(dmlStatement, project=project)\r\n    except:\r\n        print(\"Field Not Found. Please Try With a Different Name\")\r\n\r\n\r\ndef delete_et_day(field, date, date2):\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.name == field:\r\n                for l in f.loggers:\r\n                    logger_name = l.name\r\n                    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field)\r\n                    project = dbwriter.get_db_project(l.crop_type)\r\n                    dataset_id = project + \".\" + field_name + \".\" + logger_name\r\n                    dmlStatement = \"Update `\" + dataset_id + \"` Set eto = null, etc = null, et_hours = null where date between \" + \\\r\n                                   \"date('\" + date + \"') and date('\" + date2 + \"') \"\r\n                    print(dmlStatement)\r\n                    dbwriter.run_dml(dmlStatement, project=project)\r\n                    # update_missing_et_data(l)\r\n\r\n\r\ndef delete_negative_et(field, date, kc):\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.name == field:\r\n                for l in f.loggers:\r\n                    logger_name = l.name\r\n                    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field)\r\n                    project = dbwriter.get_db_project(l.crop_type)\r\n                    dataset_id = project + \".\" + field_name + \".\" + logger_name\r\n                    dmlStatement = \"Update `\" + dataset_id + \"` Set eto = null, etc = null, et_hours = null, kc = \" + \\\r\n                                   kc + \" where date = '\" + date + \"'\"\r\n                    print(dmlStatement)\r\n                    dbwriter.run_dml(dmlStatement, project=project)\r\n                    # update_missing_et_data(l)\r\n\r\n\r\ndef get_average_psi_during_growth():\r\n    start_cut = 8\r\n    end_cut = 21\r\n    psi_averages = {}\r\n    datasets = dbwriter.get_datasets()\r\n    for d in datasets[0]:\r\n        if d.dataset_id == 'ET':\r\n            continue\r\n        tables = dbwriter.get_tables(d.dataset_id)\r\n        dataset_psis = []\r\n        for t in tables:\r\n            psi_avg = average_table_psi(d.dataset_id, t.table_id, start_cut, end_cut)\r\n            dataset_psis.append(psi_avg)\r\n        dataset_psi_avg = numpy.mean(dataset_psis)\r\n        psi_averages[d.dataset_id] = dataset_psi_avg\r\n        print()\r\n        print(d.dataset_id, 'psi average:')\r\n        print(dataset_psi_avg)\r\n        print()\r\n\r\n    pprint.pprint(psi_averages)\r\n\r\n\r\ndef all_tables_analysis(crop=None, project='stomato'):\r\n    all_dataset_ats = []\r\n    all_dataset_vpds = []\r\n    all_dataset_rhs = []\r\n    all_dataset_psi = []\r\n\r\n    start_cut = 0\r\n    end_cut = 0\r\n\r\n    field_count = 0\r\n    logger_count = 0\r\n\r\n    if crop is not None:\r\n        fields_with_crop = get_fields_for_crop(crop)\r\n        for field in fields_with_crop:\r\n            field_count = field_count + 1\r\n            for logger in field.loggers:\r\n                logger_count = logger_count + 1\r\n                field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field.name)\r\n                psi_avg = average_table_psi(project, field_name, logger.name, start_cut, end_cut)\r\n                at_avg, vpd_avg, rh_avg = table_analysis(project, field_name, logger.name)\r\n                all_dataset_ats.append(at_avg)\r\n                all_dataset_vpds.append(vpd_avg)\r\n                all_dataset_rhs.append(rh_avg)\r\n                all_dataset_psi.append(psi_avg)\r\n            # time.sleep(5)\r\n    else:\r\n        datasets = dbwriter.get_datasets()\r\n\r\n        for d in datasets[0]:\r\n            if d.dataset_id == 'ET':\r\n                continue\r\n            field_count = field_count + 1\r\n            tables = dbwriter.get_tables(d.dataset_id)\r\n            for t in tables:\r\n                if t.table_id == 'Lat Long Trial':\r\n                    continue\r\n                logger_count = logger_count + 1\r\n                at_avg, vpd_avg, rh_avg = table_analysis(project, d.dataset_id, t.table_id)\r\n                psi_avg = average_table_psi(d.dataset_id, t.table_id, start_cut, end_cut)\r\n                all_dataset_ats.append(at_avg)\r\n                all_dataset_vpds.append(vpd_avg)\r\n                all_dataset_rhs.append(rh_avg)\r\n                all_dataset_psi.append(psi_avg)\r\n\r\n    all_dataset_at_avg = numpy.mean(all_dataset_ats)\r\n    all_dataset_vpd_avg = numpy.mean(all_dataset_vpds)\r\n    all_dataset_rh_avg = numpy.mean(all_dataset_rhs)\r\n    all_dataset_psi_avg = numpy.mean(all_dataset_psi)\r\n    print()\r\n    print('Total fields processed: ', field_count)\r\n    print('Total loggers processed: ', logger_count)\r\n    if crop is not None:\r\n        print('Only showing fields with crop: ', crop)\r\n    print('All Ambient Temp Avg: {}'.format(all_dataset_at_avg))\r\n    print('All VPD Avg: {}'.format(all_dataset_vpd_avg))\r\n    print('All RH Avg: {}'.format(all_dataset_rh_avg))\r\n    print('All PSI Avg: {}'.format(all_dataset_psi_avg))\r\n\r\n\r\ndef get_fields_for_crop(crop):\r\n    count = 0\r\n    fields_with_crop = []\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.loggers[0].crop_type == crop:\r\n                fields_with_crop.append(f)\r\n                count = count + 1\r\n    print('{} total fields for {} found'.format(count, crop))\r\n    return fields_with_crop\r\n\r\n\r\ndef average_table_psi(project, field_name, logger_name, start_cut=0, end_cut=0):\r\n    print('Grabbing psi average: ' + str(field_name) + ' ' + str(logger_name))\r\n    dml = \"SELECT date, psi FROM \" \\\r\n          + \"`\" + project + \".\" + str(field_name) + \".\" + str(logger_name) + \"`\" \\\r\n          + \" WHERE psi is not NULL ORDER BY date ASC\"\r\n    result = dbwriter.run_dml(dml, project=project)\r\n    date_list = []\r\n    psi_list = []\r\n    for e in result:\r\n        date = e[\"date\"]\r\n        psi = e['psi']\r\n\r\n        date_list.append(date)\r\n        psi_list.append(psi)\r\n\r\n    if start_cut != 0 and end_cut != 0:\r\n        new_date_list = date_list[start_cut:-end_cut]\r\n        new_psi_list = psi_list[start_cut:-end_cut]\r\n    else:\r\n        new_date_list = date_list\r\n        new_psi_list = psi_list\r\n    psi_avg = numpy.mean(new_psi_list)\r\n    # print('\\t Logger:',logger)\r\n    # print('\\t Psi avg:',psi_avg)\r\n    print('Analysing: {} - {}'.format(field_name, logger_name))\r\n    print('PSI Avg: ', psi_avg)\r\n\r\n    return psi_avg\r\n\r\n\r\ndef table_analysis(project: str, field: str, logger: str):\r\n    print('Grabbing at, vpd and rh averages: ' + str(field) + ' ' + str(logger))\r\n    dml = \"SELECT date, ambient_temperature, vpd, rh, psi FROM \" \\\r\n          + \"`stomato.\" + str(field) + \".\" + str(logger) + \"`\" \\\r\n          + \" WHERE ambient_temperature is not NULL and vpd is not NULL and rh is not NULL ORDER BY date ASC\"\r\n    result = dbwriter.run_dml(dml, project=project)\r\n    date_list = []\r\n    at_list = []\r\n    vpd_list = []\r\n    rh_list = []\r\n    # psi_list = []\r\n    for e in result:\r\n        date = e[\"date\"]\r\n        at = e['ambient_temperature']\r\n        vpd = e['vpd']\r\n        rh = e['rh']\r\n        # psi = e['psi']\r\n\r\n        date_list.append(date)\r\n        at_list.append(at)\r\n        vpd_list.append(vpd)\r\n        rh_list.append(rh)\r\n        # psi_list.append(psi)\r\n\r\n    at_avg = numpy.mean(at_list)\r\n    vpd_avg = numpy.mean(vpd_list)\r\n    rh_avg = numpy.mean(rh_list)\r\n    # psi_avg = numpy.mean(psi_list)\r\n\r\n    print('Analysing: {} - {}'.format(field, logger))\r\n    print('Ambient Temp Avg: ', at_avg)\r\n    print('VPD Avg: ', vpd_avg)\r\n    print('RH Avg: ', rh_avg)\r\n    # print('PSI Avg: ', psi_avg)\r\n    print()\r\n    # print('\\t Logger:',logger)\r\n    # print('\\t Psi avg:',psi_avg)\r\n    return at_avg, vpd_avg, rh_avg  ##, psi_avg\r\n\r\n\r\ndef setupIrrigationSchedulingDB(etStation:int, fieldName:str, startDate:date, endDate:date, yearIrr:int):\r\n    \"\"\"\r\n    Sets up the Irrigation Scheduling Table for a Field in the DB\r\n    :param etStation: ET Statin Number\r\n    :param fieldName: Field Name\r\n    :param startDate: Start Date\r\n    :param endDate: End Date\r\n    :param yearIrr: Year Irr. Scheduling is being set up for\r\n    \"\"\"\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(fieldName)\r\n    # Save Historical ET onto Dict\r\n    et_value = returnHistoricalETDict(etStation, startDate, endDate)\r\n    date_time_et_value = {}\r\n    for date_point in et_value:\r\n        date_time_et_value[datetime.combine(date_point, datetime.min.time())] = et_value[date_point]\r\n    # Get Logger Object to Retrieve KC\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.name == fieldName:\r\n                for l in f.loggers:\r\n                    logger = l\r\n    # Make a Dictionary of Lists that will have Dates from last year\r\n    datesDict = {\"dates\": []}\r\n    for d in range(0, 365):\r\n        datesDict[\"dates\"].append(datetime.combine(date(yearIrr - 1, 1, 1) + relativedelta(days=d), datetime.min.time()))\r\n    # Get Historical KC and return as a Dict with Dates\r\n    print(\"Getting Historical KC Values\")\r\n    datesDict = logger.get_kc(datesDict)\r\n    # Set up Dictionaries for KC, ETo and lists for Dates and KC to allow calculation of ETc and ET hours to be easier\r\n    kcDict = {}\r\n    datesList = []\r\n    kcList = []\r\n    # Need this dictionary to be different from the other kc dictionary\r\n    # New KC dictionary will be used to merge into a nested dictionary for CSV writing\r\n    kcDictOnly = {'KC': []}\r\n    etValueDict = {'Historical Eto': []}\r\n    # Separate Historical KC and dates into its own lists\r\n    for key, value in datesDict.items():\r\n        if key == 'dates':\r\n            datesList = value\r\n        elif key == 'kc':\r\n            kcList = value\r\n            kcDictOnly['KC'] = kcList\r\n    # Merge dates and kc into a dictionary\r\n    for dates, kc in zip(datesList, kcList):\r\n        kcDict[dates] = kc\r\n\r\n    # Setup ETC dictionary and ET hours dictionary for writing to csv\r\n    etcDict = {\r\n        'Historical Etc': []\r\n    }\r\n    etHoursDict = {\r\n        'Historical Hours': []\r\n    }\r\n\r\n    # Calculate etc and et hours; Store Eto dictionary for writing to csv\r\n    for dates in date_time_et_value:\r\n        etcDict['Historical Etc'].append(date_time_et_value[dates] * kcDict[dates])\r\n        etHoursDict['Historical Hours'].append(\r\n            round((etcDict['Historical Etc'][-1] * 449 * float(logger.irrigation_set_acres)) / (float(logger.gpm) * 0.85), 0))\r\n        etValueDict['Historical Eto'].append(date_time_et_value[dates])\r\n\r\n    # Setup future dates dictionary for writing to CSV\r\n    currentDateDict = {'currentDate': []}\r\n    for d in range(0, 365):\r\n        currentDateDict[\"currentDate\"].append((date(yearIrr, 1, 1) + relativedelta(days=d)))\r\n\r\n    # Merge future Dates, eto, kc, etc, and et hours into a dictionary of dictionaries containing lists for csv writing\r\n    csvDict = {**currentDateDict, **etValueDict, **kcDictOnly, **etcDict, **etHoursDict}\r\n    # print(csvDict)\r\n\r\n    # Write csv Dict onto irrScheduling csv and then create DB for Field using irrScheduling csv\r\n    Decagon.update_irr_scheduling(field_name + '_Irr_Scheduling', field_name, csvDict, overwrite=True, logger=logger)\r\n\r\n\r\ndef returnHistoricalETDict(etStation:int, startDate:date, endDate:date)->dict:\r\n    \"\"\"\r\n    Returns a dictionary with the historical average ET date and value\r\n    :param etStation: ET station\r\n    :param startDate: Start Date\r\n    :param endDate: End Date\r\n    :return: Dictionary of historical average ET date and value\r\n    \"\"\"\r\n    # Returns last year dates and averages of Historical ET into a Dictionary\r\n    project = 'stomato-info'\r\n    et_id = project + \".Historical_ET.\" + str(etStation)\r\n    last_year = \"Year_\" + str(startDate.year)\r\n    dml_statement = \"select \" + last_year + \", Average from \" + et_id + \\\r\n                    \" where \" + last_year + \" between date('\" + str(startDate) + \\\r\n                    \"') and date('\" + str(endDate) + \"') order by \" + last_year\r\n    etValue = dbwriter.return_query_dict(dml_statement, last_year, 'Average', project)\r\n    return etValue\r\n\r\n\r\ndef move_logger_db_info(project:str, field_name:str, new_logger_name:str, old_logger_name:str):\r\n    \"\"\"\r\n    Use if copying data from an old logger to a new logger table\r\n    :param project: Big Query Project\r\n    :param field_name: Field Name\r\n    :param new_logger_name: New Logger Name\r\n    :param old_logger_name: Old Logger Name\r\n    \"\"\"\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n    new_logger_dataset = project + \".\" + field_name + \".\" + new_logger_name\r\n    old_logger_dataset = project + \".\" + field_name + \".\" + old_logger_name\r\n\r\n    print(\"Updating data for table: \" + new_logger_dataset)\r\n    print(\" from\")\r\n    print(\"old logger table: \" + old_logger_dataset)\r\n\r\n    # Use when eto is not NULL\r\n    dml_statement = \"MERGE `\" + new_logger_dataset + \"` T \" \\\r\n                    + \"USING `\" + old_logger_dataset + \"` S \" \\\r\n                    + \"ON T.date = S.date \" \\\r\n                    + \"WHEN NOT MATCHED THEN \" \\\r\n                    + \"INSERT (logger_id, date, time, canopy_temperature, ambient_temperature, vpd, vwc_1, vwc_2, vwc_3, \" \\\r\n                      \"field_capacity, wilting_point,  daily_gallons, daily_switch, daily_hours, daily_pressure, \" \\\r\n                      \"daily_inches, psi, psi_threshold, psi_critical, sdd, rh, eto, kc, etc, et_hours, \" \\\r\n                      \"phase1_adjustment, phase1_adjusted, phase2_adjustment, phase2_adjusted, phase3_adjustment, \" \\\r\n                      \"phase3_adjusted, vwc_1_ec, vwc_2_ec, vwc_3_ec) \" \\\r\n                    + \"Values (S.logger_id, S.date,    S.time, S.canopy_temperature, S.ambient_temperature, S.vpd, S.vwc_1, S.vwc_2, S.vwc_3, \" \\\r\n                      \"S.field_capacity, S.wilting_point,  S.daily_gallons, S.daily_switch, S.daily_hours, S.daily_pressure, \" \\\r\n                      \"S.daily_inches, S.psi, S.psi_threshold, S.psi_critical, S.sdd, S.rh, S.eto, S.kc, S.etc, S.et_hours, \" \\\r\n                      \"S.phase1_adjustment, S.phase1_adjusted, S.phase2_adjustment, S.phase2_adjusted, S.phase3_adjustment, \" \\\r\n                      \"S.phase3_adjusted, S.vwc_1_ec, S.vwc_2_ec, S.vwc_3_ec)\"\r\n\r\n    dbwriter.run_dml(dml_statement, project=project)\r\n\r\n    print(\"Changing logger_id to match new one in old data\")\r\n    dml_statement = (\r\n            \"Update `\" + new_logger_dataset + \"`  set logger_id = '\" + new_logger_name + \"' where logger_id = '\" + old_logger_name + \"'\")\r\n    # print(dml_statement)\r\n    dbwriter.run_dml(dml_statement, project=project)\r\n    print(\"Clean up nulls\")\r\n    dml_statement = (\"Delete `\" + new_logger_dataset + \"` where date is NULL\")\r\n    dbwriter.run_dml(dml_statement, project=project)\r\n\r\n\r\ndef update_field_et(fieldName):\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        # if g.name == fieldName:\r\n        for f in g.fields:\r\n            if f.name == fieldName:\r\n                for l in f.loggers:\r\n                    # print(\"doing et\")\r\n                    update_missing_et_data(l)\r\n\r\n\r\ndef update_all_field_et():\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        for f in g.fields:\r\n            if f.active:\r\n                for l in f.loggers:\r\n                    try:\r\n                        update_missing_et_data(l)\r\n                    except:\r\n                        print(\"Couldn't update et for field: \", f.name,\r\n                              \"\\n logger: \", l.name)\r\n\r\n\r\ndef update_logger_et(fieldName, loggerName):\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        # if g.name == fieldName:\r\n        for f in g.fields:\r\n            if f.name == fieldName:\r\n                for l in f.loggers:\r\n                    if l.name == loggerName:\r\n                        update_missing_et_data(l)\r\n\r\n\r\ndef delete_where_eto_is_null(logger, date1, date2):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(logger.field.name)\r\n    project = dbwriter.get_db_project(logger.crop_type)\r\n    dataset = project + \".\" + field_name + \".\" + logger.name\r\n    dml_statement = (\"Delete `\" + dataset + \"` where date between \" + \"date('\" + date1 + \"') and date('\" + date2 + \"') \"\r\n                     + 'and eto is null')\r\n    dbwriter.run_dml(dml_statement, project=project)\r\n    # print(dml_statement)\r\n\r\n\r\ndef update_fc_wp(project, field_name_pickle, logger_name, fc, wp):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field_name_pickle)\r\n    dataset = project + \".\" + field_name + \".\" + logger_name\r\n    dml_statement = (\r\n            \"Update `\" + dataset + \"`  set field_capacity = \" + str(fc) + \", wilting_point = \" + str(wp) +\r\n            \" where date is not null\")\r\n    print(dml_statement)\r\n    dbwriter.run_dml(dml_statement, project=project)\r\n    print('Done updating data studio')\r\n    growers = Decagon.open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            if field.name == field_name_pickle:\r\n                for logger in field.loggers:\r\n                    if logger.name == logger_name:\r\n                        logger.soil.set_field_capacity_wilting_point(fc, wp)\r\n                        print(\"Updated FC and WP in pickle\")\r\n    Decagon.write_pickle(growers)\r\n\r\n\r\ndef update_portal_image(grower_name, field_name, image_url, portal_year, update_db=True):\r\n    client = DBWriter.grab_bq_client(dbwriter, 'growers-' + portal_year)\r\n    # field.preview_url = imageUrl\r\n    # print(\"Updated image preview in pickle for field: \" + field.name)\r\n    if update_db:\r\n        grower_name_db = DBWriter.remove_unwanted_chars_for_db_dataset(dbwriter, grower_name)\r\n        field_averages_portal_dataset_id = client.project + \".\" + grower_name_db + '.field_averages'\r\n        dml_statement = (\r\n                \"Update `\" + field_averages_portal_dataset_id + \"`  set preview = '\" + image_url +\r\n                \"' where field = '\" + field_name + \"'\")\r\n        print(dml_statement)\r\n        dbwriter.run_dml(dml_statement, project=client.project)\r\n        print('Done updating portal')\r\n    print('Done updating pickle')\r\n\r\n\r\ndef remove_duplicate_data(logger):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(logger.field.name)\r\n    project = dbwriter.get_db_project(logger.crop_type)\r\n    dataset = field_name + \".\" + logger.name\r\n    dml_statement = (\"CREATE OR REPLACE TABLE `\" + project + \".\" + dataset +\r\n                     \"`AS SELECT * from ( SELECT *, ROW_NUMBER() OVER (PARTITION BY date order by ambient_temperature desc) row_number \"\r\n                     \"FROM `\" + dataset + \"`) WHERE row_number = 1 \")\r\n    # print(dml_statement)\r\n    print(\"Removing Duplicate data for field: \", logger.field.name, \"\\n \\t For logger: \", logger.name)\r\n    # After removing duplicates a new column gets added, only way to bypass this is by\r\n    # specifying which columns to select in from clause\r\n    try:\r\n        dbwriter.run_dml(dml_statement, project=project)\r\n        drop_column(project, dataset, \"row_number\")\r\n    except exceptions.BadRequest as err:\r\n        print(\"Bad Request Error: \", err)\r\n\r\n\r\ndef drop_column(project, dataset, column):\r\n    print(\"\\t Dropping extra column\")\r\n    dml_statement = (\"alter table \" + \"`\" + project + \".\" + dataset + \"` drop column \" + column)\r\n    # print(dml_statement)\r\n    try:\r\n        dbwriter.run_dml(dml_statement, project=project)\r\n    except exceptions.BadRequest as err:\r\n        print(\"Bad Request Error: \", err)\r\n\r\n\r\ndef fix_weather_db(field):\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field.name)\r\n    project = dbwriter.get_db_project(field.loggers[0].crop_type)\r\n    dataset = field_name + \".weather_forecast`\"\r\n    today = datetime.today() - timedelta(days=1)\r\n    day = str(today.day)\r\n    month = str(today.month)\r\n    year = str(today.year)\r\n    date = year + \"-\" + month + \"-\" + day\r\n    # print(date)\r\n\r\n    dml_statement = (\"Update `\" + project + \".\" + dataset + \" as t\" + \" Set t.order = 99 where t.date < \" + \"'\" + date + \"'\")\r\n    dbwriter.run_dml(dml_statement, project=project)\r\n    print(f\"Finished fixing weather for {field.name}\")\r\n    # print(dml_statement)\r\n\r\n\r\ndef grab_historical_data(etStation: int, newStation: bool = False):\r\n    \"\"\"\r\n    Function creates a new historical ET table for etStation\r\n    :param etStation: Et Station\r\n    :param newStation: Boolean if ET Station doesn't exist in DB\r\n    \"\"\"\r\n\r\n    dataset = \"Historical_ET\"\r\n    # etTableHeaders = ['Year_2022', 'Year_2021', 'Year_2020', 'Year_2019', 'Year_2018']\r\n    # Get Tables that exist\r\n    tables = dbwriter.get_tables(\"Historical_ET\", project=\"stomato-info\")\r\n    tableFound = False\r\n\r\n    # Loop through existing tables checking to see if Historical ET Table already exists, if not create a new table\r\n    try:\r\n        for table in tables:\r\n            if table.table_id == etStation:\r\n                print('\\tFound Historical ET For ET station \\n\\t\\t Overwriting Historical Table')\r\n                print(table.table_id)\r\n                tableFound = True\r\n        if not tableFound:\r\n            print(\"\\tDidn't Find Historical ET Table \\nCreating Table\")\r\n\r\n            client = bigquery.Client()\r\n            schema = [\r\n                bigquery.SchemaField(\"Year_2022\", \"DATE\", mode=\"NULLABLE\"),\r\n                bigquery.SchemaField(\"Year_2022_ET\", \"Float\", mode=\"NULLABLE\"),\r\n                bigquery.SchemaField(\"Year_2021\", \"DATE\", mode=\"NULLABLE\"),\r\n                bigquery.SchemaField(\"Year_2021_ET\", \"Float\", mode=\"NULLABLE\"),\r\n                bigquery.SchemaField(\"Year_2020\", \"DATE\", mode=\"NULLABLE\"),\r\n                bigquery.SchemaField(\"Year_2020_ET\", \"Float\", mode=\"NULLABLE\"),\r\n                bigquery.SchemaField(\"Year_2019\", \"DATE\", mode=\"NULLABLE\"),\r\n                bigquery.SchemaField(\"Year_2019_ET\", \"Float\", mode=\"NULLABLE\"),\r\n                bigquery.SchemaField(\"Year_2018\", \"DATE\", mode=\"NULLABLE\"),\r\n                bigquery.SchemaField(\"Year_2018_ET\", \"Float\", mode=\"NULLABLE\"),\r\n                bigquery.SchemaField(\"Average\", \"Float\", mode=\"NULLABLE\")\r\n            ]\r\n            query_dataset = \"stomato-info.Historical_ET.\" + str(etStation)\r\n            table = bigquery.Table(query_dataset, schema=schema)\r\n        # If et station is a new station,\r\n        if newStation:\r\n            etDict2022, etDict2021, etDict2020, etDict2019, etDict2018, etDictAverage = return_historical_data_for_new_station(str(etStation))\r\n            if not tableFound:\r\n                table = client.create_table(table)  # Make an API request.\r\n                print(\r\n                    \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\r\n                )\r\n        else:\r\n            etDict2022, etDict2021, etDict2020, etDict2019, etDict2018, etDictAverage = returnHistoricalData(str(etStation))\r\n            if not tableFound:\r\n                table = client.create_table(table)  # Make an API request.\r\n                print(\r\n                    \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\r\n                )\r\n\r\n        # print(etDictAverage)\r\n\r\n        csvDict = etDict2022 | etDict2021 | etDict2020 | etDict2019 | etDict2018 | etDictAverage\r\n\r\n        Decagon.write_new_historical_et_to_db_2(dataset, str(etStation), csvDict, overwrite=True)\r\n\r\n        print(\"Done inserting values\")\r\n\r\n    except Exception as err:\r\n        print(\"ET Station Not In Database\")\r\n        print(err)\r\n\r\n\r\ndef returnHistoricalData(etStation):\r\n    print(\"Grabbing previous years historical data\")\r\n\r\n    et_id_old = \"stomato.ET.\" + str(etStation)\r\n    etValue = []\r\n    startDate = '2022-01-01'\r\n    endDate = '2022-12-31'\r\n    dml_statement = \"select date, eto from \" + et_id_old + \\\r\n                    \" as t where t.date between date('\" + str(startDate) + \\\r\n                    \"') and date('\" + str(endDate) + \"') order by date asc\"\r\n    etValue2022 = dbwriter.return_query_dict(dml_statement, 'date', 'eto', 'stomato')\r\n    etValue.append(etValue2022)\r\n\r\n    et_id = \"stomato.Historical_ET.\" + str(etStation)\r\n    startDate = '2021-01-01'\r\n    endDate = '2021-12-31'\r\n    dml_statement = \"select Year1, Year1ET from \" + et_id + \\\r\n                    \" where Year1 between date('\" + str(startDate) + \\\r\n                    \"') and date('\" + str(endDate) + \"') order by Year1\"\r\n    etValue2021 = dbwriter.return_query_dict(dml_statement, 'Year1', 'Year1ET', 'stomato')\r\n    etValue.append(etValue2021)\r\n\r\n    startDate = '2020-01-01'\r\n    endDate = '2020-12-31'\r\n    dml_statement = \"select Year2, Year2ET from \" + et_id + \\\r\n                    \" where Year2 between date('\" + str(startDate) + \\\r\n                    \"') and date('\" + str(endDate) + \"') order by Year2\"\r\n    etValue2020 = dbwriter.return_query_dict(dml_statement, 'Year2', 'Year2ET', 'stomato')\r\n    etValue.append(etValue2020)\r\n\r\n    startDate = '2019-01-01'\r\n    endDate = '2019-12-31'\r\n    dml_statement = \"select Year3, Year3ET from \" + et_id + \\\r\n                    \" where Year3 between date('\" + str(startDate) + \\\r\n                    \"') and date('\" + str(endDate) + \"') order by Year3\"\r\n    etValue2019 = dbwriter.return_query_dict(dml_statement, 'Year3', 'Year3ET', 'stomato')\r\n    etValue.append(etValue2019)\r\n\r\n    startDate = '2018-01-01'\r\n    endDate = '2018-12-31'\r\n    dml_statement = \"select Year4, Year4ET from \" + et_id + \\\r\n                    \" where Year4 between date('\" + str(startDate) + \\\r\n                    \"') and date('\" + str(endDate) + \"') order by Year4\"\r\n    etValue2018 = dbwriter.return_query_dict(dml_statement, 'Year4', 'Year4ET', 'stomato')\r\n    etValue.append(etValue2018)\r\n\r\n    # pprint.pprint(etValue[0])\r\n    startDate = '2022-01-01'\r\n    endDate = '2022-12-31'\r\n    start = datetime.strptime(startDate, '%Y-%m-%d').date()\r\n    end = datetime.strptime(endDate, '%Y-%m-%d').date()\r\n    # print(dt)\r\n    # pprint.pprint(etValue[0][start])\r\n    dict2022 = {'Year_2022': [], 'Year_2022_ET': []}\r\n    dict2021 = {'Year_2021': [], 'Year_2021_ET': []}\r\n    dict2020 = {'Year_2020': [], 'Year_2020_ET': []}\r\n    dict2019 = {'Year_2019': [], 'Year_2019_ET': []}\r\n    dict2018 = {'Year_2018': [], 'Year_2018_ET': []}\r\n    dictAverage = {'Average': []}\r\n\r\n    for single_date in daterange(start, end + relativedelta(days=1)):\r\n        etValue2022 = etValue[0][single_date]\r\n        dict2022['Year_2022_ET'].append(etValue2022)\r\n        dict2022['Year_2022'].append(single_date)\r\n        single_date = single_date - relativedelta(years=1)\r\n        etValue2021 = etValue[1][single_date]\r\n        dict2021['Year_2021_ET'].append(etValue2021)\r\n        dict2021['Year_2021'].append(single_date)\r\n        single_date = single_date - relativedelta(years=1)\r\n        etValue2020 = etValue[2][single_date]\r\n        dict2020['Year_2020_ET'].append(etValue2020)\r\n        dict2020['Year_2020'].append(single_date)\r\n        single_date = single_date - relativedelta(years=1)\r\n        etValue2019 = etValue[3][single_date]\r\n        dict2019['Year_2019_ET'].append(etValue2019)\r\n        dict2019['Year_2019'].append(single_date)\r\n        single_date = single_date - relativedelta(years=1)\r\n        etValue2018 = etValue[4][single_date]\r\n        dict2018['Year_2018_ET'].append(etValue2018)\r\n        dict2018['Year_2018'].append(single_date)\r\n        average_list = [etValue2021, etValue2020, etValue2019, etValue2018]\r\n        dictAverage['Average'].append(mean(average_list))\r\n\r\n    return dict2022, dict2021, dict2020, dict2019, dict2018, dictAverage\r\n\r\n\r\ndef return_cimis_data_in_dict(etStation, startDate, endDate, dateKey, valueKey):\r\n    \"\"\"\r\n\r\n    :param etStation: CIMIS ET station number\r\n    :param startDate: start date of cimis data\r\n    :param endDate: end date of cimis data\r\n    :param dateKey: the name of key that will be containing the ET dates\r\n    :param valueKey: the name of the key that will be containing the ET values\r\n    :return:\r\n    \"\"\"\r\n    cimis = CIMIS()\r\n    etos = cimis.get_eto(targets=[etStation], start_date=startDate, end_date=endDate)\r\n\r\n    try:\r\n        if etos is None:\r\n            print(\"ETo is none, Issue with API Call\")\r\n            return None\r\n        elif len(etos['Data']['Providers'][0]['Records']) == 0:\r\n            print('ETo call is returning blank list for values. Usually indicates station is inactive')\r\n            print(f'Station: {etStation}')\r\n            return None\r\n    except Exception as error:\r\n        print('ERROR in grabbing actual eto values from API return')\r\n        print(error)\r\n\r\n    etDict = {dateKey: [],\r\n              valueKey: []}\r\n\r\n    if etos['Data']['Providers'][0]['Records']:\r\n        cimis_et_data = etos['Data']['Providers'][0]['Records']\r\n        for single_et_data_point in cimis_et_data:\r\n            # Need to ignore extra day since it only happens once every 4 years\r\n            if single_et_data_point['Date'][-5:] == '02-29':\r\n                continue\r\n            else:\r\n                etDict[dateKey].append(single_et_data_point['Date'])\r\n                etDict[valueKey].append(single_et_data_point['DayEto']['Value'])\r\n    return etDict\r\n\r\n\r\ndef return_if_et_table_found(etStation):\r\n    \"\"\"\r\n\r\n    :param etStation: CIMIS ET station number\r\n    :return: returns True if ET station was found in Historical_ET dataset\r\n    \"\"\"\r\n    tables = dbwriter.get_tables(\"Historical_ET\", project=\"stomato-info\")\r\n    tableFound = False\r\n\r\n    for table in tables:\r\n        # print(table.table_id)\r\n        if table.table_id == str(etStation):\r\n            # print(table.table_id)\r\n            tableFound = True\r\n\r\n    return tableFound\r\n\r\n\r\ndef fix_irr_inches_for_all_fields(start_date, end_date):\r\n    \"\"\"\r\n\r\n    :param start_date: date you want fixes to start\r\n    :param end_date: date you want fixes to end\r\n    \"\"\"\r\n    growers = Decagon.open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            if field.active:\r\n                print(f\"Fixing Irrigation for Field: {field.name}\")\r\n                for logger in field.loggers:\r\n                    print(f\"\\tWorking on logger {logger.name}\")\r\n                    select_irr_hours_for_date(logger, start_date, end_date)\r\n\r\n\r\ndef select_irr_hours_for_date(loggers, start_date, end_date):\r\n    \"\"\"\r\n\r\n    :param loggers: logger object from pickle\r\n    :param start_date: date you want fixes to start\r\n    :param end_date: date  you want fixes to end\r\n    \"\"\"\r\n    project = dbwriter.get_db_project(loggers.crop_type)\r\n    field_db = dbwriter.remove_unwanted_chars_for_db_dataset(loggers.field.name)\r\n    dataset = f\"`{project}.{field_db}.{loggers.name}`\"\r\n    dml_statement = \"select date, daily_switch from \" + dataset + \\\r\n                    \" where date between date('\" + str(start_date) + \\\r\n                    \"') and date('\" + str(end_date) + \"')\"\r\n    # print(dml_statement)\r\n    daily_switch_dates_dictionary = dbwriter.return_query_dict(dml_statement, 'date', 'daily_switch', project)\r\n    #  Loop through all dates and update inches for each date\r\n    for date_data in daily_switch_dates_dictionary:\r\n        daily_hours = daily_switch_dates_dictionary[date_data] / 60\r\n        update_irrigation_hours_for_date(project, loggers.field.name, loggers.name, daily_hours, str(date_data))\r\n\r\n\r\ndef fill_missing_dates(dates: list[date], start_date: str, end_date: str) -> tuple[list[str], list[int]]:\r\n    filled_dates = []\r\n    missing_indexes = []\r\n    date_format = \"%Y-%m-%d\"\r\n    start_date = datetime.strptime(start_date, date_format)\r\n    end_date = datetime.strptime(end_date, date_format)\r\n    delta = timedelta(days=1)\r\n    current_date = start_date\r\n    index = 0\r\n\r\n    while current_date <= end_date:\r\n        if current_date.month == 2 and current_date.day == 29:\r\n            current_date += delta\r\n            continue\r\n        elif index < len(dates) and dates[index] == current_date.strftime(date_format):\r\n            filled_dates.append(dates[index])\r\n            index += 1\r\n        else:\r\n            filled_dates.append(current_date.strftime(date_format))\r\n            missing_indexes.append(len(filled_dates) - 1)\r\n        current_date += delta\r\n\r\n    return filled_dates, missing_indexes\r\n\r\n\r\ndef fill_missing_et(et_list: list, index: list[int]):\r\n    for each_index in index:\r\n        et_list.insert(each_index, '0.00')\r\n    return et_list\r\n\r\n\r\ndef copy_missing_data_to_logger_from_other_logger(field_name: str, logger_destination_name: str, logger_source_name: str):\r\n    \"\"\"\r\n    :param field_name: Name of field\r\n    :param logger_destination_name: Name of logger that is missing data\r\n    :param logger_source_name: Name of logger that has data\r\n    \"\"\"\r\n    field = ''\r\n    logger_destination = ''\r\n    logger_source = ''\r\n\r\n    growers = Decagon.open_pickle()\r\n    for grower_pickle in growers:\r\n        for field_pickle in grower_pickle.fields:\r\n            if field_pickle.name == field_name:\r\n                field = field_pickle\r\n                for logger_pickle in field.loggers:\r\n                    if logger_pickle.name == logger_destination_name and logger_pickle.active:\r\n                        logger_destination = logger_pickle\r\n                    elif logger_pickle.name == logger_source_name and logger_pickle.active:\r\n                        logger_source = logger_pickle\r\n\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field.name)\r\n    project = dbwriter.get_db_project(logger_destination.crop_type)\r\n\r\n    logger_source_dataset = project + \".\" + field_name + \".\" + logger_source.name\r\n    logger_destination_dataset = project + \".\" + field_name + \".\" + logger_destination.name\r\n\r\n    print(\"Inserting data for table: \" + logger_destination_dataset)\r\n    print(\" from\")\r\n    print(\"Logger table: \" + logger_source_dataset)\r\n\r\n    # Use when eto is not NULL\r\n    dml_statement = \"MERGE `\" + logger_destination_dataset + \"` T \" \\\r\n                    + \"USING `\" + logger_source_dataset + \"` S \" \\\r\n                    + \"ON T.date = S.date \" \\\r\n                    + \"WHEN NOT MATCHED THEN \" \\\r\n                    + \"INSERT (logger_id, date, time, canopy_temperature, ambient_temperature, vpd, vwc_1, vwc_2, vwc_3, \" \\\r\n                      \"field_capacity, wilting_point,  daily_gallons, daily_switch, daily_hours, daily_pressure, \" \\\r\n                      \"daily_inches, psi, psi_threshold, psi_critical, sdd, rh, eto, kc, etc, et_hours, \" \\\r\n                      \"phase1_adjustment, phase1_adjusted, phase2_adjustment, phase2_adjusted, phase3_adjustment, \" \\\r\n                      \"phase3_adjusted, vwc_1_ec, vwc_2_ec, vwc_3_ec) \" \\\r\n                    + \"Values (S.logger_id, S.date,    S.time, S.canopy_temperature, S.ambient_temperature, S.vpd, S.vwc_1, S.vwc_2, S.vwc_3, \" \\\r\n                      \"S.field_capacity, S.wilting_point,  S.daily_gallons, S.daily_switch, S.daily_hours, S.daily_pressure, \" \\\r\n                      \"S.daily_inches, S.psi, S.psi_threshold, S.psi_critical, S.sdd, S.rh, S.eto, S.kc, S.etc, S.et_hours, \" \\\r\n                      \"S.phase1_adjustment, S.phase1_adjusted, S.phase2_adjustment, S.phase2_adjusted, S.phase3_adjustment, \" \\\r\n                      \"S.phase3_adjusted, S.vwc_1_ec, S.vwc_2_ec, S.vwc_3_ec)\"\r\n    # print(dml_statement)\r\n    dbwriter.run_dml(dml_statement, project=project)\r\n\r\n    print(\"Changing logger_id to match new one in old data\")\r\n    dml_statement = (\r\n            \"Update `\" + logger_destination_dataset + \"`  set logger_id = '\" + logger_destination.id + \"' where logger_id = '\" + logger_source.id + \"'\")\r\n    # print(dml_statement)\r\n    dbwriter.run_dml(dml_statement, project=project)\r\n    print(\"Clean up nulls\")\r\n    dml_statement = (\"Delete `\" + logger_destination_dataset + \"` where date is NULL\")\r\n    dbwriter.run_dml(dml_statement, project=project)\r\n\r\n\r\n#Grab dates and psi where first psi was turned on. If possible pull the first 3 days of values. Loop through 2022 year dataset.\r\ndef select_first_psi_for_all_datasets():\r\n    \"\"\"\r\n    Function goes into database project for 2022 and selects the first 3 days of PSI values. It stores the data into a pickle called\r\n    psi_pickle_2022.pickle.\r\n    \"\"\"\r\n    datasets = dbwriter.get_datasets('stomato')\r\n    psi_dict = {'field': [], 'logger': [], 'dates': [], 'psi': []}\r\n    specific_file_path: str = PICKLE_DIRECTORY\r\n    filename = \"psi_pickle_2022.pickle\"\r\n    for dataset in datasets[0]:\r\n        # print(dataset.dataset_id)\r\n        tables_list = dbwriter.get_tables(dataset.dataset_id, 'stomato')\r\n        if dataset.dataset_id == '1_growers_list' or dataset.dataset_id == \"1_technician_portal\" or \\\r\n                dataset.dataset_id == \"1_uninstallation_progress\" or dataset.dataset_id == \"1_users_schema\" or \\\r\n                dataset.dataset_id == \"2022_uninstallation_progress\" or dataset.dataset_id == \"ET\" or dataset.dataset_id == \"Historical_ET\" \\\r\n                or dataset.dataset_id == \"Historical_ET_New\" or dataset.dataset_id == \"Meza\" or \"RnD\" in dataset.dataset_id \\\r\n                or dataset.dataset_id == \"SaulTest\" or dataset.dataset_id == \"YaraAyra\" or dataset.dataset_id == \"TestField\":\r\n            continue\r\n        else:\r\n            for table in tables_list:\r\n                # print(table.table_id)\r\n                if table.table_id == 'weather_forecast' or \"Irr_Scheduling\" in table.table_id or \"temp\" in table.table_id or \"copy\" in table.table_id\\\r\n                        or \"5G\" in table.table_id or \"z6\" in table.table_id:\r\n                    continue\r\n                else:\r\n                    # print(f\"Dataset: {dataset.dataset_id:<20} Table:{table.table_id:<20} Date List:{date_list:<20} PSI List:{psi_list:<20}\")\r\n                    try:\r\n                        date_list, psi_list = select_psi(dataset.dataset_id, table.table_id)\r\n                        psi_dict['field'].append(dataset.dataset_id)\r\n                        psi_dict['logger'].append(table.table_id)\r\n                        psi_dict['dates'].append(date_list)\r\n                        psi_dict['psi'].append(psi_list)\r\n                        print(f\"Working on Field: {dataset.dataset_id} \\n\\t Logger: {table.table_id}\")\r\n\r\n                    except google.api_core.exceptions.BadRequest as e:\r\n                        print(\"Caught BadRequest exception:\", e)\r\n    if path.exists(specific_file_path):\r\n        with open(specific_file_path + filename, \"wb\") as file:\r\n            pickle.dump(psi_dict, file)\r\n\r\n\r\ndef select_psi(field_name: str, logger_name: str) -> tuple[list[date], list[int]]:\r\n    \"\"\"\r\n    Function grabs first 3 values where psi occurs and returns them as a list of dates and a list of psi values\r\n    :param field_name: Dataset Field Name\r\n    :param logger_name: Dataset Logger Name\r\n    :return: date_list: List of Dates of the first 3 psi occurrences\r\n            psi_list: List of PSI of the first 3 psi occurrences\r\n    \"\"\"\r\n    field_db = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n    dataset = f\"`{'stomato'}.{field_db}.{logger_name}`\"\r\n    dml_statement = f\"select date, psi from {dataset} where psi is not null order by date asc\"\r\n    # print(dml_statement)\r\n    psi_dict = dbwriter.return_query_dict(dml_statement, 'date', 'psi', 'stomato')\r\n    psi_only_three_dict = dict(itertools.islice(psi_dict.items(),3))\r\n    date_list = list(psi_only_three_dict.keys())\r\n    psi_list = list(psi_only_three_dict.values())\r\n    return date_list, psi_list\r\n\r\ndef show_psi_pickle_2022(specific_file_path: str = PICKLE_DIRECTORY, filename: str =\"psi_pickle_2022.pickle\"):\r\n    \"\"\"\r\n    Function opens and returns psi pickle for 2022\r\n\r\n    :param specific_file_path:\r\n    :param filename:\r\n    :return:\r\n    \"\"\"\r\n    with open(specific_file_path + filename, \"rb\") as file:\r\n        data = pickle.load(file)\r\n    return data\r\n\r\n\r\ndef copy_last_day_from_old_date_to_new_date(project: str, field_name: str, logger_name: str, old_date: str, new_date: str):\r\n    \"\"\"\r\n    This function copies the old date's data from a specific logger for a specific field and inserts it into the same logger but using a different\r\n    date. This function is useful for when a logger gets disconnected for a day and we lost data for that day.\r\n    :param project: Project name\r\n    :param field_name: Field Name\r\n    :param logger_name: Logger Name\r\n    :param old_date: Old date you want to copy the information from\r\n    :param new_date: New date you want to copy the information to\r\n    \"\"\"\r\n    # Set up BigQuery client\r\n    client = dbwriter.grab_bq_client(project)\r\n    field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)\r\n    # Define the source and destination table information\r\n    source_table = f\"{project}.{field_name}.{logger_name}\"\r\n    destination_table = f\"{project}.{field_name}.{logger_name}\"\r\n    source_date = old_date  # Date of the source row\r\n    destination_date = new_date  # Date for the new row\r\n\r\n    # Query to select values from the source table for a specific date\r\n    select_query = f\"\"\"\r\n        SELECT *\r\n        FROM `{source_table}`\r\n        WHERE date = '{source_date}'\r\n    \"\"\"\r\n\r\n    query_job = client.query(select_query)\r\n    query_job.result()  # Wait for the query to complete\r\n\r\n    if query_job.errors:\r\n        print(\"Encountered errors while selecting rows.\")\r\n    else:\r\n        print(\"Rows successfully selected into the destination table.\")\r\n        for row in query_job:\r\n            # Convert the Row object to a dictionary\r\n            row_dict = dict(row)\r\n\r\n            # Set the date to the destination date\r\n            row_dict[\"date\"] = destination_date\r\n            # Convert planting date to a string and save that as the planting date. Big query will recongize it as a date time, even if it's\r\n            # inserted as string\r\n            planting_date_string = row_dict[\"planting_date\"].strftime('%Y-%m-%d')\r\n            row_dict[\"planting_date\"] = planting_date_string\r\n\r\n        # print(row_dict)\r\n        values = list(row_dict.values())\r\n\r\n        # Query to insert the selected values into the destination table with a different date\r\n        insert_query = f\"INSERT INTO `{destination_table}` \"\r\n        insert_query += \"VALUES (\"\r\n        insert_query += \", \".join([f\"{'Null' if value is None else value if not isinstance(value, str) else convert_string(value)}\" for\r\n                                   value in values])  # Loop through all the values in row_dict. If your value is None, convert into a string of Null.\r\n        # If your value is a string you want to convert that value into a string by adding a ' to the beginning and end. If not when you loop\r\n        # through the values they get inserted without the ''\r\n        insert_query += \")\"\r\n\r\n        # print(insert_query)\r\n\r\n        # Run the insert query\r\n        query_job = client.query(insert_query)\r\n        query_job.result()  # Wait for the query to complete\r\n\r\n        if query_job.errors:\r\n            print(\"Encountered errors while inserting rows.\")\r\n        else:\r\n            print(\"Rows successfully inserted into the destination table.\")\r\n\r\n\r\ndef convert_string(text):\r\n    return f\"'{text}'\"\r\n\r\ndef find_lowest_psi_fields():\r\n        \"\"\"\r\n        Function finds the lowest psi fields in the database and returns a list of the lowest psi fields.\r\n        \"\"\"\r\n        psi_list = []\r\n        logger_name_list = []\r\n        project = 'stomato-2023'\r\n        # Get list of datasets in database\r\n        client = dbwriter.grab_bq_client(project)\r\n        datasets = dbwriter.get_datasets(project)\r\n        # Loop through all datasets\r\n        for dataset in datasets[0]:\r\n            # print(f\"Working on field: {dataset.dataset_id}\")\r\n            # Get list of tables in dataset\r\n            tables = client.list_tables(dataset.dataset_id)\r\n            # Loop through all tables in dataset\r\n            for table in tables:\r\n                # print(table.table_id)\r\n                # table_id = table.table_id\r\n                if not (\"Irr_Scheduling\" in table.table_id) and not (\"weather_forecast\" in table.table_id):\r\n                    # Check if table is in algorithm list\r\n                    table_id = f\"`{project}.{dataset.dataset_id}.{table.table_id}`\"\r\n                    select_psi = f\"select avg(psi) as average_psi, count(psi) as number_of_data_points from {table_id} where psi is not null\"\r\n                    result = dbwriter.run_dml(select_psi)\r\n                    for row in result:\r\n                        if row.average_psi:\r\n                            # psi_list.append({'field': table_id,'psi':row.average_psi})\r\n                            if row.number_of_data_points > 20:\r\n                                psi_list.append(row.average_psi)\r\n                                logger_name_list.append(table.table_id)\r\n                                print(f\"{table.table_id};{row.average_psi};{row.number_of_data_points}\")\r\n\r\n        # for ind, psi in enumerate(psi_list):\r\n        #     print(f\"{logger_name_list[ind]}: {psi}\")\r\n\r\n\r\ndef generate_invite_code():\r\n    \"\"\"\r\n    Generates a random invite code\r\n    :return: Returns invite code as a 6 letter/number string\r\n    \"\"\"\r\n    invite_code = ''.join(choices(ascii_uppercase + digits, k=6))\r\n    return invite_code\r\n\r\n\r\ndef insert_grower_field(name: str, region: str, tech_assigned: str, stations: str, crop_type: str):\r\n    \"\"\"\r\n    Function inserts the growers field information in the database\r\n    :param crop_type: crop type\r\n    :param name: name of field\r\n    :param region: North or South region\r\n    :param tech_assigned: Technician assigned to field\r\n    :param stations: stations assigned to field\r\n    \"\"\"\r\n    project = 'stomato-info'\r\n    dataset = 'gradient_fields'\r\n    dataset_id = f\"`{project}.{dataset}.all`\"\r\n\r\n    dml_statement = f\"insert into {dataset_id} (name, region, tech_assigned, stations, crop_type) \" \\\r\n                    f\"values ('{name}', '{region}', '{tech_assigned}', '{stations}', '{crop_type}')\"\r\n\r\n    dbwriter.run_dml(dml_statement, project=project)\r\n\r\n\r\ndef insert_grower_loggers(grower: str, field: str, logger_name: str, logger_direction: str, lat: str, long: str, logger_id: str,\r\n                          logger_password: str, crop_type: str):\r\n    \"\"\"\r\n    Function inserts the growers logger information in the database\r\n    :param crop_type: crop type\r\n    :param grower: name of grower\r\n    :param field: name of field\r\n    :param logger_name: name of logger\r\n    :param logger_direction: direction of logger\r\n    :param lat: latitude of logger\r\n    :param long: longitude of logger\r\n    :param logger_id: logger id\r\n    :param logger_password: logger password\r\n\r\n    \"\"\"\r\n    project = 'stomato-info'\r\n    dataset = 'gradient_loggers'\r\n    dataset_id = f\"`{project}.{dataset}.all`\"\r\n\r\n    dml_statement = f\"insert into {dataset_id} (grower, field, logger_name, logger_direction, lat, long, logger_id, logger_password, crop_type) \" \\\r\n                    f\"values ('{grower}', '{field}', '{logger_name}', '{logger_direction}', '{lat}', '{long}', '{logger_id}', '{logger_password}',\" \\\r\n                    f\" '{crop_type}')\"\r\n\r\n    dbwriter.run_dml(dml_statement, project=project)\r\n\r\n\r\ndef add_new_celsius_columns_to_permanent_datasets():\r\n    \"\"\"\r\n    Function adds the canopy_temperature_celsius, ambient_temperature_celsius, lower_ambient_temperature_celsius, sdd_celsius\r\n    columns to the permanent datasets\r\n    \"\"\"\r\n    client = bigquery.Client()\r\n    growers = Decagon.open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            if (field.crop_type.lower() == 'almonds' or field.crop_type.lower() == 'almonds' or field.crop_type.lower() == 'pistachio'\r\n                    or field.crop_type.lower() == 'pistachios'):\r\n                print(f\"Field: {field.name}\")\r\n                for logger in field.loggers:\r\n                    table_id = f\"stomato-permanents.{dbwriter.remove_unwanted_chars_for_db_dataset(field.name)}.{logger.name}\"\r\n                    # print(f\"Table: {table_id}\")\r\n                    table = client.get_table(table_id)\r\n                    original_schema = table.schema\r\n                    new_schema = original_schema[:]\r\n                    new_schema.append(bigquery.SchemaField(\"canopy_temperature_celsius\", \"FLOAT\"))\r\n                    new_schema.append(bigquery.SchemaField(\"ambient_temperature_celsius\", \"FLOAT\"))\r\n                    new_schema.append(bigquery.SchemaField(\"lowest_ambient_temperature_celsius\", \"FLOAT\"))\r\n                    new_schema.append(bigquery.SchemaField(\"sdd_celsius\", \"FLOAT\"))\r\n\r\n                    table.schema = new_schema\r\n                    try:\r\n                        table = client.update_table(table, [\"schema\"])\r\n                        if len(table.schema) == len(original_schema) + 4 == len(new_schema):\r\n                            print(\"A new column has been added.\")\r\n                        else:\r\n                            print(\"The column has not been added.\")\r\n                    except Exception as e:\r\n                        print(f\"Error updating table schema: {e}\")\r\n\r\ndef add_new_year_to_historical_et(specific_station:str = None):\r\n    \"\"\"\r\n    Updates table schema and data and recalculates table averages\r\n    :param specific_station: Specific station name to update historical et table for. If not specified, all active cimis stations will be updated\r\n    \"\"\"\r\n\r\n    # Check to see if updating specific historical et table\r\n    if specific_station:\r\n        print(f\"Updating Historical ET Table: {specific_station}\")\r\n        update_historical_et_table(specific_station)\r\n        calculate_historical_averages(specific_station)\r\n\r\n    # If not update all current active cimis stations\r\n    else:\r\n        cimisStation = CimisStation()\r\n        cimisStation = cimisStation.open_cimis_station_pickle()\r\n        for station in cimisStation:\r\n            if station.active:\r\n                print(f\"Updating Historical ET Table: {station.station_number}\")\r\n                # Updates table data for most recent previous year dates and et values\r\n                update_historical_et_table(station.station_number)\r\n                # Updates averages column with new average including most recent previous year\r\n                calculate_historical_averages(station.station_number)\r\n\r\ndef update_historical_et_table(station_number:str):\r\n    \"\"\"\r\n    Updates Historical ET tables with new columns for the previous year and populates their values using ET table\r\n    :param station_number: station number\r\n    \"\"\"\r\n    try:\r\n        # Table name to update\r\n        table_id = f\"stomato-info.Historical_ET.{station_number}\"\r\n        year = date.today().year - 1\r\n\r\n        \"\"\"Query Creates a Filtered Table that contains date and eto data from the previous year, and joins it with the current historical et table\r\n            to create a new table that adds the date and eto data from the previous year to the current historical et table.\r\n        \"\"\"\r\n        dml_statement = f\"CREATE OR REPLACE TABLE `{table_id}` AS With FilteredTable as (select date, eto from `stomato-info.ET.{station_number}` as t where Extract(YEAR FROM t.date) = {year}), JoinedData AS (select historical_table.*, FT.date as Year_{year}, FT.eto as Year_{year}_ET from `{table_id}` as historical_table left join FilteredTable FT on Extract(MONTH from historical_table.Year_{year-2}) = Extract(MONTH from FT.date) and Extract(DAY from historical_table.Year_{year-2}) = Extract(DAY from FT.date)) Select * from JoinedData\"\r\n        # print(dml_statement)\r\n        dbwriter.run_dml(dml_statement, project=\"stomato-info\")\r\n        print(f\"Updated Table Data successfully for {station_number}\")\r\n\r\n    except google.api_core.exceptions.NotFound:\r\n        print(\"Table not found\")\r\n        #Todo Create table if not found\r\n\r\n    except google.api_core.exceptions.BadRequest as Error:\r\n        print(f\"Bad Request: {Error}\")\r\n\r\ndef calculate_historical_averages(station_number: str):\r\n    \"\"\"\r\n    Function calculates the average historical et data for all the years since 2018\r\n    :param station_number: Station Number\r\n    \"\"\"\r\n    end_year = datetime.today().year\r\n    start_date = datetime(2018, 1, 1).year\r\n    # Create a list of years to take et average since 2018\r\n    date_list = []\r\n    for single_date in range(start_date, end_year):\r\n        date_list.append(single_date)\r\n    try:\r\n        table_id = f\"stomato-info.Historical_ET.{station_number}\"\r\n        dml_statement_dates = \"(\"\r\n        for single_date in date_list:\r\n            if single_date == end_year - 1:\r\n                dml_statement_dates += f\"(Year_{single_date}_ET)\"\r\n            else:\r\n                dml_statement_dates += f\"(Year_{single_date}_ET) + \"\r\n        dml_statement_dates += \")\"\r\n        dml_statement = f\"Update {table_id} set Average = round(({dml_statement_dates}/{len(date_list)}),2) where true\"\r\n        dbwriter.run_dml(dml_statement)\r\n        print(f\"Updated Historical Averages for Historical ET Table {station_number}\")\r\n    except Exception as Error:\r\n        print(f\"{Error}\")\r\n\r\ndef update_grower_portal_report_and_images(grower_name: str):\r\n    \"\"\"\r\n    Function updates the grower portal DB reports and images from pickle\r\n    :param grower_name: Grower name\r\n    \"\"\"\r\n    print(f\"Updating reports and previews for {grower_name}\")\r\n    project = 'growers-2024'\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        if g.name == grower_name:\r\n            grower_db_name = dbwriter.remove_unwanted_chars_for_db_dataset(g.name)\r\n            base_table_id = f\"{project}.{grower_db_name}\"\r\n            for f in g.fields:\r\n                dml_statement_field = f\"UPDATE `{base_table_id}.field_averages` SET report = '{f.report_url}', preview = '{f.preview_url}' WHERE field = '{f.nickname}'\"\r\n                dml_statement_logger = f\"UPDATE `{base_table_id}.loggers` SET report = '{f.report_url}', crop_image = '{CwsiProcessor().get_crop_image(f.crop_type)}' WHERE field = '{f.nickname}'\"\r\n                for statement in (dml_statement_field, dml_statement_logger):\r\n                    dbwriter.run_dml(statement, project=project)\r\n    print('Done updating reports and previews')\r\n\r\n\r\n# update_portal_reports('RKB Farms')\r\n# IMPORTANT: This function updates historical et for all tables or a specific one if specified\r\n# add_new_year_to_historical_et()\r\n# add_new_year_to_historical_et(\"148\")\r\n\r\n\r\n\r\n\r\n# add_new_celsius_columns_to_permanent_datasets()\r\n# add_new_year_to_historical_et()\r\n# cimisStation = CimisStation()\r\n# cimisStation.showCimisStations()\r\n# cimisStation = cimisStation.open_cimis_station_pickle()\r\n# for station in cimisStation:\r\n    # print(f\"{station.station_number} : {station.latest_eto_value}\")\r\n    # print(f\"{station.station_number} : {station.active}\")\r\n# Dict with keys being Field, Logger, Days as a List, PSI as a List\r\n# copy_missing_data_to_logger_from_other_logger('Lucero Dillard RoadD1', 'DI-D1-NE', 'DI-D3-NW')\r\n# select_first_psi_for_all_datasets()\r\n# find_lowest_psi_fields()\r\n# psi_pickle = show_psi_pickle()\r\n# # print(psi_pickle)\r\n# for ind, dataset in enumerate(psi_pickle):\r\n#     print(dataset[ind]['field'])\r\n#     print(dataset[ind]['logger'])\r\n#     print(dataset[ind]['dates'])\r\n#     print(dataset[ind]['psi'])\r\n    # print(f\"Field: {dataset['field']:20} Logger: {dataset['logger']:20} \\n Dates: \\n{' '.join(str(date) for date in dataset['dates']):20}\"\r\n    #       f\" \\nPSI: \\n{' '.join(str(date) for date in dataset['psi']):20}\")\r\n# fix_irr_inches_for_all_fields('2023-04-01', '2023-04-06')\r\n# copy_last_day_from_old_date_to_new_date('stomato-2023', 'Lucero Dillard RoadD1', \"DI-D1-NE\", '2023-06-26', '2023-06-27')\r\n# update_fc_wp('stomato-2023', 'Lucero Dillard RoadD 8, 11', 'DI-D8-C', 36, 22)\r\n# grab_historical_data('250')\r\n# southCount = 0\r\n# northCount = 0\r\n# update_fc_wp('stomato-2023', 'Lucero Dillard RoadD2', 'DI-D2-W', 36, 22)\r\n# update_fc_wp('stomato-2023', 'Turlock Fruit Co1250', 'TU-1250-SE', 28, 14)\r\n# Decagon.show_pickle()\r\n\r\n# growers = Decagon.open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if field.name == 'Lucero Rio Vista1':\r\n#             Decagon.remove_field(grower.name, field.name)\r\n#             print(f\"{field.name}\")\r\n#             forecast = field.get_weather_forecast()\r\n#             pprint.pprint(forecast)\r\n# removeDuplicateET()\r\n# update_field_et('S&S Ranch33-3')\r\n# growers = Decagon.open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if field.crop_type.lower() == 'almonds' or field.crop_type.lower() == 'almond':\r\n#             # field.name = 'JJB FarmsGI 19, 21'\r\n#             # field.nickname  = 'GI 19, 21'\r\n#             # print(field.name)\r\n#             # print(field.nickname)\r\n#             for logger in field.loggers:\r\n#                 remove_psi(field.name, '2023-11-1', '2023-12-15', '2023')\r\n                # print(logger.name)\r\n                # print(f\"Old Logger Active: {logger.ir_active}\")\r\n                # logger.ir_active = False\r\n                # print(f\"New Logger Active: {logger.ir_active}\")\r\n#                 if logger.active and logger.name == 'SS-333-SW':\r\n#\r\n# #                     print(logger.id)\r\n# #                     logger.ir_active = True\r\n# #                     print(f\"{field.name}:\\n\\t{logger.name}:{logger.consecutive_ir_values}:{logger.ir_active}\")\r\n# Decagon.write_pickle(growers)\r\n# # # #                 if logger.name == 'BF-57-SW' and logger.active:\r\n# # # #                     project = dbwriter.get_db_project(logger.crop_type)\r\n# # # #                     update_irr_hours_for_date(project, field.name, logger.name, 1.3, '2023-06-16')\r\n#                     remove_duplicate_data(logger)\r\n#                     update_missing_et_data(logger)\r\n#         if field.name == 'S&S Ranch33-3' or field.name == \"S&S Ranch33-1\":\r\n#             for logger in field.loggers:\r\n#                 print(f\"{logger.name}: {logger.id}: {logger.field_capacity} : {logger.wilting_point}\")\r\n# if logger.name == 'SS-331-SW':\r\n#     update_fc_wp(project,field.name,logger.name, 36, 22)\r\n\r\n# Decagon.show_pickle()\r\n\r\n# growers = Decagon.open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if field.name == 'Lucero Dillard RoadD4':\r\n#             for logger in field.loggers:\r\n#                 if logger.name == 'DI-D4-W':\r\n#                     update_irr_hours_for_date_range('stomato-2023', logger.field.name, logger.name, 0, '2023-06-30', '2023-07-5')\r\n\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if f.name == 'Kruppa Enterprises LLCRokpileb':\r\n#             for l in f.loggers:\r\n# # #                 # update_fc_wp('stomato-2023', f.name, l.name, 36, 22)\r\n#                 if l.logger_direction == 'W':\r\n#                     project = dbwriter.get_db_project(l.crop_type)\r\n#                     update_irr_hours_for_date_range(project, f.name, l.name, 11.2, '2023-06-18', '2023-06-18')\r\n#                     remove_psi_specific(project, f.name, l.name, '2023-05-15', '2023-05-15')\r\n#                     delete_repeat_data(project, f.name, l.name)\r\n#             print(l)\r\n#             if not l.rnd:\r\n#                 if g.region == 'South' or g.region == 'south':\r\n#                     southCount = southCount + 1\r\n#\r\n#                 if g.region == 'North' or g.region == 'north':\r\n#                     northCount = northCount + 1\r\n# print(\"South\\n\\t\" + str(southCount))\r\n# print(\"North\\n\\t\" + str(northCount))\r\n# print(\"Total\\n\\t\" + str(southCount+northCount))\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if f.name == 'Mike Silva01-MS3':\r\n#             for logger in f.loggers:\r\n#                 if logger.name == 'MS-01MS3-NE':\r\n#                     project = dbwriter.get_db_project(logger.crop_type)\r\n#                     update_irr_hours_for_date(project, f.name, logger.name, 4.5, '2023-5-6')\r\n#         update_fc_wp(project, f.name, logger.name, 18, 8)\r\n#     # print(project)\r\n#     print(logger.name)\r\n# remove_duplicate_data(logger)\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if f.active:\r\n#             print(\"Erasing weather issue for field: \", f.name)\r\n# fixWeatherDB(f.name)\r\n# start_date = date(2022, 8, 15)\r\n# end_date = date(2022, 8, 16)\r\n# for single_date in daterange(start_date, end_date):\r\n#     copy_vp4_vals_from_table_to_table('Lucero Rio Vista2', 'RV-02-NW', 'RV-02-S', single_date.strftime(\"%Y-%m-%d\"))\r\n# copy_gdd_values_from_temp_table_to_table()\r\n# delete_repeat_data('Meza', 'Development-C')\r\n# update_portal_image('DCB', 'F3_F4', 'https://i.imgur.com/C6ePFHh.png', True)\r\n\r\n# copy_gdd_values_from_temp_table_to_table('Barrios_Farms22', 'BF-22-SE', 'BF-22-SE_temp')\r\n\r\n# update_FC_WP('Bullseye FarmsRG42', 'Bull-RG42-C', 31, 11)\r\n# move_logger_DB_info('DCBD_T', 'BR-DT1-NE', 'BR-DT1-NE_copy')\r\n# move_logger_DB_info('Lucero_Sun_Pacific31', 'LU-31WM-SE', 'LU-31-SE')\r\n# copy_vp4_vals_from_table_to_table('LemonicaTango K', 'TAG-LE-SE', 'TAG-WM-SE', '2022-04-18')\r\n# update_FC_WP('Carvalho308A', 'KC-308A-S', 36, 22)\r\n# update_logger_et('La QuintaDates Block 36 DB', 'DAT-Blk36DB-NW')\r\n# deleteWhereEToIsNull('OPC3-2', 'OP-AL-NW', '2022-04-02', '2022-04-03')\r\n# removeDuplicateET()\r\n# update_all_field_et()\r\n# update_field_et(\"OPC15-4\")\r\n# delete_et_day('CM OchoaA8', '2023-05-06', '2023-05-09')\r\n# update_field_et(\"CM OchoaA8\")\r\n# update_field_et(\"Andrew3104\")\r\n# update_field_et(\"Andrew3101-3103\")\r\n# update_field_et('DCBWarren')\r\n# growerSucks = 0\r\n# fieldCount = 0\r\n# stationCount = 0\r\n# count = 0\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if f.name == 'CM OchoaA8':\r\n#             delete_et_day(f, '2023-05-06', '2023-05-09')\r\n\r\n# for l in f.loggers:\r\n#             print(g.name,\";\", f.nickname,\";\", l.rnd)\r\n#             if l.rnd:\r\n#                 count += 1\r\n# print(count)\r\n\r\n# print(\"Grower fields: \", growerSucks)\r\n# print(\"Field Count: \", fieldCount)\r\n# print(\"Station Count: \", stationCount)\r\n\r\n# if g.name != 'RnD':\r\n#             for l in f.loggers:\r\n#                 if l.cropType == 'Tomatoes':\r\n#                     print(g.name, ';', f.nickname, ';', l.name, ';')\r\n#         if f.name == 'DCBVerway':\r\n#             previewImage = 'https://i.imgur.com/ROE4By8.png'\r\n#             update_portal_image(g, f, previewImage)\r\n# for l in f.loggers:\r\n#             update_missing_et_data(l)\r\n# update_field_et('LemonicaTango K')\r\n# update_field_et(\"F&SAirport 3 \")\r\n# update_all_field_et()\r\n# removePSISpecific('Hughes303', 'HU-303-NE', '2022-05-27', '2022-05-28')\r\n# remove_psi('Bone Farms LLCN42 N43', '2023-05-16', '2023-05-17', '2023')\r\n# startDate = date(datetime.now().year, 1, 1)\r\n# print(startDate)\r\n# endDate = date(2021, 12, 31)\r\n# setupIrrigationSchedulingDB(105, \"Andrew3125\", startDate, endDate)\r\n# Decagon.show_pickle()\r\n# all_tables_analysis()\r\n# get_average_psi_during_growth()\r\n\r\n# delete_all_null_rows()\r\n# update_missing_et_data('z6-01995')\r\n# delete_repeat_data('OPC3-3', 'OP-33-NE')\r\n# remove_duplicate_data(\"RnD77\", 'LH-77Y-N')\r\n\r\n# deleteETDay('DCBChapman', '2021-08-16')\r\n# deleteLastDay('Hughes234-2', 'z6-07156', '2021-08-18')\r\n\r\n# delete_null_rows('Ryan_JonesFirebaugh_B2', 'z6-01956', 'eto', '2022-1-1', '2022-1-13')\r\n# delete_all_null_rows('eto', '2022-1-1', '2022-1-13')\r\n\r\n# removePSISpecific('DCBSilva 5', 'z6-05978', '2021-08-17', '2021-08-17')\r\n\r\n# range(field, logger, dailyHours, startDate, endDate):\r\n# update_irr_hours_for_date('Barrios Farms84', 'BF-84-SW', 18.9, '2022-04-13')\r\n\r\n\r\n# columns_to_add = {}\r\n# columns_to_add['vwc_1_ec'] = 'FLOAT'\r\n# columns_to_add['vwc_2_ec'] = 'FLOAT'\r\n# columns_to_add['vwc_3_ec'] = 'FLOAT'\r\n# add_column_to_db_specific_field('Meza', columns_to_add)\r\n# add_column_to_db(columns_to_add)\r\n# Decagon.show_pickle()\r\n# removeDuplicateET()\r\n# update_field_et('WestSide RanchSEQ23')\r\n# update_field_et('Lucero BakersfieldTowerline')\r\n# update_all_field_et()\r\n# loggerSetups.removeField('Maricopa Orchards', 'Maricopa Orchards1831Delete')\r\n# cropType = ''\r\n# Decagon.remove_field('Maricopa Orchards', 'Maricopa Orchards1831')\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if f.name == 'Bone Farms LLCR12-13':\r\n# print(f.active)\r\n# f.active = True\r\n# print(f.active)\r\n# Decagon.write_pickle(growers)\r\n#                 print(f.preview_url)\r\n# if g.name == 'Shiraz Ranch':\r\n#     print(g.technician.name)\r\n# for l in f.loggers:\r\n#                 if l.name == 'TO-Green-N':\r\n#                     print('old id: ', l.password)\r\n#                     l.password = '78722-13527'\r\n#                     print('new id: ', l.password)\r\n#                     l.name = \"LH-77-SE\"\r\n#                 l.prev_day_switch = 120\r\n#                 print(l.name)\r\n#                 print(\"\\t\" + str(l.active))\r\n# changeName = input('Name Change: ')\r\n# f.name = changeName\r\n# Decagon.write_pickle(growers)\r\n#                 if l.name == 'MA-BEPI-NE' or l.name == 'MA-YEPI-NE':\r\n#                     l.active = False\r\n#                     print(l.name)\r\n#                     print(\"\\t\" + str(l.active))\r\n# loggerSetups.removeLoggerIDFromPickle(l.id)\r\n\r\n# cropType = l.cropType\r\n# print(f.name)\r\n# print(\"\\t\" + cropType)\r\n#             update_missing_et_data(l)\r\n# for g in growers:\r\n#     if g.active:\r\n#         for f in g.fields:\r\n#             if f.active:\r\n#                 for l in f.loggers:\r\n#                     update_missing_et_data(l)\r\n# for ind, g in enumerate(growers):\r\n#     if g.name == 'DCB':\r\n#         for f in g.fields:\r\n#             if f.name == 'DCBRoggero Almonds':\r\n#                 for l in f.loggers:\r\n#                     update_missing_et_data(l)\r\n#     updateKcValuesWithAMaxIncludingEtcEtcHours(l)\r\n#     updateKcValuesWithAMaxI(l)\r\n\r\n# if g.name == \"DCB\" or g.name == \"David Santos\" or g.name == \"Matteoli\" or g.name == \"Barrios\"\r\n\r\n# growers = Decagon.open_pickle()\r\n# for ind, g in enumerate(growers):\r\n#     if g.name == 'La Quinta':\r\n#         for f in g.fields:\r\n#             # if f.name == 'TPMM3':\r\n#             for l in f.loggers:\r\n#                 update_missing_et_data(l)\r\n# Decagon.write_pickle(growers)\r\n\r\n# removeDoubleDataLateHours(\"DCBNees 7-8\", \"z6-12427\")\r\n# deleteET(146)\r\n# Decagon.setPlantingDate(\"David Santos\", \"David SantosFA3\", 2021, 3, 8)\r\n# addETHoursCol()\r\n# addETHoursColSpecific(\"BoneFarms\")\r\n# dbwriter.add_new_column_to_table(\"Bullseye_FarmsFD85D\", \"z6-11506\", \"et_hours\", \"FLOAT\")\r\n# removeDuplicateET()\r\n\r\n\r\n# field = \"Zuckerman Farms7B-7K\"\r\n# logger = \"z6-11562\"\r\n# addETHoursColSpecific(\"DCBDF7-8\")\r\n# Decagon.show_pickle()\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if f.active:\r\n#             for l in f.loggers:\r\n#                 # if f.name == \"LemonicaLemon E\":\r\n#                 if l.active:\r\n#                     remove_duplicate_data(f.name, l.name)\r\n#             print(f.name)\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         for l in f.loggers:\r\n#             if l.active and not f.active:\r\n# removeField = input(\"Remove field: \" + f.name + \"\\n \\t Remove Logger: \" + l.name + \"\\n\")\r\n# if removeField == 'y':\r\n# Decagon.removeLogger(g.name, f.name, l.id)\r\n#         if f.name == 'La QuintaDates':\r\n#             print(f.preview_url)\r\n# f.preview_url = 'https://i.imgur.com/jsRPSad.png'\r\n# print(f.preview_url)\r\n# for l in f.loggers:\r\n# if f.name == \"LemonicaLemon E\":\r\n# if l.active:\r\n#     remove_duplicate_data(f.name, l.name)\r\n\r\n\r\n#         f.CimisStation = CimisStation()\r\n# for ind, g in enumerate(growers):\r\n#     if g.name == 'Andrew':\r\n#         for f in g.fields:\r\n#             if f.name == 'Andrew3125':\r\n#                 for l in f.loggers:\r\n#                     update_missing_et_data(l)\r\n# Decagon.write_pickle(growers)\r\n# update_missing_et_data('z6-07275')\r\n\r\n\r\n# field = \"Dougherty BrosSY\"\r\n# growers = Decagon.open_pickle()\r\n# for ind, g in enumerate(growers):\r\n#     for f in g.fields:\r\n#         if f.name == field:\r\n#             for l in f.loggers:\r\n#                 update_missing_et_data(l)\r\n\r\n\r\n# Decagon.show_pickle()\r\n# deleteAndUpdateDB(\"DCB\", \"DCBMontague \", '2021-04-22', '2021-04-23')\r\n#\r\n# deleteAndUpdateDBGrower(\"Carvalho\", \"2021-05-15\", '2021-05-16')\r\n# removePSISpecific(\"JJB FarmsGrand Island 1-4-10\", \"z6-12365\", '2021-07-08', '2021-07-24')\r\n# remove_psi(\"Bone Farms LLCR12-13\", '2023-04-01', '2023-04-11', '2023')\r\n# growers = Decagon.open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if field.name == 'Bone Farms LLCR12-13':\r\n#             fix_weather_db(field)\r\n\r\n#\r\n# copy_values_from_table_to_table()\r\n#\r\n\r\n#\r\n#\r\n# update_eto_etc('Andrew3104', 'z6-12421', [0.34, 0.31], '2021-05-03', '2021-05-04')\r\n#\r\n# copy_vp4_vals_from_table_to_table()\r\n#\r\n\r\n# delete_repeat_data('JK_VineyardsGemmer_North', 'z6-02143')\r\n# delete_repeat_data('Dougherty_BrosT4', 'z6-11510')\r\n# delete_repeat_data('DCBMaricopa_3', 'z6-11933')\r\n# delete_repeat_data('Andrew3125', 'z6-07261')\r\n# delete_repeat_data('Bullseye FarmsRG28', 'Bull-RG28-NW')\r\n\r\n#\r\n# delete_all_repeat_data()\r\n\r\n# Decagon.show_pickle()\r\n\r\n\r\n# delete_all_null_rows()\r\n# remove_unwanted_chars_for_db('OPC4-1')\r\n# update_field_et('WestSide RanchSWQ15')\r\n# Decagon.show_pickle()\r\n# update_irr_hours_for_date('stomato-2023', 'Lucero BakersfieldTowerline', 'BA-Purple-S', 0, '2023-04-17')\r\n# update_irr_hours_for_date_range('stomato-2023', 'Bone Farms LLCF7', 'BO-F7-NE', 0, '2023-04-05', '2023-04-11')\r\n# updateIrrHours('DCBNees 7-8', 'z6-12427', 8, '2021-07-31')\r\n# updateIrrHours('DCBNees 7-8', 'z6-12427', 2.6, '2021-08-01')\r\n# updateIrrHours('DCBNees 7-8', 'z6-12427', 5.2, '2021-08-02')\r\n# updateIrrHours('DCBNees 7-8', 'z6-12427', 10.7, '2021-08-03')\r\n\r\n# deleteLastDay('JHPBase5', 'z6-07262')\r\n# dt = date.today() - timedelta(days=5)\r\n# while str(dt) != '2021-07-22':\r\n#     print(dt)\r\n#     updateIrrHours('DCBNees 7-8', 'z6-12427', 12, str(dt))\r\n#     dt = dt - timedelta(days=1)\r\n#     time.sleep(1)\r\n\r\n# Decagon.show_pickle()\r\n# update_all_field_et()
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/SQLScripts.py b/SQLScripts.py
--- a/SQLScripts.py	
+++ b/SQLScripts.py	
@@ -4,7 +4,8 @@
 from datetime import datetime, timedelta, date
 from os import path
 from statistics import mean
-
+import csv
+from itertools import zip_longest
 import google.api_core.exceptions
 import numpy
 from dateutil.relativedelta import relativedelta
@@ -21,6 +22,7 @@
 DIRECTORY_YEAR = "2023"
 PICKLE_DIRECTORY = "H:\\Shared drives\\Stomato\\" + DIRECTORY_YEAR + "\\Pickle\\"
 
+
 def update_value_for_date(project, field_name, logger_name, date, value_name, value):
     dml = 'UPDATE `' + str(project) + '.' + str(field_name) + '.' + str(logger_name) + '`' \
           + ' SET ' + str(value_name) + ' = ' + str(value) \
@@ -81,6 +83,7 @@
     dbwriter.run_dml(dml, project=project)
     print("Done Updating Irr. Hours")
 
+
 # update_irrigation_hours_for_date('stomato-2023', 'Lucero Mandeville17 I J', 'LM-17J-S', 4.2, '2023-08-08')
 # update_irrigation_hours_for_date('stomato-2023', 'Lucero Mandeville17 I J', 'LM-17J-S', 5.1, '2023-08-10')
 # update_irrigation_hours_for_date('stomato-2023', 'Lucero Mandeville17 I J', 'LM-17J-S', 3.5, '2023-08-12')
@@ -101,6 +104,8 @@
     # print(dml)
     dbwriter.run_dml(dml, project=project)
     print("Done Updating Irr. Inches")
+
+
 # update_irr_inches_for_date('stomato-2023', 'Lucero Dillard RoadD4', 'DI-D4-W')
 
 
@@ -127,6 +132,7 @@
     dbwriter.run_dml(dml, project=project)
     print("Done Updating Irr. Hours")
 
+
 def update_eto_etc(project, field_name, logger_name, list_etos, start_date, end_date):
     field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field_name)
     list_etos = list_etos
@@ -479,7 +485,8 @@
                     logger_id = log.id
                     for val in column_name_and_type_dict:
                         try:
-                            dbwriter.add_new_column_to_table(fieldName, logger_id, val, column_name_and_type_dict[val], project=project)
+                            dbwriter.add_new_column_to_table(fieldName, logger_id, val, column_name_and_type_dict[val],
+                                                             project=project)
                         except:
                             print("Exception")
 
@@ -499,7 +506,8 @@
                 logger_id = log.id
                 for val in column_name_and_type_dict:
                     try:
-                        dbwriter.add_new_column_to_table(fieldName, logger_id, val, column_name_and_type_dict[val], project=project)
+                        dbwriter.add_new_column_to_table(fieldName, logger_id, val, column_name_and_type_dict[val],
+                                                         project=project)
                     except:
                         print("Field:" + fieldName + " already has ET Hours")
 
@@ -791,10 +799,10 @@
     return at_avg, vpd_avg, rh_avg  ##, psi_avg
 
 
-def setupIrrigationSchedulingDB(etStation:int, fieldName:str, startDate:date, endDate:date, yearIrr:int):
+def setupIrrigationSchedulingDB(etStation: int, fieldName: str, startDate: date, endDate: date, yearIrr: int):
     """
     Sets up the Irrigation Scheduling Table for a Field in the DB
-    :param etStation: ET Statin Number
+    :param etStation: ET Station Number
     :param fieldName: Field Name
     :param startDate: Start Date
     :param endDate: End Date
@@ -816,7 +824,8 @@
     # Make a Dictionary of Lists that will have Dates from last year
     datesDict = {"dates": []}
     for d in range(0, 365):
-        datesDict["dates"].append(datetime.combine(date(yearIrr - 1, 1, 1) + relativedelta(days=d), datetime.min.time()))
+        datesDict["dates"].append(
+            datetime.combine(date(yearIrr - 1, 1, 1) + relativedelta(days=d), datetime.min.time()))
     # Get Historical KC and return as a Dict with Dates
     print("Getting Historical KC Values")
     datesDict = logger.get_kc(datesDict)
@@ -851,7 +860,9 @@
     for dates in date_time_et_value:
         etcDict['Historical Etc'].append(date_time_et_value[dates] * kcDict[dates])
         etHoursDict['Historical Hours'].append(
-            round((etcDict['Historical Etc'][-1] * 449 * float(logger.irrigation_set_acres)) / (float(logger.gpm) * 0.85), 0))
+            round(
+                (etcDict['Historical Etc'][-1] * 449 * float(logger.irrigation_set_acres)) / (float(logger.gpm) * 0.85),
+                0))
         etValueDict['Historical Eto'].append(date_time_et_value[dates])
 
     # Setup future dates dictionary for writing to CSV
@@ -867,7 +878,7 @@
     Decagon.update_irr_scheduling(field_name + '_Irr_Scheduling', field_name, csvDict, overwrite=True, logger=logger)
 
 
-def returnHistoricalETDict(etStation:int, startDate:date, endDate:date)->dict:
+def returnHistoricalETDict(etStation: int, startDate: date, endDate: date) -> dict:
     """
     Returns a dictionary with the historical average ET date and value
     :param etStation: ET station
@@ -886,7 +897,7 @@
     return etValue
 
 
-def move_logger_db_info(project:str, field_name:str, new_logger_name:str, old_logger_name:str):
+def move_logger_db_info(project: str, field_name: str, new_logger_name: str, old_logger_name: str):
     """
     Use if copying data from an old logger to a new logger table
     :param project: Big Query Project
@@ -1043,20 +1054,41 @@
     field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field.name)
     project = dbwriter.get_db_project(field.loggers[0].crop_type)
     dataset = field_name + ".weather_forecast`"
-    today = datetime.today() - timedelta(days=1)
+    today = datetime.today() - timedelta(days=0)
     day = str(today.day)
     month = str(today.month)
     year = str(today.year)
     date = year + "-" + month + "-" + day
     # print(date)
 
-    dml_statement = ("Update `" + project + "." + dataset + " as t" + " Set t.order = 99 where t.date < " + "'" + date + "'")
+    dml_statement = (
+            "Update `" + project + "." + dataset + " as t" + " Set t.order = 99 where t.date < " + "'" + date + "'")
     dbwriter.run_dml(dml_statement, project=project)
     print(f"Finished fixing weather for {field.name}")
     # print(dml_statement)
 
 
-def grab_historical_data(etStation: int, newStation: bool = False):
+def get_historical_data_for_new_station(station: str, years=6):
+    c = CIMIS()
+    current_date = datetime.today()
+    results = {}
+    # Pull 4 years of data from station, one year at a time, starting at 1
+    for year in range(1, years):
+        new_year = current_date.year-year
+        start_date = str(datetime(new_year, 1, 1).date())
+        end_date = str(datetime(new_year, 12, 31).date())
+
+        print(f"Getting historical data for {year} year(s) behind")
+
+        station_data = c.getDictForStation(station, start_date, end_date)
+        results[f'Year_{new_year}'] = station_data["dates"]
+        results[f'Year_{new_year}_ET'] = station_data["eto"]
+
+    return results
+
+
+
+def new_et_station_data(etStation: int):
     """
     Function creates a new historical ET table for etStation
     :param etStation: Et Station
@@ -1064,66 +1096,29 @@
     """
 
     dataset = "Historical_ET"
-    # etTableHeaders = ['Year_2022', 'Year_2021', 'Year_2020', 'Year_2019', 'Year_2018']
-    # Get Tables that exist
     tables = dbwriter.get_tables("Historical_ET", project="stomato-info")
     tableFound = False
-
     # Loop through existing tables checking to see if Historical ET Table already exists, if not create a new table
-    try:
-        for table in tables:
-            if table.table_id == etStation:
-                print('\tFound Historical ET For ET station \n\t\t Overwriting Historical Table')
-                print(table.table_id)
-                tableFound = True
-        if not tableFound:
-            print("\tDidn't Find Historical ET Table \nCreating Table")
-
-            client = bigquery.Client()
-            schema = [
-                bigquery.SchemaField("Year_2022", "DATE", mode="NULLABLE"),
-                bigquery.SchemaField("Year_2022_ET", "Float", mode="NULLABLE"),
-                bigquery.SchemaField("Year_2021", "DATE", mode="NULLABLE"),
-                bigquery.SchemaField("Year_2021_ET", "Float", mode="NULLABLE"),
-                bigquery.SchemaField("Year_2020", "DATE", mode="NULLABLE"),
-                bigquery.SchemaField("Year_2020_ET", "Float", mode="NULLABLE"),
-                bigquery.SchemaField("Year_2019", "DATE", mode="NULLABLE"),
-                bigquery.SchemaField("Year_2019_ET", "Float", mode="NULLABLE"),
-                bigquery.SchemaField("Year_2018", "DATE", mode="NULLABLE"),
-                bigquery.SchemaField("Year_2018_ET", "Float", mode="NULLABLE"),
-                bigquery.SchemaField("Average", "Float", mode="NULLABLE")
-            ]
-            query_dataset = "stomato-info.Historical_ET." + str(etStation)
-            table = bigquery.Table(query_dataset, schema=schema)
-        # If et station is a new station,
-        if newStation:
-            etDict2022, etDict2021, etDict2020, etDict2019, etDict2018, etDictAverage = return_historical_data_for_new_station(str(etStation))
-            if not tableFound:
-                table = client.create_table(table)  # Make an API request.
-                print(
-                    "Created table {}.{}.{}".format(table.project, table.dataset_id, table.table_id)
-                )
-        else:
-            etDict2022, etDict2021, etDict2020, etDict2019, etDict2018, etDictAverage = returnHistoricalData(str(etStation))
-            if not tableFound:
-                table = client.create_table(table)  # Make an API request.
-                print(
-                    "Created table {}.{}.{}".format(table.project, table.dataset_id, table.table_id)
-                )
 
-        # print(etDictAverage)
+    # for table in tables:
+    #     if table.table_id == etStation:
+    #         print('\tFound Historical ET For ET station \n\t\t Overwriting Historical Table')
+    #         print(table.table_id)
+    #         tableFound = True
+        # if not tableFound:
 
-        csvDict = etDict2022 | etDict2021 | etDict2020 | etDict2019 | etDict2018 | etDictAverage
-
-        Decagon.write_new_historical_et_to_db_2(dataset, str(etStation), csvDict, overwrite=True)
-
-        print("Done inserting values")
+    new_et_results = get_historical_data_for_new_station(str(etStation))
+    Decagon.write_new_historical_et_to_db_2(dataset, str(etStation) + '_test', new_et_results, overwrite=True)
+        # else:
+        #     etDict2022, etDict2021, etDict2020, etDict2019, etDict2018, etDictAverage = returnHistoricalData(
+        #         str(etStation))
+        #     if not tableFound:
+        #         table = client.create_table(table)  # Make an API request.
+        #         print(
+        #             "Created table {}.{}.{}".format(table.project, table.dataset_id, table.table_id)
+        #         )
+    print("Done inserting values")
 
-    except Exception as err:
-        print("ET Station Not In Database")
-        print(err)
-
-
 def returnHistoricalData(etStation):
     print("Grabbing previous years historical data")
 
@@ -1336,7 +1331,8 @@
     return et_list
 
 
-def copy_missing_data_to_logger_from_other_logger(field_name: str, logger_destination_name: str, logger_source_name: str):
+def copy_missing_data_to_logger_from_other_logger(field_name: str, logger_destination_name: str,
+                                                  logger_source_name: str):
     """
     :param field_name: Name of field
     :param logger_destination_name: Name of logger that is missing data
@@ -1395,7 +1391,7 @@
     dbwriter.run_dml(dml_statement, project=project)
 
 
-#Grab dates and psi where first psi was turned on. If possible pull the first 3 days of values. Loop through 2022 year dataset.
+# Grab dates and psi where first psi was turned on. If possible pull the first 3 days of values. Loop through 2022 year dataset.
 def select_first_psi_for_all_datasets():
     """
     Function goes into database project for 2022 and selects the first 3 days of PSI values. It stores the data into a pickle called
@@ -1417,7 +1413,7 @@
         else:
             for table in tables_list:
                 # print(table.table_id)
-                if table.table_id == 'weather_forecast' or "Irr_Scheduling" in table.table_id or "temp" in table.table_id or "copy" in table.table_id\
+                if table.table_id == 'weather_forecast' or "Irr_Scheduling" in table.table_id or "temp" in table.table_id or "copy" in table.table_id \
                         or "5G" in table.table_id or "z6" in table.table_id:
                     continue
                 else:
@@ -1450,12 +1446,13 @@
     dml_statement = f"select date, psi from {dataset} where psi is not null order by date asc"
     # print(dml_statement)
     psi_dict = dbwriter.return_query_dict(dml_statement, 'date', 'psi', 'stomato')
-    psi_only_three_dict = dict(itertools.islice(psi_dict.items(),3))
+    psi_only_three_dict = dict(itertools.islice(psi_dict.items(), 3))
     date_list = list(psi_only_three_dict.keys())
     psi_list = list(psi_only_three_dict.values())
     return date_list, psi_list
 
-def show_psi_pickle_2022(specific_file_path: str = PICKLE_DIRECTORY, filename: str ="psi_pickle_2022.pickle"):
+
+def show_psi_pickle_2022(specific_file_path: str = PICKLE_DIRECTORY, filename: str = "psi_pickle_2022.pickle"):
     """
     Function opens and returns psi pickle for 2022
 
@@ -1468,7 +1465,8 @@
     return data
 
 
-def copy_last_day_from_old_date_to_new_date(project: str, field_name: str, logger_name: str, old_date: str, new_date: str):
+def copy_last_day_from_old_date_to_new_date(project: str, field_name: str, logger_name: str, old_date: str,
+                                            new_date: str):
     """
     This function copies the old date's data from a specific logger for a specific field and inserts it into the same logger but using a different
     date. This function is useful for when a logger gets disconnected for a day and we lost data for that day.
@@ -1518,8 +1516,10 @@
         # Query to insert the selected values into the destination table with a different date
         insert_query = f"INSERT INTO `{destination_table}` "
         insert_query += "VALUES ("
-        insert_query += ", ".join([f"{'Null' if value is None else value if not isinstance(value, str) else convert_string(value)}" for
-                                   value in values])  # Loop through all the values in row_dict. If your value is None, convert into a string of Null.
+        insert_query += ", ".join(
+            [f"{'Null' if value is None else value if not isinstance(value, str) else convert_string(value)}" for
+             value in
+             values])  # Loop through all the values in row_dict. If your value is None, convert into a string of Null.
         # If your value is a string you want to convert that value into a string by adding a ' to the beginning and end. If not when you loop
         # through the values they get inserted without the ''
         insert_query += ")"
@@ -1539,40 +1539,41 @@
 def convert_string(text):
     return f"'{text}'"
 
+
 def find_lowest_psi_fields():
-        """
+    """
         Function finds the lowest psi fields in the database and returns a list of the lowest psi fields.
         """
-        psi_list = []
-        logger_name_list = []
-        project = 'stomato-2023'
-        # Get list of datasets in database
-        client = dbwriter.grab_bq_client(project)
-        datasets = dbwriter.get_datasets(project)
-        # Loop through all datasets
-        for dataset in datasets[0]:
-            # print(f"Working on field: {dataset.dataset_id}")
-            # Get list of tables in dataset
-            tables = client.list_tables(dataset.dataset_id)
-            # Loop through all tables in dataset
-            for table in tables:
-                # print(table.table_id)
-                # table_id = table.table_id
-                if not ("Irr_Scheduling" in table.table_id) and not ("weather_forecast" in table.table_id):
-                    # Check if table is in algorithm list
-                    table_id = f"`{project}.{dataset.dataset_id}.{table.table_id}`"
-                    select_psi = f"select avg(psi) as average_psi, count(psi) as number_of_data_points from {table_id} where psi is not null"
-                    result = dbwriter.run_dml(select_psi)
-                    for row in result:
-                        if row.average_psi:
-                            # psi_list.append({'field': table_id,'psi':row.average_psi})
-                            if row.number_of_data_points > 20:
-                                psi_list.append(row.average_psi)
-                                logger_name_list.append(table.table_id)
-                                print(f"{table.table_id};{row.average_psi};{row.number_of_data_points}")
+    psi_list = []
+    logger_name_list = []
+    project = 'stomato-2023'
+    # Get list of datasets in database
+    client = dbwriter.grab_bq_client(project)
+    datasets = dbwriter.get_datasets(project)
+    # Loop through all datasets
+    for dataset in datasets[0]:
+        # print(f"Working on field: {dataset.dataset_id}")
+        # Get list of tables in dataset
+        tables = client.list_tables(dataset.dataset_id)
+        # Loop through all tables in dataset
+        for table in tables:
+            # print(table.table_id)
+            # table_id = table.table_id
+            if not ("Irr_Scheduling" in table.table_id) and not ("weather_forecast" in table.table_id):
+                # Check if table is in algorithm list
+                table_id = f"`{project}.{dataset.dataset_id}.{table.table_id}`"
+                select_psi = f"select avg(psi) as average_psi, count(psi) as number_of_data_points from {table_id} where psi is not null"
+                result = dbwriter.run_dml(select_psi)
+                for row in result:
+                    if row.average_psi:
+                        # psi_list.append({'field': table_id,'psi':row.average_psi})
+                        if row.number_of_data_points > 20:
+                            psi_list.append(row.average_psi)
+                            logger_name_list.append(table.table_id)
+                            print(f"{table.table_id};{row.average_psi};{row.number_of_data_points}")
 
-        # for ind, psi in enumerate(psi_list):
-        #     print(f"{logger_name_list[ind]}: {psi}")
+    # for ind, psi in enumerate(psi_list):
+    #     print(f"{logger_name_list[ind]}: {psi}")
 
 
 def generate_invite_code():
@@ -1603,7 +1604,8 @@
     dbwriter.run_dml(dml_statement, project=project)
 
 
-def insert_grower_loggers(grower: str, field: str, logger_name: str, logger_direction: str, lat: str, long: str, logger_id: str,
+def insert_grower_loggers(grower: str, field: str, logger_name: str, logger_direction: str, lat: str, long: str,
+                          logger_id: str,
                           logger_password: str, crop_type: str):
     """
     Function inserts the growers logger information in the database
@@ -1638,7 +1640,8 @@
     growers = Decagon.open_pickle()
     for grower in growers:
         for field in grower.fields:
-            if (field.crop_type.lower() == 'almonds' or field.crop_type.lower() == 'almonds' or field.crop_type.lower() == 'pistachio'
+            if (
+                    field.crop_type.lower() == 'almonds' or field.crop_type.lower() == 'almonds' or field.crop_type.lower() == 'pistachio'
                     or field.crop_type.lower() == 'pistachios'):
                 print(f"Field: {field.name}")
                 for logger in field.loggers:
@@ -1662,7 +1665,8 @@
                     except Exception as e:
                         print(f"Error updating table schema: {e}")
 
-def add_new_year_to_historical_et(specific_station:str = None):
+
+def add_new_year_to_historical_et(specific_station: str = None):
     """
     Updates table schema and data and recalculates table averages
     :param specific_station: Specific station name to update historical et table for. If not specified, all active cimis stations will be updated
@@ -1686,7 +1690,8 @@
                 # Updates averages column with new average including most recent previous year
                 calculate_historical_averages(station.station_number)
 
-def update_historical_et_table(station_number:str):
+
+def update_historical_et_table(station_number: str):
     """
     Updates Historical ET tables with new columns for the previous year and populates their values using ET table
     :param station_number: station number
@@ -1699,18 +1704,19 @@
         """Query Creates a Filtered Table that contains date and eto data from the previous year, and joins it with the current historical et table
             to create a new table that adds the date and eto data from the previous year to the current historical et table.
         """
-        dml_statement = f"CREATE OR REPLACE TABLE `{table_id}` AS With FilteredTable as (select date, eto from `stomato-info.ET.{station_number}` as t where Extract(YEAR FROM t.date) = {year}), JoinedData AS (select historical_table.*, FT.date as Year_{year}, FT.eto as Year_{year}_ET from `{table_id}` as historical_table left join FilteredTable FT on Extract(MONTH from historical_table.Year_{year-2}) = Extract(MONTH from FT.date) and Extract(DAY from historical_table.Year_{year-2}) = Extract(DAY from FT.date)) Select * from JoinedData"
+        dml_statement = f"CREATE OR REPLACE TABLE `{table_id}` AS With FilteredTable as (select date, eto from `stomato-info.ET.{station_number}` as t where Extract(YEAR FROM t.date) = {year}), JoinedData AS (select historical_table.*, FT.date as Year_{year}, FT.eto as Year_{year}_ET from `{table_id}` as historical_table left join FilteredTable FT on Extract(MONTH from historical_table.Year_{year - 2}) = Extract(MONTH from FT.date) and Extract(DAY from historical_table.Year_{year - 2}) = Extract(DAY from FT.date)) Select * from JoinedData"
         # print(dml_statement)
         dbwriter.run_dml(dml_statement, project="stomato-info")
         print(f"Updated Table Data successfully for {station_number}")
 
     except google.api_core.exceptions.NotFound:
         print("Table not found")
-        #Todo Create table if not found
+        # Todo Create table if not found
 
     except google.api_core.exceptions.BadRequest as Error:
         print(f"Bad Request: {Error}")
 
+
 def calculate_historical_averages(station_number: str):
     """
     Function calculates the average historical et data for all the years since 2018
@@ -1737,6 +1743,7 @@
     except Exception as Error:
         print(f"{Error}")
 
+
 def update_grower_portal_report_and_images(grower_name: str):
     """
     Function updates the grower portal DB reports and images from pickle
@@ -1756,23 +1763,20 @@
                     dbwriter.run_dml(statement, project=project)
     print('Done updating reports and previews')
 
-
 # update_portal_reports('RKB Farms')
 # IMPORTANT: This function updates historical et for all tables or a specific one if specified
 # add_new_year_to_historical_et()
 # add_new_year_to_historical_et("148")
 
 
-
-
 # add_new_celsius_columns_to_permanent_datasets()
 # add_new_year_to_historical_et()
 # cimisStation = CimisStation()
 # cimisStation.showCimisStations()
 # cimisStation = cimisStation.open_cimis_station_pickle()
 # for station in cimisStation:
-    # print(f"{station.station_number} : {station.latest_eto_value}")
-    # print(f"{station.station_number} : {station.active}")
+# print(f"{station.station_number} : {station.latest_eto_value}")
+# print(f"{station.station_number} : {station.active}")
 # Dict with keys being Field, Logger, Days as a List, PSI as a List
 # copy_missing_data_to_logger_from_other_logger('Lucero Dillard RoadD1', 'DI-D1-NE', 'DI-D3-NW')
 # select_first_psi_for_all_datasets()
@@ -1784,8 +1788,8 @@
 #     print(dataset[ind]['logger'])
 #     print(dataset[ind]['dates'])
 #     print(dataset[ind]['psi'])
-    # print(f"Field: {dataset['field']:20} Logger: {dataset['logger']:20} \n Dates: \n{' '.join(str(date) for date in dataset['dates']):20}"
-    #       f" \nPSI: \n{' '.join(str(date) for date in dataset['psi']):20}")
+# print(f"Field: {dataset['field']:20} Logger: {dataset['logger']:20} \n Dates: \n{' '.join(str(date) for date in dataset['dates']):20}"
+#       f" \nPSI: \n{' '.join(str(date) for date in dataset['psi']):20}")
 # fix_irr_inches_for_all_fields('2023-04-01', '2023-04-06')
 # copy_last_day_from_old_date_to_new_date('stomato-2023', 'Lucero Dillard RoadD1', "DI-D1-NE", '2023-06-26', '2023-06-27')
 # update_fc_wp('stomato-2023', 'Lucero Dillard RoadD 8, 11', 'DI-D8-C', 36, 22)
@@ -1816,10 +1820,10 @@
 #             # print(field.nickname)
 #             for logger in field.loggers:
 #                 remove_psi(field.name, '2023-11-1', '2023-12-15', '2023')
-                # print(logger.name)
-                # print(f"Old Logger Active: {logger.ir_active}")
-                # logger.ir_active = False
-                # print(f"New Logger Active: {logger.ir_active}")
+# print(logger.name)
+# print(f"Old Logger Active: {logger.ir_active}")
+# logger.ir_active = False
+# print(f"New Logger Active: {logger.ir_active}")
 #                 if logger.active and logger.name == 'SS-333-SW':
 #
 # #                     print(logger.id)
@@ -2095,12 +2099,7 @@
 
 
 # field = "Dougherty BrosSY"
-# growers = Decagon.open_pickle()
-# for ind, g in enumerate(growers):
-#     for f in g.fields:
-#         if f.name == field:
-#             for l in f.loggers:
-#                 update_missing_et_data(l)
+
 
 
 # Decagon.show_pickle()
@@ -2109,11 +2108,6 @@
 # deleteAndUpdateDBGrower("Carvalho", "2021-05-15", '2021-05-16')
 # removePSISpecific("JJB FarmsGrand Island 1-4-10", "z6-12365", '2021-07-08', '2021-07-24')
 # remove_psi("Bone Farms LLCR12-13", '2023-04-01', '2023-04-11', '2023')
-# growers = Decagon.open_pickle()
-# for grower in growers:
-#     for field in grower.fields:
-#         if field.name == 'Bone Farms LLCR12-13':
-#             fix_weather_db(field)
 
 #
 # copy_values_from_table_to_table()
@@ -2158,4 +2152,13 @@
 #     time.sleep(1)
 
 # Decagon.show_pickle()
-# update_all_field_et()
\ No newline at end of file
+# update_all_field_et()
+# update_grower_portal_report_and_images('Berra Brothers Farms')
+# get_historical_data_for_new_station('2')
+# growers = Decagon.open_pickle()
+# for ind, g in enumerate(growers):
+#     for f in g.fields:
+#         if f.name == 'Riley Chaney Farms16':
+#             for l in f.loggers:
+#                 remove_duplicate_data(l)
+# copy_last_day_from_old_date_to_new_date('stomato-permanents', 'Carvalho317', 'CA-317-NE', '2024-02-07', '2024-02-08')
\ No newline at end of file
Index: irrScheduling.csv
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>currentDate,Historical Eto,KC,Historical Etc,Historical Hours\r\n2023-01-01,0.048,0.328,0.015744,0.0\r\n2023-01-02,0.034,0.328,0.011152,0.0\r\n2023-01-03,0.026000000000000002,0.328,0.008528,0.0\r\n2023-01-04,0.028,0.328,0.009184000000000001,0.0\r\n2023-01-05,0.026,0.328,0.008527999999999999,0.0\r\n2023-01-06,0.024,0.328,0.007872,0.0\r\n2023-01-07,0.02,0.328,0.006560000000000001,0.0\r\n2023-01-08,0.012,0.328,0.003936,0.0\r\n2023-01-09,0.030000000000000002,0.328,0.009840000000000002,0.0\r\n2023-01-10,0.028,0.328,0.009184000000000001,0.0\r\n2023-01-11,0.038,0.328,0.012464,0.0\r\n2023-01-12,0.032,0.328,0.010496,0.0\r\n2023-01-13,0.04,0.328,0.013120000000000001,0.0\r\n2023-01-14,0.032,0.328,0.010496,0.0\r\n2023-01-15,0.018000000000000002,0.328,0.005904000000000001,0.0\r\n2023-01-16,0.032,0.328,0.010496,0.0\r\n2023-01-17,0.03,0.328,0.00984,0.0\r\n2023-01-18,0.074,0.328,0.024272,1.0\r\n2023-01-19,0.078,0.328,0.025584000000000003,1.0\r\n2023-01-20,0.052,0.328,0.017055999999999998,0.0\r\n2023-01-21,0.064,0.328,0.020992,1.0\r\n2023-01-22,0.052000000000000005,0.328,0.017056,0.0\r\n2023-01-23,0.046,0.328,0.015088,0.0\r\n2023-01-24,0.042,0.328,0.013776000000000002,0.0\r\n2023-01-25,0.058,0.328,0.019024000000000003,0.0\r\n2023-01-26,0.054,0.328,0.017712000000000002,0.0\r\n2023-01-27,0.054,0.328,0.017712000000000002,0.0\r\n2023-01-28,0.04,0.328,0.013120000000000001,0.0\r\n2023-01-29,0.056,0.328,0.018368000000000002,0.0\r\n2023-01-30,0.058,0.328,0.019024000000000003,0.0\r\n2023-01-31,0.064,0.328,0.020992,1.0\r\n2023-02-01,0.08,0.328,0.026240000000000003,1.0\r\n2023-02-02,0.078,0.328,0.025584000000000003,1.0\r\n2023-02-03,0.058,0.328,0.019024000000000003,0.0\r\n2023-02-04,0.07,0.328,0.022960000000000005,1.0\r\n2023-02-05,0.068,0.328,0.022304,1.0\r\n2023-02-06,0.084,0.328,0.027552000000000004,1.0\r\n2023-02-07,0.074,0.328,0.024272,1.0\r\n2023-02-08,0.07,0.328,0.022960000000000005,1.0\r\n2023-02-09,0.09,0.328,0.02952,1.0\r\n2023-02-10,0.108,0.328,0.035424000000000004,1.0\r\n2023-02-11,0.07200000000000001,0.328,0.023616000000000005,1.0\r\n2023-02-12,0.07,0.328,0.022960000000000005,1.0\r\n2023-02-13,0.082,0.328,0.026896000000000003,1.0\r\n2023-02-14,0.068,0.328,0.022304,1.0\r\n2023-02-15,0.09,0.328,0.02952,1.0\r\n2023-02-16,0.098,0.328,0.032144000000000006,1.0\r\n2023-02-17,0.104,0.328,0.034111999999999996,1.0\r\n2023-02-18,0.1,0.328,0.0328,1.0\r\n2023-02-19,0.082,0.328,0.026896000000000003,1.0\r\n2023-02-20,0.08600000000000001,0.328,0.028208000000000004,1.0\r\n2023-02-21,0.114,0.328,0.037392,1.0\r\n2023-02-22,0.104,0.328,0.034111999999999996,1.0\r\n2023-02-23,0.122,0.328,0.040016,1.0\r\n2023-02-24,0.128,0.328,0.041984,1.0\r\n2023-02-25,0.1,0.328,0.0328,1.0\r\n2023-02-26,0.072,0.328,0.023615999999999998,1.0\r\n2023-02-27,0.12,0.328,0.03936,1.0\r\n2023-02-28,0.1,0.328,0.0328,1.0\r\n2023-03-01,0.07,0.328,0.022960000000000005,1.0\r\n2023-03-02,0.078,0.328,0.025584000000000003,1.0\r\n2023-03-03,0.078,0.328,0.025584000000000003,1.0\r\n2023-03-04,0.1,0.328,0.0328,1.0\r\n2023-03-05,0.082,0.328,0.026896000000000003,1.0\r\n2023-03-06,0.092,0.328,0.030176,1.0\r\n2023-03-07,0.096,0.328,0.031488,1.0\r\n2023-03-08,0.102,0.328,0.033456,1.0\r\n2023-03-09,0.094,0.328,0.030832000000000002,1.0\r\n2023-03-10,0.098,0.328,0.032144000000000006,1.0\r\n2023-03-11,0.12000000000000001,0.328,0.039360000000000006,1.0\r\n2023-03-12,0.124,0.328,0.040672,1.0\r\n2023-03-13,0.114,0.328,0.037392,1.0\r\n2023-03-14,0.08,0.328,0.026240000000000003,1.0\r\n2023-03-15,0.076,0.328,0.024928,1.0\r\n2023-03-16,0.098,0.328,0.032144000000000006,1.0\r\n2023-03-17,0.1,0.328,0.0328,1.0\r\n2023-03-18,0.076,0.328,0.024928,1.0\r\n2023-03-19,0.09,0.328,0.02952,1.0\r\n2023-03-20,0.114,0.328,0.037392,1.0\r\n2023-03-21,0.138,0.328,0.045264000000000006,1.0\r\n2023-03-22,0.11,0.328,0.03608,1.0\r\n2023-03-23,0.154,0.328,0.050512,1.0\r\n2023-03-24,0.126,0.328,0.041328000000000004,1.0\r\n2023-03-25,0.122,0.328,0.040016,1.0\r\n2023-03-26,0.158,0.328,0.051824,1.0\r\n2023-03-27,0.132,0.328,0.043296,1.0\r\n2023-03-28,0.106,0.328,0.034768,1.0\r\n2023-03-29,0.148,0.328,0.048544,1.0\r\n2023-03-30,0.16,0.328,0.052480000000000006,1.0\r\n2023-03-31,0.162,0.328,0.053136,1.0\r\n2023-04-01,0.14,0.328,0.04592000000000001,1.0\r\n2023-04-02,0.162,0.328,0.053136,1.0\r\n2023-04-03,0.158,0.328,0.051824,1.0\r\n2023-04-04,0.114,0.328,0.037392,1.0\r\n2023-04-05,0.106,0.328,0.034768,1.0\r\n2023-04-06,0.134,0.328,0.043952000000000005,1.0\r\n2023-04-07,0.17400000000000002,0.328,0.057072000000000005,1.0\r\n2023-04-08,0.152,0.328,0.049856,1.0\r\n2023-04-09,0.194,0.328,0.06363200000000001,2.0\r\n2023-04-10,0.188,0.328,0.061664000000000004,2.0\r\n2023-04-11,0.158,0.328,0.051824,1.0\r\n2023-04-12,0.17400000000000002,0.328,0.057072000000000005,1.0\r\n2023-04-13,0.17200000000000001,0.328,0.05641600000000001,1.0\r\n2023-04-14,0.162,0.328,0.053136,1.0\r\n2023-04-15,0.154,0.328,0.050512,1.0\r\n2023-04-16,0.13999999999999999,0.328,0.045919999999999996,1.0\r\n2023-04-17,0.186,0.328,0.061008,2.0\r\n2023-04-18,0.178,0.328,0.058384,1.0\r\n2023-04-19,0.186,0.328,0.061008,2.0\r\n2023-04-20,0.184,0.328,0.060352,2.0\r\n2023-04-21,0.182,0.328,0.059696,2.0\r\n2023-04-22,0.2,0.328,0.0656,2.0\r\n2023-04-23,0.21,0.328,0.06888,2.0\r\n2023-04-24,0.212,0.328,0.069536,2.0\r\n2023-04-25,0.196,0.328,0.06428800000000001,2.0\r\n2023-04-26,0.224,0.328,0.07347200000000001,2.0\r\n2023-04-27,0.222,0.328,0.072816,2.0\r\n2023-04-28,0.212,0.328,0.069536,2.0\r\n2023-04-29,0.214,0.328,0.070192,2.0\r\n2023-04-30,0.228,0.328,0.074784,2.0\r\n2023-05-01,0.246,0.328,0.080688,2.0\r\n2023-05-02,0.238,0.328,0.078064,2.0\r\n2023-05-03,0.264,0.328,0.086592,2.0\r\n2023-05-04,0.234,0.328,0.076752,2.0\r\n2023-05-05,0.23,0.328,0.07544000000000001,2.0\r\n2023-05-06,0.22,0.328,0.07216,2.0\r\n2023-05-07,0.23600000000000002,0.328,0.077408,2.0\r\n2023-05-08,0.272,0.328,0.089216,2.0\r\n2023-05-09,0.268,0.328,0.08790400000000001,2.0\r\n2023-05-10,0.254,0.328,0.08331200000000001,2.0\r\n2023-05-11,0.248,0.328,0.081344,2.0\r\n2023-05-12,0.24600000000000002,0.328,0.08068800000000001,2.0\r\n2023-05-13,0.224,0.328,0.07347200000000001,2.0\r\n2023-05-14,0.214,0.328,0.070192,2.0\r\n2023-05-15,0.208,0.328,0.06822399999999999,2.0\r\n2023-05-16,0.214,0.328,0.070192,2.0\r\n2023-05-17,0.21200000000000002,0.328,0.06953600000000001,2.0\r\n2023-05-18,0.22,0.328,0.07216,2.0\r\n2023-05-19,0.22200000000000003,0.328,0.07281600000000002,2.0\r\n2023-05-20,0.256,0.328,0.083968,2.0\r\n2023-05-21,0.252,0.378,0.09525600000000001,2.0\r\n2023-05-22,0.26,0.378,0.09828,2.0\r\n2023-05-23,0.268,0.378,0.101304,3.0\r\n2023-05-24,0.272,0.378,0.102816,3.0\r\n2023-05-25,0.24000000000000002,0.378,0.09072000000000001,2.0\r\n2023-05-26,0.222,0.378,0.083916,2.0\r\n2023-05-27,0.24,0.378,0.09072,2.0\r\n2023-05-28,0.26,0.378,0.09828,2.0\r\n2023-05-29,0.27,0.378,0.10206000000000001,3.0\r\n2023-05-30,0.248,0.378,0.093744,2.0\r\n2023-05-31,0.266,0.398,0.10586800000000002,3.0\r\n2023-06-01,0.272,0.398,0.10825600000000002,3.0\r\n2023-06-02,0.27,0.398,0.10746000000000001,3.0\r\n2023-06-03,0.266,0.398,0.10586800000000002,3.0\r\n2023-06-04,0.266,0.398,0.10586800000000002,3.0\r\n2023-06-05,0.252,0.398,0.10029600000000001,3.0\r\n2023-06-06,0.29000000000000004,0.398,0.11542000000000002,3.0\r\n2023-06-07,0.28,0.398,0.11144000000000001,3.0\r\n2023-06-08,0.304,0.398,0.120992,3.0\r\n2023-06-09,0.27,0.398,0.10746000000000001,3.0\r\n2023-06-10,0.272,0.478,0.130016,3.0\r\n2023-06-11,0.28,0.478,0.13384000000000001,3.0\r\n2023-06-12,0.268,0.478,0.128104,3.0\r\n2023-06-13,0.28200000000000003,0.478,0.134796,3.0\r\n2023-06-14,0.28200000000000003,0.478,0.134796,3.0\r\n2023-06-15,0.274,0.478,0.130972,3.0\r\n2023-06-16,0.278,0.478,0.132884,3.0\r\n2023-06-17,0.28200000000000003,0.478,0.134796,3.0\r\n2023-06-18,0.29000000000000004,0.478,0.13862000000000002,4.0\r\n2023-06-19,0.3,0.478,0.1434,4.0\r\n2023-06-20,0.294,0.528,0.155232,4.0\r\n2023-06-21,0.296,0.528,0.156288,4.0\r\n2023-06-22,0.294,0.528,0.155232,4.0\r\n2023-06-23,0.314,0.528,0.165792,4.0\r\n2023-06-24,0.294,0.528,0.155232,4.0\r\n2023-06-25,0.294,0.528,0.155232,4.0\r\n2023-06-26,0.302,0.528,0.15945600000000001,4.0\r\n2023-06-27,0.28,0.528,0.14784000000000003,4.0\r\n2023-06-28,0.27999999999999997,0.528,0.14784,4.0\r\n2023-06-29,0.298,0.528,0.157344,4.0\r\n2023-06-30,0.296,0.828,0.24508799999999997,6.0\r\n2023-07-01,0.288,0.828,0.23846399999999998,6.0\r\n2023-07-02,0.27,0.828,0.22356,6.0\r\n2023-07-03,0.26,0.828,0.21528,5.0\r\n2023-07-04,0.278,0.828,0.230184,6.0\r\n2023-07-05,0.286,0.828,0.23680799999999996,6.0\r\n2023-07-06,0.276,0.828,0.228528,6.0\r\n2023-07-07,0.274,0.828,0.22687200000000002,6.0\r\n2023-07-08,0.28400000000000003,0.828,0.235152,6.0\r\n2023-07-09,0.29,0.828,0.24011999999999997,6.0\r\n2023-07-10,0.3,1.028,0.3084,8.0\r\n2023-07-11,0.296,1.028,0.304288,8.0\r\n2023-07-12,0.3,1.028,0.3084,8.0\r\n2023-07-13,0.274,1.028,0.28167200000000003,7.0\r\n2023-07-14,0.278,1.028,0.28578400000000004,7.0\r\n2023-07-15,0.278,1.028,0.28578400000000004,7.0\r\n2023-07-16,0.278,1.028,0.28578400000000004,7.0\r\n2023-07-17,0.274,1.028,0.28167200000000003,7.0\r\n2023-07-18,0.278,1.028,0.28578400000000004,7.0\r\n2023-07-19,0.29,1.028,0.29812,8.0\r\n2023-07-20,0.276,1.1,0.30360000000000004,8.0\r\n2023-07-21,0.278,1.1,0.30580000000000007,8.0\r\n2023-07-22,0.288,1.1,0.3168,8.0\r\n2023-07-23,0.27999999999999997,1.1,0.308,8.0\r\n2023-07-24,0.28400000000000003,1.1,0.31240000000000007,8.0\r\n2023-07-25,0.294,1.1,0.3234,8.0\r\n2023-07-26,0.27,1.1,0.29700000000000004,8.0\r\n2023-07-27,0.274,1.1,0.30140000000000006,8.0\r\n2023-07-28,0.27,1.1,0.29700000000000004,8.0\r\n2023-07-29,0.258,1.1,0.28380000000000005,7.0\r\n2023-07-30,0.266,1.1,0.2926,7.0\r\n2023-07-31,0.244,1.1,0.2684,7.0\r\n2023-08-01,0.244,1.1,0.2684,7.0\r\n2023-08-02,0.268,1.1,0.29480000000000006,7.0\r\n2023-08-03,0.26,1.1,0.28600000000000003,7.0\r\n2023-08-04,0.28,1.1,0.30800000000000005,8.0\r\n2023-08-05,0.23,1.1,0.25300000000000006,6.0\r\n2023-08-06,0.23,1.1,0.25300000000000006,6.0\r\n2023-08-07,0.232,1.1,0.25520000000000004,6.0\r\n2023-08-08,0.248,1.1,0.27280000000000004,7.0\r\n2023-08-09,0.256,1.1,0.2816,7.0\r\n2023-08-10,0.264,1.1,0.29040000000000005,7.0\r\n2023-08-11,0.272,1.1,0.2992,8.0\r\n2023-08-12,0.254,1.1,0.27940000000000004,7.0\r\n2023-08-13,0.25,1.1,0.275,7.0\r\n2023-08-14,0.244,1.1,0.2684,7.0\r\n2023-08-15,0.242,1.1,0.2662,7.0\r\n2023-08-16,0.268,1.1,0.29480000000000006,7.0\r\n2023-08-17,0.23,1.1,0.25300000000000006,6.0\r\n2023-08-18,0.246,1.1,0.2706,7.0\r\n2023-08-19,0.232,1.1,0.25520000000000004,6.0\r\n2023-08-20,0.224,1.1,0.24640000000000004,6.0\r\n2023-08-21,0.23600000000000002,1.1,0.25960000000000005,7.0\r\n2023-08-22,0.23399999999999999,1.1,0.2574,7.0\r\n2023-08-23,0.248,1.1,0.27280000000000004,7.0\r\n2023-08-24,0.244,1.1,0.2684,7.0\r\n2023-08-25,0.242,1.1,0.2662,7.0\r\n2023-08-26,0.23600000000000002,1.1,0.25960000000000005,7.0\r\n2023-08-27,0.242,1.1,0.2662,7.0\r\n2023-08-28,0.232,1.1,0.25520000000000004,6.0\r\n2023-08-29,0.248,1.1,0.27280000000000004,7.0\r\n2023-08-30,0.226,1.1,0.24860000000000002,6.0\r\n2023-08-31,0.228,1.1,0.2508,6.0\r\n2023-09-01,0.232,1.1,0.25520000000000004,6.0\r\n2023-09-02,0.226,1.1,0.24860000000000002,6.0\r\n2023-09-03,0.228,1.1,0.2508,6.0\r\n2023-09-04,0.216,1.1,0.2376,6.0\r\n2023-09-05,0.228,1.1,0.2508,6.0\r\n2023-09-06,0.222,1.1,0.24420000000000003,6.0\r\n2023-09-07,0.232,1.1,0.25520000000000004,6.0\r\n2023-09-08,0.244,1.1,0.2684,7.0\r\n2023-09-09,0.2,1.1,0.22000000000000003,6.0\r\n2023-09-10,0.176,1.1,0.1936,5.0\r\n2023-09-11,0.186,1.1,0.2046,5.0\r\n2023-09-12,0.188,1.1,0.2068,5.0\r\n2023-09-13,0.192,1.1,0.21120000000000003,5.0\r\n2023-09-14,0.192,1.1,0.21120000000000003,5.0\r\n2023-09-15,0.192,1.1,0.21120000000000003,5.0\r\n2023-09-16,0.168,1.1,0.18480000000000002,5.0\r\n2023-09-17,0.184,1.1,0.20240000000000002,5.0\r\n2023-09-18,0.154,1.1,0.16940000000000002,4.0\r\n2023-09-19,0.162,1.1,0.17820000000000003,5.0\r\n2023-09-20,0.17200000000000001,1.1,0.18920000000000003,5.0\r\n2023-09-21,0.164,1.1,0.18040000000000003,5.0\r\n2023-09-22,0.188,1.1,0.2068,5.0\r\n2023-09-23,0.194,1.1,0.21340000000000003,5.0\r\n2023-09-24,0.198,1.1,0.21780000000000002,6.0\r\n2023-09-25,0.176,1.1,0.1936,5.0\r\n2023-09-26,0.188,1.1,0.2068,5.0\r\n2023-09-27,0.18,1.1,0.198,5.0\r\n2023-09-28,0.20600000000000002,1.1,0.22660000000000002,6.0\r\n2023-09-29,0.164,1.1,0.18040000000000003,5.0\r\n2023-09-30,0.164,1.1,0.18040000000000003,5.0\r\n2023-10-01,0.156,1.1,0.1716,4.0\r\n2023-10-02,0.162,1.1,0.17820000000000003,5.0\r\n2023-10-03,0.156,1.1,0.1716,4.0\r\n2023-10-04,0.166,1.1,0.1826,5.0\r\n2023-10-05,0.16,1.1,0.17600000000000002,4.0\r\n2023-10-06,0.166,1.1,0.1826,5.0\r\n2023-10-07,0.186,1.1,0.2046,5.0\r\n2023-10-08,0.146,1.1,0.1606,4.0\r\n2023-10-09,0.17,1.1,0.18700000000000003,5.0\r\n2023-10-10,0.164,1.1,0.18040000000000003,5.0\r\n2023-10-11,0.184,1.1,0.20240000000000002,5.0\r\n2023-10-12,0.17,1.1,0.18700000000000003,5.0\r\n2023-10-13,0.13,1.1,0.14300000000000002,4.0\r\n2023-10-14,0.186,1.1,0.2046,5.0\r\n2023-10-15,0.158,1.1,0.1738,4.0\r\n2023-10-16,0.124,1.1,0.13640000000000002,3.0\r\n2023-10-17,0.124,1.1,0.13640000000000002,3.0\r\n2023-10-18,0.108,1.1,0.1188,3.0\r\n2023-10-19,0.114,1.1,0.1254,3.0\r\n2023-10-20,0.106,1.1,0.11660000000000001,3.0\r\n2023-10-21,0.124,1.1,0.13640000000000002,3.0\r\n2023-10-22,0.134,1.1,0.14740000000000003,4.0\r\n2023-10-23,0.13,1.1,0.14300000000000002,4.0\r\n2023-10-24,0.1,1.1,0.11000000000000001,3.0\r\n2023-10-25,0.122,1.1,0.1342,3.0\r\n2023-10-26,0.13,1.1,0.14300000000000002,4.0\r\n2023-10-27,0.14600000000000002,1.1,0.16060000000000002,4.0\r\n2023-10-28,0.098,1.1,0.1078,3.0\r\n2023-10-29,0.116,1.1,0.12760000000000002,3.0\r\n2023-10-30,0.12,1.1,0.132,3.0\r\n2023-10-31,0.082,1.1,0.09020000000000002,2.0\r\n2023-11-01,0.066,1.1,0.07260000000000001,2.0\r\n2023-11-02,0.08,1.1,0.08800000000000001,2.0\r\n2023-11-03,0.098,1.1,0.1078,3.0\r\n2023-11-04,0.088,1.1,0.0968,2.0\r\n2023-11-05,0.084,1.1,0.09240000000000001,2.0\r\n2023-11-06,0.092,1.1,0.10120000000000001,3.0\r\n2023-11-07,0.09,1.1,0.099,3.0\r\n2023-11-08,0.11,1.1,0.12100000000000001,3.0\r\n2023-11-09,0.07200000000000001,1.1,0.07920000000000002,2.0\r\n2023-11-10,0.066,1.1,0.07260000000000001,2.0\r\n2023-11-11,0.066,1.1,0.07260000000000001,2.0\r\n2023-11-12,0.056,1.1,0.06160000000000001,2.0\r\n2023-11-13,0.052000000000000005,1.1,0.05720000000000001,1.0\r\n2023-11-14,0.052000000000000005,1.1,0.05720000000000001,1.0\r\n2023-11-15,0.056,1.1,0.06160000000000001,2.0\r\n2023-11-16,0.060000000000000005,1.1,0.06600000000000002,2.0\r\n2023-11-17,0.046,1.1,0.050600000000000006,1.0\r\n2023-11-18,0.06,1.1,0.066,2.0\r\n2023-11-19,0.066,1.1,0.07260000000000001,2.0\r\n2023-11-20,0.076,1.1,0.08360000000000001,2.0\r\n2023-11-21,0.048,1.1,0.05280000000000001,1.0\r\n2023-11-22,0.054,1.1,0.0594,2.0\r\n2023-11-23,0.05,1.1,0.05500000000000001,1.0\r\n2023-11-24,0.062,1.1,0.06820000000000001,2.0\r\n2023-11-25,0.066,1.1,0.07260000000000001,2.0\r\n2023-11-26,0.07,1.1,0.07700000000000001,2.0\r\n2023-11-27,0.044,1.1,0.0484,1.0\r\n2023-11-28,0.052000000000000005,1.1,0.05720000000000001,1.0\r\n2023-11-29,0.046,1.1,0.050600000000000006,1.0\r\n2023-11-30,0.044,1.1,0.0484,1.0\r\n2023-12-01,0.034,1.1,0.0374,1.0\r\n2023-12-02,0.034,1.1,0.0374,1.0\r\n2023-12-03,0.026,1.1,0.0286,1.0\r\n2023-12-04,0.022,1.1,0.0242,1.0\r\n2023-12-05,0.032,1.1,0.0352,1.0\r\n2023-12-06,0.042,1.1,0.046200000000000005,1.0\r\n2023-12-07,0.066,1.1,0.07260000000000001,2.0\r\n2023-12-08,0.032,1.1,0.0352,1.0\r\n2023-12-09,0.036000000000000004,1.1,0.03960000000000001,1.0\r\n2023-12-10,0.032,1.1,0.0352,1.0\r\n2023-12-11,0.032,1.1,0.0352,1.0\r\n2023-12-12,0.032,1.1,0.0352,1.0\r\n2023-12-13,0.018000000000000002,1.1,0.019800000000000005,1.0\r\n2023-12-14,0.04,1.1,0.044000000000000004,1.0\r\n2023-12-15,0.036,1.1,0.0396,1.0\r\n2023-12-16,0.028,1.1,0.030800000000000004,1.0\r\n2023-12-17,0.032,1.1,0.0352,1.0\r\n2023-12-18,0.024,1.1,0.026400000000000003,1.0\r\n2023-12-19,0.014,1.1,0.015400000000000002,0.0\r\n2023-12-20,0.02,1.1,0.022000000000000002,1.0\r\n2023-12-21,0.006,1.1,0.006600000000000001,0.0\r\n2023-12-22,0.018000000000000002,1.1,0.019800000000000005,1.0\r\n2023-12-23,0.028,1.1,0.030800000000000004,1.0\r\n2023-12-24,0.028,1.1,0.030800000000000004,1.0\r\n2023-12-25,0.026000000000000002,1.1,0.028600000000000004,1.0\r\n2023-12-26,0.032,1.1,0.0352,1.0\r\n2023-12-27,0.042,1.1,0.046200000000000005,1.0\r\n2023-12-28,0.044,1.1,0.0484,1.0\r\n2023-12-29,0.022,1.1,0.0242,1.0\r\n2023-12-30,0.036000000000000004,1.1,0.03960000000000001,1.0\r\n2023-12-31,0.038,1.1,0.041800000000000004,1.0\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/irrScheduling.csv b/irrScheduling.csv
--- a/irrScheduling.csv	
+++ b/irrScheduling.csv	
@@ -1,366 +1,366 @@
 currentDate,Historical Eto,KC,Historical Etc,Historical Hours
-2023-01-01,0.048,0.328,0.015744,0.0
-2023-01-02,0.034,0.328,0.011152,0.0
-2023-01-03,0.026000000000000002,0.328,0.008528,0.0
-2023-01-04,0.028,0.328,0.009184000000000001,0.0
-2023-01-05,0.026,0.328,0.008527999999999999,0.0
-2023-01-06,0.024,0.328,0.007872,0.0
-2023-01-07,0.02,0.328,0.006560000000000001,0.0
-2023-01-08,0.012,0.328,0.003936,0.0
-2023-01-09,0.030000000000000002,0.328,0.009840000000000002,0.0
-2023-01-10,0.028,0.328,0.009184000000000001,0.0
-2023-01-11,0.038,0.328,0.012464,0.0
-2023-01-12,0.032,0.328,0.010496,0.0
-2023-01-13,0.04,0.328,0.013120000000000001,0.0
-2023-01-14,0.032,0.328,0.010496,0.0
-2023-01-15,0.018000000000000002,0.328,0.005904000000000001,0.0
-2023-01-16,0.032,0.328,0.010496,0.0
-2023-01-17,0.03,0.328,0.00984,0.0
-2023-01-18,0.074,0.328,0.024272,1.0
-2023-01-19,0.078,0.328,0.025584000000000003,1.0
-2023-01-20,0.052,0.328,0.017055999999999998,0.0
-2023-01-21,0.064,0.328,0.020992,1.0
-2023-01-22,0.052000000000000005,0.328,0.017056,0.0
-2023-01-23,0.046,0.328,0.015088,0.0
-2023-01-24,0.042,0.328,0.013776000000000002,0.0
-2023-01-25,0.058,0.328,0.019024000000000003,0.0
-2023-01-26,0.054,0.328,0.017712000000000002,0.0
-2023-01-27,0.054,0.328,0.017712000000000002,0.0
-2023-01-28,0.04,0.328,0.013120000000000001,0.0
-2023-01-29,0.056,0.328,0.018368000000000002,0.0
-2023-01-30,0.058,0.328,0.019024000000000003,0.0
-2023-01-31,0.064,0.328,0.020992,1.0
-2023-02-01,0.08,0.328,0.026240000000000003,1.0
-2023-02-02,0.078,0.328,0.025584000000000003,1.0
-2023-02-03,0.058,0.328,0.019024000000000003,0.0
-2023-02-04,0.07,0.328,0.022960000000000005,1.0
-2023-02-05,0.068,0.328,0.022304,1.0
-2023-02-06,0.084,0.328,0.027552000000000004,1.0
-2023-02-07,0.074,0.328,0.024272,1.0
-2023-02-08,0.07,0.328,0.022960000000000005,1.0
-2023-02-09,0.09,0.328,0.02952,1.0
-2023-02-10,0.108,0.328,0.035424000000000004,1.0
-2023-02-11,0.07200000000000001,0.328,0.023616000000000005,1.0
-2023-02-12,0.07,0.328,0.022960000000000005,1.0
-2023-02-13,0.082,0.328,0.026896000000000003,1.0
-2023-02-14,0.068,0.328,0.022304,1.0
-2023-02-15,0.09,0.328,0.02952,1.0
-2023-02-16,0.098,0.328,0.032144000000000006,1.0
-2023-02-17,0.104,0.328,0.034111999999999996,1.0
-2023-02-18,0.1,0.328,0.0328,1.0
-2023-02-19,0.082,0.328,0.026896000000000003,1.0
-2023-02-20,0.08600000000000001,0.328,0.028208000000000004,1.0
-2023-02-21,0.114,0.328,0.037392,1.0
-2023-02-22,0.104,0.328,0.034111999999999996,1.0
-2023-02-23,0.122,0.328,0.040016,1.0
-2023-02-24,0.128,0.328,0.041984,1.0
-2023-02-25,0.1,0.328,0.0328,1.0
-2023-02-26,0.072,0.328,0.023615999999999998,1.0
-2023-02-27,0.12,0.328,0.03936,1.0
-2023-02-28,0.1,0.328,0.0328,1.0
-2023-03-01,0.07,0.328,0.022960000000000005,1.0
-2023-03-02,0.078,0.328,0.025584000000000003,1.0
-2023-03-03,0.078,0.328,0.025584000000000003,1.0
-2023-03-04,0.1,0.328,0.0328,1.0
-2023-03-05,0.082,0.328,0.026896000000000003,1.0
-2023-03-06,0.092,0.328,0.030176,1.0
-2023-03-07,0.096,0.328,0.031488,1.0
-2023-03-08,0.102,0.328,0.033456,1.0
-2023-03-09,0.094,0.328,0.030832000000000002,1.0
-2023-03-10,0.098,0.328,0.032144000000000006,1.0
-2023-03-11,0.12000000000000001,0.328,0.039360000000000006,1.0
-2023-03-12,0.124,0.328,0.040672,1.0
-2023-03-13,0.114,0.328,0.037392,1.0
-2023-03-14,0.08,0.328,0.026240000000000003,1.0
-2023-03-15,0.076,0.328,0.024928,1.0
-2023-03-16,0.098,0.328,0.032144000000000006,1.0
-2023-03-17,0.1,0.328,0.0328,1.0
-2023-03-18,0.076,0.328,0.024928,1.0
-2023-03-19,0.09,0.328,0.02952,1.0
-2023-03-20,0.114,0.328,0.037392,1.0
-2023-03-21,0.138,0.328,0.045264000000000006,1.0
-2023-03-22,0.11,0.328,0.03608,1.0
-2023-03-23,0.154,0.328,0.050512,1.0
-2023-03-24,0.126,0.328,0.041328000000000004,1.0
-2023-03-25,0.122,0.328,0.040016,1.0
-2023-03-26,0.158,0.328,0.051824,1.0
-2023-03-27,0.132,0.328,0.043296,1.0
-2023-03-28,0.106,0.328,0.034768,1.0
-2023-03-29,0.148,0.328,0.048544,1.0
-2023-03-30,0.16,0.328,0.052480000000000006,1.0
-2023-03-31,0.162,0.328,0.053136,1.0
-2023-04-01,0.14,0.328,0.04592000000000001,1.0
-2023-04-02,0.162,0.328,0.053136,1.0
-2023-04-03,0.158,0.328,0.051824,1.0
-2023-04-04,0.114,0.328,0.037392,1.0
-2023-04-05,0.106,0.328,0.034768,1.0
-2023-04-06,0.134,0.328,0.043952000000000005,1.0
-2023-04-07,0.17400000000000002,0.328,0.057072000000000005,1.0
-2023-04-08,0.152,0.328,0.049856,1.0
-2023-04-09,0.194,0.328,0.06363200000000001,2.0
-2023-04-10,0.188,0.328,0.061664000000000004,2.0
-2023-04-11,0.158,0.328,0.051824,1.0
-2023-04-12,0.17400000000000002,0.328,0.057072000000000005,1.0
-2023-04-13,0.17200000000000001,0.328,0.05641600000000001,1.0
-2023-04-14,0.162,0.328,0.053136,1.0
-2023-04-15,0.154,0.328,0.050512,1.0
-2023-04-16,0.13999999999999999,0.328,0.045919999999999996,1.0
-2023-04-17,0.186,0.328,0.061008,2.0
-2023-04-18,0.178,0.328,0.058384,1.0
-2023-04-19,0.186,0.328,0.061008,2.0
-2023-04-20,0.184,0.328,0.060352,2.0
-2023-04-21,0.182,0.328,0.059696,2.0
-2023-04-22,0.2,0.328,0.0656,2.0
-2023-04-23,0.21,0.328,0.06888,2.0
-2023-04-24,0.212,0.328,0.069536,2.0
-2023-04-25,0.196,0.328,0.06428800000000001,2.0
-2023-04-26,0.224,0.328,0.07347200000000001,2.0
-2023-04-27,0.222,0.328,0.072816,2.0
-2023-04-28,0.212,0.328,0.069536,2.0
-2023-04-29,0.214,0.328,0.070192,2.0
-2023-04-30,0.228,0.328,0.074784,2.0
-2023-05-01,0.246,0.328,0.080688,2.0
-2023-05-02,0.238,0.328,0.078064,2.0
-2023-05-03,0.264,0.328,0.086592,2.0
-2023-05-04,0.234,0.328,0.076752,2.0
-2023-05-05,0.23,0.328,0.07544000000000001,2.0
-2023-05-06,0.22,0.328,0.07216,2.0
-2023-05-07,0.23600000000000002,0.328,0.077408,2.0
-2023-05-08,0.272,0.328,0.089216,2.0
-2023-05-09,0.268,0.328,0.08790400000000001,2.0
-2023-05-10,0.254,0.328,0.08331200000000001,2.0
-2023-05-11,0.248,0.328,0.081344,2.0
-2023-05-12,0.24600000000000002,0.328,0.08068800000000001,2.0
-2023-05-13,0.224,0.328,0.07347200000000001,2.0
-2023-05-14,0.214,0.328,0.070192,2.0
-2023-05-15,0.208,0.328,0.06822399999999999,2.0
-2023-05-16,0.214,0.328,0.070192,2.0
-2023-05-17,0.21200000000000002,0.328,0.06953600000000001,2.0
-2023-05-18,0.22,0.328,0.07216,2.0
-2023-05-19,0.22200000000000003,0.328,0.07281600000000002,2.0
-2023-05-20,0.256,0.328,0.083968,2.0
-2023-05-21,0.252,0.378,0.09525600000000001,2.0
-2023-05-22,0.26,0.378,0.09828,2.0
-2023-05-23,0.268,0.378,0.101304,3.0
-2023-05-24,0.272,0.378,0.102816,3.0
-2023-05-25,0.24000000000000002,0.378,0.09072000000000001,2.0
-2023-05-26,0.222,0.378,0.083916,2.0
-2023-05-27,0.24,0.378,0.09072,2.0
-2023-05-28,0.26,0.378,0.09828,2.0
-2023-05-29,0.27,0.378,0.10206000000000001,3.0
-2023-05-30,0.248,0.378,0.093744,2.0
-2023-05-31,0.266,0.398,0.10586800000000002,3.0
-2023-06-01,0.272,0.398,0.10825600000000002,3.0
-2023-06-02,0.27,0.398,0.10746000000000001,3.0
-2023-06-03,0.266,0.398,0.10586800000000002,3.0
-2023-06-04,0.266,0.398,0.10586800000000002,3.0
-2023-06-05,0.252,0.398,0.10029600000000001,3.0
-2023-06-06,0.29000000000000004,0.398,0.11542000000000002,3.0
-2023-06-07,0.28,0.398,0.11144000000000001,3.0
-2023-06-08,0.304,0.398,0.120992,3.0
-2023-06-09,0.27,0.398,0.10746000000000001,3.0
-2023-06-10,0.272,0.478,0.130016,3.0
-2023-06-11,0.28,0.478,0.13384000000000001,3.0
-2023-06-12,0.268,0.478,0.128104,3.0
-2023-06-13,0.28200000000000003,0.478,0.134796,3.0
-2023-06-14,0.28200000000000003,0.478,0.134796,3.0
-2023-06-15,0.274,0.478,0.130972,3.0
-2023-06-16,0.278,0.478,0.132884,3.0
-2023-06-17,0.28200000000000003,0.478,0.134796,3.0
-2023-06-18,0.29000000000000004,0.478,0.13862000000000002,4.0
-2023-06-19,0.3,0.478,0.1434,4.0
-2023-06-20,0.294,0.528,0.155232,4.0
-2023-06-21,0.296,0.528,0.156288,4.0
-2023-06-22,0.294,0.528,0.155232,4.0
-2023-06-23,0.314,0.528,0.165792,4.0
-2023-06-24,0.294,0.528,0.155232,4.0
-2023-06-25,0.294,0.528,0.155232,4.0
-2023-06-26,0.302,0.528,0.15945600000000001,4.0
-2023-06-27,0.28,0.528,0.14784000000000003,4.0
-2023-06-28,0.27999999999999997,0.528,0.14784,4.0
-2023-06-29,0.298,0.528,0.157344,4.0
-2023-06-30,0.296,0.828,0.24508799999999997,6.0
-2023-07-01,0.288,0.828,0.23846399999999998,6.0
-2023-07-02,0.27,0.828,0.22356,6.0
-2023-07-03,0.26,0.828,0.21528,5.0
-2023-07-04,0.278,0.828,0.230184,6.0
-2023-07-05,0.286,0.828,0.23680799999999996,6.0
-2023-07-06,0.276,0.828,0.228528,6.0
-2023-07-07,0.274,0.828,0.22687200000000002,6.0
-2023-07-08,0.28400000000000003,0.828,0.235152,6.0
-2023-07-09,0.29,0.828,0.24011999999999997,6.0
-2023-07-10,0.3,1.028,0.3084,8.0
-2023-07-11,0.296,1.028,0.304288,8.0
-2023-07-12,0.3,1.028,0.3084,8.0
-2023-07-13,0.274,1.028,0.28167200000000003,7.0
-2023-07-14,0.278,1.028,0.28578400000000004,7.0
-2023-07-15,0.278,1.028,0.28578400000000004,7.0
-2023-07-16,0.278,1.028,0.28578400000000004,7.0
-2023-07-17,0.274,1.028,0.28167200000000003,7.0
-2023-07-18,0.278,1.028,0.28578400000000004,7.0
-2023-07-19,0.29,1.028,0.29812,8.0
-2023-07-20,0.276,1.1,0.30360000000000004,8.0
-2023-07-21,0.278,1.1,0.30580000000000007,8.0
-2023-07-22,0.288,1.1,0.3168,8.0
-2023-07-23,0.27999999999999997,1.1,0.308,8.0
-2023-07-24,0.28400000000000003,1.1,0.31240000000000007,8.0
-2023-07-25,0.294,1.1,0.3234,8.0
-2023-07-26,0.27,1.1,0.29700000000000004,8.0
-2023-07-27,0.274,1.1,0.30140000000000006,8.0
-2023-07-28,0.27,1.1,0.29700000000000004,8.0
-2023-07-29,0.258,1.1,0.28380000000000005,7.0
-2023-07-30,0.266,1.1,0.2926,7.0
-2023-07-31,0.244,1.1,0.2684,7.0
-2023-08-01,0.244,1.1,0.2684,7.0
-2023-08-02,0.268,1.1,0.29480000000000006,7.0
-2023-08-03,0.26,1.1,0.28600000000000003,7.0
-2023-08-04,0.28,1.1,0.30800000000000005,8.0
-2023-08-05,0.23,1.1,0.25300000000000006,6.0
-2023-08-06,0.23,1.1,0.25300000000000006,6.0
-2023-08-07,0.232,1.1,0.25520000000000004,6.0
-2023-08-08,0.248,1.1,0.27280000000000004,7.0
-2023-08-09,0.256,1.1,0.2816,7.0
-2023-08-10,0.264,1.1,0.29040000000000005,7.0
-2023-08-11,0.272,1.1,0.2992,8.0
-2023-08-12,0.254,1.1,0.27940000000000004,7.0
-2023-08-13,0.25,1.1,0.275,7.0
-2023-08-14,0.244,1.1,0.2684,7.0
-2023-08-15,0.242,1.1,0.2662,7.0
-2023-08-16,0.268,1.1,0.29480000000000006,7.0
-2023-08-17,0.23,1.1,0.25300000000000006,6.0
-2023-08-18,0.246,1.1,0.2706,7.0
-2023-08-19,0.232,1.1,0.25520000000000004,6.0
-2023-08-20,0.224,1.1,0.24640000000000004,6.0
-2023-08-21,0.23600000000000002,1.1,0.25960000000000005,7.0
-2023-08-22,0.23399999999999999,1.1,0.2574,7.0
-2023-08-23,0.248,1.1,0.27280000000000004,7.0
-2023-08-24,0.244,1.1,0.2684,7.0
-2023-08-25,0.242,1.1,0.2662,7.0
-2023-08-26,0.23600000000000002,1.1,0.25960000000000005,7.0
-2023-08-27,0.242,1.1,0.2662,7.0
-2023-08-28,0.232,1.1,0.25520000000000004,6.0
-2023-08-29,0.248,1.1,0.27280000000000004,7.0
-2023-08-30,0.226,1.1,0.24860000000000002,6.0
-2023-08-31,0.228,1.1,0.2508,6.0
-2023-09-01,0.232,1.1,0.25520000000000004,6.0
-2023-09-02,0.226,1.1,0.24860000000000002,6.0
-2023-09-03,0.228,1.1,0.2508,6.0
-2023-09-04,0.216,1.1,0.2376,6.0
-2023-09-05,0.228,1.1,0.2508,6.0
-2023-09-06,0.222,1.1,0.24420000000000003,6.0
-2023-09-07,0.232,1.1,0.25520000000000004,6.0
-2023-09-08,0.244,1.1,0.2684,7.0
-2023-09-09,0.2,1.1,0.22000000000000003,6.0
-2023-09-10,0.176,1.1,0.1936,5.0
-2023-09-11,0.186,1.1,0.2046,5.0
-2023-09-12,0.188,1.1,0.2068,5.0
-2023-09-13,0.192,1.1,0.21120000000000003,5.0
-2023-09-14,0.192,1.1,0.21120000000000003,5.0
-2023-09-15,0.192,1.1,0.21120000000000003,5.0
-2023-09-16,0.168,1.1,0.18480000000000002,5.0
-2023-09-17,0.184,1.1,0.20240000000000002,5.0
-2023-09-18,0.154,1.1,0.16940000000000002,4.0
-2023-09-19,0.162,1.1,0.17820000000000003,5.0
-2023-09-20,0.17200000000000001,1.1,0.18920000000000003,5.0
-2023-09-21,0.164,1.1,0.18040000000000003,5.0
-2023-09-22,0.188,1.1,0.2068,5.0
-2023-09-23,0.194,1.1,0.21340000000000003,5.0
-2023-09-24,0.198,1.1,0.21780000000000002,6.0
-2023-09-25,0.176,1.1,0.1936,5.0
-2023-09-26,0.188,1.1,0.2068,5.0
-2023-09-27,0.18,1.1,0.198,5.0
-2023-09-28,0.20600000000000002,1.1,0.22660000000000002,6.0
-2023-09-29,0.164,1.1,0.18040000000000003,5.0
-2023-09-30,0.164,1.1,0.18040000000000003,5.0
-2023-10-01,0.156,1.1,0.1716,4.0
-2023-10-02,0.162,1.1,0.17820000000000003,5.0
-2023-10-03,0.156,1.1,0.1716,4.0
-2023-10-04,0.166,1.1,0.1826,5.0
-2023-10-05,0.16,1.1,0.17600000000000002,4.0
-2023-10-06,0.166,1.1,0.1826,5.0
-2023-10-07,0.186,1.1,0.2046,5.0
-2023-10-08,0.146,1.1,0.1606,4.0
-2023-10-09,0.17,1.1,0.18700000000000003,5.0
-2023-10-10,0.164,1.1,0.18040000000000003,5.0
-2023-10-11,0.184,1.1,0.20240000000000002,5.0
-2023-10-12,0.17,1.1,0.18700000000000003,5.0
-2023-10-13,0.13,1.1,0.14300000000000002,4.0
-2023-10-14,0.186,1.1,0.2046,5.0
-2023-10-15,0.158,1.1,0.1738,4.0
-2023-10-16,0.124,1.1,0.13640000000000002,3.0
-2023-10-17,0.124,1.1,0.13640000000000002,3.0
-2023-10-18,0.108,1.1,0.1188,3.0
-2023-10-19,0.114,1.1,0.1254,3.0
-2023-10-20,0.106,1.1,0.11660000000000001,3.0
-2023-10-21,0.124,1.1,0.13640000000000002,3.0
-2023-10-22,0.134,1.1,0.14740000000000003,4.0
-2023-10-23,0.13,1.1,0.14300000000000002,4.0
-2023-10-24,0.1,1.1,0.11000000000000001,3.0
-2023-10-25,0.122,1.1,0.1342,3.0
-2023-10-26,0.13,1.1,0.14300000000000002,4.0
-2023-10-27,0.14600000000000002,1.1,0.16060000000000002,4.0
-2023-10-28,0.098,1.1,0.1078,3.0
-2023-10-29,0.116,1.1,0.12760000000000002,3.0
-2023-10-30,0.12,1.1,0.132,3.0
-2023-10-31,0.082,1.1,0.09020000000000002,2.0
-2023-11-01,0.066,1.1,0.07260000000000001,2.0
-2023-11-02,0.08,1.1,0.08800000000000001,2.0
-2023-11-03,0.098,1.1,0.1078,3.0
-2023-11-04,0.088,1.1,0.0968,2.0
-2023-11-05,0.084,1.1,0.09240000000000001,2.0
-2023-11-06,0.092,1.1,0.10120000000000001,3.0
-2023-11-07,0.09,1.1,0.099,3.0
-2023-11-08,0.11,1.1,0.12100000000000001,3.0
-2023-11-09,0.07200000000000001,1.1,0.07920000000000002,2.0
-2023-11-10,0.066,1.1,0.07260000000000001,2.0
-2023-11-11,0.066,1.1,0.07260000000000001,2.0
-2023-11-12,0.056,1.1,0.06160000000000001,2.0
-2023-11-13,0.052000000000000005,1.1,0.05720000000000001,1.0
-2023-11-14,0.052000000000000005,1.1,0.05720000000000001,1.0
-2023-11-15,0.056,1.1,0.06160000000000001,2.0
-2023-11-16,0.060000000000000005,1.1,0.06600000000000002,2.0
-2023-11-17,0.046,1.1,0.050600000000000006,1.0
-2023-11-18,0.06,1.1,0.066,2.0
-2023-11-19,0.066,1.1,0.07260000000000001,2.0
-2023-11-20,0.076,1.1,0.08360000000000001,2.0
-2023-11-21,0.048,1.1,0.05280000000000001,1.0
-2023-11-22,0.054,1.1,0.0594,2.0
-2023-11-23,0.05,1.1,0.05500000000000001,1.0
-2023-11-24,0.062,1.1,0.06820000000000001,2.0
-2023-11-25,0.066,1.1,0.07260000000000001,2.0
-2023-11-26,0.07,1.1,0.07700000000000001,2.0
-2023-11-27,0.044,1.1,0.0484,1.0
-2023-11-28,0.052000000000000005,1.1,0.05720000000000001,1.0
-2023-11-29,0.046,1.1,0.050600000000000006,1.0
-2023-11-30,0.044,1.1,0.0484,1.0
-2023-12-01,0.034,1.1,0.0374,1.0
-2023-12-02,0.034,1.1,0.0374,1.0
-2023-12-03,0.026,1.1,0.0286,1.0
-2023-12-04,0.022,1.1,0.0242,1.0
-2023-12-05,0.032,1.1,0.0352,1.0
-2023-12-06,0.042,1.1,0.046200000000000005,1.0
-2023-12-07,0.066,1.1,0.07260000000000001,2.0
-2023-12-08,0.032,1.1,0.0352,1.0
-2023-12-09,0.036000000000000004,1.1,0.03960000000000001,1.0
-2023-12-10,0.032,1.1,0.0352,1.0
-2023-12-11,0.032,1.1,0.0352,1.0
-2023-12-12,0.032,1.1,0.0352,1.0
-2023-12-13,0.018000000000000002,1.1,0.019800000000000005,1.0
-2023-12-14,0.04,1.1,0.044000000000000004,1.0
-2023-12-15,0.036,1.1,0.0396,1.0
-2023-12-16,0.028,1.1,0.030800000000000004,1.0
-2023-12-17,0.032,1.1,0.0352,1.0
-2023-12-18,0.024,1.1,0.026400000000000003,1.0
-2023-12-19,0.014,1.1,0.015400000000000002,0.0
-2023-12-20,0.02,1.1,0.022000000000000002,1.0
-2023-12-21,0.006,1.1,0.006600000000000001,0.0
-2023-12-22,0.018000000000000002,1.1,0.019800000000000005,1.0
-2023-12-23,0.028,1.1,0.030800000000000004,1.0
-2023-12-24,0.028,1.1,0.030800000000000004,1.0
-2023-12-25,0.026000000000000002,1.1,0.028600000000000004,1.0
-2023-12-26,0.032,1.1,0.0352,1.0
-2023-12-27,0.042,1.1,0.046200000000000005,1.0
-2023-12-28,0.044,1.1,0.0484,1.0
-2023-12-29,0.022,1.1,0.0242,1.0
-2023-12-30,0.036000000000000004,1.1,0.03960000000000001,1.0
-2023-12-31,0.038,1.1,0.041800000000000004,1.0
+2024-01-01,,0.378,,
+2024-01-02,,0.378,,
+2024-01-03,,0.378,,
+2024-01-04,,0.378,,
+2024-01-05,,0.378,,
+2024-01-06,,0.378,,
+2024-01-07,,0.378,,
+2024-01-08,,0.378,,
+2024-01-09,,0.378,,
+2024-01-10,,0.378,,
+2024-01-11,,0.378,,
+2024-01-12,,0.378,,
+2024-01-13,,0.378,,
+2024-01-14,,0.378,,
+2024-01-15,,0.378,,
+2024-01-16,,0.378,,
+2024-01-17,,0.378,,
+2024-01-18,,0.378,,
+2024-01-19,,0.378,,
+2024-01-20,,0.378,,
+2024-01-21,,0.378,,
+2024-01-22,,0.378,,
+2024-01-23,,0.378,,
+2024-01-24,,0.378,,
+2024-01-25,,0.378,,
+2024-01-26,,0.378,,
+2024-01-27,,0.378,,
+2024-01-28,,0.378,,
+2024-01-29,,0.378,,
+2024-01-30,,0.378,,
+2024-01-31,,0.378,,
+2024-02-01,,0.378,,
+2024-02-02,,0.378,,
+2024-02-03,,0.378,,
+2024-02-04,,0.378,,
+2024-02-05,,0.378,,
+2024-02-06,,0.378,,
+2024-02-07,,0.378,,
+2024-02-08,,0.378,,
+2024-02-09,,0.378,,
+2024-02-10,,0.378,,
+2024-02-11,,0.378,,
+2024-02-12,,0.378,,
+2024-02-13,,0.378,,
+2024-02-14,,0.378,,
+2024-02-15,,0.378,,
+2024-02-16,,0.378,,
+2024-02-17,,0.378,,
+2024-02-18,,0.378,,
+2024-02-19,,0.378,,
+2024-02-20,,0.378,,
+2024-02-21,,0.378,,
+2024-02-22,,0.378,,
+2024-02-23,,0.378,,
+2024-02-24,,0.378,,
+2024-02-25,,0.378,,
+2024-02-26,,0.378,,
+2024-02-27,,0.378,,
+2024-02-28,,0.378,,
+2024-02-29,,0.378,,
+2024-03-01,,0.378,,
+2024-03-02,,0.378,,
+2024-03-03,,0.378,,
+2024-03-04,,0.378,,
+2024-03-05,,0.378,,
+2024-03-06,,0.378,,
+2024-03-07,,0.378,,
+2024-03-08,,0.378,,
+2024-03-09,,0.378,,
+2024-03-10,,0.378,,
+2024-03-11,,0.398,,
+2024-03-12,,0.398,,
+2024-03-13,,0.398,,
+2024-03-14,,0.398,,
+2024-03-15,,0.398,,
+2024-03-16,,0.398,,
+2024-03-17,,0.398,,
+2024-03-18,,0.398,,
+2024-03-19,,0.398,,
+2024-03-20,,0.398,,
+2024-03-21,,0.398,,
+2024-03-22,,0.398,,
+2024-03-23,,0.398,,
+2024-03-24,,0.398,,
+2024-03-25,,0.398,,
+2024-03-26,,0.398,,
+2024-03-27,,0.398,,
+2024-03-28,,0.398,,
+2024-03-29,,0.398,,
+2024-03-30,,0.398,,
+2024-03-31,,0.41800000000000004,,
+2024-04-01,,0.41800000000000004,,
+2024-04-02,,0.41800000000000004,,
+2024-04-03,,0.41800000000000004,,
+2024-04-04,,0.41800000000000004,,
+2024-04-05,,0.41800000000000004,,
+2024-04-06,,0.41800000000000004,,
+2024-04-07,,0.41800000000000004,,
+2024-04-08,,0.41800000000000004,,
+2024-04-09,,0.41800000000000004,,
+2024-04-10,,0.42800000000000005,,
+2024-04-11,,0.42800000000000005,,
+2024-04-12,,0.42800000000000005,,
+2024-04-13,,0.42800000000000005,,
+2024-04-14,,0.42800000000000005,,
+2024-04-15,,0.42800000000000005,,
+2024-04-16,,0.42800000000000005,,
+2024-04-17,,0.42800000000000005,,
+2024-04-18,,0.42800000000000005,,
+2024-04-19,,0.42800000000000005,,
+2024-04-20,,0.528,,
+2024-04-21,,0.528,,
+2024-04-22,,0.528,,
+2024-04-23,,0.528,,
+2024-04-24,,0.528,,
+2024-04-25,,0.528,,
+2024-04-26,,0.528,,
+2024-04-27,,0.528,,
+2024-04-28,,0.528,,
+2024-04-29,,0.528,,
+2024-04-30,,0.628,,
+2024-05-01,,0.628,,
+2024-05-02,,0.628,,
+2024-05-03,,0.628,,
+2024-05-04,,0.628,,
+2024-05-05,,0.628,,
+2024-05-06,,0.628,,
+2024-05-07,,0.628,,
+2024-05-08,,0.628,,
+2024-05-09,,0.628,,
+2024-05-10,,0.828,,
+2024-05-11,,0.828,,
+2024-05-12,,0.828,,
+2024-05-13,,0.828,,
+2024-05-14,,0.828,,
+2024-05-15,,0.828,,
+2024-05-16,,0.828,,
+2024-05-17,,0.828,,
+2024-05-18,,0.828,,
+2024-05-19,,0.828,,
+2024-05-20,,1.1,,
+2024-05-21,,1.1,,
+2024-05-22,,1.1,,
+2024-05-23,,1.1,,
+2024-05-24,,1.1,,
+2024-05-25,,1.1,,
+2024-05-26,,1.1,,
+2024-05-27,,1.1,,
+2024-05-28,,1.1,,
+2024-05-29,,1.1,,
+2024-05-30,,1.1,,
+2024-05-31,,1.1,,
+2024-06-01,,1.1,,
+2024-06-02,,1.1,,
+2024-06-03,,1.1,,
+2024-06-04,,1.1,,
+2024-06-05,,1.1,,
+2024-06-06,,1.1,,
+2024-06-07,,1.1,,
+2024-06-08,,1.1,,
+2024-06-09,,1.1,,
+2024-06-10,,1.1,,
+2024-06-11,,1.1,,
+2024-06-12,,1.1,,
+2024-06-13,,1.1,,
+2024-06-14,,1.1,,
+2024-06-15,,1.1,,
+2024-06-16,,1.1,,
+2024-06-17,,1.1,,
+2024-06-18,,1.1,,
+2024-06-19,,1.1,,
+2024-06-20,,1.1,,
+2024-06-21,,1.1,,
+2024-06-22,,1.1,,
+2024-06-23,,1.1,,
+2024-06-24,,1.1,,
+2024-06-25,,1.1,,
+2024-06-26,,1.1,,
+2024-06-27,,1.1,,
+2024-06-28,,1.1,,
+2024-06-29,,1.1,,
+2024-06-30,,1.1,,
+2024-07-01,,1.1,,
+2024-07-02,,1.1,,
+2024-07-03,,1.1,,
+2024-07-04,,1.1,,
+2024-07-05,,1.1,,
+2024-07-06,,1.1,,
+2024-07-07,,1.1,,
+2024-07-08,,1.1,,
+2024-07-09,,1.1,,
+2024-07-10,,1.1,,
+2024-07-11,,1.1,,
+2024-07-12,,1.1,,
+2024-07-13,,1.1,,
+2024-07-14,,1.1,,
+2024-07-15,,1.1,,
+2024-07-16,,1.1,,
+2024-07-17,,1.1,,
+2024-07-18,,1.1,,
+2024-07-19,,1.1,,
+2024-07-20,,1.1,,
+2024-07-21,,1.1,,
+2024-07-22,,1.1,,
+2024-07-23,,1.1,,
+2024-07-24,,1.1,,
+2024-07-25,,1.1,,
+2024-07-26,,1.1,,
+2024-07-27,,1.1,,
+2024-07-28,,1.1,,
+2024-07-29,,1.1,,
+2024-07-30,,1.1,,
+2024-07-31,,1.1,,
+2024-08-01,,1.1,,
+2024-08-02,,1.1,,
+2024-08-03,,1.1,,
+2024-08-04,,1.1,,
+2024-08-05,,1.1,,
+2024-08-06,,1.1,,
+2024-08-07,,1.1,,
+2024-08-08,,1.1,,
+2024-08-09,,1.1,,
+2024-08-10,,1.1,,
+2024-08-11,,1.1,,
+2024-08-12,,1.1,,
+2024-08-13,,1.1,,
+2024-08-14,,1.1,,
+2024-08-15,,1.1,,
+2024-08-16,,1.1,,
+2024-08-17,,1.1,,
+2024-08-18,,1.1,,
+2024-08-19,,1.1,,
+2024-08-20,,1.1,,
+2024-08-21,,1.1,,
+2024-08-22,,1.1,,
+2024-08-23,,1.1,,
+2024-08-24,,1.1,,
+2024-08-25,,1.1,,
+2024-08-26,,1.1,,
+2024-08-27,,1.1,,
+2024-08-28,,1.1,,
+2024-08-29,,1.1,,
+2024-08-30,,1.1,,
+2024-08-31,,1.1,,
+2024-09-01,,1.1,,
+2024-09-02,,1.1,,
+2024-09-03,,1.1,,
+2024-09-04,,1.1,,
+2024-09-05,,1.1,,
+2024-09-06,,1.1,,
+2024-09-07,,1.1,,
+2024-09-08,,1.1,,
+2024-09-09,,1.1,,
+2024-09-10,,1.1,,
+2024-09-11,,1.1,,
+2024-09-12,,1.1,,
+2024-09-13,,1.1,,
+2024-09-14,,1.1,,
+2024-09-15,,1.1,,
+2024-09-16,,1.1,,
+2024-09-17,,1.1,,
+2024-09-18,,1.1,,
+2024-09-19,,1.1,,
+2024-09-20,,1.1,,
+2024-09-21,,1.1,,
+2024-09-22,,1.1,,
+2024-09-23,,1.1,,
+2024-09-24,,1.1,,
+2024-09-25,,1.1,,
+2024-09-26,,1.1,,
+2024-09-27,,1.1,,
+2024-09-28,,1.1,,
+2024-09-29,,1.1,,
+2024-09-30,,1.1,,
+2024-10-01,,1.1,,
+2024-10-02,,1.1,,
+2024-10-03,,1.1,,
+2024-10-04,,1.1,,
+2024-10-05,,1.1,,
+2024-10-06,,1.1,,
+2024-10-07,,1.1,,
+2024-10-08,,1.1,,
+2024-10-09,,1.1,,
+2024-10-10,,1.1,,
+2024-10-11,,1.1,,
+2024-10-12,,1.1,,
+2024-10-13,,1.1,,
+2024-10-14,,1.1,,
+2024-10-15,,1.1,,
+2024-10-16,,1.1,,
+2024-10-17,,1.1,,
+2024-10-18,,1.1,,
+2024-10-19,,1.1,,
+2024-10-20,,1.1,,
+2024-10-21,,1.1,,
+2024-10-22,,1.1,,
+2024-10-23,,1.1,,
+2024-10-24,,1.1,,
+2024-10-25,,1.1,,
+2024-10-26,,1.1,,
+2024-10-27,,1.1,,
+2024-10-28,,1.1,,
+2024-10-29,,1.1,,
+2024-10-30,,1.1,,
+2024-10-31,,1.1,,
+2024-11-01,,1.1,,
+2024-11-02,,1.1,,
+2024-11-03,,1.1,,
+2024-11-04,,1.1,,
+2024-11-05,,1.1,,
+2024-11-06,,1.1,,
+2024-11-07,,1.1,,
+2024-11-08,,1.1,,
+2024-11-09,,1.1,,
+2024-11-10,,1.1,,
+2024-11-11,,1.1,,
+2024-11-12,,1.1,,
+2024-11-13,,1.1,,
+2024-11-14,,1.1,,
+2024-11-15,,1.1,,
+2024-11-16,,1.1,,
+2024-11-17,,1.1,,
+2024-11-18,,1.1,,
+2024-11-19,,1.1,,
+2024-11-20,,1.1,,
+2024-11-21,,1.1,,
+2024-11-22,,1.1,,
+2024-11-23,,1.1,,
+2024-11-24,,1.1,,
+2024-11-25,,1.1,,
+2024-11-26,,1.1,,
+2024-11-27,,1.1,,
+2024-11-28,,1.1,,
+2024-11-29,,1.1,,
+2024-11-30,,1.1,,
+2024-12-01,,1.1,,
+2024-12-02,,1.1,,
+2024-12-03,,1.1,,
+2024-12-04,,1.1,,
+2024-12-05,,1.1,,
+2024-12-06,,1.1,,
+2024-12-07,,1.1,,
+2024-12-08,,1.1,,
+2024-12-09,,1.1,,
+2024-12-10,,1.1,,
+2024-12-11,,1.1,,
+2024-12-12,,1.1,,
+2024-12-13,,1.1,,
+2024-12-14,,1.1,,
+2024-12-15,,1.1,,
+2024-12-16,,1.1,,
+2024-12-17,,1.1,,
+2024-12-18,,1.1,,
+2024-12-19,,1.1,,
+2024-12-20,,1.1,,
+2024-12-21,,1.1,,
+2024-12-22,,1.1,,
+2024-12-23,,1.1,,
+2024-12-24,,1.1,,
+2024-12-25,,1.1,,
+2024-12-26,,1.1,,
+2024-12-27,,1.1,,
+2024-12-28,,1.1,,
+2024-12-29,,1.1,,
+2024-12-30,,1.1,,
Index: credentials2.json
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>{\"installed\":{\"client_id\":\"833486550311-3vmvo3luh7ornb5v8qo56ng6o5mnfn4g.apps.googleusercontent.com\",\"project_id\":\"stomato\",\"auth_uri\":\"https://accounts.google.com/o/oauth2/auth\",\"token_uri\":\"https://oauth2.googleapis.com/token\",\"auth_provider_x509_cert_url\":\"https://www.googleapis.com/oauth2/v1/certs\",\"client_secret\":\"DiKFMQApE6jvVI8w3q9TUDka\",\"redirect_uris\":[\"urn:ietf:wg:oauth:2.0:oob\",\"http://localhost\"]}}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/credentials2.json b/credentials2.json
--- a/credentials2.json	
+++ b/credentials2.json	
@@ -1,1 +1,2 @@
-{"installed":{"client_id":"833486550311-3vmvo3luh7ornb5v8qo56ng6o5mnfn4g.apps.googleusercontent.com","project_id":"stomato","auth_uri":"https://accounts.google.com/o/oauth2/auth","token_uri":"https://oauth2.googleapis.com/token","auth_provider_x509_cert_url":"https://www.googleapis.com/oauth2/v1/certs","client_secret":"DiKFMQApE6jvVI8w3q9TUDka","redirect_uris":["urn:ietf:wg:oauth:2.0:oob","http://localhost"]}}
\ No newline at end of file
+{"installed":
+{"client_id":"833486550311-3vmvo3luh7ornb5v8qo56ng6o5mnfn4g.apps.googleusercontent.com","project_id":"stomato","auth_uri":"https://accounts.google.com/o/oauth2/auth","token_uri":"https://oauth2.googleapis.com/token","auth_provider_x509_cert_url":"https://www.googleapis.com/oauth2/v1/certs","client_secret":"DiKFMQApE6jvVI8w3q9TUDka","redirect_uris":["urn:ietf:wg:oauth:2.0:oob","http://localhost"]}}
\ No newline at end of file
Index: newhistoricalET.csv
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>Year_2022,Year_2022_ET,Year_2021,Year_2021_ET,Year_2020,Year_2020_ET,Year_2019,Year_2019_ET,Year_2018,Year_2018_ET,Average\r\n2022-01-01,0.05,2021-01-01,0.03,2020-01-01,0.04,2019-01-01,0.06,2018-01-01,0.04,0.042499999999999996\r\n2022-01-02,0.03,2021-01-02,0.02,2020-01-02,0.06,2019-01-02,0.05,2018-01-02,0.02,0.0375\r\n2022-01-03,0.03,2021-01-03,0.02,2020-01-03,0.04,2019-01-03,0.04,2018-01-03,0.01,0.0275\r\n2022-01-04,0.02,2021-01-04,0.02,2020-01-04,0.05,2019-01-04,0.05,2018-01-04,0.05,0.0425\r\n2022-01-05,0.05,2021-01-05,0.01,2020-01-05,0.07,2019-01-05,0.02,2018-01-05,0.01,0.027500000000000004\r\n2022-01-06,0.01,2021-01-06,0.03,2020-01-06,0.05,2019-01-06,0.0,2018-01-06,0.06,0.035\r\n2022-01-07,0.01,2021-01-07,0.04,2020-01-07,0.01,2019-01-07,0.03,2018-01-07,0.0,0.02\r\n2022-01-08,0.01,2021-01-08,0.02,2020-01-08,0.02,2019-01-08,0.01,2018-01-08,0.0,0.0125\r\n2022-01-09,0.04,2021-01-09,0.06,2020-01-09,0.01,2019-01-09,0.04,2018-01-09,0.0,0.0275\r\n2022-01-10,0.05,2021-01-10,0.02,2020-01-10,0.05,2019-01-10,0.01,2018-01-10,0.01,0.0225\r\n2022-01-11,0.05,2021-01-11,0.04,2020-01-11,0.06,2019-01-11,0.03,2018-01-11,0.03,0.04\r\n2022-01-12,0.04,2021-01-12,0.02,2020-01-12,0.03,2019-01-12,0.03,2018-01-12,0.0,0.02\r\n2022-01-13,0.04,2021-01-13,0.06,2020-01-13,0.04,2019-01-13,0.03,2018-01-13,0.0,0.0325\r\n2022-01-14,0.05,2021-01-14,0.06,2020-01-14,0.07,2019-01-14,0.01,2018-01-14,0.0,0.035\r\n2022-01-15,0.02,2021-01-15,0.05,2020-01-15,0.04,2019-01-15,0.0,2018-01-15,0.0,0.0225\r\n2022-01-16,0.05,2021-01-16,0.08,2020-01-16,0.02,2019-01-16,0.02,2018-01-16,0.0,0.03\r\n2022-01-17,0.06,2021-01-17,0.06,2020-01-17,0.02,2019-01-17,0.03,2018-01-17,0.0,0.0275\r\n2022-01-18,0.05,2021-01-18,0.18,2020-01-18,0.01,2019-01-18,0.04,2018-01-18,0.02,0.0625\r\n2022-01-19,0.05,2021-01-19,0.18,2020-01-19,0.0,2019-01-19,0.06,2018-01-19,0.07,0.0775\r\n2022-01-20,0.06,2021-01-20,0.09,2020-01-20,0.01,2019-01-20,0.03,2018-01-20,0.07,0.05\r\n2022-01-21,0.1,2021-01-21,0.07,2020-01-21,0.03,2019-01-21,0.07,2018-01-21,0.04,0.052500000000000005\r\n2022-01-22,0.07,2021-01-22,0.02,2020-01-22,0.05,2019-01-22,0.07,2018-01-22,0.02,0.04\r\n2022-01-23,0.04,2021-01-23,0.06,2020-01-23,0.02,2019-01-23,0.07,2018-01-23,0.03,0.045\r\n2022-01-24,0.07,2021-01-24,0.03,2020-01-24,0.07,2019-01-24,0.07,2018-01-24,0.01,0.045000000000000005\r\n2022-01-25,0.07,2021-01-25,0.08,2020-01-25,0.02,2019-01-25,0.06,2018-01-25,0.05,0.0525\r\n2022-01-26,0.06,2021-01-26,0.08,2020-01-26,0.07,2019-01-26,0.05,2018-01-26,0.06,0.065\r\n2022-01-27,0.07,2021-01-27,0.01,2020-01-27,0.07,2019-01-27,0.06,2018-01-27,0.07,0.052500000000000005\r\n2022-01-28,0.06,2021-01-28,0.0,2020-01-28,0.04,2019-01-28,0.04,2018-01-28,0.06,0.035\r\n2022-01-29,0.07,2021-01-29,0.06,2020-01-29,0.08,2019-01-29,0.06,2018-01-29,0.02,0.055\r\n2022-01-30,0.07,2021-01-30,0.07,2020-01-30,0.06,2019-01-30,0.06,2018-01-30,0.04,0.0575\r\n2022-01-31,0.06,2021-01-31,0.08,2020-01-31,0.07,2019-01-31,0.06,2018-01-31,0.07,0.07\r\n2022-02-01,0.13,2021-02-01,0.06,2020-02-01,0.04,2019-02-01,0.03,2018-02-01,0.07,0.05\r\n2022-02-02,0.15,2021-02-02,0.02,2020-02-02,0.1,2019-02-02,0.05,2018-02-02,0.07,0.060000000000000005\r\n2022-02-03,0.07,2021-02-03,0.07,2020-02-03,0.13,2019-02-03,0.03,2018-02-03,0.07,0.07500000000000001\r\n2022-02-04,0.07,2021-02-04,0.08,2020-02-04,0.09,2019-02-04,0.03,2018-02-04,0.05,0.0625\r\n2022-02-05,0.07,2021-02-05,0.08,2020-02-05,0.08,2019-02-05,0.07,2018-02-05,0.07,0.07500000000000001\r\n2022-02-06,0.08,2021-02-06,0.08,2020-02-06,0.08,2019-02-06,0.07,2018-02-06,0.11,0.085\r\n2022-02-07,0.08,2021-02-07,0.07,2020-02-07,0.08,2019-02-07,0.06,2018-02-07,0.08,0.07250000000000001\r\n2022-02-08,0.08,2021-02-08,0.05,2020-02-08,0.09,2019-02-08,0.05,2018-02-08,0.09,0.07\r\n2022-02-09,0.07,2021-02-09,0.05,2020-02-09,0.19,2019-02-09,0.05,2018-02-09,0.09,0.095\r\n2022-02-10,0.09,2021-02-10,0.09,2020-02-10,0.13,2019-02-10,0.08,2018-02-10,0.15,0.1125\r\n2022-02-11,0.09,2021-02-11,0.03,2020-02-11,0.09,2019-02-11,0.07,2018-02-11,0.07,0.065\r\n2022-02-12,0.09,2021-02-12,0.09,2020-02-12,0.09,2019-02-12,0.02,2018-02-12,0.09,0.0725\r\n2022-02-13,0.09,2021-02-13,0.11,2020-02-13,0.09,2019-02-13,0.05,2018-02-13,0.09,0.08499999999999999\r\n2022-02-14,0.09,2021-02-14,0.05,2020-02-14,0.08,2019-02-14,0.05,2018-02-14,0.08,0.065\r\n2022-02-15,0.15,2021-02-15,0.05,2020-02-15,0.09,2019-02-15,0.06,2018-02-15,0.13,0.0825\r\n2022-02-16,0.13,2021-02-16,0.08,2020-02-16,0.11,2019-02-16,0.08,2018-02-16,0.11,0.095\r\n2022-02-17,0.09,2021-02-17,0.15,2020-02-17,0.13,2019-02-17,0.08,2018-02-17,0.09,0.1125\r\n2022-02-18,0.1,2021-02-18,0.09,2020-02-18,0.11,2019-02-18,0.1,2018-02-18,0.13,0.1075\r\n2022-02-19,0.1,2021-02-19,0.06,2020-02-19,0.1,2019-02-19,0.09,2018-02-19,0.1,0.0875\r\n2022-02-20,0.08,2021-02-20,0.11,2020-02-20,0.1,2019-02-20,0.08,2018-02-20,0.08,0.0925\r\n2022-02-21,0.12,2021-02-21,0.12,2020-02-21,0.11,2019-02-21,0.12,2018-02-21,0.1,0.1125\r\n2022-02-22,0.1,2021-02-22,0.1,2020-02-22,0.13,2019-02-22,0.1,2018-02-22,0.1,0.10750000000000001\r\n2022-02-23,0.12,2021-02-23,0.15,2020-02-23,0.1,2019-02-23,0.07,2018-02-23,0.12,0.11\r\n2022-02-24,0.1,2021-02-24,0.19,2020-02-24,0.15,2019-02-24,0.07,2018-02-24,0.1,0.1275\r\n2022-02-25,0.11,2021-02-25,0.13,2020-02-25,0.12,2019-02-25,0.03,2018-02-25,0.1,0.095\r\n2022-02-26,0.08,2021-02-26,0.12,2020-02-26,0.12,2019-02-26,0.02,2018-02-26,0.02,0.06999999999999999\r\n2022-02-27,0.13,2021-02-27,0.17,2020-02-27,0.12,2019-02-27,0.09,2018-02-27,0.12,0.125\r\n2022-02-28,0.12,2021-02-28,0.12,2020-02-28,0.11,2019-02-28,0.06,2018-02-28,0.08,0.0925\r\n2022-03-01,0.11,2021-03-01,0.13,2020-03-01,0.1,2019-03-01,0.04,2018-03-01,0.02,0.07250000000000001\r\n2022-03-02,0.12,2021-03-02,0.11,2020-03-02,0.22,2019-03-02,0.01,2018-03-02,0.04,0.095\r\n2022-03-03,0.1,2021-03-03,0.08,2020-03-03,0.12,2019-03-03,0.04,2018-03-03,0.04,0.07\r\n2022-03-04,0.11,2021-03-04,0.11,2020-03-04,0.13,2019-03-04,0.09,2018-03-04,0.09,0.105\r\n2022-03-05,0.08,2021-03-05,0.12,2020-03-05,0.12,2019-03-05,0.03,2018-03-05,0.1,0.0925\r\n2022-03-06,0.13,2021-03-06,0.12,2020-03-06,0.11,2019-03-06,0.07,2018-03-06,0.09,0.0975\r\n2022-03-07,0.17,2021-03-07,0.13,2020-03-07,0.04,2019-03-07,0.02,2018-03-07,0.09,0.07\r\n2022-03-08,0.13,2021-03-08,0.12,2020-03-08,0.07,2019-03-08,0.11,2018-03-08,0.1,0.1\r\n2022-03-09,0.15,2021-03-09,0.08,2020-03-09,0.12,2019-03-09,0.06,2018-03-09,0.09,0.0875\r\n2022-03-10,0.2,2021-03-10,0.06,2020-03-10,0.12,2019-03-10,0.09,2018-03-10,0.01,0.06999999999999999\r\n2022-03-11,0.13,2021-03-11,0.09,2020-03-11,0.14,2019-03-11,0.14,2018-03-11,0.1,0.11750000000000001\r\n2022-03-12,0.14,2021-03-12,0.12,2020-03-12,0.17,2019-03-12,0.15,2018-03-12,0.1,0.135\r\n2022-03-13,0.13,2021-03-13,0.14,2020-03-13,0.16,2019-03-13,0.18,2018-03-13,0.02,0.125\r\n2022-03-14,0.13,2021-03-14,0.08,2020-03-14,0.06,2019-03-14,0.13,2018-03-14,0.05,0.08\r\n2022-03-15,0.11,2021-03-15,0.1,2020-03-15,0.07,2019-03-15,0.13,2018-03-15,0.04,0.085\r\n2022-03-16,0.17,2021-03-16,0.12,2020-03-16,0.02,2019-03-16,0.14,2018-03-16,0.07,0.08750000000000001\r\n2022-03-17,0.14,2021-03-17,0.09,2020-03-17,0.1,2019-03-17,0.12,2018-03-17,0.07,0.095\r\n2022-03-18,0.14,2021-03-18,0.04,2020-03-18,0.07,2019-03-18,0.14,2018-03-18,0.07,0.08\r\n2022-03-19,0.06,2021-03-19,0.04,2020-03-19,0.13,2019-03-19,0.1,2018-03-19,0.11,0.095\r\n2022-03-20,0.21,2021-03-20,0.14,2020-03-20,0.14,2019-03-20,0.09,2018-03-20,0.01,0.095\r\n2022-03-21,0.19,2021-03-21,0.18,2020-03-21,0.12,2019-03-21,0.14,2018-03-21,0.06,0.125\r\n2022-03-22,0.17,2021-03-22,0.14,2020-03-22,0.13,2019-03-22,0.05,2018-03-22,0.12,0.11\r\n2022-03-23,0.17,2021-03-23,0.23,2020-03-23,0.15,2019-03-23,0.11,2018-03-23,0.13,0.155\r\n2022-03-24,0.18,2021-03-24,0.16,2020-03-24,0.11,2019-03-24,0.1,2018-03-24,0.11,0.12\r\n2022-03-25,0.17,2021-03-25,0.16,2020-03-25,0.11,2019-03-25,0.06,2018-03-25,0.16,0.1225\r\n2022-03-26,0.18,2021-03-26,0.19,2020-03-26,0.13,2019-03-26,0.12,2018-03-26,0.22,0.165\r\n2022-03-27,0.13,2021-03-27,0.17,2020-03-27,0.16,2019-03-27,0.08,2018-03-27,0.16,0.14250000000000002\r\n2022-03-28,0.06,2021-03-28,0.18,2020-03-28,0.04,2019-03-28,0.12,2018-03-28,0.16,0.125\r\n2022-03-29,0.13,2021-03-29,0.2,2020-03-29,0.13,2019-03-29,0.16,2018-03-29,0.17,0.165\r\n2022-03-30,0.12,2021-03-30,0.23,2020-03-30,0.14,2019-03-30,0.17,2018-03-30,0.13,0.1675\r\n2022-03-31,0.17,2021-03-31,0.17,2020-03-31,0.15,2019-03-31,0.17,2018-03-31,0.14,0.1575\r\n2022-04-01,0.18,2021-04-01,0.19,2020-04-01,0.17,2019-04-01,0.05,2018-04-01,0.15,0.14\r\n2022-04-02,0.19,2021-04-02,0.2,2020-04-02,0.2,2019-04-02,0.12,2018-04-02,0.17,0.17250000000000001\r\n2022-04-03,0.23,2021-04-03,0.17,2020-04-03,0.18,2019-04-03,0.07,2018-04-03,0.18,0.15\r\n2022-04-04,0.18,2021-04-04,0.15,2020-04-04,0.05,2019-04-04,0.08,2018-04-04,0.15,0.1075\r\n2022-04-05,0.21,2021-04-05,0.16,2020-04-05,0.04,2019-04-05,0.05,2018-04-05,0.08,0.0825\r\n2022-04-06,0.19,2021-04-06,0.18,2020-04-06,0.06,2019-04-06,0.12,2018-04-06,0.02,0.095\r\n2022-04-07,0.19,2021-04-07,0.18,2020-04-07,0.16,2019-04-07,0.17,2018-04-07,0.18,0.1725\r\n2022-04-08,0.22,2021-04-08,0.2,2020-04-08,0.13,2019-04-08,0.13,2018-04-08,0.2,0.165\r\n2022-04-09,0.27,2021-04-09,0.19,2020-04-09,0.08,2019-04-09,0.2,2018-04-09,0.17,0.16\r\n2022-04-10,0.24,2021-04-10,0.2,2020-04-10,0.14,2019-04-10,0.22,2018-04-10,0.13,0.17250000000000001\r\n2022-04-11,0.15,2021-04-11,0.21,2020-04-11,0.16,2019-04-11,0.12,2018-04-11,0.18,0.16749999999999998\r\n2022-04-12,0.18,2021-04-12,0.21,2020-04-12,0.14,2019-04-12,0.22,2018-04-12,0.2,0.1925\r\n2022-04-13,0.15,2021-04-13,0.21,2020-04-13,0.2,2019-04-13,0.18,2018-04-13,0.21,0.2\r\n2022-04-14,0.07,2021-04-14,0.2,2020-04-14,0.22,2019-04-14,0.2,2018-04-14,0.19,0.2025\r\n2022-04-15,0.18,2021-04-15,0.2,2020-04-15,0.2,2019-04-15,0.08,2018-04-15,0.23,0.17750000000000002\r\n2022-04-16,0.13,2021-04-16,0.22,2020-04-16,0.17,2019-04-16,0.14,2018-04-16,0.08,0.1525\r\n2022-04-17,0.19,2021-04-17,0.25,2020-04-17,0.16,2019-04-17,0.19,2018-04-17,0.14,0.185\r\n2022-04-18,0.17,2021-04-18,0.25,2020-04-18,0.16,2019-04-18,0.2,2018-04-18,0.07,0.17\r\n2022-04-19,0.14,2021-04-19,0.23,2020-04-19,0.18,2019-04-19,0.19,2018-04-19,0.18,0.195\r\n2022-04-20,0.18,2021-04-20,0.21,2020-04-20,0.14,2019-04-20,0.19,2018-04-20,0.2,0.185\r\n2022-04-21,0.08,2021-04-21,0.21,2020-04-21,0.21,2019-04-21,0.21,2018-04-21,0.18,0.20249999999999999\r\n2022-04-22,0.16,2021-04-22,0.2,2020-04-22,0.22,2019-04-22,0.25,2018-04-22,0.19,0.215\r\n2022-04-23,0.22,2021-04-23,0.2,2020-04-23,0.25,2019-04-23,0.21,2018-04-23,0.2,0.215\r\n2022-04-24,0.21,2021-04-24,0.19,2020-04-24,0.25,2019-04-24,0.22,2018-04-24,0.21,0.2175\r\n2022-04-25,0.21,2021-04-25,0.06,2020-04-25,0.23,2019-04-25,0.23,2018-04-25,0.19,0.1775\r\n2022-04-26,0.21,2021-04-26,0.2,2020-04-26,0.24,2019-04-26,0.22,2018-04-26,0.16,0.20500000000000002\r\n2022-04-27,0.22,2021-04-27,0.24,2020-04-27,0.24,2019-04-27,0.19,2018-04-27,0.12,0.1975\r\n2022-04-28,0.21,2021-04-28,0.24,2020-04-28,0.24,2019-04-28,0.21,2018-04-28,0.09,0.195\r\n2022-04-29,0.22,2021-04-29,0.24,2020-04-29,0.18,2019-04-29,0.21,2018-04-29,0.13,0.19\r\n2022-04-30,0.24,2021-04-30,0.23,2020-04-30,0.25,2019-04-30,0.21,2018-04-30,0.13,0.20500000000000002\r\n2022-05-01,0.25,2021-05-01,0.24,2020-05-01,0.25,2019-05-01,0.23,2018-05-01,0.18,0.225\r\n2022-05-02,0.22,2021-05-02,0.29,2020-05-02,0.21,2019-05-02,0.23,2018-05-02,0.17,0.225\r\n2022-05-03,0.26,2021-05-03,0.3,2020-05-03,0.24,2019-05-03,0.22,2018-05-03,0.17,0.23249999999999998\r\n2022-05-04,0.23,2021-05-04,0.27,2020-05-04,0.24,2019-05-04,0.22,2018-05-04,0.17,0.225\r\n2022-05-05,0.21,2021-05-05,0.25,2020-05-05,0.25,2019-05-05,0.2,2018-05-05,0.12,0.20500000000000002\r\n2022-05-06,0.16,2021-05-06,0.25,2020-05-06,0.27,2019-05-06,0.18,2018-05-06,0.17,0.2175\r\n2022-05-07,0.23,2021-05-07,0.24,2020-05-07,0.27,2019-05-07,0.21,2018-05-07,0.19,0.2275\r\n2022-05-08,0.24,2021-05-08,0.32,2020-05-08,0.26,2019-05-08,0.21,2018-05-08,0.21,0.25\r\n2022-05-09,0.18,2021-05-09,0.29,2020-05-09,0.25,2019-05-09,0.21,2018-05-09,0.21,0.24\r\n2022-05-10,0.18,2021-05-10,0.3,2020-05-10,0.24,2019-05-10,0.22,2018-05-10,0.18,0.235\r\n2022-05-11,0.23,2021-05-11,0.28,2020-05-11,0.21,2019-05-11,0.22,2018-05-11,0.2,0.2275\r\n2022-05-12,0.22,2021-05-12,0.27,2020-05-12,0.18,2019-05-12,0.23,2018-05-12,0.22,0.225\r\n2022-05-13,0.24,2021-05-13,0.24,2020-05-13,0.15,2019-05-13,0.23,2018-05-13,0.2,0.20500000000000002\r\n2022-05-14,0.27,2021-05-14,0.25,2020-05-14,0.16,2019-05-14,0.16,2018-05-14,0.2,0.1925\r\n2022-05-15,0.28,2021-05-15,0.2,2020-05-15,0.24,2019-05-15,0.06,2018-05-15,0.2,0.175\r\n2022-05-16,0.25,2021-05-16,0.22,2020-05-16,0.25,2019-05-16,0.1,2018-05-16,0.13,0.175\r\n2022-05-17,0.27,2021-05-17,0.23,2020-05-17,0.12,2019-05-17,0.13,2018-05-17,0.21,0.1725\r\n2022-05-18,0.29,2021-05-18,0.28,2020-05-18,0.18,2019-05-18,0.05,2018-05-18,0.2,0.17750000000000002\r\n2022-05-19,0.29,2021-05-19,0.27,2020-05-19,0.18,2019-05-19,0.07,2018-05-19,0.21,0.1825\r\n2022-05-20,0.33,2021-05-20,0.27,2020-05-20,0.23,2019-05-20,0.16,2018-05-20,0.19,0.21250000000000002\r\n2022-05-21,0.28,2021-05-21,0.28,2020-05-21,0.26,2019-05-21,0.15,2018-05-21,0.19,0.22\r\n2022-05-22,0.28,2021-05-22,0.26,2020-05-22,0.27,2019-05-22,0.21,2018-05-22,0.2,0.23500000000000001\r\n2022-05-23,0.29,2021-05-23,0.24,2020-05-23,0.29,2019-05-23,0.2,2018-05-23,0.19,0.22999999999999998\r\n2022-05-24,0.3,2021-05-24,0.27,2020-05-24,0.28,2019-05-24,0.21,2018-05-24,0.18,0.23500000000000001\r\n2022-05-25,0.29,2021-05-25,0.27,2020-05-25,0.28,2019-05-25,0.23,2018-05-25,0.05,0.20750000000000002\r\n2022-05-26,0.22,2021-05-26,0.27,2020-05-26,0.29,2019-05-26,0.19,2018-05-26,0.15,0.225\r\n2022-05-27,0.22,2021-05-27,0.27,2020-05-27,0.31,2019-05-27,0.14,2018-05-27,0.2,0.23\r\n2022-05-28,0.26,2021-05-28,0.27,2020-05-28,0.3,2019-05-28,0.23,2018-05-28,0.22,0.255\r\n2022-05-29,0.28,2021-05-29,0.27,2020-05-29,0.24,2019-05-29,0.25,2018-05-29,0.22,0.245\r\n2022-05-30,0.28,2021-05-30,0.27,2020-05-30,0.17,2019-05-30,0.24,2018-05-30,0.16,0.21000000000000002\r\n2022-05-31,0.31,2021-05-31,0.3,2020-05-31,0.19,2019-05-31,0.26,2018-05-31,0.18,0.23249999999999998\r\n2022-06-01,0.28,2021-06-01,0.28,2020-06-01,0.26,2019-06-01,0.27,2018-06-01,0.21,0.255\r\n2022-06-02,0.28,2021-06-02,0.27,2020-06-02,0.3,2019-06-02,0.25,2018-06-02,0.25,0.2675\r\n2022-06-03,0.22,2021-06-03,0.28,2020-06-03,0.31,2019-06-03,0.25,2018-06-03,0.25,0.2725\r\n2022-06-04,0.16,2021-06-04,0.29,2020-06-04,0.32,2019-06-04,0.27,2018-06-04,0.3,0.295\r\n2022-06-05,0.17,2021-06-05,0.27,2020-06-05,0.32,2019-06-05,0.29,2018-06-05,0.25,0.2825\r\n2022-06-06,0.27,2021-06-06,0.31,2020-06-06,0.3,2019-06-06,0.31,2018-06-06,0.23,0.2875\r\n2022-06-07,0.28,2021-06-07,0.31,2020-06-07,0.27,2019-06-07,0.29,2018-06-07,0.24,0.27749999999999997\r\n2022-06-08,0.27,2021-06-08,0.27,2020-06-08,0.31,2019-06-08,0.32,2018-06-08,0.27,0.2925\r\n2022-06-09,0.29,2021-06-09,0.27,2020-06-09,0.28,2019-06-09,0.27,2018-06-09,0.24,0.265\r\n2022-06-10,0.3,2021-06-10,0.26,2020-06-10,0.26,2019-06-10,0.28,2018-06-10,0.27,0.2675\r\n2022-06-11,0.31,2021-06-11,0.28,2020-06-11,0.28,2019-06-11,0.28,2018-06-11,0.27,0.2775\r\n2022-06-12,0.23,2021-06-12,0.28,2020-06-12,0.23,2019-06-12,0.32,2018-06-12,0.28,0.2775\r\n2022-06-13,0.3,2021-06-13,0.28,2020-06-13,0.24,2019-06-13,0.28,2018-06-13,0.28,0.27\r\n2022-06-14,0.31,2021-06-14,0.28,2020-06-14,0.27,2019-06-14,0.26,2018-06-14,0.26,0.2675\r\n2022-06-15,0.31,2021-06-15,0.3,2020-06-15,0.26,2019-06-15,0.25,2018-06-15,0.26,0.2675\r\n2022-06-16,0.3,2021-06-16,0.29,2020-06-16,0.27,2019-06-16,0.25,2018-06-16,0.24,0.2625\r\n2022-06-17,0.25,2021-06-17,0.32,2020-06-17,0.32,2019-06-17,0.26,2018-06-17,0.21,0.2775\r\n2022-06-18,0.25,2021-06-18,0.32,2020-06-18,0.29,2019-06-18,0.29,2018-06-18,0.24,0.285\r\n2022-06-19,0.28,2021-06-19,0.31,2020-06-19,0.29,2019-06-19,0.28,2018-06-19,0.25,0.2825\r\n2022-06-20,0.3,2021-06-20,0.29,2020-06-20,0.27,2019-06-20,0.27,2018-06-20,0.26,0.2725\r\n2022-06-21,0.3,2021-06-21,0.27,2020-06-21,0.3,2019-06-21,0.29,2018-06-21,0.26,0.28\r\n2022-06-22,0.18,2021-06-22,0.26,2020-06-22,0.28,2019-06-22,0.33,2018-06-22,0.28,0.28750000000000003\r\n2022-06-23,0.3,2021-06-23,0.27,2020-06-23,0.28,2019-06-23,0.29,2018-06-23,0.3,0.28500000000000003\r\n2022-06-24,0.29,2021-06-24,0.27,2020-06-24,0.28,2019-06-24,0.28,2018-06-24,0.28,0.2775\r\n2022-06-25,0.3,2021-06-25,0.27,2020-06-25,0.29,2019-06-25,0.31,2018-06-25,0.24,0.27749999999999997\r\n2022-06-26,0.29,2021-06-26,0.27,2020-06-26,0.29,2019-06-26,0.28,2018-06-26,0.26,0.275\r\n2022-06-27,0.3,2021-06-27,0.28,2020-06-27,0.3,2019-06-27,0.24,2018-06-27,0.25,0.2675\r\n2022-06-28,0.32,2021-06-28,0.3,2020-06-28,0.3,2019-06-28,0.22,2018-06-28,0.25,0.2675\r\n2022-06-29,0.27,2021-06-29,0.29,2020-06-29,0.32,2019-06-29,0.26,2018-06-29,0.27,0.28500000000000003\r\n2022-06-30,0.26,2021-06-30,0.29,2020-06-30,0.29,2019-06-30,0.29,2018-06-30,0.3,0.2925\r\n2022-07-01,0.27,2021-07-01,0.27,2020-07-01,0.28,2019-07-01,0.28,2018-07-01,0.27,0.275\r\n2022-07-02,0.27,2021-07-02,0.28,2020-07-02,0.26,2019-07-02,0.28,2018-07-02,0.19,0.2525\r\n2022-07-03,0.24,2021-07-03,0.26,2020-07-03,0.26,2019-07-03,0.27,2018-07-03,0.24,0.2575\r\n2022-07-04,0.26,2021-07-04,0.27,2020-07-04,0.29,2019-07-04,0.27,2018-07-04,0.23,0.265\r\n2022-07-05,0.24,2021-07-05,0.27,2020-07-05,0.32,2019-07-05,0.28,2018-07-05,0.24,0.2775\r\n2022-07-06,0.25,2021-07-06,0.28,2020-07-06,0.32,2019-07-06,0.28,2018-07-06,0.27,0.28750000000000003\r\n2022-07-07,0.26,2021-07-07,0.28,2020-07-07,0.29,2019-07-07,0.27,2018-07-07,0.31,0.2875\r\n2022-07-08,0.29,2021-07-08,0.27,2020-07-08,0.29,2019-07-08,0.27,2018-07-08,0.3,0.2825\r\n2022-07-09,0.27,2021-07-09,0.32,2020-07-09,0.28,2019-07-09,0.24,2018-07-09,0.29,0.2825\r\n2022-07-10,0.28,2021-07-10,0.32,2020-07-10,0.27,2019-07-10,0.26,2018-07-10,0.29,0.28500000000000003\r\n2022-07-11,0.29,2021-07-11,0.3,2020-07-11,0.3,2019-07-11,0.28,2018-07-11,0.26,0.28500000000000003\r\n2022-07-12,0.28,2021-07-12,0.27,2020-07-12,0.31,2019-07-12,0.27,2018-07-12,0.24,0.2725\r\n2022-07-13,0.26,2021-07-13,0.25,2020-07-13,0.29,2019-07-13,0.28,2018-07-13,0.24,0.265\r\n2022-07-14,0.29,2021-07-14,0.25,2020-07-14,0.26,2019-07-14,0.28,2018-07-14,0.26,0.2625\r\n2022-07-15,0.28,2021-07-15,0.25,2020-07-15,0.26,2019-07-15,0.29,2018-07-15,0.25,0.2625\r\n2022-07-16,0.29,2021-07-16,0.25,2020-07-16,0.26,2019-07-16,0.28,2018-07-16,0.26,0.2625\r\n2022-07-17,0.3,2021-07-17,0.27,2020-07-17,0.26,2019-07-17,0.25,2018-07-17,0.27,0.2625\r\n2022-07-18,0.29,2021-07-18,0.27,2020-07-18,0.27,2019-07-18,0.26,2018-07-18,0.25,0.2625\r\n2022-07-19,0.29,2021-07-19,0.27,2020-07-19,0.27,2019-07-19,0.25,2018-07-19,0.25,0.26\r\n2022-07-20,0.29,2021-07-20,0.28,2020-07-20,0.25,2019-07-20,0.25,2018-07-20,0.23,0.2525\r\n2022-07-21,0.28,2021-07-21,0.28,2020-07-21,0.22,2019-07-21,0.25,2018-07-21,0.25,0.25\r\n2022-07-22,0.3,2021-07-22,0.28,2020-07-22,0.25,2019-07-22,0.27,2018-07-22,0.24,0.26\r\n2022-07-23,0.27,2021-07-23,0.27,2020-07-23,0.25,2019-07-23,0.28,2018-07-23,0.26,0.265\r\n2022-07-24,0.27,2021-07-24,0.27,2020-07-24,0.26,2019-07-24,0.28,2018-07-24,0.25,0.265\r\n2022-07-25,0.25,2021-07-25,0.26,2020-07-25,0.26,2019-07-25,0.28,2018-07-25,0.28,0.27\r\n2022-07-26,0.26,2021-07-26,0.21,2020-07-26,0.27,2019-07-26,0.26,2018-07-26,0.24,0.245\r\n2022-07-27,0.27,2021-07-27,0.27,2020-07-27,0.27,2019-07-27,0.27,2018-07-27,0.24,0.2625\r\n2022-07-28,0.24,2021-07-28,0.26,2020-07-28,0.26,2019-07-28,0.29,2018-07-28,0.21,0.255\r\n2022-07-29,0.24,2021-07-29,0.27,2020-07-29,0.28,2019-07-29,0.27,2018-07-29,0.12,0.23500000000000001\r\n2022-07-30,0.23,2021-07-30,0.27,2020-07-30,0.26,2019-07-30,0.25,2018-07-30,0.2,0.245\r\n2022-07-31,0.15,2021-07-31,0.26,2020-07-31,0.27,2019-07-31,0.25,2018-07-31,0.22,0.25\r\n2022-08-01,0.17,2021-08-01,0.26,2020-08-01,0.26,2019-08-01,0.25,2018-08-01,0.24,0.2525\r\n2022-08-02,0.28,2021-08-02,0.24,2020-08-02,0.26,2019-08-02,0.25,2018-08-02,0.24,0.2475\r\n2022-08-03,0.28,2021-08-03,0.26,2020-08-03,0.28,2019-08-03,0.26,2018-08-03,0.21,0.2525\r\n2022-08-04,0.27,2021-08-04,0.26,2020-08-04,0.26,2019-08-04,0.25,2018-08-04,0.26,0.2575\r\n2022-08-05,0.18,2021-08-05,0.23,2020-08-05,0.25,2019-08-05,0.22,2018-08-05,0.21,0.2275\r\n2022-08-06,0.23,2021-08-06,0.17,2020-08-06,0.23,2019-08-06,0.25,2018-08-06,0.21,0.215\r\n2022-08-07,0.24,2021-08-07,0.19,2020-08-07,0.24,2019-08-07,0.26,2018-08-07,0.18,0.2175\r\n2022-08-08,0.24,2021-08-08,0.24,2020-08-08,0.24,2019-08-08,0.26,2018-08-08,0.18,0.22999999999999998\r\n2022-08-09,0.23,2021-08-09,0.25,2020-08-09,0.26,2019-08-09,0.22,2018-08-09,0.22,0.2375\r\n2022-08-10,0.24,2021-08-10,0.25,2020-08-10,0.26,2019-08-10,0.22,2018-08-10,0.25,0.245\r\n2022-08-11,0.25,2021-08-11,0.28,2020-08-11,0.24,2019-08-11,0.25,2018-08-11,0.24,0.2525\r\n2022-08-12,0.25,2021-08-12,0.26,2020-08-12,0.25,2019-08-12,0.25,2018-08-12,0.24,0.25\r\n2022-08-13,0.26,2021-08-13,0.24,2020-08-13,0.24,2019-08-13,0.25,2018-08-13,0.21,0.235\r\n2022-08-14,0.26,2021-08-14,0.25,2020-08-14,0.25,2019-08-14,0.26,2018-08-14,0.2,0.24\r\n2022-08-15,0.25,2021-08-15,0.21,2020-08-15,0.23,2019-08-15,0.26,2018-08-15,0.22,0.23\r\n2022-08-16,0.26,2021-08-16,0.25,2020-08-16,0.28,2019-08-16,0.26,2018-08-16,0.23,0.255\r\n2022-08-17,0.15,2021-08-17,0.24,2020-08-17,0.24,2019-08-17,0.23,2018-08-17,0.25,0.24\r\n2022-08-18,0.26,2021-08-18,0.17,2020-08-18,0.26,2019-08-18,0.22,2018-08-18,0.26,0.2275\r\n2022-08-19,0.25,2021-08-19,0.19,2020-08-19,0.22,2019-08-19,0.21,2018-08-19,0.24,0.215\r\n2022-08-20,0.25,2021-08-20,0.17,2020-08-20,0.23,2019-08-20,0.22,2018-08-20,0.23,0.21250000000000002\r\n2022-08-21,0.24,2021-08-21,0.19,2020-08-21,0.16,2019-08-21,0.24,2018-08-21,0.19,0.195\r\n2022-08-22,0.25,2021-08-22,0.2,2020-08-22,0.17,2019-08-22,0.24,2018-08-22,0.21,0.20500000000000002\r\n2022-08-23,0.23,2021-08-23,0.21,2020-08-23,0.18,2019-08-23,0.24,2018-08-23,0.2,0.2075\r\n2022-08-24,0.24,2021-08-24,0.21,2020-08-24,0.18,2019-08-24,0.24,2018-08-24,0.19,0.205\r\n2022-08-25,0.22,2021-08-25,0.21,2020-08-25,0.2,2019-08-25,0.26,2018-08-25,0.19,0.215\r\n2022-08-26,0.22,2021-08-26,0.22,2020-08-26,0.22,2019-08-26,0.26,2018-08-26,0.21,0.2275\r\n2022-08-27,0.22,2021-08-27,0.22,2020-08-27,0.22,2019-08-27,0.25,2018-08-27,0.2,0.2225\r\n2022-08-28,0.22,2021-08-28,0.22,2020-08-28,0.2,2019-08-28,0.23,2018-08-28,0.2,0.21250000000000002\r\n2022-08-29,0.22,2021-08-29,0.24,2020-08-29,0.2,2019-08-29,0.21,2018-08-29,0.21,0.215\r\n2022-08-30,0.22,2021-08-30,0.22,2020-08-30,0.2,2019-08-30,0.22,2018-08-30,0.2,0.21000000000000002\r\n2022-08-31,0.23,2021-08-31,0.23,2020-08-31,0.19,2019-08-31,0.22,2018-08-31,0.21,0.2125\r\n2022-09-01,0.24,2021-09-01,0.2,2020-09-01,0.18,2019-09-01,0.24,2018-09-01,0.21,0.2075\r\n2022-09-02,0.25,2021-09-02,0.18,2020-09-02,0.19,2019-09-02,0.24,2018-09-02,0.21,0.205\r\n2022-09-03,0.24,2021-09-03,0.19,2020-09-03,0.2,2019-09-03,0.22,2018-09-03,0.2,0.2025\r\n2022-09-04,0.23,2021-09-04,0.22,2020-09-04,0.21,2019-09-04,0.21,2018-09-04,0.2,0.21\r\n2022-09-05,0.24,2021-09-05,0.23,2020-09-05,0.2,2019-09-05,0.18,2018-09-05,0.2,0.2025\r\n2022-09-06,0.23,2021-09-06,0.23,2020-09-06,0.22,2019-09-06,0.21,2018-09-06,0.2,0.215\r\n2022-09-07,0.24,2021-09-07,0.26,2020-09-07,0.22,2019-09-07,0.21,2018-09-07,0.21,0.225\r\n2022-09-08,0.24,2021-09-08,0.23,2020-09-08,0.26,2019-09-08,0.2,2018-09-08,0.22,0.2275\r\n2022-09-09,0.22,2021-09-09,0.21,2020-09-09,0.1,2019-09-09,0.21,2018-09-09,0.2,0.18\r\n2022-09-10,0.13,2021-09-10,0.19,2020-09-10,0.08,2019-09-10,0.19,2018-09-10,0.21,0.1675\r\n2022-09-11,0.17,2021-09-11,0.21,2020-09-11,0.14,2019-09-11,0.2,2018-09-11,0.21,0.19\r\n2022-09-12,0.21,2021-09-12,0.21,2020-09-12,0.12,2019-09-12,0.19,2018-09-12,0.19,0.1775\r\n2022-09-13,0.2,2021-09-13,0.21,2020-09-13,0.14,2019-09-13,0.21,2018-09-13,0.18,0.185\r\n2022-09-14,0.18,2021-09-14,0.2,2020-09-14,0.15,2019-09-14,0.2,2018-09-14,0.18,0.1825\r\n2022-09-15,0.16,2021-09-15,0.18,2020-09-15,0.16,2019-09-15,0.22,2018-09-15,0.19,0.1875\r\n2022-09-16,0.17,2021-09-16,0.17,2020-09-16,0.17,2019-09-16,0.14,2018-09-16,0.18,0.165\r\n2022-09-17,0.18,2021-09-17,0.17,2020-09-17,0.17,2019-09-17,0.18,2018-09-17,0.18,0.175\r\n2022-09-18,0.1,2021-09-18,0.18,2020-09-18,0.17,2019-09-18,0.09,2018-09-18,0.17,0.1525\r\n2022-09-19,0.08,2021-09-19,0.18,2020-09-19,0.17,2019-09-19,0.18,2018-09-19,0.19,0.18\r\n2022-09-20,0.13,2021-09-20,0.19,2020-09-20,0.17,2019-09-20,0.19,2018-09-20,0.19,0.185\r\n2022-09-21,0.15,2021-09-21,0.17,2020-09-21,0.18,2019-09-21,0.19,2018-09-21,0.19,0.1825\r\n2022-09-22,0.18,2021-09-22,0.2,2020-09-22,0.19,2019-09-22,0.16,2018-09-22,0.19,0.185\r\n2022-09-23,0.17,2021-09-23,0.19,2020-09-23,0.19,2019-09-23,0.2,2018-09-23,0.19,0.1925\r\n2022-09-24,0.19,2021-09-24,0.17,2020-09-24,0.19,2019-09-24,0.2,2018-09-24,0.18,0.185\r\n2022-09-25,0.18,2021-09-25,0.15,2020-09-25,0.17,2019-09-25,0.18,2018-09-25,0.18,0.16999999999999998\r\n2022-09-26,0.17,2021-09-26,0.16,2020-09-26,0.19,2019-09-26,0.18,2018-09-26,0.18,0.1775\r\n2022-09-27,0.16,2021-09-27,0.17,2020-09-27,0.18,2019-09-27,0.15,2018-09-27,0.17,0.1675\r\n2022-09-28,0.18,2021-09-28,0.22,2020-09-28,0.18,2019-09-28,0.16,2018-09-28,0.16,0.18\r\n2022-09-29,0.16,2021-09-29,0.18,2020-09-29,0.16,2019-09-29,0.14,2018-09-29,0.13,0.1525\r\n2022-09-30,0.17,2021-09-30,0.15,2020-09-30,0.18,2019-09-30,0.14,2018-09-30,0.14,0.1525\r\n2022-10-01,0.16,2021-10-01,0.16,2020-10-01,0.14,2019-10-01,0.16,2018-10-01,0.12,0.14500000000000002\r\n2022-10-02,0.15,2021-10-02,0.15,2020-10-02,0.13,2019-10-02,0.16,2018-10-02,0.13,0.14250000000000002\r\n2022-10-03,0.16,2021-10-03,0.13,2020-10-03,0.13,2019-10-03,0.16,2018-10-03,0.09,0.1275\r\n2022-10-04,0.15,2021-10-04,0.14,2020-10-04,0.17,2019-10-04,0.17,2018-10-04,0.11,0.14750000000000002\r\n2022-10-05,0.15,2021-10-05,0.14,2020-10-05,0.16,2019-10-05,0.16,2018-10-05,0.14,0.15000000000000002\r\n2022-10-06,0.16,2021-10-06,0.13,2020-10-06,0.14,2019-10-06,0.15,2018-10-06,0.17,0.14750000000000002\r\n2022-10-07,0.17,2021-10-07,0.13,2020-10-07,0.13,2019-10-07,0.15,2018-10-07,0.25,0.165\r\n2022-10-08,0.16,2021-10-08,0.15,2020-10-08,0.08,2019-10-08,0.15,2018-10-08,0.16,0.135\r\n2022-10-09,0.15,2021-10-09,0.14,2020-10-09,0.1,2019-10-09,0.21,2018-10-09,0.15,0.15\r\n2022-10-10,0.15,2021-10-10,0.14,2020-10-10,0.1,2019-10-10,0.19,2018-10-10,0.13,0.14\r\n2022-10-11,0.15,2021-10-11,0.25,2020-10-11,0.15,2019-10-11,0.13,2018-10-11,0.13,0.165\r\n2022-10-12,0.14,2021-10-12,0.21,2020-10-12,0.15,2019-10-12,0.13,2018-10-12,0.16,0.1625\r\n2022-10-13,0.13,2021-10-13,0.12,2020-10-13,0.15,2019-10-13,0.14,2018-10-13,0.15,0.14\r\n2022-10-14,0.12,2021-10-14,0.16,2020-10-14,0.2,2019-10-14,0.14,2018-10-14,0.18,0.17\r\n2022-10-15,0.13,2021-10-15,0.13,2020-10-15,0.16,2019-10-15,0.13,2018-10-15,0.16,0.14500000000000002\r\n2022-10-16,0.11,2021-10-16,0.13,2020-10-16,0.15,2019-10-16,0.11,2018-10-16,0.14,0.1325\r\n2022-10-17,0.11,2021-10-17,0.12,2020-10-17,0.13,2019-10-17,0.15,2018-10-17,0.12,0.13\r\n2022-10-18,0.09,2021-10-18,0.08,2020-10-18,0.14,2019-10-18,0.12,2018-10-18,0.12,0.115\r\n2022-10-19,0.13,2021-10-19,0.1,2020-10-19,0.14,2019-10-19,0.11,2018-10-19,0.13,0.12000000000000001\r\n2022-10-20,0.12,2021-10-20,0.06,2020-10-20,0.13,2019-10-20,0.14,2018-10-20,0.12,0.1125\r\n2022-10-21,0.12,2021-10-21,0.07,2020-10-21,0.13,2019-10-21,0.16,2018-10-21,0.13,0.1225\r\n2022-10-22,0.13,2021-10-22,0.05,2020-10-22,0.15,2019-10-22,0.13,2018-10-22,0.12,0.1125\r\n2022-10-23,0.16,2021-10-23,0.08,2020-10-23,0.13,2019-10-23,0.15,2018-10-23,0.09,0.1125\r\n2022-10-24,0.12,2021-10-24,0.02,2020-10-24,0.1,2019-10-24,0.14,2018-10-24,0.11,0.0925\r\n2022-10-25,0.11,2021-10-25,0.08,2020-10-25,0.13,2019-10-25,0.12,2018-10-25,0.12,0.1125\r\n2022-10-26,0.12,2021-10-26,0.08,2020-10-26,0.19,2019-10-26,0.12,2018-10-26,0.1,0.1225\r\n2022-10-27,0.1,2021-10-27,0.09,2020-10-27,0.1,2019-10-27,0.27,2018-10-27,0.11,0.14250000000000002\r\n2022-10-28,0.09,2021-10-28,0.09,2020-10-28,0.09,2019-10-28,0.11,2018-10-28,0.12,0.1025\r\n2022-10-29,0.11,2021-10-29,0.07,2020-10-29,0.09,2019-10-29,0.14,2018-10-29,0.12,0.10500000000000001\r\n2022-10-30,0.11,2021-10-30,0.08,2020-10-30,0.1,2019-10-30,0.1,2018-10-30,0.15,0.1075\r\n2022-10-31,0.05,2021-10-31,0.08,2020-10-31,0.1,2019-10-31,0.1,2018-10-31,0.11,0.0975\r\n2022-11-01,0.05,2021-11-01,0.01,2020-11-01,0.09,2019-11-01,0.1,2018-11-01,0.1,0.075\r\n2022-11-02,0.05,2021-11-02,0.05,2020-11-02,0.1,2019-11-02,0.1,2018-11-02,0.11,0.09\r\n2022-11-03,0.11,2021-11-03,0.09,2020-11-03,0.1,2019-11-03,0.09,2018-11-03,0.11,0.0975\r\n2022-11-04,0.07,2021-11-04,0.09,2020-11-04,0.11,2019-11-04,0.09,2018-11-04,0.11,0.1\r\n2022-11-05,0.03,2021-11-05,0.08,2020-11-05,0.1,2019-11-05,0.1,2018-11-05,0.14,0.10500000000000001\r\n2022-11-06,0.09,2021-11-06,0.06,2020-11-06,0.1,2019-11-06,0.09,2018-11-06,0.12,0.0925\r\n2022-11-07,0.08,2021-11-07,0.1,2020-11-07,0.07,2019-11-07,0.09,2018-11-07,0.11,0.0925\r\n2022-11-08,0.03,2021-11-08,0.07,2020-11-08,0.12,2019-11-08,0.09,2018-11-08,0.14,0.10500000000000001\r\n2022-11-09,0.06,2021-11-09,0.05,2020-11-09,0.09,2019-11-09,0.09,2018-11-09,0.09,0.08\r\n2022-11-10,0.08,2021-11-10,0.05,2020-11-10,0.08,2019-11-10,0.09,2018-11-10,0.05,0.0675\r\n2022-11-11,0.06,2021-11-11,0.08,2020-11-11,0.04,2019-11-11,0.08,2018-11-11,0.08,0.07\r\n2022-11-12,0.07,2021-11-12,0.02,2020-11-12,0.06,2019-11-12,0.08,2018-11-12,0.07,0.0575\r\n2022-11-13,0.1,2021-11-13,0.01,2020-11-13,0.03,2019-11-13,0.06,2018-11-13,0.05,0.0375\r\n2022-11-14,0.06,2021-11-14,0.0,2020-11-14,0.04,2019-11-14,0.07,2018-11-14,0.06,0.0425\r\n2022-11-15,0.09,2021-11-15,0.0,2020-11-15,0.07,2019-11-15,0.08,2018-11-15,0.04,0.0475\r\n2022-11-16,0.07,2021-11-16,0.01,2020-11-16,0.07,2019-11-16,0.07,2018-11-16,0.05,0.05\r\n2022-11-17,0.06,2021-11-17,0.02,2020-11-17,0.04,2019-11-17,0.07,2018-11-17,0.06,0.0475\r\n2022-11-18,0.09,2021-11-18,0.02,2020-11-18,0.05,2019-11-18,0.07,2018-11-18,0.06,0.05\r\n2022-11-19,0.07,2021-11-19,0.04,2020-11-19,0.07,2019-11-19,0.09,2018-11-19,0.05,0.0625\r\n2022-11-20,0.07,2021-11-20,0.07,2020-11-20,0.07,2019-11-20,0.13,2018-11-20,0.05,0.08\r\n2022-11-21,0.06,2021-11-21,0.05,2020-11-21,0.06,2019-11-21,0.06,2018-11-21,0.02,0.0475\r\n2022-11-22,0.06,2021-11-22,0.05,2020-11-22,0.07,2019-11-22,0.07,2018-11-22,0.06,0.0625\r\n2022-11-23,0.08,2021-11-23,0.04,2020-11-23,0.07,2019-11-23,0.08,2018-11-23,0.01,0.05\r\n2022-11-24,0.06,2021-11-24,0.07,2020-11-24,0.08,2019-11-24,0.07,2018-11-24,0.05,0.0675\r\n2022-11-25,0.05,2021-11-25,0.05,2020-11-25,0.09,2019-11-25,0.14,2018-11-25,0.07,0.08750000000000001\r\n2022-11-26,0.07,2021-11-26,0.06,2020-11-26,0.13,2019-11-26,0.04,2018-11-26,0.04,0.0675\r\n2022-11-27,0.06,2021-11-27,0.06,2020-11-27,0.06,2019-11-27,0.04,2018-11-27,0.01,0.042499999999999996\r\n2022-11-28,0.09,2021-11-28,0.06,2020-11-28,0.07,2019-11-28,0.02,2018-11-28,0.02,0.0425\r\n2022-11-29,0.07,2021-11-29,0.05,2020-11-29,0.06,2019-11-29,0.05,2018-11-29,0.01,0.0425\r\n2022-11-30,0.06,2021-11-30,0.06,2020-11-30,0.07,2019-11-30,0.02,2018-11-30,0.06,0.0525\r\n2022-12-01,0.01,2021-12-01,0.05,2020-12-01,0.07,2019-12-01,0.01,2018-12-01,0.04,0.0425\r\n2022-12-02,0.04,2021-12-02,0.04,2020-12-02,0.06,2019-12-02,0.0,2018-12-02,0.06,0.04\r\n2022-12-03,0.0,2021-12-03,0.03,2020-12-03,0.05,2019-12-03,0.0,2018-12-03,0.04,0.03\r\n2022-12-04,0.05,2021-12-04,0.01,2020-12-04,0.06,2019-12-04,0.02,2018-12-04,0.01,0.025\r\n2022-12-05,0.05,2021-12-05,0.02,2020-12-05,0.06,2019-12-05,0.02,2018-12-05,0.04,0.035\r\n2022-12-06,0.02,2021-12-06,0.0,2020-12-06,0.07,2019-12-06,0.08,2018-12-06,0.06,0.052500000000000005\r\n2022-12-07,0.05,2021-12-07,0.01,2020-12-07,0.1,2019-12-07,0.05,2018-12-07,0.05,0.052500000000000005\r\n2022-12-08,0.02,2021-12-08,0.01,2020-12-08,0.07,2019-12-08,0.04,2018-12-08,0.01,0.0325\r\n2022-12-09,0.03,2021-12-09,0.04,2020-12-09,0.07,2019-12-09,0.04,2018-12-09,0.0,0.037500000000000006\r\n2022-12-10,0.01,2021-12-10,0.06,2020-12-10,0.08,2019-12-10,0.01,2018-12-10,0.02,0.0425\r\n2022-12-11,0.05,2021-12-11,0.05,2020-12-11,0.03,2019-12-11,0.01,2018-12-11,0.04,0.0325\r\n2022-12-12,0.05,2021-12-12,0.0,2020-12-12,0.0,2019-12-12,0.02,2018-12-12,0.06,0.02\r\n2022-12-13,0.06,2021-12-13,0.0,2020-12-13,0.01,2019-12-13,0.0,2018-12-13,0.05,0.015000000000000001\r\n2022-12-14,0.03,2021-12-14,0.04,2020-12-14,0.06,2019-12-14,0.06,2018-12-14,0.02,0.045\r\n2022-12-15,0.04,2021-12-15,0.04,2020-12-15,0.04,2019-12-15,0.06,2018-12-15,0.03,0.042499999999999996\r\n2022-12-16,0.02,2021-12-16,0.04,2020-12-16,0.03,2019-12-16,0.05,2018-12-16,0.01,0.0325\r\n2022-12-17,0.03,2021-12-17,0.04,2020-12-17,0.05,2019-12-17,0.04,2018-12-17,0.05,0.045\r\n2022-12-18,0.0,2021-12-18,0.01,2020-12-18,0.05,2019-12-18,0.03,2018-12-18,0.05,0.035\r\n2022-12-19,0.0,2021-12-19,0.0,2020-12-19,0.03,2019-12-19,0.03,2018-12-19,0.02,0.02\r\n2022-12-20,0.03,2021-12-20,0.01,2020-12-20,0.04,2019-12-20,0.04,2018-12-20,0.0,0.0225\r\n2022-12-21,0.0,2021-12-21,0.01,2020-12-21,0.0,2019-12-21,0.02,2018-12-21,0.02,0.0125\r\n2022-12-22,0.0,2021-12-22,0.03,2020-12-22,0.02,2019-12-22,0.03,2018-12-22,0.04,0.03\r\n2022-12-23,0.02,2021-12-23,0.01,2020-12-23,0.03,2019-12-23,0.04,2018-12-23,0.03,0.0275\r\n2022-12-24,0.03,2021-12-24,0.05,2020-12-24,0.01,2019-12-24,0.04,2018-12-24,0.01,0.0275\r\n2022-12-25,0.0,2021-12-25,0.01,2020-12-25,0.03,2019-12-25,0.04,2018-12-25,0.07,0.0375\r\n2022-12-26,0.0,2021-12-26,0.01,2020-12-26,0.04,2019-12-26,0.07,2018-12-26,0.06,0.045\r\n2022-12-27,0.0,2021-12-27,0.02,2020-12-27,0.05,2019-12-27,0.06,2018-12-27,0.09,0.055\r\n2022-12-28,0.04,2021-12-28,0.04,2020-12-28,0.03,2019-12-28,0.05,2018-12-28,0.08,0.05\r\n2022-12-29,0.0,2021-12-29,0.02,2020-12-29,0.06,2019-12-29,0.02,2018-12-29,0.05,0.0375\r\n2022-12-30,0.0,2021-12-30,0.05,2020-12-30,0.05,2019-12-30,0.06,2018-12-30,0.05,0.052500000000000005\r\n2022-12-31,0.0,2021-12-31,0.03,2020-12-31,0.05,2019-12-31,0.04,2018-12-31,0.11,0.0575\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/newhistoricalET.csv b/newhistoricalET.csv
--- a/newhistoricalET.csv	
+++ b/newhistoricalET.csv	
@@ -1,366 +1,367 @@
-Year_2022,Year_2022_ET,Year_2021,Year_2021_ET,Year_2020,Year_2020_ET,Year_2019,Year_2019_ET,Year_2018,Year_2018_ET,Average
-2022-01-01,0.05,2021-01-01,0.03,2020-01-01,0.04,2019-01-01,0.06,2018-01-01,0.04,0.042499999999999996
-2022-01-02,0.03,2021-01-02,0.02,2020-01-02,0.06,2019-01-02,0.05,2018-01-02,0.02,0.0375
-2022-01-03,0.03,2021-01-03,0.02,2020-01-03,0.04,2019-01-03,0.04,2018-01-03,0.01,0.0275
-2022-01-04,0.02,2021-01-04,0.02,2020-01-04,0.05,2019-01-04,0.05,2018-01-04,0.05,0.0425
-2022-01-05,0.05,2021-01-05,0.01,2020-01-05,0.07,2019-01-05,0.02,2018-01-05,0.01,0.027500000000000004
-2022-01-06,0.01,2021-01-06,0.03,2020-01-06,0.05,2019-01-06,0.0,2018-01-06,0.06,0.035
-2022-01-07,0.01,2021-01-07,0.04,2020-01-07,0.01,2019-01-07,0.03,2018-01-07,0.0,0.02
-2022-01-08,0.01,2021-01-08,0.02,2020-01-08,0.02,2019-01-08,0.01,2018-01-08,0.0,0.0125
-2022-01-09,0.04,2021-01-09,0.06,2020-01-09,0.01,2019-01-09,0.04,2018-01-09,0.0,0.0275
-2022-01-10,0.05,2021-01-10,0.02,2020-01-10,0.05,2019-01-10,0.01,2018-01-10,0.01,0.0225
-2022-01-11,0.05,2021-01-11,0.04,2020-01-11,0.06,2019-01-11,0.03,2018-01-11,0.03,0.04
-2022-01-12,0.04,2021-01-12,0.02,2020-01-12,0.03,2019-01-12,0.03,2018-01-12,0.0,0.02
-2022-01-13,0.04,2021-01-13,0.06,2020-01-13,0.04,2019-01-13,0.03,2018-01-13,0.0,0.0325
-2022-01-14,0.05,2021-01-14,0.06,2020-01-14,0.07,2019-01-14,0.01,2018-01-14,0.0,0.035
-2022-01-15,0.02,2021-01-15,0.05,2020-01-15,0.04,2019-01-15,0.0,2018-01-15,0.0,0.0225
-2022-01-16,0.05,2021-01-16,0.08,2020-01-16,0.02,2019-01-16,0.02,2018-01-16,0.0,0.03
-2022-01-17,0.06,2021-01-17,0.06,2020-01-17,0.02,2019-01-17,0.03,2018-01-17,0.0,0.0275
-2022-01-18,0.05,2021-01-18,0.18,2020-01-18,0.01,2019-01-18,0.04,2018-01-18,0.02,0.0625
-2022-01-19,0.05,2021-01-19,0.18,2020-01-19,0.0,2019-01-19,0.06,2018-01-19,0.07,0.0775
-2022-01-20,0.06,2021-01-20,0.09,2020-01-20,0.01,2019-01-20,0.03,2018-01-20,0.07,0.05
-2022-01-21,0.1,2021-01-21,0.07,2020-01-21,0.03,2019-01-21,0.07,2018-01-21,0.04,0.052500000000000005
-2022-01-22,0.07,2021-01-22,0.02,2020-01-22,0.05,2019-01-22,0.07,2018-01-22,0.02,0.04
-2022-01-23,0.04,2021-01-23,0.06,2020-01-23,0.02,2019-01-23,0.07,2018-01-23,0.03,0.045
-2022-01-24,0.07,2021-01-24,0.03,2020-01-24,0.07,2019-01-24,0.07,2018-01-24,0.01,0.045000000000000005
-2022-01-25,0.07,2021-01-25,0.08,2020-01-25,0.02,2019-01-25,0.06,2018-01-25,0.05,0.0525
-2022-01-26,0.06,2021-01-26,0.08,2020-01-26,0.07,2019-01-26,0.05,2018-01-26,0.06,0.065
-2022-01-27,0.07,2021-01-27,0.01,2020-01-27,0.07,2019-01-27,0.06,2018-01-27,0.07,0.052500000000000005
-2022-01-28,0.06,2021-01-28,0.0,2020-01-28,0.04,2019-01-28,0.04,2018-01-28,0.06,0.035
-2022-01-29,0.07,2021-01-29,0.06,2020-01-29,0.08,2019-01-29,0.06,2018-01-29,0.02,0.055
-2022-01-30,0.07,2021-01-30,0.07,2020-01-30,0.06,2019-01-30,0.06,2018-01-30,0.04,0.0575
-2022-01-31,0.06,2021-01-31,0.08,2020-01-31,0.07,2019-01-31,0.06,2018-01-31,0.07,0.07
-2022-02-01,0.13,2021-02-01,0.06,2020-02-01,0.04,2019-02-01,0.03,2018-02-01,0.07,0.05
-2022-02-02,0.15,2021-02-02,0.02,2020-02-02,0.1,2019-02-02,0.05,2018-02-02,0.07,0.060000000000000005
-2022-02-03,0.07,2021-02-03,0.07,2020-02-03,0.13,2019-02-03,0.03,2018-02-03,0.07,0.07500000000000001
-2022-02-04,0.07,2021-02-04,0.08,2020-02-04,0.09,2019-02-04,0.03,2018-02-04,0.05,0.0625
-2022-02-05,0.07,2021-02-05,0.08,2020-02-05,0.08,2019-02-05,0.07,2018-02-05,0.07,0.07500000000000001
-2022-02-06,0.08,2021-02-06,0.08,2020-02-06,0.08,2019-02-06,0.07,2018-02-06,0.11,0.085
-2022-02-07,0.08,2021-02-07,0.07,2020-02-07,0.08,2019-02-07,0.06,2018-02-07,0.08,0.07250000000000001
-2022-02-08,0.08,2021-02-08,0.05,2020-02-08,0.09,2019-02-08,0.05,2018-02-08,0.09,0.07
-2022-02-09,0.07,2021-02-09,0.05,2020-02-09,0.19,2019-02-09,0.05,2018-02-09,0.09,0.095
-2022-02-10,0.09,2021-02-10,0.09,2020-02-10,0.13,2019-02-10,0.08,2018-02-10,0.15,0.1125
-2022-02-11,0.09,2021-02-11,0.03,2020-02-11,0.09,2019-02-11,0.07,2018-02-11,0.07,0.065
-2022-02-12,0.09,2021-02-12,0.09,2020-02-12,0.09,2019-02-12,0.02,2018-02-12,0.09,0.0725
-2022-02-13,0.09,2021-02-13,0.11,2020-02-13,0.09,2019-02-13,0.05,2018-02-13,0.09,0.08499999999999999
-2022-02-14,0.09,2021-02-14,0.05,2020-02-14,0.08,2019-02-14,0.05,2018-02-14,0.08,0.065
-2022-02-15,0.15,2021-02-15,0.05,2020-02-15,0.09,2019-02-15,0.06,2018-02-15,0.13,0.0825
-2022-02-16,0.13,2021-02-16,0.08,2020-02-16,0.11,2019-02-16,0.08,2018-02-16,0.11,0.095
-2022-02-17,0.09,2021-02-17,0.15,2020-02-17,0.13,2019-02-17,0.08,2018-02-17,0.09,0.1125
-2022-02-18,0.1,2021-02-18,0.09,2020-02-18,0.11,2019-02-18,0.1,2018-02-18,0.13,0.1075
-2022-02-19,0.1,2021-02-19,0.06,2020-02-19,0.1,2019-02-19,0.09,2018-02-19,0.1,0.0875
-2022-02-20,0.08,2021-02-20,0.11,2020-02-20,0.1,2019-02-20,0.08,2018-02-20,0.08,0.0925
-2022-02-21,0.12,2021-02-21,0.12,2020-02-21,0.11,2019-02-21,0.12,2018-02-21,0.1,0.1125
-2022-02-22,0.1,2021-02-22,0.1,2020-02-22,0.13,2019-02-22,0.1,2018-02-22,0.1,0.10750000000000001
-2022-02-23,0.12,2021-02-23,0.15,2020-02-23,0.1,2019-02-23,0.07,2018-02-23,0.12,0.11
-2022-02-24,0.1,2021-02-24,0.19,2020-02-24,0.15,2019-02-24,0.07,2018-02-24,0.1,0.1275
-2022-02-25,0.11,2021-02-25,0.13,2020-02-25,0.12,2019-02-25,0.03,2018-02-25,0.1,0.095
-2022-02-26,0.08,2021-02-26,0.12,2020-02-26,0.12,2019-02-26,0.02,2018-02-26,0.02,0.06999999999999999
-2022-02-27,0.13,2021-02-27,0.17,2020-02-27,0.12,2019-02-27,0.09,2018-02-27,0.12,0.125
-2022-02-28,0.12,2021-02-28,0.12,2020-02-28,0.11,2019-02-28,0.06,2018-02-28,0.08,0.0925
-2022-03-01,0.11,2021-03-01,0.13,2020-03-01,0.1,2019-03-01,0.04,2018-03-01,0.02,0.07250000000000001
-2022-03-02,0.12,2021-03-02,0.11,2020-03-02,0.22,2019-03-02,0.01,2018-03-02,0.04,0.095
-2022-03-03,0.1,2021-03-03,0.08,2020-03-03,0.12,2019-03-03,0.04,2018-03-03,0.04,0.07
-2022-03-04,0.11,2021-03-04,0.11,2020-03-04,0.13,2019-03-04,0.09,2018-03-04,0.09,0.105
-2022-03-05,0.08,2021-03-05,0.12,2020-03-05,0.12,2019-03-05,0.03,2018-03-05,0.1,0.0925
-2022-03-06,0.13,2021-03-06,0.12,2020-03-06,0.11,2019-03-06,0.07,2018-03-06,0.09,0.0975
-2022-03-07,0.17,2021-03-07,0.13,2020-03-07,0.04,2019-03-07,0.02,2018-03-07,0.09,0.07
-2022-03-08,0.13,2021-03-08,0.12,2020-03-08,0.07,2019-03-08,0.11,2018-03-08,0.1,0.1
-2022-03-09,0.15,2021-03-09,0.08,2020-03-09,0.12,2019-03-09,0.06,2018-03-09,0.09,0.0875
-2022-03-10,0.2,2021-03-10,0.06,2020-03-10,0.12,2019-03-10,0.09,2018-03-10,0.01,0.06999999999999999
-2022-03-11,0.13,2021-03-11,0.09,2020-03-11,0.14,2019-03-11,0.14,2018-03-11,0.1,0.11750000000000001
-2022-03-12,0.14,2021-03-12,0.12,2020-03-12,0.17,2019-03-12,0.15,2018-03-12,0.1,0.135
-2022-03-13,0.13,2021-03-13,0.14,2020-03-13,0.16,2019-03-13,0.18,2018-03-13,0.02,0.125
-2022-03-14,0.13,2021-03-14,0.08,2020-03-14,0.06,2019-03-14,0.13,2018-03-14,0.05,0.08
-2022-03-15,0.11,2021-03-15,0.1,2020-03-15,0.07,2019-03-15,0.13,2018-03-15,0.04,0.085
-2022-03-16,0.17,2021-03-16,0.12,2020-03-16,0.02,2019-03-16,0.14,2018-03-16,0.07,0.08750000000000001
-2022-03-17,0.14,2021-03-17,0.09,2020-03-17,0.1,2019-03-17,0.12,2018-03-17,0.07,0.095
-2022-03-18,0.14,2021-03-18,0.04,2020-03-18,0.07,2019-03-18,0.14,2018-03-18,0.07,0.08
-2022-03-19,0.06,2021-03-19,0.04,2020-03-19,0.13,2019-03-19,0.1,2018-03-19,0.11,0.095
-2022-03-20,0.21,2021-03-20,0.14,2020-03-20,0.14,2019-03-20,0.09,2018-03-20,0.01,0.095
-2022-03-21,0.19,2021-03-21,0.18,2020-03-21,0.12,2019-03-21,0.14,2018-03-21,0.06,0.125
-2022-03-22,0.17,2021-03-22,0.14,2020-03-22,0.13,2019-03-22,0.05,2018-03-22,0.12,0.11
-2022-03-23,0.17,2021-03-23,0.23,2020-03-23,0.15,2019-03-23,0.11,2018-03-23,0.13,0.155
-2022-03-24,0.18,2021-03-24,0.16,2020-03-24,0.11,2019-03-24,0.1,2018-03-24,0.11,0.12
-2022-03-25,0.17,2021-03-25,0.16,2020-03-25,0.11,2019-03-25,0.06,2018-03-25,0.16,0.1225
-2022-03-26,0.18,2021-03-26,0.19,2020-03-26,0.13,2019-03-26,0.12,2018-03-26,0.22,0.165
-2022-03-27,0.13,2021-03-27,0.17,2020-03-27,0.16,2019-03-27,0.08,2018-03-27,0.16,0.14250000000000002
-2022-03-28,0.06,2021-03-28,0.18,2020-03-28,0.04,2019-03-28,0.12,2018-03-28,0.16,0.125
-2022-03-29,0.13,2021-03-29,0.2,2020-03-29,0.13,2019-03-29,0.16,2018-03-29,0.17,0.165
-2022-03-30,0.12,2021-03-30,0.23,2020-03-30,0.14,2019-03-30,0.17,2018-03-30,0.13,0.1675
-2022-03-31,0.17,2021-03-31,0.17,2020-03-31,0.15,2019-03-31,0.17,2018-03-31,0.14,0.1575
-2022-04-01,0.18,2021-04-01,0.19,2020-04-01,0.17,2019-04-01,0.05,2018-04-01,0.15,0.14
-2022-04-02,0.19,2021-04-02,0.2,2020-04-02,0.2,2019-04-02,0.12,2018-04-02,0.17,0.17250000000000001
-2022-04-03,0.23,2021-04-03,0.17,2020-04-03,0.18,2019-04-03,0.07,2018-04-03,0.18,0.15
-2022-04-04,0.18,2021-04-04,0.15,2020-04-04,0.05,2019-04-04,0.08,2018-04-04,0.15,0.1075
-2022-04-05,0.21,2021-04-05,0.16,2020-04-05,0.04,2019-04-05,0.05,2018-04-05,0.08,0.0825
-2022-04-06,0.19,2021-04-06,0.18,2020-04-06,0.06,2019-04-06,0.12,2018-04-06,0.02,0.095
-2022-04-07,0.19,2021-04-07,0.18,2020-04-07,0.16,2019-04-07,0.17,2018-04-07,0.18,0.1725
-2022-04-08,0.22,2021-04-08,0.2,2020-04-08,0.13,2019-04-08,0.13,2018-04-08,0.2,0.165
-2022-04-09,0.27,2021-04-09,0.19,2020-04-09,0.08,2019-04-09,0.2,2018-04-09,0.17,0.16
-2022-04-10,0.24,2021-04-10,0.2,2020-04-10,0.14,2019-04-10,0.22,2018-04-10,0.13,0.17250000000000001
-2022-04-11,0.15,2021-04-11,0.21,2020-04-11,0.16,2019-04-11,0.12,2018-04-11,0.18,0.16749999999999998
-2022-04-12,0.18,2021-04-12,0.21,2020-04-12,0.14,2019-04-12,0.22,2018-04-12,0.2,0.1925
-2022-04-13,0.15,2021-04-13,0.21,2020-04-13,0.2,2019-04-13,0.18,2018-04-13,0.21,0.2
-2022-04-14,0.07,2021-04-14,0.2,2020-04-14,0.22,2019-04-14,0.2,2018-04-14,0.19,0.2025
-2022-04-15,0.18,2021-04-15,0.2,2020-04-15,0.2,2019-04-15,0.08,2018-04-15,0.23,0.17750000000000002
-2022-04-16,0.13,2021-04-16,0.22,2020-04-16,0.17,2019-04-16,0.14,2018-04-16,0.08,0.1525
-2022-04-17,0.19,2021-04-17,0.25,2020-04-17,0.16,2019-04-17,0.19,2018-04-17,0.14,0.185
-2022-04-18,0.17,2021-04-18,0.25,2020-04-18,0.16,2019-04-18,0.2,2018-04-18,0.07,0.17
-2022-04-19,0.14,2021-04-19,0.23,2020-04-19,0.18,2019-04-19,0.19,2018-04-19,0.18,0.195
-2022-04-20,0.18,2021-04-20,0.21,2020-04-20,0.14,2019-04-20,0.19,2018-04-20,0.2,0.185
-2022-04-21,0.08,2021-04-21,0.21,2020-04-21,0.21,2019-04-21,0.21,2018-04-21,0.18,0.20249999999999999
-2022-04-22,0.16,2021-04-22,0.2,2020-04-22,0.22,2019-04-22,0.25,2018-04-22,0.19,0.215
-2022-04-23,0.22,2021-04-23,0.2,2020-04-23,0.25,2019-04-23,0.21,2018-04-23,0.2,0.215
-2022-04-24,0.21,2021-04-24,0.19,2020-04-24,0.25,2019-04-24,0.22,2018-04-24,0.21,0.2175
-2022-04-25,0.21,2021-04-25,0.06,2020-04-25,0.23,2019-04-25,0.23,2018-04-25,0.19,0.1775
-2022-04-26,0.21,2021-04-26,0.2,2020-04-26,0.24,2019-04-26,0.22,2018-04-26,0.16,0.20500000000000002
-2022-04-27,0.22,2021-04-27,0.24,2020-04-27,0.24,2019-04-27,0.19,2018-04-27,0.12,0.1975
-2022-04-28,0.21,2021-04-28,0.24,2020-04-28,0.24,2019-04-28,0.21,2018-04-28,0.09,0.195
-2022-04-29,0.22,2021-04-29,0.24,2020-04-29,0.18,2019-04-29,0.21,2018-04-29,0.13,0.19
-2022-04-30,0.24,2021-04-30,0.23,2020-04-30,0.25,2019-04-30,0.21,2018-04-30,0.13,0.20500000000000002
-2022-05-01,0.25,2021-05-01,0.24,2020-05-01,0.25,2019-05-01,0.23,2018-05-01,0.18,0.225
-2022-05-02,0.22,2021-05-02,0.29,2020-05-02,0.21,2019-05-02,0.23,2018-05-02,0.17,0.225
-2022-05-03,0.26,2021-05-03,0.3,2020-05-03,0.24,2019-05-03,0.22,2018-05-03,0.17,0.23249999999999998
-2022-05-04,0.23,2021-05-04,0.27,2020-05-04,0.24,2019-05-04,0.22,2018-05-04,0.17,0.225
-2022-05-05,0.21,2021-05-05,0.25,2020-05-05,0.25,2019-05-05,0.2,2018-05-05,0.12,0.20500000000000002
-2022-05-06,0.16,2021-05-06,0.25,2020-05-06,0.27,2019-05-06,0.18,2018-05-06,0.17,0.2175
-2022-05-07,0.23,2021-05-07,0.24,2020-05-07,0.27,2019-05-07,0.21,2018-05-07,0.19,0.2275
-2022-05-08,0.24,2021-05-08,0.32,2020-05-08,0.26,2019-05-08,0.21,2018-05-08,0.21,0.25
-2022-05-09,0.18,2021-05-09,0.29,2020-05-09,0.25,2019-05-09,0.21,2018-05-09,0.21,0.24
-2022-05-10,0.18,2021-05-10,0.3,2020-05-10,0.24,2019-05-10,0.22,2018-05-10,0.18,0.235
-2022-05-11,0.23,2021-05-11,0.28,2020-05-11,0.21,2019-05-11,0.22,2018-05-11,0.2,0.2275
-2022-05-12,0.22,2021-05-12,0.27,2020-05-12,0.18,2019-05-12,0.23,2018-05-12,0.22,0.225
-2022-05-13,0.24,2021-05-13,0.24,2020-05-13,0.15,2019-05-13,0.23,2018-05-13,0.2,0.20500000000000002
-2022-05-14,0.27,2021-05-14,0.25,2020-05-14,0.16,2019-05-14,0.16,2018-05-14,0.2,0.1925
-2022-05-15,0.28,2021-05-15,0.2,2020-05-15,0.24,2019-05-15,0.06,2018-05-15,0.2,0.175
-2022-05-16,0.25,2021-05-16,0.22,2020-05-16,0.25,2019-05-16,0.1,2018-05-16,0.13,0.175
-2022-05-17,0.27,2021-05-17,0.23,2020-05-17,0.12,2019-05-17,0.13,2018-05-17,0.21,0.1725
-2022-05-18,0.29,2021-05-18,0.28,2020-05-18,0.18,2019-05-18,0.05,2018-05-18,0.2,0.17750000000000002
-2022-05-19,0.29,2021-05-19,0.27,2020-05-19,0.18,2019-05-19,0.07,2018-05-19,0.21,0.1825
-2022-05-20,0.33,2021-05-20,0.27,2020-05-20,0.23,2019-05-20,0.16,2018-05-20,0.19,0.21250000000000002
-2022-05-21,0.28,2021-05-21,0.28,2020-05-21,0.26,2019-05-21,0.15,2018-05-21,0.19,0.22
-2022-05-22,0.28,2021-05-22,0.26,2020-05-22,0.27,2019-05-22,0.21,2018-05-22,0.2,0.23500000000000001
-2022-05-23,0.29,2021-05-23,0.24,2020-05-23,0.29,2019-05-23,0.2,2018-05-23,0.19,0.22999999999999998
-2022-05-24,0.3,2021-05-24,0.27,2020-05-24,0.28,2019-05-24,0.21,2018-05-24,0.18,0.23500000000000001
-2022-05-25,0.29,2021-05-25,0.27,2020-05-25,0.28,2019-05-25,0.23,2018-05-25,0.05,0.20750000000000002
-2022-05-26,0.22,2021-05-26,0.27,2020-05-26,0.29,2019-05-26,0.19,2018-05-26,0.15,0.225
-2022-05-27,0.22,2021-05-27,0.27,2020-05-27,0.31,2019-05-27,0.14,2018-05-27,0.2,0.23
-2022-05-28,0.26,2021-05-28,0.27,2020-05-28,0.3,2019-05-28,0.23,2018-05-28,0.22,0.255
-2022-05-29,0.28,2021-05-29,0.27,2020-05-29,0.24,2019-05-29,0.25,2018-05-29,0.22,0.245
-2022-05-30,0.28,2021-05-30,0.27,2020-05-30,0.17,2019-05-30,0.24,2018-05-30,0.16,0.21000000000000002
-2022-05-31,0.31,2021-05-31,0.3,2020-05-31,0.19,2019-05-31,0.26,2018-05-31,0.18,0.23249999999999998
-2022-06-01,0.28,2021-06-01,0.28,2020-06-01,0.26,2019-06-01,0.27,2018-06-01,0.21,0.255
-2022-06-02,0.28,2021-06-02,0.27,2020-06-02,0.3,2019-06-02,0.25,2018-06-02,0.25,0.2675
-2022-06-03,0.22,2021-06-03,0.28,2020-06-03,0.31,2019-06-03,0.25,2018-06-03,0.25,0.2725
-2022-06-04,0.16,2021-06-04,0.29,2020-06-04,0.32,2019-06-04,0.27,2018-06-04,0.3,0.295
-2022-06-05,0.17,2021-06-05,0.27,2020-06-05,0.32,2019-06-05,0.29,2018-06-05,0.25,0.2825
-2022-06-06,0.27,2021-06-06,0.31,2020-06-06,0.3,2019-06-06,0.31,2018-06-06,0.23,0.2875
-2022-06-07,0.28,2021-06-07,0.31,2020-06-07,0.27,2019-06-07,0.29,2018-06-07,0.24,0.27749999999999997
-2022-06-08,0.27,2021-06-08,0.27,2020-06-08,0.31,2019-06-08,0.32,2018-06-08,0.27,0.2925
-2022-06-09,0.29,2021-06-09,0.27,2020-06-09,0.28,2019-06-09,0.27,2018-06-09,0.24,0.265
-2022-06-10,0.3,2021-06-10,0.26,2020-06-10,0.26,2019-06-10,0.28,2018-06-10,0.27,0.2675
-2022-06-11,0.31,2021-06-11,0.28,2020-06-11,0.28,2019-06-11,0.28,2018-06-11,0.27,0.2775
-2022-06-12,0.23,2021-06-12,0.28,2020-06-12,0.23,2019-06-12,0.32,2018-06-12,0.28,0.2775
-2022-06-13,0.3,2021-06-13,0.28,2020-06-13,0.24,2019-06-13,0.28,2018-06-13,0.28,0.27
-2022-06-14,0.31,2021-06-14,0.28,2020-06-14,0.27,2019-06-14,0.26,2018-06-14,0.26,0.2675
-2022-06-15,0.31,2021-06-15,0.3,2020-06-15,0.26,2019-06-15,0.25,2018-06-15,0.26,0.2675
-2022-06-16,0.3,2021-06-16,0.29,2020-06-16,0.27,2019-06-16,0.25,2018-06-16,0.24,0.2625
-2022-06-17,0.25,2021-06-17,0.32,2020-06-17,0.32,2019-06-17,0.26,2018-06-17,0.21,0.2775
-2022-06-18,0.25,2021-06-18,0.32,2020-06-18,0.29,2019-06-18,0.29,2018-06-18,0.24,0.285
-2022-06-19,0.28,2021-06-19,0.31,2020-06-19,0.29,2019-06-19,0.28,2018-06-19,0.25,0.2825
-2022-06-20,0.3,2021-06-20,0.29,2020-06-20,0.27,2019-06-20,0.27,2018-06-20,0.26,0.2725
-2022-06-21,0.3,2021-06-21,0.27,2020-06-21,0.3,2019-06-21,0.29,2018-06-21,0.26,0.28
-2022-06-22,0.18,2021-06-22,0.26,2020-06-22,0.28,2019-06-22,0.33,2018-06-22,0.28,0.28750000000000003
-2022-06-23,0.3,2021-06-23,0.27,2020-06-23,0.28,2019-06-23,0.29,2018-06-23,0.3,0.28500000000000003
-2022-06-24,0.29,2021-06-24,0.27,2020-06-24,0.28,2019-06-24,0.28,2018-06-24,0.28,0.2775
-2022-06-25,0.3,2021-06-25,0.27,2020-06-25,0.29,2019-06-25,0.31,2018-06-25,0.24,0.27749999999999997
-2022-06-26,0.29,2021-06-26,0.27,2020-06-26,0.29,2019-06-26,0.28,2018-06-26,0.26,0.275
-2022-06-27,0.3,2021-06-27,0.28,2020-06-27,0.3,2019-06-27,0.24,2018-06-27,0.25,0.2675
-2022-06-28,0.32,2021-06-28,0.3,2020-06-28,0.3,2019-06-28,0.22,2018-06-28,0.25,0.2675
-2022-06-29,0.27,2021-06-29,0.29,2020-06-29,0.32,2019-06-29,0.26,2018-06-29,0.27,0.28500000000000003
-2022-06-30,0.26,2021-06-30,0.29,2020-06-30,0.29,2019-06-30,0.29,2018-06-30,0.3,0.2925
-2022-07-01,0.27,2021-07-01,0.27,2020-07-01,0.28,2019-07-01,0.28,2018-07-01,0.27,0.275
-2022-07-02,0.27,2021-07-02,0.28,2020-07-02,0.26,2019-07-02,0.28,2018-07-02,0.19,0.2525
-2022-07-03,0.24,2021-07-03,0.26,2020-07-03,0.26,2019-07-03,0.27,2018-07-03,0.24,0.2575
-2022-07-04,0.26,2021-07-04,0.27,2020-07-04,0.29,2019-07-04,0.27,2018-07-04,0.23,0.265
-2022-07-05,0.24,2021-07-05,0.27,2020-07-05,0.32,2019-07-05,0.28,2018-07-05,0.24,0.2775
-2022-07-06,0.25,2021-07-06,0.28,2020-07-06,0.32,2019-07-06,0.28,2018-07-06,0.27,0.28750000000000003
-2022-07-07,0.26,2021-07-07,0.28,2020-07-07,0.29,2019-07-07,0.27,2018-07-07,0.31,0.2875
-2022-07-08,0.29,2021-07-08,0.27,2020-07-08,0.29,2019-07-08,0.27,2018-07-08,0.3,0.2825
-2022-07-09,0.27,2021-07-09,0.32,2020-07-09,0.28,2019-07-09,0.24,2018-07-09,0.29,0.2825
-2022-07-10,0.28,2021-07-10,0.32,2020-07-10,0.27,2019-07-10,0.26,2018-07-10,0.29,0.28500000000000003
-2022-07-11,0.29,2021-07-11,0.3,2020-07-11,0.3,2019-07-11,0.28,2018-07-11,0.26,0.28500000000000003
-2022-07-12,0.28,2021-07-12,0.27,2020-07-12,0.31,2019-07-12,0.27,2018-07-12,0.24,0.2725
-2022-07-13,0.26,2021-07-13,0.25,2020-07-13,0.29,2019-07-13,0.28,2018-07-13,0.24,0.265
-2022-07-14,0.29,2021-07-14,0.25,2020-07-14,0.26,2019-07-14,0.28,2018-07-14,0.26,0.2625
-2022-07-15,0.28,2021-07-15,0.25,2020-07-15,0.26,2019-07-15,0.29,2018-07-15,0.25,0.2625
-2022-07-16,0.29,2021-07-16,0.25,2020-07-16,0.26,2019-07-16,0.28,2018-07-16,0.26,0.2625
-2022-07-17,0.3,2021-07-17,0.27,2020-07-17,0.26,2019-07-17,0.25,2018-07-17,0.27,0.2625
-2022-07-18,0.29,2021-07-18,0.27,2020-07-18,0.27,2019-07-18,0.26,2018-07-18,0.25,0.2625
-2022-07-19,0.29,2021-07-19,0.27,2020-07-19,0.27,2019-07-19,0.25,2018-07-19,0.25,0.26
-2022-07-20,0.29,2021-07-20,0.28,2020-07-20,0.25,2019-07-20,0.25,2018-07-20,0.23,0.2525
-2022-07-21,0.28,2021-07-21,0.28,2020-07-21,0.22,2019-07-21,0.25,2018-07-21,0.25,0.25
-2022-07-22,0.3,2021-07-22,0.28,2020-07-22,0.25,2019-07-22,0.27,2018-07-22,0.24,0.26
-2022-07-23,0.27,2021-07-23,0.27,2020-07-23,0.25,2019-07-23,0.28,2018-07-23,0.26,0.265
-2022-07-24,0.27,2021-07-24,0.27,2020-07-24,0.26,2019-07-24,0.28,2018-07-24,0.25,0.265
-2022-07-25,0.25,2021-07-25,0.26,2020-07-25,0.26,2019-07-25,0.28,2018-07-25,0.28,0.27
-2022-07-26,0.26,2021-07-26,0.21,2020-07-26,0.27,2019-07-26,0.26,2018-07-26,0.24,0.245
-2022-07-27,0.27,2021-07-27,0.27,2020-07-27,0.27,2019-07-27,0.27,2018-07-27,0.24,0.2625
-2022-07-28,0.24,2021-07-28,0.26,2020-07-28,0.26,2019-07-28,0.29,2018-07-28,0.21,0.255
-2022-07-29,0.24,2021-07-29,0.27,2020-07-29,0.28,2019-07-29,0.27,2018-07-29,0.12,0.23500000000000001
-2022-07-30,0.23,2021-07-30,0.27,2020-07-30,0.26,2019-07-30,0.25,2018-07-30,0.2,0.245
-2022-07-31,0.15,2021-07-31,0.26,2020-07-31,0.27,2019-07-31,0.25,2018-07-31,0.22,0.25
-2022-08-01,0.17,2021-08-01,0.26,2020-08-01,0.26,2019-08-01,0.25,2018-08-01,0.24,0.2525
-2022-08-02,0.28,2021-08-02,0.24,2020-08-02,0.26,2019-08-02,0.25,2018-08-02,0.24,0.2475
-2022-08-03,0.28,2021-08-03,0.26,2020-08-03,0.28,2019-08-03,0.26,2018-08-03,0.21,0.2525
-2022-08-04,0.27,2021-08-04,0.26,2020-08-04,0.26,2019-08-04,0.25,2018-08-04,0.26,0.2575
-2022-08-05,0.18,2021-08-05,0.23,2020-08-05,0.25,2019-08-05,0.22,2018-08-05,0.21,0.2275
-2022-08-06,0.23,2021-08-06,0.17,2020-08-06,0.23,2019-08-06,0.25,2018-08-06,0.21,0.215
-2022-08-07,0.24,2021-08-07,0.19,2020-08-07,0.24,2019-08-07,0.26,2018-08-07,0.18,0.2175
-2022-08-08,0.24,2021-08-08,0.24,2020-08-08,0.24,2019-08-08,0.26,2018-08-08,0.18,0.22999999999999998
-2022-08-09,0.23,2021-08-09,0.25,2020-08-09,0.26,2019-08-09,0.22,2018-08-09,0.22,0.2375
-2022-08-10,0.24,2021-08-10,0.25,2020-08-10,0.26,2019-08-10,0.22,2018-08-10,0.25,0.245
-2022-08-11,0.25,2021-08-11,0.28,2020-08-11,0.24,2019-08-11,0.25,2018-08-11,0.24,0.2525
-2022-08-12,0.25,2021-08-12,0.26,2020-08-12,0.25,2019-08-12,0.25,2018-08-12,0.24,0.25
-2022-08-13,0.26,2021-08-13,0.24,2020-08-13,0.24,2019-08-13,0.25,2018-08-13,0.21,0.235
-2022-08-14,0.26,2021-08-14,0.25,2020-08-14,0.25,2019-08-14,0.26,2018-08-14,0.2,0.24
-2022-08-15,0.25,2021-08-15,0.21,2020-08-15,0.23,2019-08-15,0.26,2018-08-15,0.22,0.23
-2022-08-16,0.26,2021-08-16,0.25,2020-08-16,0.28,2019-08-16,0.26,2018-08-16,0.23,0.255
-2022-08-17,0.15,2021-08-17,0.24,2020-08-17,0.24,2019-08-17,0.23,2018-08-17,0.25,0.24
-2022-08-18,0.26,2021-08-18,0.17,2020-08-18,0.26,2019-08-18,0.22,2018-08-18,0.26,0.2275
-2022-08-19,0.25,2021-08-19,0.19,2020-08-19,0.22,2019-08-19,0.21,2018-08-19,0.24,0.215
-2022-08-20,0.25,2021-08-20,0.17,2020-08-20,0.23,2019-08-20,0.22,2018-08-20,0.23,0.21250000000000002
-2022-08-21,0.24,2021-08-21,0.19,2020-08-21,0.16,2019-08-21,0.24,2018-08-21,0.19,0.195
-2022-08-22,0.25,2021-08-22,0.2,2020-08-22,0.17,2019-08-22,0.24,2018-08-22,0.21,0.20500000000000002
-2022-08-23,0.23,2021-08-23,0.21,2020-08-23,0.18,2019-08-23,0.24,2018-08-23,0.2,0.2075
-2022-08-24,0.24,2021-08-24,0.21,2020-08-24,0.18,2019-08-24,0.24,2018-08-24,0.19,0.205
-2022-08-25,0.22,2021-08-25,0.21,2020-08-25,0.2,2019-08-25,0.26,2018-08-25,0.19,0.215
-2022-08-26,0.22,2021-08-26,0.22,2020-08-26,0.22,2019-08-26,0.26,2018-08-26,0.21,0.2275
-2022-08-27,0.22,2021-08-27,0.22,2020-08-27,0.22,2019-08-27,0.25,2018-08-27,0.2,0.2225
-2022-08-28,0.22,2021-08-28,0.22,2020-08-28,0.2,2019-08-28,0.23,2018-08-28,0.2,0.21250000000000002
-2022-08-29,0.22,2021-08-29,0.24,2020-08-29,0.2,2019-08-29,0.21,2018-08-29,0.21,0.215
-2022-08-30,0.22,2021-08-30,0.22,2020-08-30,0.2,2019-08-30,0.22,2018-08-30,0.2,0.21000000000000002
-2022-08-31,0.23,2021-08-31,0.23,2020-08-31,0.19,2019-08-31,0.22,2018-08-31,0.21,0.2125
-2022-09-01,0.24,2021-09-01,0.2,2020-09-01,0.18,2019-09-01,0.24,2018-09-01,0.21,0.2075
-2022-09-02,0.25,2021-09-02,0.18,2020-09-02,0.19,2019-09-02,0.24,2018-09-02,0.21,0.205
-2022-09-03,0.24,2021-09-03,0.19,2020-09-03,0.2,2019-09-03,0.22,2018-09-03,0.2,0.2025
-2022-09-04,0.23,2021-09-04,0.22,2020-09-04,0.21,2019-09-04,0.21,2018-09-04,0.2,0.21
-2022-09-05,0.24,2021-09-05,0.23,2020-09-05,0.2,2019-09-05,0.18,2018-09-05,0.2,0.2025
-2022-09-06,0.23,2021-09-06,0.23,2020-09-06,0.22,2019-09-06,0.21,2018-09-06,0.2,0.215
-2022-09-07,0.24,2021-09-07,0.26,2020-09-07,0.22,2019-09-07,0.21,2018-09-07,0.21,0.225
-2022-09-08,0.24,2021-09-08,0.23,2020-09-08,0.26,2019-09-08,0.2,2018-09-08,0.22,0.2275
-2022-09-09,0.22,2021-09-09,0.21,2020-09-09,0.1,2019-09-09,0.21,2018-09-09,0.2,0.18
-2022-09-10,0.13,2021-09-10,0.19,2020-09-10,0.08,2019-09-10,0.19,2018-09-10,0.21,0.1675
-2022-09-11,0.17,2021-09-11,0.21,2020-09-11,0.14,2019-09-11,0.2,2018-09-11,0.21,0.19
-2022-09-12,0.21,2021-09-12,0.21,2020-09-12,0.12,2019-09-12,0.19,2018-09-12,0.19,0.1775
-2022-09-13,0.2,2021-09-13,0.21,2020-09-13,0.14,2019-09-13,0.21,2018-09-13,0.18,0.185
-2022-09-14,0.18,2021-09-14,0.2,2020-09-14,0.15,2019-09-14,0.2,2018-09-14,0.18,0.1825
-2022-09-15,0.16,2021-09-15,0.18,2020-09-15,0.16,2019-09-15,0.22,2018-09-15,0.19,0.1875
-2022-09-16,0.17,2021-09-16,0.17,2020-09-16,0.17,2019-09-16,0.14,2018-09-16,0.18,0.165
-2022-09-17,0.18,2021-09-17,0.17,2020-09-17,0.17,2019-09-17,0.18,2018-09-17,0.18,0.175
-2022-09-18,0.1,2021-09-18,0.18,2020-09-18,0.17,2019-09-18,0.09,2018-09-18,0.17,0.1525
-2022-09-19,0.08,2021-09-19,0.18,2020-09-19,0.17,2019-09-19,0.18,2018-09-19,0.19,0.18
-2022-09-20,0.13,2021-09-20,0.19,2020-09-20,0.17,2019-09-20,0.19,2018-09-20,0.19,0.185
-2022-09-21,0.15,2021-09-21,0.17,2020-09-21,0.18,2019-09-21,0.19,2018-09-21,0.19,0.1825
-2022-09-22,0.18,2021-09-22,0.2,2020-09-22,0.19,2019-09-22,0.16,2018-09-22,0.19,0.185
-2022-09-23,0.17,2021-09-23,0.19,2020-09-23,0.19,2019-09-23,0.2,2018-09-23,0.19,0.1925
-2022-09-24,0.19,2021-09-24,0.17,2020-09-24,0.19,2019-09-24,0.2,2018-09-24,0.18,0.185
-2022-09-25,0.18,2021-09-25,0.15,2020-09-25,0.17,2019-09-25,0.18,2018-09-25,0.18,0.16999999999999998
-2022-09-26,0.17,2021-09-26,0.16,2020-09-26,0.19,2019-09-26,0.18,2018-09-26,0.18,0.1775
-2022-09-27,0.16,2021-09-27,0.17,2020-09-27,0.18,2019-09-27,0.15,2018-09-27,0.17,0.1675
-2022-09-28,0.18,2021-09-28,0.22,2020-09-28,0.18,2019-09-28,0.16,2018-09-28,0.16,0.18
-2022-09-29,0.16,2021-09-29,0.18,2020-09-29,0.16,2019-09-29,0.14,2018-09-29,0.13,0.1525
-2022-09-30,0.17,2021-09-30,0.15,2020-09-30,0.18,2019-09-30,0.14,2018-09-30,0.14,0.1525
-2022-10-01,0.16,2021-10-01,0.16,2020-10-01,0.14,2019-10-01,0.16,2018-10-01,0.12,0.14500000000000002
-2022-10-02,0.15,2021-10-02,0.15,2020-10-02,0.13,2019-10-02,0.16,2018-10-02,0.13,0.14250000000000002
-2022-10-03,0.16,2021-10-03,0.13,2020-10-03,0.13,2019-10-03,0.16,2018-10-03,0.09,0.1275
-2022-10-04,0.15,2021-10-04,0.14,2020-10-04,0.17,2019-10-04,0.17,2018-10-04,0.11,0.14750000000000002
-2022-10-05,0.15,2021-10-05,0.14,2020-10-05,0.16,2019-10-05,0.16,2018-10-05,0.14,0.15000000000000002
-2022-10-06,0.16,2021-10-06,0.13,2020-10-06,0.14,2019-10-06,0.15,2018-10-06,0.17,0.14750000000000002
-2022-10-07,0.17,2021-10-07,0.13,2020-10-07,0.13,2019-10-07,0.15,2018-10-07,0.25,0.165
-2022-10-08,0.16,2021-10-08,0.15,2020-10-08,0.08,2019-10-08,0.15,2018-10-08,0.16,0.135
-2022-10-09,0.15,2021-10-09,0.14,2020-10-09,0.1,2019-10-09,0.21,2018-10-09,0.15,0.15
-2022-10-10,0.15,2021-10-10,0.14,2020-10-10,0.1,2019-10-10,0.19,2018-10-10,0.13,0.14
-2022-10-11,0.15,2021-10-11,0.25,2020-10-11,0.15,2019-10-11,0.13,2018-10-11,0.13,0.165
-2022-10-12,0.14,2021-10-12,0.21,2020-10-12,0.15,2019-10-12,0.13,2018-10-12,0.16,0.1625
-2022-10-13,0.13,2021-10-13,0.12,2020-10-13,0.15,2019-10-13,0.14,2018-10-13,0.15,0.14
-2022-10-14,0.12,2021-10-14,0.16,2020-10-14,0.2,2019-10-14,0.14,2018-10-14,0.18,0.17
-2022-10-15,0.13,2021-10-15,0.13,2020-10-15,0.16,2019-10-15,0.13,2018-10-15,0.16,0.14500000000000002
-2022-10-16,0.11,2021-10-16,0.13,2020-10-16,0.15,2019-10-16,0.11,2018-10-16,0.14,0.1325
-2022-10-17,0.11,2021-10-17,0.12,2020-10-17,0.13,2019-10-17,0.15,2018-10-17,0.12,0.13
-2022-10-18,0.09,2021-10-18,0.08,2020-10-18,0.14,2019-10-18,0.12,2018-10-18,0.12,0.115
-2022-10-19,0.13,2021-10-19,0.1,2020-10-19,0.14,2019-10-19,0.11,2018-10-19,0.13,0.12000000000000001
-2022-10-20,0.12,2021-10-20,0.06,2020-10-20,0.13,2019-10-20,0.14,2018-10-20,0.12,0.1125
-2022-10-21,0.12,2021-10-21,0.07,2020-10-21,0.13,2019-10-21,0.16,2018-10-21,0.13,0.1225
-2022-10-22,0.13,2021-10-22,0.05,2020-10-22,0.15,2019-10-22,0.13,2018-10-22,0.12,0.1125
-2022-10-23,0.16,2021-10-23,0.08,2020-10-23,0.13,2019-10-23,0.15,2018-10-23,0.09,0.1125
-2022-10-24,0.12,2021-10-24,0.02,2020-10-24,0.1,2019-10-24,0.14,2018-10-24,0.11,0.0925
-2022-10-25,0.11,2021-10-25,0.08,2020-10-25,0.13,2019-10-25,0.12,2018-10-25,0.12,0.1125
-2022-10-26,0.12,2021-10-26,0.08,2020-10-26,0.19,2019-10-26,0.12,2018-10-26,0.1,0.1225
-2022-10-27,0.1,2021-10-27,0.09,2020-10-27,0.1,2019-10-27,0.27,2018-10-27,0.11,0.14250000000000002
-2022-10-28,0.09,2021-10-28,0.09,2020-10-28,0.09,2019-10-28,0.11,2018-10-28,0.12,0.1025
-2022-10-29,0.11,2021-10-29,0.07,2020-10-29,0.09,2019-10-29,0.14,2018-10-29,0.12,0.10500000000000001
-2022-10-30,0.11,2021-10-30,0.08,2020-10-30,0.1,2019-10-30,0.1,2018-10-30,0.15,0.1075
-2022-10-31,0.05,2021-10-31,0.08,2020-10-31,0.1,2019-10-31,0.1,2018-10-31,0.11,0.0975
-2022-11-01,0.05,2021-11-01,0.01,2020-11-01,0.09,2019-11-01,0.1,2018-11-01,0.1,0.075
-2022-11-02,0.05,2021-11-02,0.05,2020-11-02,0.1,2019-11-02,0.1,2018-11-02,0.11,0.09
-2022-11-03,0.11,2021-11-03,0.09,2020-11-03,0.1,2019-11-03,0.09,2018-11-03,0.11,0.0975
-2022-11-04,0.07,2021-11-04,0.09,2020-11-04,0.11,2019-11-04,0.09,2018-11-04,0.11,0.1
-2022-11-05,0.03,2021-11-05,0.08,2020-11-05,0.1,2019-11-05,0.1,2018-11-05,0.14,0.10500000000000001
-2022-11-06,0.09,2021-11-06,0.06,2020-11-06,0.1,2019-11-06,0.09,2018-11-06,0.12,0.0925
-2022-11-07,0.08,2021-11-07,0.1,2020-11-07,0.07,2019-11-07,0.09,2018-11-07,0.11,0.0925
-2022-11-08,0.03,2021-11-08,0.07,2020-11-08,0.12,2019-11-08,0.09,2018-11-08,0.14,0.10500000000000001
-2022-11-09,0.06,2021-11-09,0.05,2020-11-09,0.09,2019-11-09,0.09,2018-11-09,0.09,0.08
-2022-11-10,0.08,2021-11-10,0.05,2020-11-10,0.08,2019-11-10,0.09,2018-11-10,0.05,0.0675
-2022-11-11,0.06,2021-11-11,0.08,2020-11-11,0.04,2019-11-11,0.08,2018-11-11,0.08,0.07
-2022-11-12,0.07,2021-11-12,0.02,2020-11-12,0.06,2019-11-12,0.08,2018-11-12,0.07,0.0575
-2022-11-13,0.1,2021-11-13,0.01,2020-11-13,0.03,2019-11-13,0.06,2018-11-13,0.05,0.0375
-2022-11-14,0.06,2021-11-14,0.0,2020-11-14,0.04,2019-11-14,0.07,2018-11-14,0.06,0.0425
-2022-11-15,0.09,2021-11-15,0.0,2020-11-15,0.07,2019-11-15,0.08,2018-11-15,0.04,0.0475
-2022-11-16,0.07,2021-11-16,0.01,2020-11-16,0.07,2019-11-16,0.07,2018-11-16,0.05,0.05
-2022-11-17,0.06,2021-11-17,0.02,2020-11-17,0.04,2019-11-17,0.07,2018-11-17,0.06,0.0475
-2022-11-18,0.09,2021-11-18,0.02,2020-11-18,0.05,2019-11-18,0.07,2018-11-18,0.06,0.05
-2022-11-19,0.07,2021-11-19,0.04,2020-11-19,0.07,2019-11-19,0.09,2018-11-19,0.05,0.0625
-2022-11-20,0.07,2021-11-20,0.07,2020-11-20,0.07,2019-11-20,0.13,2018-11-20,0.05,0.08
-2022-11-21,0.06,2021-11-21,0.05,2020-11-21,0.06,2019-11-21,0.06,2018-11-21,0.02,0.0475
-2022-11-22,0.06,2021-11-22,0.05,2020-11-22,0.07,2019-11-22,0.07,2018-11-22,0.06,0.0625
-2022-11-23,0.08,2021-11-23,0.04,2020-11-23,0.07,2019-11-23,0.08,2018-11-23,0.01,0.05
-2022-11-24,0.06,2021-11-24,0.07,2020-11-24,0.08,2019-11-24,0.07,2018-11-24,0.05,0.0675
-2022-11-25,0.05,2021-11-25,0.05,2020-11-25,0.09,2019-11-25,0.14,2018-11-25,0.07,0.08750000000000001
-2022-11-26,0.07,2021-11-26,0.06,2020-11-26,0.13,2019-11-26,0.04,2018-11-26,0.04,0.0675
-2022-11-27,0.06,2021-11-27,0.06,2020-11-27,0.06,2019-11-27,0.04,2018-11-27,0.01,0.042499999999999996
-2022-11-28,0.09,2021-11-28,0.06,2020-11-28,0.07,2019-11-28,0.02,2018-11-28,0.02,0.0425
-2022-11-29,0.07,2021-11-29,0.05,2020-11-29,0.06,2019-11-29,0.05,2018-11-29,0.01,0.0425
-2022-11-30,0.06,2021-11-30,0.06,2020-11-30,0.07,2019-11-30,0.02,2018-11-30,0.06,0.0525
-2022-12-01,0.01,2021-12-01,0.05,2020-12-01,0.07,2019-12-01,0.01,2018-12-01,0.04,0.0425
-2022-12-02,0.04,2021-12-02,0.04,2020-12-02,0.06,2019-12-02,0.0,2018-12-02,0.06,0.04
-2022-12-03,0.0,2021-12-03,0.03,2020-12-03,0.05,2019-12-03,0.0,2018-12-03,0.04,0.03
-2022-12-04,0.05,2021-12-04,0.01,2020-12-04,0.06,2019-12-04,0.02,2018-12-04,0.01,0.025
-2022-12-05,0.05,2021-12-05,0.02,2020-12-05,0.06,2019-12-05,0.02,2018-12-05,0.04,0.035
-2022-12-06,0.02,2021-12-06,0.0,2020-12-06,0.07,2019-12-06,0.08,2018-12-06,0.06,0.052500000000000005
-2022-12-07,0.05,2021-12-07,0.01,2020-12-07,0.1,2019-12-07,0.05,2018-12-07,0.05,0.052500000000000005
-2022-12-08,0.02,2021-12-08,0.01,2020-12-08,0.07,2019-12-08,0.04,2018-12-08,0.01,0.0325
-2022-12-09,0.03,2021-12-09,0.04,2020-12-09,0.07,2019-12-09,0.04,2018-12-09,0.0,0.037500000000000006
-2022-12-10,0.01,2021-12-10,0.06,2020-12-10,0.08,2019-12-10,0.01,2018-12-10,0.02,0.0425
-2022-12-11,0.05,2021-12-11,0.05,2020-12-11,0.03,2019-12-11,0.01,2018-12-11,0.04,0.0325
-2022-12-12,0.05,2021-12-12,0.0,2020-12-12,0.0,2019-12-12,0.02,2018-12-12,0.06,0.02
-2022-12-13,0.06,2021-12-13,0.0,2020-12-13,0.01,2019-12-13,0.0,2018-12-13,0.05,0.015000000000000001
-2022-12-14,0.03,2021-12-14,0.04,2020-12-14,0.06,2019-12-14,0.06,2018-12-14,0.02,0.045
-2022-12-15,0.04,2021-12-15,0.04,2020-12-15,0.04,2019-12-15,0.06,2018-12-15,0.03,0.042499999999999996
-2022-12-16,0.02,2021-12-16,0.04,2020-12-16,0.03,2019-12-16,0.05,2018-12-16,0.01,0.0325
-2022-12-17,0.03,2021-12-17,0.04,2020-12-17,0.05,2019-12-17,0.04,2018-12-17,0.05,0.045
-2022-12-18,0.0,2021-12-18,0.01,2020-12-18,0.05,2019-12-18,0.03,2018-12-18,0.05,0.035
-2022-12-19,0.0,2021-12-19,0.0,2020-12-19,0.03,2019-12-19,0.03,2018-12-19,0.02,0.02
-2022-12-20,0.03,2021-12-20,0.01,2020-12-20,0.04,2019-12-20,0.04,2018-12-20,0.0,0.0225
-2022-12-21,0.0,2021-12-21,0.01,2020-12-21,0.0,2019-12-21,0.02,2018-12-21,0.02,0.0125
-2022-12-22,0.0,2021-12-22,0.03,2020-12-22,0.02,2019-12-22,0.03,2018-12-22,0.04,0.03
-2022-12-23,0.02,2021-12-23,0.01,2020-12-23,0.03,2019-12-23,0.04,2018-12-23,0.03,0.0275
-2022-12-24,0.03,2021-12-24,0.05,2020-12-24,0.01,2019-12-24,0.04,2018-12-24,0.01,0.0275
-2022-12-25,0.0,2021-12-25,0.01,2020-12-25,0.03,2019-12-25,0.04,2018-12-25,0.07,0.0375
-2022-12-26,0.0,2021-12-26,0.01,2020-12-26,0.04,2019-12-26,0.07,2018-12-26,0.06,0.045
-2022-12-27,0.0,2021-12-27,0.02,2020-12-27,0.05,2019-12-27,0.06,2018-12-27,0.09,0.055
-2022-12-28,0.04,2021-12-28,0.04,2020-12-28,0.03,2019-12-28,0.05,2018-12-28,0.08,0.05
-2022-12-29,0.0,2021-12-29,0.02,2020-12-29,0.06,2019-12-29,0.02,2018-12-29,0.05,0.0375
-2022-12-30,0.0,2021-12-30,0.05,2020-12-30,0.05,2019-12-30,0.06,2018-12-30,0.05,0.052500000000000005
-2022-12-31,0.0,2021-12-31,0.03,2020-12-31,0.05,2019-12-31,0.04,2018-12-31,0.11,0.0575
+Year_1,Year_1_ET,Year_2,Year_2_ET,Year_3,Year_3_ET,Year_4,Year_4_ET,Year_5,Year_5_ET
+2023-01-01,0.08,2022-01-01,0.04,2021-01-01,0.05,2020-01-01,0.05,2019-01-01,0.07
+2023-01-02,0.01,2022-01-02,0.05,2021-01-02,0.05,2020-01-02,0.06,2019-01-02,0.06
+2023-01-03,0.03,2022-01-03,0.04,2021-01-03,0.05,2020-01-03,0.06,2019-01-03,0.06
+2023-01-04,0.04,2022-01-04,0.05,2021-01-04,0.05,2020-01-04,0.06,2019-01-04,0.07
+2023-01-05,0.03,2022-01-05,0.03,2021-01-05,0.07,2020-01-05,0.07,2019-01-05,0.04
+2023-01-06,0.05,2022-01-06,0.04,2021-01-06,0.05,2020-01-06,0.03,2019-01-06,0.02
+2023-01-07,0.04,2022-01-07,0.03,2021-01-07,0.03,2020-01-07,0.02,2019-01-07,0.06
+2023-01-08,0.04,2022-01-08,0.06,2021-01-08,0.05,2020-01-08,0.03,2019-01-08,0.05
+2023-01-09,0,2022-01-09,0.04,2021-01-09,0.07,2020-01-09,0.02,2019-01-09,0.02
+2023-01-10,0.07,2022-01-10,0.04,2021-01-10,0.06,2020-01-10,0.05,2019-01-10,0.04
+2023-01-11,0.01,2022-01-11,0.06,2021-01-11,0.06,2020-01-11,0.06,2019-01-11,0.02
+2023-01-12,0.06,2022-01-12,0.05,2021-01-12,0.03,2020-01-12,0.06,2019-01-12,0.06
+2023-01-13,0.04,2022-01-13,0.04,2021-01-13,0.07,2020-01-13,0.06,2019-01-13,0.06
+2023-01-14,0,2022-01-14,0.03,2021-01-14,0.07,2020-01-14,0.04,2019-01-14,0.01
+2023-01-15,0.01,2022-01-15,0.01,2021-01-15,0.08,2020-01-15,0.06,2019-01-15,0.02
+2023-01-16,0.03,2022-01-16,0.05,2021-01-16,0.08,2020-01-16,0.06,2019-01-16,0.05
+2023-01-17,0.04,2022-01-17,0.04,2021-01-17,0.08,2020-01-17,0.04,2019-01-17,0.04
+2023-01-18,0.04,2022-01-18,0.07,2021-01-18,0.13,2020-01-18,0.03,2019-01-18,0.07
+2023-01-19,0.04,2022-01-19,0.07,2021-01-19,0.15,2020-01-19,0.01,2019-01-19,0.07
+2023-01-20,0.05,2022-01-20,0.07,2021-01-20,0.13,2020-01-20,0.02,2019-01-20,0.05
+2023-01-21,0.05,2022-01-21,0.09,2021-01-21,0.09,2020-01-21,0.05,2019-01-21,0.08
+2023-01-22,0.07,2022-01-22,0.08,2021-01-22,0.04,2020-01-22,0.06,2019-01-22,0.08
+2023-01-23,0.07,2022-01-23,0.07,2021-01-23,0.03,2020-01-23,0.05,2019-01-23,0.07
+2023-01-24,0.06,2022-01-24,0.08,2021-01-24,0.06,2020-01-24,0.05,2019-01-24,0.07
+2023-01-25,0.06,2022-01-25,0.08,2021-01-25,0.06,2020-01-25,0.05,2019-01-25,0.08
+2023-01-26,0.06,2022-01-26,0.08,2021-01-26,0.09,2020-01-26,0.06,2019-01-26,0.07
+2023-01-27,0.05,2022-01-27,0.08,2021-01-27,0.03,2020-01-27,0.08,2019-01-27,0.08
+2023-01-28,0.06,2022-01-28,0.09,2021-01-28,0,2020-01-28,0.08,2019-01-28,0.06
+2023-01-29,0.03,2022-01-29,0.07,2021-01-29,0.06,2020-01-29,0.06,2019-01-29,0.04
+2023-01-30,0.08,2022-01-30,0.09,2021-01-30,0.06,2020-01-30,0.06,2019-01-30,0.08
+2023-01-31,0.06,2022-01-31,0.05,2021-01-31,0.06,2020-01-31,0.07,2019-01-31,0.08
+2023-02-01,0.06,2022-02-01,0.12,2021-02-01,0.11,2020-02-01,0.08,2019-02-01,0.03
+2023-02-02,0.05,2022-02-02,0.12,2021-02-02,0.09,2020-02-02,0.12,2019-02-02,0.06
+2023-02-03,0.07,2022-02-03,0.09,2021-02-03,0.09,2020-02-03,0.15,2019-02-03,0.06
+2023-02-04,0.07,2022-02-04,0.09,2021-02-04,0.09,2020-02-04,0.1,2019-02-04,0.09
+2023-02-05,0.07,2022-02-05,0.09,2021-02-05,0.08,2020-02-05,0.09,2019-02-05,0.07
+2023-02-06,0.07,2022-02-06,0.09,2021-02-06,0.08,2020-02-06,0.09,2019-02-06,0.08
+2023-02-07,0.07,2022-02-07,0.1,2021-02-07,0.08,2020-02-07,0.09,2019-02-07,0.08
+2023-02-08,0.07,2022-02-08,0.1,2021-02-08,0.08,2020-02-08,0.1,2019-02-08,0.1
+2023-02-09,0.08,2022-02-09,0.1,2021-02-09,0.07,2020-02-09,0.11,2019-02-09,0.08
+2023-02-10,0.1,2022-02-10,0.11,2021-02-10,0.09,2020-02-10,0.12,2019-02-10,0.06
+2023-02-11,0.07,2022-02-11,0.12,2021-02-11,0.06,2020-02-11,0.11,2019-02-11,0.08
+2023-02-12,0.1,2022-02-12,0.13,2021-02-12,0.11,2020-02-12,0.1,2019-02-12,0.04
+2023-02-13,0.09,2022-02-13,0.12,2021-02-13,0.08,2020-02-13,0.11,2019-02-13,0.02
+2023-02-14,0.14,2022-02-14,0.13,2021-02-14,0.11,2020-02-14,0.1,2019-02-14,0.12
+2023-02-15,0.11,2022-02-15,0.13,2021-02-15,0.08,2020-02-15,0.1,2019-02-15,0.08
+2023-02-16,0.09,2022-02-16,0.14,2021-02-16,0.13,2020-02-16,0.12,2019-02-16,0.08
+2023-02-17,0.09,2022-02-17,0.12,2021-02-17,0.15,2020-02-17,0.14,2019-02-17,0.06
+2023-02-18,0.1,2022-02-18,0.11,2021-02-18,0.11,2020-02-18,0.14,2019-02-18,0.11
+2023-02-19,0.1,2022-02-19,0.13,2021-02-19,0.11,2020-02-19,0.12,2019-02-19,0.11
+2023-02-20,0.1,2022-02-20,0.12,2021-02-20,0.14,2020-02-20,0.13,2019-02-20,0.06
+2023-02-21,0.14,2022-02-21,0.13,2021-02-21,0.13,2020-02-21,0.13,2019-02-21,0.07
+2023-02-22,0.07,2022-02-22,0.07,2021-02-22,0.12,2020-02-22,0.04,2019-02-22,0.11
+2023-02-23,0.08,2022-02-23,0.14,2021-02-23,0.12,2020-02-23,0.11,2019-02-23,0.1
+2023-02-24,0.01,2022-02-24,0.13,2021-02-24,0.2,2020-02-24,0.14,2019-02-24,0.11
+2023-02-25,0.03,2022-02-25,0.12,2021-02-25,0.16,2020-02-25,0.14,2019-02-25,0.16
+2023-02-26,0.06,2022-02-26,0.1,2021-02-26,0.14,2020-02-26,0.15,2019-02-26,0.09
+2023-02-27,0.06,2022-02-27,0.13,2021-02-27,0.2,2020-02-27,0.14,2019-02-27,0.07
+2023-02-28,0.04,2022-02-28,0.15,2021-02-28,0.14,2020-02-28,0.14,2019-02-28,0.1
+2023-03-01,0.13,2022-03-01,0.13,2021-03-01,0.17,2020-02-29,0.18,2019-03-01,0.05
+2023-03-02,0.11,2022-03-02,0.15,2021-03-02,0.15,2020-03-01,0.11,2019-03-02,0.12
+2023-03-03,0.1,2022-03-03,0.12,2021-03-03,0.12,2020-03-02,0.16,2019-03-03,0.11
+2023-03-04,0.09,2022-03-04,0.06,2021-03-04,0.13,2020-03-03,0.14,2019-03-04,0.07
+2023-03-05,0.06,2022-03-05,0.1,2021-03-05,0.14,2020-03-04,0.14,2019-03-05,0.02
+2023-03-06,0.07,2022-03-06,0.13,2021-03-06,0.16,2020-03-05,0.15,2019-03-06,0.09
+2023-03-07,0.09,2022-03-07,0.14,2021-03-07,0.12,2020-03-06,0.16,2019-03-07,0.08
+2023-03-08,0.08,2022-03-08,0.15,2021-03-08,0.14,2020-03-07,0.09,2019-03-08,0.13
+2023-03-09,0.05,2022-03-09,0.16,2021-03-09,0.11,2020-03-08,0.12,2019-03-09,0.12
+2023-03-10,0.02,2022-03-10,0.22,2021-03-10,0.08,2020-03-09,0.11,2019-03-10,0.12
+2023-03-11,0.1,2022-03-11,0.15,2021-03-11,0.08,2020-03-10,0.07,2019-03-11,0.17
+2023-03-12,0.11,2022-03-12,0.17,2021-03-12,0.12,2020-03-11,0.12,2019-03-12,0.19
+2023-03-13,0.11,2022-03-13,0.18,2021-03-13,0.15,2020-03-12,0.14,2019-03-13,0.21
+2023-03-14,0.02,2022-03-14,0.15,2021-03-14,0.11,2020-03-13,0.18,2019-03-14,0.15
+2023-03-15,0.13,2022-03-15,0.13,2021-03-15,0.08,2020-03-14,0.18,2019-03-15,0.16
+2023-03-16,0.13,2022-03-16,0.19,2021-03-16,0.13,2020-03-15,0.13,2019-03-16,0.17
+2023-03-17,0.13,2022-03-17,0.15,2021-03-17,0.14,2020-03-16,0,2019-03-17,0.17
+2023-03-18,0.11,2022-03-18,0.17,2021-03-18,0.14,2020-03-17,0.05,2019-03-18,0.18
+2023-03-19,0.06,2022-03-19,0.09,2021-03-19,0.05,2020-03-18,0.08,2019-03-19,0.18
+2023-03-20,0.1,2022-03-20,0.19,2021-03-20,0.16,2020-03-19,0.08,2019-03-20,0.07
+2023-03-21,0.09,2022-03-21,0.2,2021-03-21,0.18,2020-03-20,0.14,2019-03-21,0.14
+2023-03-22,0.05,2022-03-22,0.18,2021-03-22,0.16,2020-03-21,0.06,2019-03-22,0.14
+2023-03-23,0.08,2022-03-23,0.19,2021-03-23,0.25,2020-03-22,0.09,2019-03-23,0.08
+2023-03-24,0.17,2022-03-24,0.2,2021-03-24,0.16,2020-03-23,0.12,2019-03-24,0.15
+2023-03-25,0.17,2022-03-25,0.2,2021-03-25,0.14,2020-03-24,0.07,2019-03-25,0.21
+2023-03-26,0.17,2022-03-26,0.21,2021-03-26,0.19,2020-03-25,0.09,2019-03-26,0.17
+2023-03-27,0.15,2022-03-27,0.25,2021-03-27,0.18,2020-03-26,0.13,2019-03-27,0.13
+2023-03-28,0.08,2022-03-28,0.07,2021-03-28,0.2,2020-03-27,0.14,2019-03-28,0.19
+2023-03-29,0.09,2022-03-29,0.13,2021-03-29,0.24,2020-03-28,0.1,2019-03-29,0.21
+2023-03-30,0.07,2022-03-30,0.13,2021-03-30,0.26,2020-03-29,0.11,2019-03-30,0.21
+2023-03-31,0.11,2022-03-31,0.13,2021-03-31,0.2,2020-03-30,0.16,2019-03-31,0.2
+2023-04-01,0.15,2022-04-01,0.16,2021-04-01,0.2,2020-03-31,0.18,2019-04-01,0.19
+2023-04-02,0.14,2022-04-02,0.19,2021-04-02,0.22,2020-04-01,0.19,2019-04-02,0.17
+2023-04-03,0.21,2022-04-03,0.23,2021-04-03,0.21,2020-04-02,0.22,2019-04-03,0.16
+2023-04-04,0.18,2022-04-04,0.22,2021-04-04,0.18,2020-04-03,0.18,2019-04-04,0.13
+2023-04-05,0.16,2022-04-05,0.23,2021-04-05,0.2,2020-04-04,0.16,2019-04-05,0.12
+2023-04-06,0.17,2022-04-06,0.22,2021-04-06,0.19,2020-04-05,0.12,2019-04-06,0.18
+2023-04-07,0.1,2022-04-07,0.23,2021-04-07,0.21,2020-04-06,0.14,2019-04-07,0.2
+2023-04-08,0.14,2022-04-08,0.26,2021-04-08,0.23,2020-04-07,0.16,2019-04-08,0.19
+2023-04-09,0.19,2022-04-09,0.35,2021-04-09,0.22,2020-04-08,0.11,2019-04-09,0.31
+2023-04-10,0.21,2022-04-10,0.3,2021-04-10,0.22,2020-04-09,0.11,2019-04-10,0.31
+2023-04-11,0.18,2022-04-11,0.15,2021-04-11,0.22,2020-04-10,0.16,2019-04-11,0.23
+2023-04-12,0.19,2022-04-12,0.24,2021-04-12,0.23,2020-04-11,0.15,2019-04-12,0.25
+2023-04-13,0.23,2022-04-13,0.2,2021-04-13,0.27,2020-04-12,0.17,2019-04-13,0.23
+2023-04-14,0.18,2022-04-14,0.18,2021-04-14,0.2,2020-04-13,0.19,2019-04-14,0.24
+2023-04-15,0.2,2022-04-15,0.19,2021-04-15,0.23,2020-04-14,0.24,2019-04-15,0.23
+2023-04-16,0.21,2022-04-16,0.17,2021-04-16,0.26,2020-04-15,0.22,2019-04-16,0.15
+2023-04-17,0.18,2022-04-17,0.22,2021-04-17,0.25,2020-04-16,0.22,2019-04-17,0.21
+2023-04-18,0.16,2022-04-18,0.22,2021-04-18,0.27,2020-04-17,0.14,2019-04-18,0.22
+2023-04-19,0.22,2022-04-19,0.18,2021-04-19,0.26,2020-04-18,0.1,2019-04-19,0.23
+2023-04-20,0.24,2022-04-20,0.21,2021-04-20,0.24,2020-04-19,0.18,2019-04-20,0.22
+2023-04-21,0.24,2022-04-21,0.12,2021-04-21,0.22,2020-04-20,0.1,2019-04-21,0.22
+2023-04-22,0.25,2022-04-22,0.18,2021-04-22,0.24,2020-04-21,0.21,2019-04-22,0.27
+2023-04-23,0.24,2022-04-23,0.23,2021-04-23,0.22,2020-04-22,0.23,2019-04-23,0.26
+2023-04-24,0.25,2022-04-24,0.23,2021-04-24,0.23,2020-04-23,0.29,2019-04-24,0.27
+2023-04-25,0.25,2022-04-25,0.25,2021-04-25,0.09,2020-04-24,0.29,2019-04-25,0.27
+2023-04-26,0.24,2022-04-26,0.22,2021-04-26,0.21,2020-04-25,0.29,2019-04-26,0.28
+2023-04-27,0.23,2022-04-27,0.22,2021-04-27,0.24,2020-04-26,0.28,2019-04-27,0.25
+2023-04-28,0.25,2022-04-28,0.28,2021-04-28,0.25,2020-04-27,0.29,2019-04-28,0.25
+2023-04-29,0.24,2022-04-29,0.26,2021-04-29,0.26,2020-04-28,0.28,2019-04-29,0.24
+2023-04-30,0.29,2022-04-30,0.27,2021-04-30,0.29,2020-04-29,0.26,2019-04-30,0.2
+2023-05-01,0.16,2022-05-01,0.27,2021-05-01,0.32,2020-04-30,0.34,2019-05-01,0.22
+2023-05-02,0.15,2022-05-02,0.27,2021-05-02,0.33,2020-05-01,0.3,2019-05-02,0.24
+2023-05-03,0.09,2022-05-03,0.3,2021-05-03,0.33,2020-05-02,0.27,2019-05-03,0.26
+2023-05-04,0.09,2022-05-04,0.24,2021-05-04,0.3,2020-05-03,0.26,2019-05-04,0.27
+2023-05-05,0.06,2022-05-05,0.3,2021-05-05,0.27,2020-05-04,0.29,2019-05-05,0.24
+2023-05-06,0.08,2022-05-06,0.26,2021-05-06,0.33,2020-05-05,0.31,2019-05-06,0.19
+2023-05-07,0.11,2022-05-07,0.27,2021-05-07,0.28,2020-05-06,0.32,2019-05-07,0.22
+2023-05-08,0.12,2022-05-08,0.31,2021-05-08,0.34,2020-05-07,0.3,2019-05-08,0.23
+2023-05-09,0.09,2022-05-09,0.2,2021-05-09,0.34,2020-05-08,0.28,2019-05-09,0.25
+2023-05-10,0.1,2022-05-10,0.22,2021-05-10,0.32,2020-05-09,0.28,2019-05-10,0.13
+2023-05-11,0.12,2022-05-11,0.27,2021-05-11,0.29,2020-05-10,0.28,2019-05-11,0.23
+2023-05-12,0.12,2022-05-12,0.25,2021-05-12,0.3,2020-05-11,0.29,2019-05-12,0.27
+2023-05-13,0.11,2022-05-13,0.28,2021-05-13,0.31,2020-05-12,0.23,2019-05-13,0.3
+2023-05-14,0.16,2022-05-14,0.31,2021-05-14,0.28,2020-05-13,0.26,2019-05-14,0.27
+2023-05-15,0.26,2022-05-15,0.32,2021-05-15,0.24,2020-05-14,0.29,2019-05-15,0.12
+2023-05-16,0.34,2022-05-16,0.31,2021-05-16,0.24,2020-05-15,0.28,2019-05-16,0.14
+2023-05-17,0.33,2022-05-17,0.29,2021-05-17,0.27,2020-05-16,0.27,2019-05-17,0.23
+2023-05-18,0.32,2022-05-18,0.32,2021-05-18,0.31,2020-05-17,0.24,2019-05-18,0.1
+2023-05-19,0.29,2022-05-19,0.39,2021-05-19,0.3,2020-05-18,0.25,2019-05-19,0.13
+2023-05-20,0.28,2022-05-20,0.37,2021-05-20,0.34,2020-05-19,0.21,2019-05-20,0.19
+2023-05-21,0.27,2022-05-21,0.28,2021-05-21,0.28,2020-05-20,0.25,2019-05-21,0.2
+2023-05-22,0.28,2022-05-22,0.3,2021-05-22,0.26,2020-05-21,0.28,2019-05-22,0.16
+2023-05-23,0.26,2022-05-23,0.34,2021-05-23,0.27,2020-05-22,0.31,2019-05-23,0.15
+2023-05-24,0.23,2022-05-24,0.32,2021-05-24,0.29,2020-05-23,0.3,2019-05-24,0.22
+2023-05-25,0.24,2022-05-25,0.29,2021-05-25,0.33,2020-05-24,0.29,2019-05-25,0.27
+2023-05-26,0.24,2022-05-26,0.3,2021-05-26,0.29,2020-05-25,0.28,2019-05-26,0.09
+2023-05-27,0.26,2022-05-27,0.26,2021-05-27,0.31,2020-05-26,0.3,2019-05-27,0.17
+2023-05-28,0.26,2022-05-28,0.31,2021-05-28,0.28,2020-05-27,0.32,2019-05-28,0.19
+2023-05-29,0.24,2022-05-29,0.33,2021-05-29,0.28,2020-05-28,0.32,2019-05-29,0.25
+2023-05-30,0.22,2022-05-30,0.32,2021-05-30,0.28,2020-05-29,0.32,2019-05-30,0.26
+2023-05-31,0.24,2022-05-31,0.31,2021-05-31,0.3,2020-05-30,0.24,2019-05-31,0.3
+2023-06-01,0.25,2022-06-01,0.31,2021-06-01,0.32,2020-05-31,0.17,2019-06-01,0.29
+2023-06-02,0.26,2022-06-02,0.33,2021-06-02,0.32,2020-06-01,0.22,2019-06-02,0.28
+2023-06-03,0.27,2022-06-03,0.31,2021-06-03,0.31,2020-06-02,0.29,2019-06-03,0.29
+2023-06-04,0.3,2022-06-04,0.29,2021-06-04,0.31,2020-06-03,0.32,2019-06-04,0.31
+2023-06-05,0.21,2022-06-05,0.29,2021-06-05,0.31,2020-06-04,0.34,2019-06-05,0.31
+2023-06-06,0.22,2022-06-06,0.33,2021-06-06,0.3,2020-06-05,0.28,2019-06-06,0.37
+2023-06-07,0.17,2022-06-07,0.31,2021-06-07,0.25,2020-06-06,0.27,2019-06-07,0.34
+2023-06-08,0.17,2022-06-08,0.31,2021-06-08,0.27,2020-06-07,0.32,2019-06-08,0.34
+2023-06-09,0.25,2022-06-09,0.29,2021-06-09,0.28,2020-06-08,0.3,2019-06-09,0.31
+2023-06-10,0.22,2022-06-10,0.35,2021-06-10,0.29,2020-06-09,0.29,2019-06-10,0.29
+2023-06-11,0.18,2022-06-11,0.37,2021-06-11,0.29,2020-06-10,0.31,2019-06-11,0.27
+2023-06-12,0.22,2022-06-12,0.31,2021-06-12,0.29,2020-06-11,0.31,2019-06-12,0.3
+2023-06-13,0.26,2022-06-13,0.36,2021-06-13,0.3,2020-06-12,0.29,2019-06-13,0.32
+2023-06-14,0.26,2022-06-14,0.35,2021-06-14,0.3,2020-06-13,0.28,2019-06-14,0.3
+2023-06-15,0.27,2022-06-15,0.35,2021-06-15,0.36,2020-06-14,0.28,2019-06-15,0.29
+2023-06-16,0.27,2022-06-16,0.33,2021-06-16,0.31,2020-06-15,0.29,2019-06-16,0.26
+2023-06-17,0.27,2022-06-17,0.23,2021-06-17,0.32,2020-06-16,0.3,2019-06-17,0.28
+2023-06-18,0.29,2022-06-18,0.28,2021-06-18,0.31,2020-06-17,0.33,2019-06-18,0.3
+2023-06-19,0.29,2022-06-19,0.32,2021-06-19,0.33,2020-06-18,0.3,2019-06-19,0.31
+2023-06-20,0.3,2022-06-20,0.32,2021-06-20,0.32,2020-06-19,0.31,2019-06-20,0.28
+2023-06-21,0.26,2022-06-21,0.33,2021-06-21,0.32,2020-06-20,0.31,2019-06-21,0.31
+2023-06-22,0.24,2022-06-22,0.28,2021-06-22,0.3,2020-06-21,0.31,2019-06-22,0.31
+2023-06-23,0.23,2022-06-23,0.31,2021-06-23,0.3,2020-06-22,0.29,2019-06-23,0.31
+2023-06-24,0.23,2022-06-24,0.33,2021-06-24,0.28,2020-06-23,0.31,2019-06-24,0.31
+2023-06-25,0.28,2022-06-25,0.34,2021-06-25,0.29,2020-06-24,0.28,2019-06-25,0.32
+2023-06-26,0.25,2022-06-26,0.36,2021-06-26,0.3,2020-06-25,0.3,2019-06-26,0.31
+2023-06-27,0.26,2022-06-27,0.37,2021-06-27,0.33,2020-06-26,0.29,2019-06-27,0.29
+2023-06-28,0.26,2022-06-28,0.36,2021-06-28,0.34,2020-06-27,0.31,2019-06-28,0.26
+2023-06-29,0.26,2022-06-29,0.33,2021-06-29,0.29,2020-06-28,0.31,2019-06-29,0.29
+2023-06-30,0.28,2022-06-30,0.3,2021-06-30,0.31,2020-06-29,0.3,2019-06-30,0.3
+2023-07-01,0.33,2022-07-01,0.3,2021-07-01,0.3,2020-06-30,0.28,2019-07-01,0.31
+2023-07-02,0.34,2022-07-02,0.32,2021-07-02,0.29,2020-07-01,0.27,2019-07-02,0.3
+2023-07-03,0.3,2022-07-03,0.29,2021-07-03,0.29,2020-07-02,0.28,2019-07-03,0.28
+2023-07-04,0.28,2022-07-04,0.28,2021-07-04,0.3,2020-07-03,0.29,2019-07-04,0.28
+2023-07-05,0.29,2022-07-05,0.28,2021-07-05,0.31,2020-07-04,0.3,2019-07-05,0.3
+2023-07-06,0.29,2022-07-06,0.29,2021-07-06,0.33,2020-07-05,0.32,2019-07-06,0.29
+2023-07-07,0.27,2022-07-07,0.3,2021-07-07,0.32,2020-07-06,0.31,2019-07-07,0.28
+2023-07-08,0.29,2022-07-08,0.29,2021-07-08,0.31,2020-07-07,0.29,2019-07-08,0.29
+2023-07-09,0.27,2022-07-09,0.33,2021-07-09,0.33,2020-07-08,0.28,2019-07-09,0.29
+2023-07-10,0.26,2022-07-10,0.3,2021-07-10,0.34,2020-07-09,0.3,2019-07-10,0.29
+2023-07-11,0.27,2022-07-11,0.3,2021-07-11,0.35,2020-07-10,0.29,2019-07-11,0.3
+2023-07-12,0.3,2022-07-12,0.33,2021-07-12,0.31,2020-07-11,0.31,2019-07-12,0.3
+2023-07-13,0.3,2022-07-13,0.31,2021-07-13,0.3,2020-07-12,0.31,2019-07-13,0.31
+2023-07-14,0.3,2022-07-14,0.33,2021-07-14,0.29,2020-07-13,0.3,2019-07-14,0.34
+2023-07-15,0.29,2022-07-15,0.35,2021-07-15,0.29,2020-07-14,0.26,2019-07-15,0.31
+2023-07-16,0.26,2022-07-16,0.33,2021-07-16,0.28,2020-07-15,0.27,2019-07-16,0.31
+2023-07-17,0.28,2022-07-17,0.33,2021-07-17,0.28,2020-07-16,0.29,2019-07-17,0.28
+2023-07-18,0.24,2022-07-18,0.21,2021-07-18,0.2,2020-07-17,0.28,2019-07-18,0.29
+2023-07-19,0.3,2022-07-19,0.34,2021-07-19,0.3,2020-07-18,0.28,2019-07-19,0.28
+2023-07-20,0.3,2022-07-20,0.33,2021-07-20,0.33,2020-07-19,0.29,2019-07-20,0.28
+2023-07-21,0.28,2022-07-21,0.34,2021-07-21,0.3,2020-07-20,0.29,2019-07-21,0.28
+2023-07-22,0.28,2022-07-22,0.34,2021-07-22,0.3,2020-07-21,0.23,2019-07-22,0.29
+2023-07-23,0.28,2022-07-23,0.3,2021-07-23,0.29,2020-07-22,0.27,2019-07-23,0.3
+2023-07-24,0.3,2022-07-24,0.3,2021-07-24,0.29,2020-07-23,0.26,2019-07-24,0.31
+2023-07-25,0.28,2022-07-25,0.29,2021-07-25,0.28,2020-07-24,0.28,2019-07-25,0.26
+2023-07-26,0.28,2022-07-26,0.31,2021-07-26,0.27,2020-07-25,0.27,2019-07-26,0.31
+2023-07-27,0.28,2022-07-27,0.31,2021-07-27,0.32,2020-07-26,0.3,2019-07-27,0.31
+2023-07-28,0.28,2022-07-28,0.29,2021-07-28,0.28,2020-07-27,0.3,2019-07-28,0.31
+2023-07-29,0.29,2022-07-29,0.28,2021-07-29,0.3,2020-07-28,0.31,2019-07-29,0.31
+2023-07-30,0.26,2022-07-30,0.28,2021-07-30,0.3,2020-07-29,0.31,2019-07-30,0.3
+2023-07-31,0.27,2022-07-31,0.27,2021-07-31,0.3,2020-07-30,0.32,2019-07-31,0.28
+2023-08-01,0.27,2022-08-01,0.24,2021-08-01,0.3,2020-07-31,0.33,2019-08-01,0.29
+2023-08-02,0.25,2022-08-02,0.29,2021-08-02,0.29,2020-08-01,0.3,2019-08-02,0.29
+2023-08-03,0.25,2022-08-03,0.31,2021-08-03,0.31,2020-08-02,0.29,2019-08-03,0.28
+2023-08-04,0.25,2022-08-04,0.29,2021-08-04,0.33,2020-08-03,0.3,2019-08-04,0.31
+2023-08-05,0.29,2022-08-05,0.24,2021-08-05,0.3,2020-08-04,0.27,2019-08-05,0.27
+2023-08-06,0.29,2022-08-06,0.28,2021-08-06,0.29,2020-08-05,0.27,2019-08-06,0.29
+2023-08-07,0.27,2022-08-07,0.3,2021-08-07,0.25,2020-08-06,0.23,2019-08-07,0.3
+2023-08-08,0.27,2022-08-08,0.3,2021-08-08,0.26,2020-08-07,0.25,2019-08-08,0.29
+2023-08-09,0.25,2022-08-09,0.3,2021-08-09,0.27,2020-08-08,0.26,2019-08-09,0.28
+2023-08-10,0.2,2022-08-10,0.28,2021-08-10,0.28,2020-08-09,0.28,2019-08-10,0.28
+2023-08-11,0.22,2022-08-11,0.3,2021-08-11,0.29,2020-08-10,0.29,2019-08-11,0.28
+2023-08-12,0.21,2022-08-12,0.3,2021-08-12,0.29,2020-08-11,0.27,2019-08-12,0.28
+2023-08-13,0.23,2022-08-13,0.29,2021-08-13,0.28,2020-08-12,0.27,2019-08-13,0.29
+2023-08-14,0.25,2022-08-14,0.3,2021-08-14,0.26,2020-08-13,0.09,2019-08-14,0.3
+2023-08-15,0.24,2022-08-15,0.29,2021-08-15,0.27,2020-08-14,0.28,2019-08-15,0.29
+2023-08-16,0.19,2022-08-16,0.29,2021-08-16,0.24,2020-08-15,0.15,2019-08-16,0.29
+2023-08-17,0.25,2022-08-17,0.28,2021-08-17,0.27,2020-08-16,0.35,2019-08-17,0.28
+2023-08-18,0.25,2022-08-18,0.31,2021-08-18,0.25,2020-08-17,0.34,2019-08-18,0.25
+2023-08-19,0.21,2022-08-19,0.28,2021-08-19,0.17,2020-08-18,0.33,2019-08-19,0.26
+2023-08-20,0.04,2022-08-20,0.25,2021-08-20,0.21,2020-08-19,0.26,2019-08-20,0.27
+2023-08-21,0.24,2022-08-21,0.26,2021-08-21,0.24,2020-08-20,0.26,2019-08-21,0.27
+2023-08-22,0.22,2022-08-22,0.27,2021-08-22,0.22,2020-08-21,0.21,2019-08-22,0.25
+2023-08-23,0.23,2022-08-23,0.24,2021-08-23,0.24,2020-08-22,0.2,2019-08-23,0.25
+2023-08-24,0.24,2022-08-24,0.24,2021-08-24,0.24,2020-08-23,0.16,2019-08-24,0.27
+2023-08-25,0.22,2022-08-25,0.26,2021-08-25,0.24,2020-08-24,0.23,2019-08-25,0.26
+2023-08-26,0.23,2022-08-26,0.24,2021-08-26,0.26,2020-08-25,0.24,2019-08-26,0.27
+2023-08-27,0.26,2022-08-27,0.24,2021-08-27,0.26,2020-08-26,0.24,2019-08-27,0.28
+2023-08-28,0.27,2022-08-28,0.24,2021-08-28,0.25,2020-08-27,0.27,2019-08-28,0.29
+2023-08-29,0.28,2022-08-29,0.24,2021-08-29,0.27,2020-08-28,0.25,2019-08-29,0.26
+2023-08-30,0.26,2022-08-30,0.26,2021-08-30,0.27,2020-08-29,0.26,2019-08-30,0.25
+2023-08-31,0.28,2022-08-31,0.27,2021-08-31,0.26,2020-08-30,0.26,2019-08-31,0.25
+2023-09-01,0.22,2022-09-01,0.28,2021-09-01,0.23,2020-08-31,0.23,2019-09-01,0.28
+2023-09-02,0.09,2022-09-02,0.3,2021-09-02,0.22,2020-09-01,0.24,2019-09-02,0.27
+2023-09-03,0.12,2022-09-03,0.31,2021-09-03,0.22,2020-09-02,0.24,2019-09-03,0.28
+2023-09-04,0.19,2022-09-04,0.22,2021-09-04,0.23,2020-09-03,0.23,2019-09-04,0.26
+2023-09-05,0.19,2022-09-05,0.22,2021-09-05,0.24,2020-09-04,0.27,2019-09-05,0.25
+2023-09-06,0.2,2022-09-06,0.21,2021-09-06,0.24,2020-09-05,0.26,2019-09-06,0.26
+2023-09-07,0.21,2022-09-07,0.25,2021-09-07,0.29,2020-09-06,0.27,2019-09-07,0.26
+2023-09-08,0.21,2022-09-08,0.22,2021-09-08,0.25,2020-09-07,0.25,2019-09-08,0.21
+2023-09-09,0.23,2022-09-09,0.25,2021-09-09,0.22,2020-09-08,0.3,2019-09-09,0.23
+2023-09-10,0.23,2022-09-10,0.16,2021-09-10,0.27,2020-09-09,0.19,2019-09-10,0.21
+2023-09-11,0.18,2022-09-11,0.24,2021-09-11,0.24,2020-09-10,0.09,2019-09-11,0.22
+2023-09-12,0.21,2022-09-12,0.23,2021-09-12,0.25,2020-09-11,0.13,2019-09-12,0.23
+2023-09-13,0.2,2022-09-13,0.24,2021-09-13,0.22,2020-09-12,0.17,2019-09-13,0.23
+2023-09-14,0.18,2022-09-14,0.18,2021-09-14,0.23,2020-09-13,0.16,2019-09-14,0.22
+2023-09-15,0.2,2022-09-15,0.21,2021-09-15,0.21,2020-09-14,0.19,2019-09-15,0.21
+2023-09-16,0.2,2022-09-16,0.19,2021-09-16,0.22,2020-09-15,0.16,2019-09-16,0.19
+2023-09-17,0.16,2022-09-17,0.2,2021-09-17,0.19,2020-09-16,0.19,2019-09-17,0.2
+2023-09-18,0.12,2022-09-18,0.15,2021-09-18,0.21,2020-09-17,0.14,2019-09-18,0.21
+2023-09-19,0.16,2022-09-19,0.05,2021-09-19,0.22,2020-09-18,0.21,2019-09-19,0.22
+2023-09-20,0.17,2022-09-20,0.15,2021-09-20,0.2,2020-09-19,0.21,2019-09-20,0.21
+2023-09-21,0.15,2022-09-21,0.15,2021-09-21,0.18,2020-09-20,0.18,2019-09-21,0.21
+2023-09-22,0.16,2022-09-22,0.19,2021-09-22,0.21,2020-09-21,0.19,2019-09-22,0.2
+2023-09-23,0.16,2022-09-23,0.17,2021-09-23,0.22,2020-09-22,0.23,2019-09-23,0.23
+2023-09-24,0.16,2022-09-24,0.18,2021-09-24,0.17,2020-09-23,0.22,2019-09-24,0.22
+2023-09-25,0.17,2022-09-25,0.19,2021-09-25,0.19,2020-09-24,0.22,2019-09-25,0.2
+2023-09-26,0.18,2022-09-26,0.19,2021-09-26,0.16,2020-09-25,0.2,2019-09-26,0.21
+2023-09-27,0.19,2022-09-27,0.21,2021-09-27,0.17,2020-09-26,0.21,2019-09-27,0.17
+2023-09-28,0.19,2022-09-28,0.22,2021-09-28,0.21,2020-09-27,0.19,2019-09-28,0.19
+2023-09-29,0.18,2022-09-29,0.13,2021-09-29,0.2,2020-09-28,0.18,2019-09-29,0.17
+2023-09-30,0.1,2022-09-30,0.1,2021-09-30,0.16,2020-09-29,0.19,2019-09-30,0.18
+2023-10-01,0.09,2022-10-01,0.11,2021-10-01,0.17,2020-09-30,0.2,2019-10-01,0.18
+2023-10-02,0.16,2022-10-02,0.11,2021-10-02,0.18,2020-10-01,0.16,2019-10-02,0.17
+2023-10-03,0.15,2022-10-03,0.1,2021-10-03,0.17,2020-10-02,0.16,2019-10-03,0.17
+2023-10-04,0.15,2022-10-04,0.11,2021-10-04,0.15,2020-10-03,0.17,2019-10-04,0.21
+2023-10-05,0.16,2022-10-05,0.1,2021-10-05,0.17,2020-10-04,0.18,2019-10-05,0.18
+2023-10-06,0.16,2022-10-06,0.11,2021-10-06,0.18,2020-10-05,0.19,2019-10-06,0.16
+2023-10-07,0.15,2022-10-07,0.12,2021-10-07,0.16,2020-10-06,0.11,2019-10-07,0.17
+2023-10-08,0.16,2022-10-08,0.12,2021-10-08,0.12,2020-10-07,0.17,2019-10-08,0.18
+2023-10-09,0.14,2022-10-09,0.13,2021-10-09,0.14,2020-10-08,0.15,2019-10-09,0.25
+2023-10-10,0.14,2022-10-10,0.15,2021-10-10,0.14,2020-10-09,0.13,2019-10-10,0.19
+2023-10-11,0.22,2022-10-11,0.14,2021-10-11,0.29,2020-10-10,0.13,2019-10-11,0.16
+2023-10-12,0.16,2022-10-12,0.16,2021-10-12,0.22,2020-10-11,0.17,2019-10-12,0.15
+2023-10-13,0.17,2022-10-13,0.17,2021-10-13,0.15,2020-10-12,0.17,2019-10-13,0.16
+2023-10-14,0.14,2022-10-14,0.15,2021-10-14,0.17,2020-10-13,0.17,2019-10-14,0.16
+2023-10-15,0.14,2022-10-15,0.16,2021-10-15,0.14,2020-10-14,0.19,2019-10-15,0.15
+2023-10-16,0.16,2022-10-16,0.12,2021-10-16,0.15,2020-10-15,0.17,2019-10-16,0.12
+2023-10-17,0.16,2022-10-17,0.12,2021-10-17,0.18,2020-10-16,0.15,2019-10-17,0.19
+2023-10-18,0.13,2022-10-18,0.11,2021-10-18,0.13,2020-10-17,0.14,2019-10-18,0.16
+2023-10-19,0.14,2022-10-19,0.14,2021-10-19,0.13,2020-10-18,0.15,2019-10-19,0.14
+2023-10-20,0.14,2022-10-20,0.14,2021-10-20,0.14,2020-10-19,0.15,2019-10-20,0.17
+2023-10-21,0.15,2022-10-21,0.13,2021-10-21,0.12,2020-10-20,0.15,2019-10-21,0.15
+2023-10-22,0.11,2022-10-22,0.12,2021-10-22,0.07,2020-10-21,0.14,2019-10-22,0.14
+2023-10-23,0.12,2022-10-23,0.2,2021-10-23,0.11,2020-10-22,0.18,2019-10-23,0.14
+2023-10-24,0.11,2022-10-24,0.13,2021-10-24,0.08,2020-10-23,0.17,2019-10-24,0.14
+2023-10-25,0.14,2022-10-25,0.12,2021-10-25,0.07,2020-10-24,0.12,2019-10-25,0.13
+2023-10-26,0.12,2022-10-26,0.14,2021-10-26,0.06,2020-10-25,0.1,2019-10-26,0.13
+2023-10-27,0.11,2022-10-27,0.12,2021-10-27,0.07,2020-10-26,0.14,2019-10-27,0.21
+2023-10-28,0.14,2022-10-28,0.12,2021-10-28,0.08,2020-10-27,0.11,2019-10-28,0.13
+2023-10-29,0.12,2022-10-29,0.13,2021-10-29,0.09,2020-10-28,0.11,2019-10-29,0.13
+2023-10-30,0.1,2022-10-30,0.11,2021-10-30,0.05,2020-10-29,0.11,2019-10-30,0.13
+2023-10-31,0.1,2022-10-31,0.05,2021-10-31,0.06,2020-10-30,0.11,2019-10-31,0.11
+2023-11-01,0.11,2022-11-01,0.09,2021-11-01,0.07,2020-10-31,0.11,2019-11-01,0.11
+2023-11-02,0.11,2022-11-02,0.07,2021-11-02,0.1,2020-11-01,0.11,2019-11-02,0.11
+2023-11-03,0.11,2022-11-03,0.1,2021-11-03,0.08,2020-11-02,0.09,2019-11-03,0.11
+2023-11-04,0.11,2022-11-04,0.08,2021-11-04,0.08,2020-11-03,0.11,2019-11-04,0.11
+2023-11-05,0.11,2022-11-05,0.08,2021-11-05,0.08,2020-11-04,0.13,2019-11-05,0.11
+2023-11-06,0.11,2022-11-06,0.07,2021-11-06,0.1,2020-11-05,0.09,2019-11-06,0.11
+2023-11-07,0.12,2022-11-07,0.02,2021-11-07,0.11,2020-11-06,0.12,2019-11-07,0.11
+2023-11-08,0.11,2022-11-08,0.04,2021-11-08,0.09,2020-11-07,0.04,2019-11-08,0.11
+2023-11-09,0.09,2022-11-09,0.07,2021-11-09,0.06,2020-11-08,0.09,2019-11-09,0.1
+2023-11-10,0.09,2022-11-10,0.08,2021-11-10,0.07,2020-11-09,0.09,2019-11-10,0.1
+2023-11-11,0.09,2022-11-11,0.06,2021-11-11,0.05,2020-11-10,0.07,2019-11-11,0.1
+2023-11-12,0.11,2022-11-12,0.07,2021-11-12,0.06,2020-11-11,0.06,2019-11-12,0.1
+2023-11-13,0.1,2022-11-13,0.09,2021-11-13,0.04,2020-11-12,0.08,2019-11-13,0.09
+2023-11-14,0.1,2022-11-14,0.07,2021-11-14,0.02,2020-11-13,0.08,2019-11-14,0.09
+2023-11-15,0.04,2022-11-15,0.09,2021-11-15,0.01,2020-11-14,0.09,2019-11-15,0.08
+2023-11-16,0.09,2022-11-16,0.07,2021-11-16,0,2020-11-15,0.07,2019-11-16,0.08
+2023-11-17,0.08,2022-11-17,0.08,2021-11-17,0.03,2020-11-16,0.08,2019-11-17,0.08
+2023-11-18,0.05,2022-11-18,0.08,2021-11-18,0.06,2020-11-17,0.11,2019-11-18,0.09
+2023-11-19,0.14,2022-11-19,0.08,2021-11-19,0.07,2020-11-18,0.06,2019-11-19,0.1
+2023-11-20,0.08,2022-11-20,0.08,2021-11-20,0.06,2020-11-19,0.11,2019-11-20,0.05
+2023-11-21,0.08,2022-11-21,0.06,2021-11-21,0.06,2020-11-20,0.06,2019-11-21,0.08
+2023-11-22,0.08,2022-11-22,0.07,2021-11-22,0.06,2020-11-21,0.06,2019-11-22,0.08
+2023-11-23,0.11,2022-11-23,0.07,2021-11-23,0.06,2020-11-22,0.08,2019-11-23,0.09
+2023-11-24,0.11,2022-11-24,0.08,2021-11-24,0.09,2020-11-23,0.09,2019-11-24,0.08
+2023-11-25,0.08,2022-11-25,0.07,2021-11-25,0.08,2020-11-24,0.08,2019-11-25,0.17
+2023-11-26,0.05,2022-11-26,0.08,2021-11-26,0.06,2020-11-25,0.1,2019-11-26,0.1
+2023-11-27,0.07,2022-11-27,0.07,2021-11-27,0.07,2020-11-26,0.09,2019-11-27,0.04
+2023-11-28,0.09,2022-11-28,0.09,2021-11-28,0.07,2020-11-27,0.07,2019-11-28,0.02
+2023-11-29,0.07,2022-11-29,0.07,2021-11-29,0.07,2020-11-28,0.07,2019-11-29,0.06
+2023-11-30,0.08,2022-11-30,0.08,2021-11-30,0.06,2020-11-29,0.07,2019-11-30,0.01
+2023-12-01,0.09,2022-12-01,0.03,2021-12-01,0.07,2020-11-30,0.08,2019-12-01,0
+2023-12-02,0.07,2022-12-02,0.04,2021-12-02,0.06,2020-12-01,0.07,2019-12-02,0.05
+2023-12-03,0.05,2022-12-03,0.03,2021-12-03,0.06,2020-12-02,0.07,2019-12-03,0
+2023-12-04,0.06,2022-12-04,0.05,2021-12-04,0.01,2020-12-03,0.11,2019-12-04,0.01
+2023-12-05,0.06,2022-12-05,0.05,2021-12-05,0,2020-12-04,0.06,2019-12-05,0.06
+2023-12-06,0.1,2022-12-06,0.04,2021-12-06,0.02,2020-12-05,0.08,2019-12-06,0.07
+2023-12-07,0.09,2022-12-07,0.04,2021-12-07,0.01,2020-12-06,0.07,2019-12-07,0.04
+2023-12-08,0.08,2022-12-08,0.04,2021-12-08,0.04,2020-12-07,0.09,2019-12-08,0.04
+2023-12-09,0.07,2022-12-09,0.05,2021-12-09,0.03,2020-12-08,0.05,2019-12-09,0.02
+2023-12-10,0.06,2022-12-10,0.06,2021-12-10,0.06,2020-12-09,0.08,2019-12-10,0.02
+2023-12-11,0.06,2022-12-11,0.04,2021-12-11,0.06,2020-12-10,0.07,2019-12-11,0
+2023-12-12,0.07,2022-12-12,0.03,2021-12-12,0.04,2020-12-11,0.07,2019-12-12,0.05
+2023-12-13,0.06,2022-12-13,0.04,2021-12-13,0.04,2020-12-12,0.02,2019-12-13,0.04
+2023-12-14,0.06,2022-12-14,0.04,2021-12-14,0.01,2020-12-13,0.02,2019-12-14,0.06
+2023-12-15,0.06,2022-12-15,0.03,2021-12-15,0.01,2020-12-14,0.07,2019-12-15,0.07
+2023-12-16,0.07,2022-12-16,0.03,2021-12-16,0.01,2020-12-15,0.05,2019-12-16,0.06
+2023-12-17,0.04,2022-12-17,0.01,2021-12-17,0.01,2020-12-16,0.05,2019-12-17,0.05
+2023-12-18,0.02,2022-12-18,0,2021-12-18,0.01,2020-12-17,0.06,2019-12-18,0.07
+2023-12-19,0.04,2022-12-19,0,2021-12-19,0,2020-12-18,0.07,2019-12-19,0.06
+2023-12-20,0,2022-12-20,0.01,2021-12-20,0,2020-12-19,0.06,2019-12-20,0.06
+2023-12-21,0,2022-12-21,0,2021-12-21,0,2020-12-20,0.05,2019-12-21,0.07
+2023-12-22,0.02,2022-12-22,0,2021-12-22,0,2020-12-21,0.04,2019-12-22,0.04
+2023-12-23,0.02,2022-12-23,0,2021-12-23,0,2020-12-22,0.01,2019-12-23,0
+2023-12-24,0.04,2022-12-24,0.01,2021-12-24,0.05,2020-12-23,0.04,2019-12-24,0.04
+2023-12-25,0.04,2022-12-25,0,2021-12-25,0.05,2020-12-24,0.02,2019-12-25,0.04
+2023-12-26,0.03,2022-12-26,0,2021-12-26,0.05,2020-12-25,0.06,2019-12-26,0.03
+2023-12-27,0.06,2022-12-27,0,2021-12-27,0.03,2020-12-26,0.07,2019-12-27,0.05
+2023-12-28,0.06,2022-12-28,0.04,2021-12-28,0.03,2020-12-27,0.06,2019-12-28,0.04
+2023-12-29,0.08,2022-12-29,0,2021-12-29,0.02,2020-12-28,0.05,2019-12-29,0.02
+2023-12-30,0.03,2022-12-30,0.01,2021-12-30,0.02,2020-12-29,0.07,2019-12-30,0.06
+2023-12-31,0.02,2022-12-31,0.01,2021-12-31,0.02,2020-12-30,0.06,2019-12-31,0.05
+,,,,,,2020-12-31,0,,
Index: pylintrc
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/pylintrc b/pylintrc
new file mode 100644
--- /dev/null	
+++ b/pylintrc	
@@ -0,0 +1,399 @@
+# This Pylint rcfile contains a best-effort configuration to uphold the
+# best-practices and style described in the Google Python style guide:
+#   https://google.github.io/styleguide/pyguide.html
+#
+# Its canonical open-source location is:
+#   https://google.github.io/styleguide/pylintrc
+
+[MAIN]
+
+# Files or directories to be skipped. They should be base names, not paths.
+ignore=third_party
+
+# Files or directories matching the regex patterns are skipped. The regex
+# matches against base names, not paths.
+ignore-patterns=
+
+# Pickle collected data for later comparisons.
+persistent=no
+
+# List of plugins (as comma separated values of python modules names) to load,
+# usually to register additional checkers.
+load-plugins=
+
+# Use multiple processes to speed up Pylint.
+jobs=4
+
+# Allow loading of arbitrary C extensions. Extensions are imported into the
+# active Python interpreter and may run arbitrary code.
+unsafe-load-any-extension=no
+
+
+[MESSAGES CONTROL]
+
+# Only show warnings with the listed confidence levels. Leave empty to show
+# all. Valid levels: HIGH, INFERENCE, INFERENCE_FAILURE, UNDEFINED
+confidence=
+
+# Enable the message, report, category or checker with the given id(s). You can
+# either give multiple identifier separated by comma (,) or put this option
+# multiple time (only on the command line, not in the configuration file where
+# it should appear only once). See also the "--disable" option for examples.
+#enable=
+
+# Disable the message, report, category or checker with the given id(s). You
+# can either give multiple identifiers separated by comma (,) or put this
+# option multiple times (only on the command line, not in the configuration
+# file where it should appear only once).You can also use "--disable=all" to
+# disable everything first and then reenable specific checks. For example, if
+# you want to run only the similarities checker, you can use "--disable=all
+# --enable=similarities". If you want to run only the classes checker, but have
+# no Warning level messages displayed, use"--disable=all --enable=classes
+# --disable=W"
+disable=R,
+        abstract-method,
+        apply-builtin,
+        arguments-differ,
+        attribute-defined-outside-init,
+        backtick,
+        bad-option-value,
+        basestring-builtin,
+        buffer-builtin,
+        c-extension-no-member,
+        consider-using-enumerate,
+        cmp-builtin,
+        cmp-method,
+        coerce-builtin,
+        coerce-method,
+        delslice-method,
+        div-method,
+        eq-without-hash,
+        execfile-builtin,
+        file-builtin,
+        filter-builtin-not-iterating,
+        fixme,
+        getslice-method,
+        global-statement,
+        hex-method,
+        idiv-method,
+        implicit-str-concat,
+        import-error,
+        import-self,
+        import-star-module-level,
+        input-builtin,
+        intern-builtin,
+        invalid-str-codec,
+        locally-disabled,
+        long-builtin,
+        long-suffix,
+        map-builtin-not-iterating,
+        misplaced-comparison-constant,
+        missing-function-docstring,
+        metaclass-assignment,
+        next-method-called,
+        next-method-defined,
+        no-absolute-import,
+        no-init,  # added
+        no-member,
+        no-name-in-module,
+        no-self-use,
+        nonzero-method,
+        oct-method,
+        old-division,
+        old-ne-operator,
+        old-octal-literal,
+        old-raise-syntax,
+        parameter-unpacking,
+        print-statement,
+        raising-string,
+        range-builtin-not-iterating,
+        raw_input-builtin,
+        rdiv-method,
+        reduce-builtin,
+        relative-import,
+        reload-builtin,
+        round-builtin,
+        setslice-method,
+        signature-differs,
+        standarderror-builtin,
+        suppressed-message,
+        sys-max-int,
+        trailing-newlines,
+        unichr-builtin,
+        unicode-builtin,
+        unnecessary-pass,
+        unpacking-in-except,
+        useless-else-on-loop,
+        useless-suppression,
+        using-cmp-argument,
+        wrong-import-order,
+        xrange-builtin,
+        zip-builtin-not-iterating,
+
+
+[REPORTS]
+
+# Set the output format. Available formats are text, parseable, colorized, msvs
+# (visual studio) and html. You can also give a reporter class, eg
+# mypackage.mymodule.MyReporterClass.
+output-format=text
+
+# Tells whether to display a full report or only the messages
+reports=no
+
+# Python expression which should return a note less than 10 (10 is the highest
+# note). You have access to the variables errors warning, statement which
+# respectively contain the number of errors / warnings messages and the total
+# number of statements analyzed. This is used by the global evaluation report
+# (RP0004).
+evaluation=10.0 - ((float(5 * error + warning + refactor + convention) / statement) * 10)
+
+# Template used to display messages. This is a python new-style format string
+# used to format the message information. See doc for all details
+#msg-template=
+
+
+[BASIC]
+
+# Good variable names which should always be accepted, separated by a comma
+good-names=main,_
+
+# Bad variable names which should always be refused, separated by a comma
+bad-names=
+
+# Colon-delimited sets of names that determine each other's naming style when
+# the name regexes allow several styles.
+name-group=
+
+# Include a hint for the correct naming format with invalid-name
+include-naming-hint=no
+
+# List of decorators that produce properties, such as abc.abstractproperty. Add
+# to this list to register other decorators that produce valid properties.
+property-classes=abc.abstractproperty,cached_property.cached_property,cached_property.threaded_cached_property,cached_property.cached_property_with_ttl,cached_property.threaded_cached_property_with_ttl
+
+# Regular expression matching correct function names
+function-rgx=^(?:(?P<exempt>setUp|tearDown|setUpModule|tearDownModule)|(?P<camel_case>_?[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_?[a-z][a-z0-9_]*))$
+
+# Regular expression matching correct variable names
+variable-rgx=^[a-z][a-z0-9_]*$
+
+# Regular expression matching correct constant names
+const-rgx=^(_?[A-Z][A-Z0-9_]*|__[a-z0-9_]+__|_?[a-z][a-z0-9_]*)$
+
+# Regular expression matching correct attribute names
+attr-rgx=^_{0,2}[a-z][a-z0-9_]*$
+
+# Regular expression matching correct argument names
+argument-rgx=^[a-z][a-z0-9_]*$
+
+# Regular expression matching correct class attribute names
+class-attribute-rgx=^(_?[A-Z][A-Z0-9_]*|__[a-z0-9_]+__|_?[a-z][a-z0-9_]*)$
+
+# Regular expression matching correct inline iteration names
+inlinevar-rgx=^[a-z][a-z0-9_]*$
+
+# Regular expression matching correct class names
+class-rgx=^_?[A-Z][a-zA-Z0-9]*$
+
+# Regular expression matching correct module names
+module-rgx=^(_?[a-z][a-z0-9_]*|__init__)$
+
+# Regular expression matching correct method names
+method-rgx=(?x)^(?:(?P<exempt>_[a-z0-9_]+__|runTest|setUp|tearDown|setUpTestCase|tearDownTestCase|setupSelf|tearDownClass|setUpClass|(test|assert)_*[A-Z0-9][a-zA-Z0-9_]*|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9_]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$
+
+# Regular expression which should only match function or class names that do
+# not require a docstring.
+no-docstring-rgx=(__.*__|main|test.*|.*test|.*Test)$
+
+# Minimum line length for functions/classes that require docstrings, shorter
+# ones are exempt.
+docstring-min-length=12
+
+
+[TYPECHECK]
+
+# List of decorators that produce context managers, such as
+# contextlib.contextmanager. Add to this list to register other decorators that
+# produce valid context managers.
+contextmanager-decorators=contextlib.contextmanager,contextlib2.contextmanager
+
+# List of module names for which member attributes should not be checked
+# (useful for modules/projects where namespaces are manipulated during runtime
+# and thus existing member attributes cannot be deduced by static analysis. It
+# supports qualified module names, as well as Unix pattern matching.
+ignored-modules=
+
+# List of class names for which member attributes should not be checked (useful
+# for classes with dynamically set attributes). This supports the use of
+# qualified names.
+ignored-classes=optparse.Values,thread._local,_thread._local
+
+# List of members which are set dynamically and missed by pylint inference
+# system, and so shouldn't trigger E1101 when accessed. Python regular
+# expressions are accepted.
+generated-members=
+
+
+[FORMAT]
+
+# Maximum number of characters on a single line.
+max-line-length=80
+
+# TODO(https://github.com/pylint-dev/pylint/issues/3352): Direct pylint to exempt
+# lines made too long by directives to pytype.
+
+# Regexp for a line that is allowed to be longer than the limit.
+ignore-long-lines=(?x)(
+  ^\s*(\#\ )?<?https?://\S+>?$|
+  ^\s*(from\s+\S+\s+)?import\s+.+$)
+
+# Allow the body of an if to be on the same line as the test if there is no
+# else.
+single-line-if-stmt=yes
+
+# Maximum number of lines in a module
+max-module-lines=99999
+
+# String used as indentation unit.  The internal Google style guide mandates 2
+# spaces.  Google's externaly-published style guide says 4, consistent with
+# PEP 8.  Here, we use 2 spaces, for conformity with many open-sourced Google
+# projects (like TensorFlow).
+indent-string='  '
+
+# Number of spaces of indent required inside a hanging  or continued line.
+indent-after-paren=4
+
+# Expected format of line ending, e.g. empty (any line ending), LF or CRLF.
+expected-line-ending-format=
+
+
+[MISCELLANEOUS]
+
+# List of note tags to take in consideration, separated by a comma.
+notes=TODO
+
+
+[STRING]
+
+# This flag controls whether inconsistent-quotes generates a warning when the
+# character used as a quote delimiter is used inconsistently within a module.
+check-quote-consistency=yes
+
+
+[VARIABLES]
+
+# Tells whether we should check for unused import in __init__ files.
+init-import=no
+
+# A regular expression matching the name of dummy variables (i.e. expectedly
+# not used).
+dummy-variables-rgx=^\*{0,2}(_$|unused_|dummy_)
+
+# List of additional names supposed to be defined in builtins. Remember that
+# you should avoid to define new builtins when possible.
+additional-builtins=
+
+# List of strings which can identify a callback function by name. A callback
+# name must start or end with one of those strings.
+callbacks=cb_,_cb
+
+# List of qualified module names which can have objects that can redefine
+# builtins.
+redefining-builtins-modules=six,six.moves,past.builtins,future.builtins,functools
+
+
+[LOGGING]
+
+# Logging modules to check that the string format arguments are in logging
+# function parameter format
+logging-modules=logging,absl.logging,tensorflow.io.logging
+
+
+[SIMILARITIES]
+
+# Minimum lines number of a similarity.
+min-similarity-lines=4
+
+# Ignore comments when computing similarities.
+ignore-comments=yes
+
+# Ignore docstrings when computing similarities.
+ignore-docstrings=yes
+
+# Ignore imports when computing similarities.
+ignore-imports=no
+
+
+[SPELLING]
+
+# Spelling dictionary name. Available dictionaries: none. To make it working
+# install python-enchant package.
+spelling-dict=
+
+# List of comma separated words that should not be checked.
+spelling-ignore-words=
+
+# A path to a file that contains private dictionary; one word per line.
+spelling-private-dict-file=
+
+# Tells whether to store unknown words to indicated private dictionary in
+# --spelling-private-dict-file option instead of raising a message.
+spelling-store-unknown-words=no
+
+
+[IMPORTS]
+
+# Deprecated modules which should not be used, separated by a comma
+deprecated-modules=regsub,
+                   TERMIOS,
+                   Bastion,
+                   rexec,
+                   sets
+
+# Create a graph of every (i.e. internal and external) dependencies in the
+# given file (report RP0402 must not be disabled)
+import-graph=
+
+# Create a graph of external dependencies in the given file (report RP0402 must
+# not be disabled)
+ext-import-graph=
+
+# Create a graph of internal dependencies in the given file (report RP0402 must
+# not be disabled)
+int-import-graph=
+
+# Force import order to recognize a module as part of the standard
+# compatibility libraries.
+known-standard-library=
+
+# Force import order to recognize a module as part of a third party library.
+known-third-party=enchant, absl
+
+# Analyse import fallback blocks. This can be used to support both Python 2 and
+# 3 compatible code, which means that the block might have code that exists
+# only in one or another interpreter, leading to false positives when analysed.
+analyse-fallback-blocks=no
+
+
+[CLASSES]
+
+# List of method names used to declare (i.e. assign) instance attributes.
+defining-attr-methods=__init__,
+                      __new__,
+                      setUp
+
+# List of member names, which should be excluded from the protected access
+# warning.
+exclude-protected=_asdict,
+                  _fields,
+                  _replace,
+                  _source,
+                  _make
+
+# List of valid names for the first argument in a class method.
+valid-classmethod-first-arg=cls,
+                            class_
+
+# List of valid names for the first argument in a metaclass class method.
+valid-metaclass-classmethod-first-arg=mcs
Index: data.csv
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>logger_id,date,time,canopy_temperature,ambient_temperature,vpd,vwc_1,vwc_2,vwc_3,field_capacity,wilting_point,daily_gallons,daily_switch,daily_hours,daily_pressure,daily_inches,psi,psi_threshold,psi_critical,sdd,rh,eto,kc,etc,et_hours,phase1_adjustment,phase1_adjusted,phase2_adjustment,phase2_adjusted,phase3_adjustment,phase3_adjusted,vwc_1_ec,vwc_2_ec,vwc_3_ec,lowest_ambient_temperature,gdd,crop_stage,id,planting_date,variety\r\nz6-07156,2023-06-24,06:00 PM,,84.70400000000001,2.878745920483505,19.854270349879698,18.0140852962003,21.56450467022204,12,5,,409.0,6.8,,0.3,,1.6,2.2,,29.264726183655803,,0.528,,,,,,,,,,,,57.2,20.951999999999998,Bloom,be0dc883-bb70-4d9e-afba-483840f7f548,2023-06-15,\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/data.csv b/data.csv
--- a/data.csv	
+++ b/data.csv	
@@ -1,2 +1,56 @@
-logger_id,date,time,canopy_temperature,ambient_temperature,vpd,vwc_1,vwc_2,vwc_3,field_capacity,wilting_point,daily_gallons,daily_switch,daily_hours,daily_pressure,daily_inches,psi,psi_threshold,psi_critical,sdd,rh,eto,kc,etc,et_hours,phase1_adjustment,phase1_adjusted,phase2_adjustment,phase2_adjusted,phase3_adjustment,phase3_adjusted,vwc_1_ec,vwc_2_ec,vwc_3_ec,lowest_ambient_temperature,gdd,crop_stage,id,planting_date,variety
-z6-07156,2023-06-24,06:00 PM,,84.70400000000001,2.878745920483505,19.854270349879698,18.0140852962003,21.56450467022204,12,5,,409.0,6.8,,0.3,,1.6,2.2,,29.264726183655803,,0.528,,,,,,,,,,,,57.2,20.951999999999998,Bloom,be0dc883-bb70-4d9e-afba-483840f7f548,2023-06-15,
+logger_id,date,time,canopy_temperature,canopy_temperature_celsius,ambient_temperature,ambient_temperature_celsius,vpd,vwc_1,vwc_2,vwc_3,field_capacity,wilting_point,daily_gallons,daily_switch,daily_hours,daily_pressure,daily_inches,psi,psi_threshold,psi_critical,sdd,sdd_celsius,rh,eto,kc,etc,et_hours,phase1_adjustment,phase1_adjusted,phase2_adjustment,phase2_adjusted,phase3_adjustment,phase3_adjusted,vwc_1_ec,vwc_2_ec,vwc_3_ec,lowest_ambient_temperature,lowest_ambient_temperature_celsius,gdd,crop_stage,id,planting_date,variety
+z6-12363,2024-02-16,03:00 PM,,,62.618,17.01,0.6973907001269659,40.690871197891724,38.97866360368476,40.55360594588748,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,64.00361062529811,0.05,0.41,0.0205,1,,,,,,,,,,5.699999999999999,,,,664cbdb3-6b3e-4484-a29e-f1dff5d7e782,2011-01-01,
+z6-12363,2024-02-17,02:00 PM,,,58.80200000000001,14.890000000000006,0.37795745920510226,40.3398866327505,39.443929401980604,41.12529151252291,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,77.66152705856622,0.01,0.41,0.0040999999999999995,0,,,,,,,,,,8.919999999999998,,,,56820839-bfbd-4e43-b958-93b306a557d7,2011-01-01,
+z6-12363,2024-02-18,03:00 PM,,,69.80000000000001,21.000000000000007,1.1591534031130046,40.244916831558754,39.40010677612315,41.13460618781204,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,53.35686715914593,0.1,0.41,0.041,2,,,,,,,,,,8.26,,,,fe61aa2e-05f8-4fd9-aadf-4b2db6cefcba,2011-01-01,
+z6-12363,2024-02-19,01:00 PM,,,68.576,20.319999999999997,1.1731834261998304,40.88416080013752,39.62434100020968,41.28405004634459,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,50.772424258146096,0.13,0.41,0.0533,3,,,,,,,,,,13.079999999999998,,,,2cb41f2d-a2e6-4b96-8504-9faaee527530,2011-01-01,
+z6-12363,2024-02-20,12:00 PM,,,66.18199999999999,18.989999999999995,0.9872877991156026,40.66794755055376,39.6641030938365,41.25129331239101,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,55.00645815405234,0.06,0.41,0.024599999999999997,1,,,,,,,,,,9.4,,,,782bb1c7-47b8-468b-b903-1d6e98074ab8,2011-01-01,
+z6-12363,2024-02-21,02:00 PM,,,64.616,18.119999999999997,0.8929474125367447,40.39429951351163,39.69064316753097,41.27000692088912,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,57.02742970542069,0.09,0.41,0.036899999999999995,2,,,,,,,,,,5.900000000000002,,,,27e331c0-8d7d-45dc-9884-95264c1ef63d,2011-01-01,
+z6-12363,2024-02-22,04:00 PM,,,67.80199999999999,19.889999999999997,1.2236112050873067,40.07836870974448,39.69949555514694,41.27936825008574,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,47.27202892044677,0.1,0.41,0.041,2,,,,,,,,,,5.62,,,,8ef7f67a-3de7-4934-bf5e-0fccf9c6de85,2011-01-01,
+z6-12363,2024-02-23,04:00 PM,,,66.902,19.39,1.128667042267991,39.89942953017609,39.71277948026204,41.27936825008574,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,49.82959606635252,0.07,0.41,0.0287,1,,,,,,,,,,5.93,,,,68866010-e8b4-4421-8ce9-3fe5cebaddb8,2011-01-01,
+z6-12363,2024-02-24,04:00 PM,,,73.598,23.11,1.6902917205419665,39.76597936679025,39.677369927375935,41.30278477861209,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,40.194010821436436,0.1,0.41,0.041,2,,,,,,,,,,4.200000000000001,,,,71acd3b8-0db5-428a-b64c-09815e0f8b1d,2011-01-01,
+z6-12363,2024-02-25,05:00 PM,,,75.074,23.93,1.7365247683057818,39.70835079257,39.68179362875319,41.307470349092235,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,41.52179544552072,0.11,0.41,0.045099999999999994,2,,,,,,,,,,4.309999999999998,,,,afe21458-081e-427c-bce8-02ab74de5fe7,2011-01-01,
+z6-12363,2024-02-26,01:00 PM,,,63.176,17.32,0.7827794102346537,39.71277948026204,39.68621804209782,41.307470349092235,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,60.381234555851215,0.04,0.41,0.016399999999999998,1,,,,,,,,,,8.880000000000003,,,,41425da6-72f7-4fce-a2b8-d89aaa045ee1,2011-01-01,
+z6-12363,2024-02-27,04:00 PM,,,64.886,18.269999999999996,1.1356113573572804,39.602275817592854,39.721638994212995,41.32153159226304,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,45.86168913635154,0.11,0.41,0.045099999999999994,2,,,,,,,,,,6.720000000000002,,,,aa85ff38-38f3-4b7a-a73d-9a4dd83e7b64,2011-01-01,
+z6-12363,2024-02-28,05:00 PM,,,71.33000000000001,21.85000000000001,1.489974785941225,39.4176273690968,39.75710558200176,41.35436761029787,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,43.08674040932204,0.11,0.41,0.045099999999999994,2,,,,,,,,,,2.1400000000000023,,,,4ef3e18a-d3c4-4d20-8b67-190d16067189,2011-01-01,
+z6-12363,2024-02-29,03:00 PM,,,68.63,20.349999999999998,1.2366035698159188,39.3563545718203,39.77929540129033,41.36375613568903,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,48.20733284833967,0.09,0.41,0.036899999999999995,2,,,,,,,,,,5.240000000000001,,,,ca159668-397d-4cc5-9f97-0f840ca3898d,2011-01-01,
+z6-12363,2024-03-01,03:00 PM,,,65.22800000000001,18.460000000000004,0.8697531871666933,39.3563545718203,39.79706011937023,41.344982110582066,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,59.02711665091971,0.07,0.62,0.0434,2,,,,,,,,,,10.96,,,,cc5c0e64-289e-411b-bed6-c7ecc9832838,2011-01-01,
+z6-12363,2024-03-02,12:00 AM,,,55.706,13.170000000000002,0.3603524528924842,39.3563545718203,39.79706011937023,41.344982110582066,36,22,,0.0,0.0,,0.0,,0.5,1.0,,,76.18846474238441,0.05,0.62,0.031,1,,,,,,,,,,8.890000000000002,,,,3eb87809-5983-4713-bab4-7f1490478ad2,2011-01-01,
+z6-12363,2024-03-03,03:00 PM,61.718,16.510000000000005,61.664,16.48,0.9562731024683151,39.05205077104856,39.832623888871765,41.359061494723726,36,22,,0.0,0.0,,0.0,0.45559684559061586,0.5,1.0,0.054000000000002046,-17.747777777777777,48.951751818339595,0.07,0.62,0.0434,2,,,,,,,,,,6.400000000000002,,,,7483d046-8921-4a6e-b636-813bf0ad17f3,2011-01-01,
+z6-12363,2024-03-04,03:00 PM,62.564,16.98,62.87,17.15,1.0326457035849161,38.922679067626746,39.832623888871765,41.35436761029787,36,22,,0.0,0.0,,0.0,0.4273807825433758,0.5,1.0,-0.3059999999999974,-17.947777777777773,47.16967368096462,0.1,0.62,0.062,3,,,,,,,,,,4.879999999999999,,,,24ce31ae-aab0-44c0-b4dc-c9d2b4ac39fd,2011-01-01,
+z6-12363,2024-03-05,04:00 PM,65.94800000000001,18.860000000000003,65.138,18.410000000000004,1.0911114272226277,38.83248904258969,39.841521989679094,41.34029049504973,36,22,,0.0,0.0,,0.0,0.6593061171880369,0.5,1.0,0.8100000000000023,-17.327777777777776,48.43790297684375,0.09,0.62,0.055799999999999995,3,,,,,,,,,,2.4899999999999998,,,,b04c82bc-5fef-41e2-9e5f-1327b50f7e55,2011-01-01,
+z6-12363,2024-03-06,02:00 PM,68.018,20.01,67.04599999999999,19.469999999999995,1.2038887217302605,38.772531073894626,39.83707258117208,41.326220184300325,36,22,,0.0,0.0,,0.0,0.7177491141101879,0.5,1.0,0.9720000000000084,-17.237777777777772,46.75152694782239,0.08,0.62,0.0496,2,,,,,,,,,,6.280000000000001,,,,34d75b99-d28d-4d43-a70b-6f60b827a58d,2011-01-01,
+z6-12363,2024-03-07,03:00 PM,64.436,18.020000000000003,64.148,17.86,0.8562460515163444,38.759700458721056,39.89051278752882,41.30278477861209,36,22,,0.0,0.0,,0.0,0.44559788504311826,0.5,1.0,0.2880000000000109,-17.61777777777777,58.114335068363545,0.1,0.62,0.062,3,,,,,,,,,,7.230000000000002,,,,31226a4a-1513-4bab-a835-2a182f5e49d1,2011-01-01,
+z6-12363,2024-03-08,05:00 PM,65.876,18.820000000000004,68.81,20.450000000000003,1.464389297011089,38.53404171535249,39.95745839615381,41.326220184300325,36,22,,0.0,0.0,,0.0,0.24372982049918776,0.5,1.0,-2.9339999999999975,-19.407777777777778,39.044462992197154,0.12,0.62,0.0744,4,,,,,,,,,,3.6000000000000023,,,,e41a90f9-06d1-48c2-966c-10ac3e8c22f9,2011-01-01,
+z6-12363,2024-03-09,04:00 PM,68.63,20.349999999999998,69.44,20.799999999999997,1.2307729516669894,38.440933973743526,39.98428194375223,41.326220184300325,36,22,,0.0,0.0,,0.0,0.4392267454283971,0.5,1.0,-0.8100000000000023,-18.227777777777778,49.86204525224237,0.11,0.62,0.0682,3,,,,,,,,,,3.3999999999999986,,,,9d91ecf5-d729-4467-b81e-928dbb8957c3,2011-01-01,
+z6-12363,2024-03-10,04:00 PM,67.334,19.630000000000003,67.64,19.799999999999997,1.0426984375249309,38.33552750898921,40.020087009804286,41.326220184300325,36,22,,0.0,0.0,,0.0,0.43291475752990943,0.5,1.0,-0.3059999999999974,-17.947777777777773,54.816521059690395,0.09,0.62,0.055799999999999995,3,,,,,,,,,,6.88,,,,a6fc30e7-45c5-4978-8f20-84fd025c0c23,2011-01-01,
+z6-12363,2024-03-11,05:00 PM,68.072,20.040000000000003,70.07,21.149999999999995,1.5741543365992219,38.08426754277012,40.06490825516451,41.33090953202982,36,22,,0.0,0.0,,0.0,0.4134157010457899,0.5,1.0,-1.9979999999999905,-18.88777777777777,37.2385377714196,0.13,0.62,0.0806,4,,,,,,,,,,5.41,,,,6ed490d6-f2b9-47d7-a4e3-bb9d58725882,2011-01-01,
+z6-12363,2024-03-12,05:00 PM,66.488,19.16,67.74799999999999,19.859999999999996,0.970299932002681,37.93052233364374,40.11878911490907,41.344982110582066,36,22,,0.0,0.0,,0.0,0.197055716452276,0.5,1.0,-1.259999999999991,-18.477777777777774,58.109918383334914,0.09,0.62,0.055799999999999995,3,,,,,,,,,,9.899999999999999,,,,3a0965db-6a0f-4a39-811b-bd198c61f103,2011-01-01,
+z6-12363,2024-03-13,04:00 PM,64.202,17.89,65.066,18.37,1.1578111482861289,37.50728581235565,40.15926815088666,41.36375613568903,36,22,,0.0,0.0,,0.0,0.39463965187144034,0.5,1.0,-0.8640000000000043,-18.25777777777778,45.148520310487626,0.14,0.62,0.0868,4,,,,,,,,,,7.029999999999998,,,,b59ba2d7-265e-458e-a74c-798909be5592,2011-01-01,
+z6-12363,2024-03-14,05:00 PM,68.414,20.23,70.214,21.23,1.8744975575304048,36.75641704982944,40.11429506504602,41.3825422673729,36,22,,0.0,0.0,,0.0,0.5282831992529394,0.5,1.0,-1.7999999999999972,-18.77777777777778,25.629860186532134,0.17,0.62,0.10540000000000001,5,,,,,,,,,,5.059999999999999,,,,70307b14-e2c4-4489-9867-4e254284e1d7,2011-01-01,
+z6-12363,2024-03-15,05:00 PM,71.906,22.17,73.868,23.259999999999998,2.0990318928319254,36.0620761152684,40.08285697327052,41.41074418168786,36,22,,0.0,0.0,,0.0,0.5636402251771959,0.5,1.0,-1.961999999999989,-18.86777777777777,26.40222929808504,0.15,0.62,0.093,4,,,,,,,,,,6.219999999999999,,,,fd5b2e7e-024e-4477-8602-b58d89cc03b9,2011-01-01,
+z6-12363,2024-03-16,05:00 PM,73.976,23.32,75.362,24.089999999999996,2.096200862455345,35.521959209282805,40.105309136346534,41.415447152586715,36,22,,0.0,0.0,,0.0,0.6170362688973358,0.5,1.0,-1.3859999999999957,-18.547777777777775,30.084708843066526,0.15,0.62,0.093,4,,,,,,,,,,3.6299999999999994,,,,e9033b43-8644-4b30-863a-69c6038a614a,2011-01-01,
+z6-12363,2024-03-17,05:00 PM,74.714,23.73,76.136,24.519999999999996,2.1204708991545225,34.80681626920119,40.05145430203836,41.42015088147906,36,22,,0.0,0.0,,0.0,0.6180892390548471,0.5,1.0,-1.421999999999997,-18.567777777777778,31.074566649167018,0.15,0.62,0.093,4,,,,,,,,,,5.540000000000001,,,,47398c8b-96b4-4a02-832b-31dc67b70ab1,2011-01-01,
+z6-12363,2024-03-18,05:00 PM,77.756,25.42,79.52,26.399999999999995,2.201035223968356,34.233511143515294,39.988755055024505,41.42015088147906,36,22,,0.0,0.0,,0.0,0.6015584733500049,0.5,1.0,-1.7639999999999958,-18.757777777777775,36.0170730627204,0.15,0.62,0.093,4,,,,,,,,,,5.360000000000002,,,,72f83e61-64b8-4815-a031-f1d662f7667a,2011-01-01,
+z6-12363,2024-03-19,05:00 PM,79.61,26.450000000000003,81.392,27.439999999999998,2.49284298434156,33.684439081117375,39.935125226544834,41.42956061372818,36,22,,0.0,0.0,,0.0,0.6468279362524638,0.5,1.0,-1.7819999999999965,-18.767777777777773,31.830735007879657,0.17,0.62,0.10540000000000001,5,,,,,,,,,,7.249999999999998,,,,44e948ae-420e-47ce-8833-45e4621082dc,2011-01-01,
+z6-12363,2024-03-20,05:00 PM,79.68199999999999,26.489999999999995,81.84200000000001,27.69000000000001,2.867703950789015,33.168585731259135,39.89497079996176,41.46251857119756,36,22,,0.0,0.0,,0.0,0.6671456750687889,0.5,1.0,-2.160000000000025,-18.977777777777792,22.71806134846061,0.18,0.62,0.11159999999999999,5,,,,,,,,,,7.740000000000001,,,,ff6877d2-f5de-49eb-85f4-86c662315298,2011-01-01,
+z6-12363,2024-03-21,05:00 PM,73.562,23.09,75.398,24.11,1.8808023418284576,32.764165993123214,39.89051278752882,41.490797856433744,36,22,,0.0,0.0,,0.0,0.526105521954903,0.5,1.0,-1.8359999999999985,-18.797777777777778,37.34423097681963,0.15,0.62,0.093,4,,,,,,,,,,7.789999999999998,,,,33079060-bff2-4692-95f6-b8e503a3837f,2011-01-01,
+z6-12363,2024-03-22,05:00 PM,78.602,25.89,78.278,25.710000000000004,2.028464106692045,32.41614494080394,39.801503086378396,41.519104499198,36,22,,0.0,0.0,,0.0,0.7698618279120758,0.5,1.0,0.32399999999999807,-17.59777777777778,38.577255008416074,0.18,0.62,0.11159999999999999,5,,,,,,,,,,9.449999999999998,,,,050c7f37-0716-4777-92f8-b7f4bfadc291,2011-01-01,
+z6-12363,2024-03-23,02:00 PM,62.94200000000001,17.190000000000005,62.402,16.89,0.857707249708092,32.46553388734159,39.76597936679025,41.55688929092385,36,22,,0.0,0.0,,0.0,0.5043687815722964,0.5,1.0,0.5400000000000063,-17.477777777777774,55.390647752625355,0.11,0.62,0.0682,3,,,,,,,,,,8.400000000000002,,,,18e5a0b9-d394-4940-87e4-9323fa459c33,2011-01-01,
+z6-12363,2024-03-24,06:00 PM,61.664,16.48,61.466,16.37,0.7522016275030454,31.989375510232378,39.443929401980604,41.58525986966248,36,22,,0.0,0.0,,0.0,0.3450989456992327,0.5,1.0,0.1980000000000004,-17.667777777777776,59.56343568451082,0.11,0.62,0.0682,3,,,,,,,,,,5.589999999999999,,,,ab8afc3c-c873-43e3-8892-83e67cda6f6d,2011-01-01,
+z6-12363,2024-03-25,05:00 PM,65.768,18.76,66.77600000000001,19.320000000000007,1.1428881517587155,31.634027752437134,39.1646784112619,41.56634310270331,36,22,,0.0,0.0,,0.0,0.3619388429009067,0.5,1.0,-1.0080000000000098,-18.337777777777784,48.97565975062895,0.13,0.62,0.0806,4,,,,,,,,,,5.379999999999999,,,,5e06f8c2-9d60-4262-b852-e7523dd19faf,2011-01-01,
+z6-12363,2024-03-26,05:00 PM,69.062,20.59,69.584,20.880000000000003,1.3668858709938867,31.51366592641849,38.91407643212408,41.523824934588745,36,22,,0.0,0.0,,0.0,0.5365924454509358,0.5,1.0,-0.5220000000000056,-18.067777777777778,44.59063197588544,0.16,0.62,0.0992,5,,,,,,,,,,5.41,,,,7668172f-f62e-49b1-87f3-be09c52dbffc,2011-01-01,
+z6-12363,2024-03-27,03:00 PM,73.166,22.869999999999997,72.662,22.590000000000003,1.569625601384078,31.485254110245677,38.75115014692181,41.490797856433744,36,22,,0.0,0.0,,0.0,0.7250188060137976,0.5,1.0,0.5039999999999907,-17.497777777777785,42.68564492383323,0.15,0.62,0.093,4,,,,,,,,,,4.759999999999999,,,,ce5734a8-8418-4c7f-af25-ab19fa254ef4,2011-01-01,
+z6-12363,2024-03-28,03:00 PM,65.03,18.35,65.26400000000001,18.480000000000004,1.105415005626432,31.523144585701203,38.55949179062321,41.44368090008071,36,22,,0.0,0.0,,0.0,0.47797242557729835,0.5,1.0,-0.23400000000000887,-17.90777777777778,47.99062758566397,0.13,0.62,0.0806,4,,,,,,,,,,11.300000000000002,,,,ba75dbd0-a63b-4c5f-ba7f-5ca12e5dbaf9,2011-01-01,
+z6-12363,2024-03-29,03:00 PM,61.466,16.37,61.934,16.63,1.0882277661389006,31.44112982033702,38.589214514101755,41.42485536848595,36,22,,0.0,0.0,,0.0,0.4274154079269167,0.5,1.0,-0.4679999999999964,-18.037777777777777,42.45919049926977,0.07,0.62,0.0434,2,,,,,,,,,,8.1,,,,b34d3b4b-f06a-4db9-8519-bd72d15ee393,2011-01-01,
+z6-12363,2024-03-30,03:00 PM,64.832,18.239999999999995,64.652,18.14,1.1095598941563143,31.39080881583407,38.504380893125536,41.42015088147906,36,22,,0.0,0.0,,0.0,0.5533114798317066,0.5,1.0,0.1799999999999926,-17.67777777777778,46.67012964766146,0.15,0.62,0.093,4,,,,,,,,,,9.07,,,,4f2c2317-599c-4bf9-9a18-bc44c257c518,2011-01-01,
+z6-12363,2024-03-31,05:00 PM,66.146,18.970000000000002,66.884,19.380000000000003,1.2322677708612333,31.41281027290961,38.3692116430439,41.396639815740244,36,22,,0.0,0.0,,0.0,0.4513974450477104,0.5,1.0,-0.7379999999999995,-18.18777777777778,45.19034668236185,0.12,0.62,0.0744,4,,,,,,,,,,7.130000000000002,,,,8843690e-618b-43bc-b49d-40979b443d22,2011-01-01,
+z6-12363,2024-04-01,05:00 PM,72.464,22.48,72.84200000000001,22.69000000000001,1.727297234218054,31.350006519890393,38.238925751951534,41.368451533315564,36,22,,0.0,0.0,,0.0,0.6498091193326233,0.5,1.0,-0.3780000000000143,-17.987777777777787,37.30994925822381,0.16,0.8,0.128,6,,,,,,,,,,5.150000000000002,,,,dbc3a858-2a38-45df-9875-60b36cb33fc3,2011-01-01,
+z6-12363,2024-04-02,05:00 PM,79.05199999999999,26.139999999999997,77.774,25.43,1.9870241589418798,31.271749992645592,38.0759337041789,41.34029049504973,36,22,,0.0,0.0,,0.0,0.8593896752777268,0.5,1.0,1.2779999999999916,-17.06777777777778,38.823602851858105,0.18,0.8,0.144,7,,,,,,,,,,5.559999999999998,,,,2062a3d2-403a-4211-9c3e-b5d049010492,2011-01-01,
+z6-12363,2024-04-03,03:00 PM,80.78,27.1,79.952,26.64,2.113045286211673,31.306148999433603,37.942954295184265,41.326220184300325,36,22,,0.0,0.0,,0.0,0.8259455739682638,0.5,1.0,0.828000000000003,-17.317777777777778,39.437722560890855,0.18,0.8,0.144,7,,,,,,,,,,7.559999999999999,,,,eed404a1-db25-45f0-ab44-59bc966205a5,2011-01-01,
+z6-12363,2024-04-04,01:00 PM,60.367999999999995,15.759999999999998,59.522,15.29,0.8260551541920033,31.419100395929078,37.827154193308445,41.326220184300325,36,22,,0.0,0.0,,0.0,0.5582327976717012,0.5,1.0,0.8459999999999965,-17.30777777777778,52.41768948426832,0.11,0.8,0.08800000000000001,4,,,,,,,,,,6.940000000000002,,,,4f126e95-87f9-423e-acc3-87839750f497,2011-01-01,
+z6-12363,2024-04-05,12:00 PM,55.49,13.050000000000002,54.32,12.399999999999999,0.6609224682397254,31.125367914085267,37.629841006944446,41.359061494723726,36,22,,0.0,0.0,,0.0,0.5440006145391456,0.5,1.0,1.1700000000000017,-17.127777777777776,54.0682362790366,,0.8,,,,,,,,,,,,4.180000000000001,,,,10ae3d09-343d-409d-875e-1f472f747474,2011-01-01,
+z6-12363,2024-04-06,06:00 PM,63.806000000000004,17.67,64.598,18.11,1.3076422510676342,30.8691897604918,37.20747718324154,41.33090953202982,36,22,,0.0,0.0,,0.0,0.47496133602388824,0.5,1.0,-0.7919999999999945,-18.217777777777776,37.03093296905834,0.15,0.8,0.12,6,,,,,,,,,,1.2900000000000016,,,,cd270117-dd4d-4131-ba6b-5bb370a43c22,2011-01-01,
+z6-12363,2024-04-07,04:00 PM,65.12,18.400000000000002,64.994,18.33,1.3455225159784943,30.561375024939473,36.883330320502374,41.26532738770958,36,22,,0.0,0.0,,0.0,0.6239028214638085,0.5,1.0,0.12600000000000477,-17.707777777777775,36.09555320508207,0.17,0.8,0.136,7,,,,,,,,,,5.289999999999999,,,,9dc10f62-4a02-433f-a957-90405bb5f7c9,2011-01-01,
+z6-12363,2024-04-08,06:00 PM,69.926,21.07,70.73599999999999,21.519999999999996,1.6696887755570193,30.27566916276423,36.524101777013044,41.185890604799354,36,22,,0.0,0.0,,0.0,0.5868605460684452,0.5,1.0,-0.8099999999999881,-18.227777777777774,34.922396221087865,0.18,0.8,0.144,7,,,,,,,,,,2.3599999999999985,,,,8c9aa658-3098-4ff1-a1b0-b1019a5e88fc,2011-01-01,
+z6-12363,2024-04-09,05:00 PM,78.962,26.09,78.872,26.040000000000003,2.405647339039649,30.254760816409167,36.32891534619116,41.13460618781204,36,22,,0.0,0.0,,0.0,0.786875285689114,0.5,1.0,0.09000000000000341,-17.727777777777774,28.565936487706377,0.19,0.8,0.15200000000000002,7,,,,,,,,,,3.75,,,,4d54e0a1-28ab-4b7e-b244-dae712126ef8,2011-01-01,
+z6-12363,2024-04-10,04:00 PM,80.348,26.86,82.976,28.32,2.5765148375363145,40.40791917810225,37.06289653504062,41.08341260868515,36,22,,693.0,11.6,,0.3,0.5938122876984133,0.5,1.0,-2.628,-19.237777777777776,33.069102308350075,0.2,0.8,0.16000000000000003,8,,,,,,,,,,6.470000000000001,,,,c78c10a7-7c85-4213-86e6-90de305efa90,2011-01-01,
Index: weather forecast.csv
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>date,day,order,temp,rh,vpd,icon\r\n2023-06-25,Sun,1,85.6,43.0,2.4,https://i.imgur.com/8enBPX2.gif\r\n2023-06-26,Mon,2,88.3,43.0,2.6,https://i.imgur.com/8enBPX2.gif\r\n2023-06-27,Tue,3,87.7,39.0,2.7,https://i.imgur.com/q9T5REp.gif\r\n2023-06-28,Wed,4,91.2,41.0,2.9,https://i.imgur.com/8enBPX2.gif\r\n2023-06-29,Thu,5,96.2,36.0,3.7,https://i.imgur.com/8enBPX2.gif\r\n2023-06-30,Fri,6,103.2,29.0,5.1,https://i.imgur.com/8enBPX2.gif\r\n2023-07-01,Sat,7,105.7,24.0,5.9,https://i.imgur.com/8enBPX2.gif\r\n2023-07-02,Sun,8,106.5,23.0,6.1,https://i.imgur.com/8enBPX2.gif\r\n2023-07-03,Mon,9,105.4,24.0,5.8,https://i.imgur.com/8enBPX2.gif\r\n2023-07-04,Tue,10,108.8,22.0,6.6,https://i.imgur.com/8enBPX2.gif\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/weather forecast.csv b/weather forecast.csv
--- a/weather forecast.csv	
+++ b/weather forecast.csv	
@@ -1,11 +1,11 @@
 date,day,order,temp,rh,vpd,icon
-2023-06-25,Sun,1,85.6,43.0,2.4,https://i.imgur.com/8enBPX2.gif
-2023-06-26,Mon,2,88.3,43.0,2.6,https://i.imgur.com/8enBPX2.gif
-2023-06-27,Tue,3,87.7,39.0,2.7,https://i.imgur.com/q9T5REp.gif
-2023-06-28,Wed,4,91.2,41.0,2.9,https://i.imgur.com/8enBPX2.gif
-2023-06-29,Thu,5,96.2,36.0,3.7,https://i.imgur.com/8enBPX2.gif
-2023-06-30,Fri,6,103.2,29.0,5.1,https://i.imgur.com/8enBPX2.gif
-2023-07-01,Sat,7,105.7,24.0,5.9,https://i.imgur.com/8enBPX2.gif
-2023-07-02,Sun,8,106.5,23.0,6.1,https://i.imgur.com/8enBPX2.gif
-2023-07-03,Mon,9,105.4,24.0,5.8,https://i.imgur.com/8enBPX2.gif
-2023-07-04,Tue,10,108.8,22.0,6.6,https://i.imgur.com/8enBPX2.gif
+2024-03-29,Fri,1,66.0,53.0,1.0,https://i.imgur.com/CS7hqtE.gif
+2024-03-30,Sat,2,63.3,61.0,0.8,https://i.imgur.com/xPvUxi9.gif
+2024-03-31,Sun,3,64.7,60.0,0.8,https://i.imgur.com/xPvUxi9.gif
+2024-04-01,Mon,4,67.6,61.0,0.9,https://i.imgur.com/8enBPX2.gif
+2024-04-02,Tue,5,75.4,48.0,1.6,https://i.imgur.com/8enBPX2.gif
+2024-04-03,Wed,6,77.5,48.0,1.7,https://i.imgur.com/8enBPX2.gif
+2024-04-04,Thu,7,63.7,53.0,0.9,https://i.imgur.com/q9T5REp.gif
+2024-04-05,Fri,8,57.2,52.0,0.8,https://i.imgur.com/q9T5REp.gif
+2024-04-06,Sat,9,62.1,52.0,0.9,https://i.imgur.com/8enBPX2.gif
+2024-04-07,Sun,10,56.7,60.0,0.6,https://i.imgur.com/q9T5REp.gif
Index: backup.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/backup.py b/backup.py
new file mode 100644
--- /dev/null	
+++ b/backup.py	
@@ -0,0 +1,87 @@
+def write_new_historical_et_to_db_2(dataset_id, table, data, filename="HistoricalET.csv", overwrite=False):
+    """
+    Function writes irr scheduling data into csv then creates a db table from csv given a data table of dates and etos
+
+    :param dataset_id:
+    :param table: The station number
+    :param data: Dictionary of dates and etos
+    :param filename:
+    :param overwrite:
+    """
+    print('\t- writing data to csv')
+    with open(filename, "w", newline='') as outfile:
+        writer = csv.writer(outfile)
+        writer.writerow(data.keys())
+        writer.writerows(zip_longest(*data.values()))
+    print('...Done - file: ' + filename)
+    keys_list = list(data.keys())
+    schema = [
+        bigquery.SchemaField(keys_list[0], "DATE", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[1], "Float", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[2], "DATE", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[3], "Float", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[4], "DATE", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[5], "Float", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[6], "DATE", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[7], "Float", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[8], "DATE", mode="NULLABLE"),
+        bigquery.SchemaField(keys_list[9], "Float", mode="NULLABLE"),
+    ]
+    dbwriter = DBWriter()
+    print("Writing Data to DB")
+    project = 'stomato-info'
+    full_table_id = f'{project}.{dataset_id}.{table}'
+    dbwriter.write_to_table_from_csv(dataset_id, table, filename, schema, project, overwrite=overwrite)
+    dml_statement1 = f'ALTER TABLE {full_table_id} ADD COLUMN Average FLOAT64'
+    dbwriter.run_dml(dml_statement1)
+    dml_statement2 = f'UPDATE {full_table_id} SET Average = ({keys_list[1]} + {keys_list[3]} + {keys_list[5]} + {keys_list[7]} + {keys_list[9]} ) / 5 WHERE True'
+    dbwriter.run_dml(dml_statement2)
+
+def get_historical_data_for_new_station(station: str, years=6):
+    c = CIMIS()
+    current_date = datetime.today()
+    results = {}
+    # Pull 4 years of data from station, one year at a time, starting at 1
+    for year in range(1, years):
+        new_year = current_date.year-year
+        start_date = str(datetime(new_year, 1, 1).date())
+        end_date = str(datetime(new_year, 12, 31).date())
+
+        print(f"Getting historical data for {year} year(s) behind")
+
+        station_data = c.getDictForStation(station, start_date, end_date)
+        results[f'Year_{new_year}'] = station_data["dates"]
+        results[f'Year_{new_year}_ET'] = station_data["eto"]
+
+    return results
+
+def new_et_station_data(etStation: int):
+    """
+    Function creates a new historical ET table for etStation
+    :param etStation: Et Station
+    :param newStation: Boolean if ET Station doesn't exist in DB
+    """
+
+    dataset = "Historical_ET"
+    tables = dbwriter.get_tables("Historical_ET", project="stomato-info")
+    tableFound = False
+    # Loop through existing tables checking to see if Historical ET Table already exists, if not create a new table
+
+    # for table in tables:
+    #     if table.table_id == etStation:
+    #         print('\tFound Historical ET For ET station \n\t\t Overwriting Historical Table')
+    #         print(table.table_id)
+    #         tableFound = True
+        # if not tableFound:
+
+    new_et_results = get_historical_data_for_new_station(str(etStation))
+    Decagon.write_new_historical_et_to_db_2(dataset, str(etStation) + '_test', new_et_results, overwrite=True)
+        # else:
+        #     etDict2022, etDict2021, etDict2020, etDict2019, etDict2018, etDictAverage = returnHistoricalData(
+        #         str(etStation))
+        #     if not tableFound:
+        #         table = client.create_table(table)  # Make an API request.
+        #         print(
+        #             "Created table {}.{}.{}".format(table.project, table.dataset_id, table.table_id)
+        #         )
+    print("Done inserting values")
\ No newline at end of file
Index: portal_data.csv
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>order,field,crop_type,crop_image,soil_moisture_num,soil_moisture_desc,si_num,si_desc,report,preview,logger_name,logger_direction\r\n90,D1,Tomatoes,https://i.imgur.com/yqTglkD.png,29.6,Optimum Moisture,,No Stress Index,https://lookerstudio.google.com/reporting/3a81b33b-a83e-4e8d-b9c5-9db3a09e1d0a,https://i.imgur.com/eyn0tht.png,DI-D1-NE,NE\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/portal_data.csv b/portal_data.csv
--- a/portal_data.csv	
+++ b/portal_data.csv	
@@ -1,2 +1,2 @@
 order,field,crop_type,crop_image,soil_moisture_num,soil_moisture_desc,si_num,si_desc,report,preview,logger_name,logger_direction
-90,D1,Tomatoes,https://i.imgur.com/yqTglkD.png,29.6,Optimum Moisture,,No Stress Index,https://lookerstudio.google.com/reporting/3a81b33b-a83e-4e8d-b9c5-9db3a09e1d0a,https://i.imgur.com/eyn0tht.png,DI-D1-NE,NE
+92,Ladd 4,Tomatoes,https://i.imgur.com/04UdmBH.png,24.9,Very Low Moisture,,No Stress Index,https://i.imgur.com/04UdmBH.png,https://i.imgur.com/04UdmBH.png,JD-L4-SE,NW
Index: Grower.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import uuid\r\n\r\nfrom google.cloud import bigquery\r\n\r\nfrom DBWriter import DBWriter\r\nfrom Notifications import AllNotifications\r\nfrom Technician import Technician\r\n\r\nFIELD_PORTALS_BIGQUERY_PROJECT = 'growers-2024'\r\n\r\n\r\nclass Grower(object):\r\n    \"\"\"\r\n    Class to hold information for a grower\r\n\r\n    Attributes:\r\n            name: String variable to hold the name of the Grower\r\n            email: String variable to hold the grower email for notification purposes\r\n            id: UUID4 unique string id\r\n            fields: A list of Field objects for each Field we have our system in with this grower\r\n    \"\"\"\r\n\r\n    def __init__(self, name: str, fields: list, technician: Technician, email: str, region: str = '',\r\n                 active: bool = True):\r\n        \"\"\"\r\n        Inits Grower class with the following parameters:\r\n\r\n        :param name:\r\n        :param email:\r\n        :param fields:\r\n        :param region:\r\n        \"\"\"\r\n        self.name = name\r\n        self.email = email\r\n        self.portalGSheetURL = ''\r\n        self.id = uuid.uuid4()\r\n        self.fields = fields\r\n        self.region = region\r\n        self.technician = technician\r\n        self.updated = False\r\n        self.active = active\r\n        self.all_notifications = AllNotifications()\r\n\r\n    def __repr__(self):\r\n        return f'Grower: {self.name}, Active: {self.active}, # of Fields: {len(self.fields)}'\r\n\r\n    def check_successful_updated_fields(self):\r\n        successfulFields = 0\r\n        number_of_active_fields, number_of_inactive_fields = self.get_number_of_active_fields()\r\n        for f in self.fields:\r\n            if f.updated and f.active:\r\n                successfulFields = successfulFields + 1\r\n        if successfulFields == number_of_active_fields:\r\n            print(\"All fields for Grower {0} successful! \".format(self.name))\r\n            print(\"{0}/{1}\".format(successfulFields, number_of_active_fields))\r\n            self.updated = True\r\n        else:\r\n            print(\"{0}/{1} fields updated successfully\".format(successfulFields, number_of_active_fields))\r\n            self.updated = False\r\n\r\n    def get_number_of_active_fields(self) -> (int, int):\r\n        active_fields = 0\r\n        inactive_fields = 0\r\n        for field in self.fields:\r\n            if field.active:\r\n                active_fields += 1\r\n            else:\r\n                inactive_fields += 1\r\n        return active_fields, inactive_fields\r\n\r\n    def update(\r\n            self,\r\n            cimis_stations_pickle,\r\n            get_weather: bool = False,\r\n            get_data: bool = False,\r\n            write_to_portal: bool = False,\r\n            write_to_db: bool = False,\r\n            check_for_notifications: bool = False,\r\n            check_updated: bool = False,\r\n            subtract_from_mrid: int = 0\r\n    ):\r\n        \"\"\"\r\n        Function used to update each fields information. This function will be called every day.\r\n        This function then calls the update function on each of its plots[]\r\n\r\n        :param subtract_from_mrid: Int used to subtract a specific amount from the logger MRIDs for API calls\r\n        :param cimis_stations_pickle:\r\n        :param check_updated:\r\n        :param write_to_db:\r\n        :param write_to_portal:\r\n        :param get_et: Boolean that dictates if we want to get the field Et\r\n        :param get_weather: Boolean that dictates if we want to get the fields weather forecast\r\n        :param get_data: Boolean that dictates if we want to get the logger data\r\n        :param check_for_notifications: Boolean that dictates if we want to process notifications\r\n        :return:\r\n        \"\"\"\r\n\r\n        if self.active:\r\n            if self.updated:\r\n                print('\\tGrower: ' + self.name + '  already updated. Skipping...')\r\n            else:\r\n                print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\r\n                print(f'GROWER updating: {str(self.name)} ->')\r\n                print()\r\n\r\n                if write_to_portal:\r\n                    try:\r\n                        print('Setting up Portal Tables')\r\n                        self.setup_portal_tables()\r\n                    except Exception as e:\r\n                        print(\"Error in Grower Update - Setting up Portal Tables\" + self.name)\r\n                        print(\"Error type: \" + str(e))\r\n\r\n                for field in self.fields:\r\n                    field.update(cimis_stations_pickle, get_weather=get_weather, get_data=get_data,\r\n                                 write_to_portal=write_to_portal, write_to_db=write_to_db,\r\n                                 check_for_notifications=check_for_notifications, check_updated=check_updated,\r\n                                 subtract_from_mrid=subtract_from_mrid)\r\n\r\n                self.check_successful_updated_fields()\r\n\r\n                print()\r\n                print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\r\n                print()\r\n        else:\r\n            print('Grower - {} not active'.format(self.name))\r\n            # except Exception as e:\r\n            #     print(\"Error in Grower Update - \" + f.name)\r\n            #     print(\"Error type: \" + str(e))\r\n            #     self.all_notifications.create_error_notification(datetime.now(), f, \"Decagon API Error\")\r\n\r\n    def setup_portal_tables(self):\r\n        dbwriter = DBWriter()\r\n        grower_name = dbwriter.remove_unwanted_chars_for_db_dataset(self.name)\r\n        # Create grower dataset for portal data\r\n        dbwriter.create_dataset(grower_name, project=FIELD_PORTALS_BIGQUERY_PROJECT)\r\n        field_averages_table_exists = dbwriter.check_if_table_exists(\r\n            grower_name, 'field_averages',\r\n            project=FIELD_PORTALS_BIGQUERY_PROJECT\r\n        )\r\n        if not field_averages_table_exists:\r\n            field_averages_table_schema = [\r\n                bigquery.SchemaField(\"order\", \"FLOAT\"),\r\n                bigquery.SchemaField(\"field\", \"STRING\"),\r\n                bigquery.SchemaField(\"crop_type\", \"STRING\"),\r\n                bigquery.SchemaField(\"crop_image\", \"STRING\"),\r\n                bigquery.SchemaField(\"soil_moisture_num\", \"FLOAT\"),\r\n                bigquery.SchemaField(\"soil_moisture_desc\", \"STRING\"),\r\n                bigquery.SchemaField(\"si_num\", \"FLOAT\"),\r\n                bigquery.SchemaField(\"si_desc\", \"STRING\"),\r\n                bigquery.SchemaField(\"report\", \"STRING\"),\r\n                bigquery.SchemaField(\"preview\", \"STRING\")\r\n            ]\r\n            table = dbwriter.create_table(\r\n                grower_name, 'field_averages', field_averages_table_schema,\r\n                project=FIELD_PORTALS_BIGQUERY_PROJECT\r\n            )\r\n\r\n        loggers_table_exists = dbwriter.check_if_table_exists(\r\n            grower_name, 'loggers',\r\n            project=FIELD_PORTALS_BIGQUERY_PROJECT\r\n        )\r\n        if not loggers_table_exists:\r\n            loggers_table_schema = [\r\n                bigquery.SchemaField(\"order\", \"FLOAT\"),\r\n                bigquery.SchemaField(\"field\", \"STRING\"),\r\n                bigquery.SchemaField(\"crop_type\", \"STRING\"),\r\n                bigquery.SchemaField(\"crop_image\", \"STRING\"),\r\n                bigquery.SchemaField(\"soil_moisture_num\", \"FLOAT\"),\r\n                bigquery.SchemaField(\"soil_moisture_desc\", \"STRING\"),\r\n                bigquery.SchemaField(\"si_num\", \"FLOAT\"),\r\n                bigquery.SchemaField(\"si_desc\", \"STRING\"),\r\n                bigquery.SchemaField(\"report\", \"STRING\"),\r\n                bigquery.SchemaField(\"preview\", \"STRING\"),\r\n                bigquery.SchemaField(\"logger_name\", \"STRING\"),\r\n                bigquery.SchemaField(\"logger_direction\", \"STRING\")\r\n            ]\r\n            table = dbwriter.create_table(\r\n                grower_name, 'loggers', loggers_table_schema,\r\n                project=FIELD_PORTALS_BIGQUERY_PROJECT\r\n            )\r\n\r\n    def to_string(self, include_fields: bool = True):\r\n        \"\"\"\r\n        Function used to print out output to screen. Prints out the Plot type.\r\n        Then this calls on its loggers list and has each object in the list call its own toString function\r\n        :return:\r\n        \"\"\"\r\n        tech_str = f'Tech: {str(self.technician.name)}'\r\n        region_str = f'Region: {self.region}'\r\n        print()\r\n        print(\r\n            '*****************************************************************************************************************************'\r\n        )\r\n        print(f'\\tGrower: {self.name}')\r\n        print(f'\\t{tech_str:40} | Active: {str(self.active)}')\r\n        print(f'\\t{region_str:40} | Updated: {str(self.updated)}')\r\n        print()\r\n        if include_fields:\r\n            for f in self.fields:\r\n                f.to_string()\r\n\r\n    def deactivate(self):\r\n        print('Deactivating Grower {}...'.format(self.name))\r\n        self.active = False\r\n        for field in self.fields:\r\n            field.deactivate()\r\n        print('Done')\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Grower.py b/Grower.py
--- a/Grower.py	
+++ b/Grower.py	
@@ -45,6 +45,10 @@
         return f'Grower: {self.name}, Active: {self.active}, # of Fields: {len(self.fields)}'
 
     def check_successful_updated_fields(self):
+        """
+        Function used to check if we've successfully updated all active fields
+        :return:
+        """
         successfulFields = 0
         number_of_active_fields, number_of_inactive_fields = self.get_number_of_active_fields()
         for f in self.fields:
@@ -59,6 +63,10 @@
             self.updated = False
 
     def get_number_of_active_fields(self) -> (int, int):
+        """
+        Function used to count and return a tuple of active and inactive fields
+        :return:
+        """
         active_fields = 0
         inactive_fields = 0
         for field in self.fields:
@@ -88,7 +96,6 @@
         :param check_updated:
         :param write_to_db:
         :param write_to_portal:
-        :param get_et: Boolean that dictates if we want to get the field Et
         :param get_weather: Boolean that dictates if we want to get the fields weather forecast
         :param get_data: Boolean that dictates if we want to get the logger data
         :param check_for_notifications: Boolean that dictates if we want to process notifications
@@ -130,6 +137,11 @@
             #     self.all_notifications.create_error_notification(datetime.now(), f, "Decagon API Error")
 
     def setup_portal_tables(self):
+        """
+        Function used to set up the grower's fields portal. Called before the fields update
+
+        :return:
+        """
         dbwriter = DBWriter()
         grower_name = dbwriter.remove_unwanted_chars_for_db_dataset(self.name)
         # Create grower dataset for portal data
@@ -151,7 +163,7 @@
                 bigquery.SchemaField("report", "STRING"),
                 bigquery.SchemaField("preview", "STRING")
             ]
-            table = dbwriter.create_table(
+            dbwriter.create_table(
                 grower_name, 'field_averages', field_averages_table_schema,
                 project=FIELD_PORTALS_BIGQUERY_PROJECT
             )
@@ -175,7 +187,7 @@
                 bigquery.SchemaField("logger_name", "STRING"),
                 bigquery.SchemaField("logger_direction", "STRING")
             ]
-            table = dbwriter.create_table(
+            dbwriter.create_table(
                 grower_name, 'loggers', loggers_table_schema,
                 project=FIELD_PORTALS_BIGQUERY_PROJECT
             )
@@ -201,6 +213,10 @@
                 f.to_string()
 
     def deactivate(self):
+        """
+        Function used to deactivate a grower and its associated fields
+        :return:
+        """
         print('Deactivating Grower {}...'.format(self.name))
         self.active = False
         for field in self.fields:
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project version=\"4\">\r\n  <component name=\"AnalysisUIOptions\">\r\n    <option name=\"SCOPE_TYPE\" value=\"3\" />\r\n  </component>\r\n  <component name=\"AutoImportSettings\">\r\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\r\n  </component>\r\n  <component name=\"ChangeListManager\">\r\n    <list default=\"true\" id=\"3aa7c90b-1f87-403f-bac4-0b49ed107be9\" name=\"Default\" comment=\"VP4 Notification Changes&#10;&#10;Simplified vp4 notifications into 1 single method to handle air temp, rh, and vpd notifications. This allows us to just create a single notification if any of those are None instead of one for each type since it is almost never the case that just 1 fails.&#10;New method is called vp4_notifications.&#10;Removed old individual methods for air temp notifications, rh notifications, and vpd notifications.&#10;Formatting changes.\">\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/misc.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/misc.xml\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/CimisUpdate.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/CimisUpdate.py\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/Decagon.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/Decagon.py\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/ai_data.csv\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/ai_data.csv\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/all et.csv\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/all et.csv\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/data.csv\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/data.csv\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/irrScheduling.csv\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/irrScheduling.csv\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/portal_data.csv\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/portal_data.csv\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/weather forecast.csv\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/weather forecast.csv\" afterDir=\"false\" />\r\n    </list>\r\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\r\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\r\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\r\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\r\n  </component>\r\n  <component name=\"CreatePatchCommitExecutor\">\r\n    <option name=\"PATCH_PATH\" value=\"\" />\r\n  </component>\r\n  <component name=\"FileTemplateManagerImpl\">\r\n    <option name=\"RECENT_TEMPLATES\">\r\n      <list>\r\n        <option value=\"Python Script\" />\r\n      </list>\r\n    </option>\r\n  </component>\r\n  <component name=\"FindInProjectRecents\">\r\n    <findStrings>\r\n      <find>IN LOGGER</find>\r\n      <find>delete</find>\r\n      <find>vwc 36</find>\r\n      <find>failed_cimis.pickle</find>\r\n      <find>SB-140</find>\r\n      <find>'Final results</find>\r\n      <find>Final</find>\r\n      <find>Results</find>\r\n      <find>vp4_connected</find>\r\n      <find>MODEL</find>\r\n      <find>Grower</find>\r\n      <find>Nothing new</find>\r\n      <find>Converting</find>\r\n      <find>JK</find>\r\n      <find>Switch</find>\r\n      <find>prev_day_minutes</find>\r\n      <find>switch</find>\r\n      <find>OPC112</find>\r\n      <find>get_swi</find>\r\n      <find>OPCN2</find>\r\n      <find>get_sw</find>\r\n      <find>TP</find>\r\n      <find>F&amp;S</find>\r\n      <find>get_switch</find>\r\n      <find>TeixeiraR34</find>\r\n      <find>Ochoa</find>\r\n      <find>Carvalho342</find>\r\n      <find>DohertyD3</find>\r\n      <find>QuadH2</find>\r\n      <find>CM</find>\r\n    </findStrings>\r\n  </component>\r\n  <component name=\"Git.Merge.Settings\">\r\n    <option name=\"BRANCH\" value=\"origin/master\" />\r\n  </component>\r\n  <component name=\"Git.Rebase.Settings\">\r\n    <option name=\"NEW_BASE\" value=\"master\" />\r\n  </component>\r\n  <component name=\"Git.Settings\">\r\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\r\n      <map>\r\n        <entry key=\"$PROJECT_DIR$\" value=\"master\" />\r\n      </map>\r\n    </option>\r\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\r\n  </component>\r\n  <component name=\"GitSEFilterConfiguration\">\r\n    <file-type-list>\r\n      <filtered-out-file-type name=\"LOCAL_BRANCH\" />\r\n      <filtered-out-file-type name=\"REMOTE_BRANCH\" />\r\n      <filtered-out-file-type name=\"TAG\" />\r\n      <filtered-out-file-type name=\"COMMIT_BY_MESSAGE\" />\r\n    </file-type-list>\r\n  </component>\r\n  <component name=\"HighlightingSettingsPerFile\">\r\n    <setting file=\"mock:///\" root0=\"FORCE_HIGHLIGHTING\" />\r\n  </component>\r\n  <component name=\"JupyterTrust\" id=\"a5593add-7099-434b-9a5f-e365579fda73\" />\r\n  <component name=\"MarkdownSettingsMigration\">\r\n    <option name=\"stateVersion\" value=\"1\" />\r\n  </component>\r\n  <component name=\"ProblemsViewState\">\r\n    <option name=\"selectedIndex\" value=\"2\" />\r\n  </component>\r\n  <component name=\"ProjectFrameBounds\">\r\n    <option name=\"x\" value=\"-8\" />\r\n    <option name=\"y\" value=\"-8\" />\r\n    <option name=\"width\" value=\"1936\" />\r\n    <option name=\"height\" value=\"1100\" />\r\n  </component>\r\n  <component name=\"ProjectId\" id=\"1aMD9QCNddDn0kzcajQ5kQOkEBT\" />\r\n  <component name=\"ProjectLevelVcsManager\">\r\n    <ConfirmationsSetting value=\"2\" id=\"Add\" />\r\n  </component>\r\n  <component name=\"ProjectViewState\">\r\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\r\n    <option name=\"showLibraryContents\" value=\"true\" />\r\n  </component>\r\n  <component name=\"PropertiesComponent\">{\r\n  &quot;keyToString&quot;: {\r\n    &quot;WebServerToolWindowFactoryState&quot;: &quot;false&quot;,\r\n    &quot;git-widget-placeholder&quot;: &quot;master&quot;,\r\n    &quot;ignore.virus.scanning.warn.message&quot;: &quot;true&quot;,\r\n    &quot;last_opened_file_path&quot;: &quot;C:/Users/javie/PycharmProjects/Stomato&quot;,\r\n    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,\r\n    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,\r\n    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,\r\n    &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,\r\n    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,\r\n    &quot;settings.editor.selected.configurable&quot;: &quot;configurable.group.language&quot;,\r\n    &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;\r\n  }\r\n}</component>\r\n  <component name=\"PyConsoleOptionsProvider\">\r\n    <option name=\"myPythonConsoleState\">\r\n      <console-settings module-name=\"Stomato\" is-module-sdk=\"true\">\r\n        <option name=\"myUseModuleSdk\" value=\"true\" />\r\n        <option name=\"myModuleName\" value=\"Stomato\" />\r\n      </console-settings>\r\n    </option>\r\n  </component>\r\n  <component name=\"PyDebuggerOptionsProvider\">\r\n    <option name=\"mySupportGeventDebugging\" value=\"true\" />\r\n  </component>\r\n  <component name=\"RecentsManager\">\r\n    <key name=\"CopyFile.RECENT_KEYS\">\r\n      <recent name=\"C:\\Users\\javie\\PycharmProjects\\Stomato\" />\r\n      <recent name=\"C:\\Users\\javie\\Projects\\S-TOMAto\" />\r\n      <recent name=\"C:\\Users\\Javier\\Documents\\Stomato\" />\r\n    </key>\r\n    <key name=\"MoveFile.RECENT_KEYS\">\r\n      <recent name=\"C:\\Users\\javie\\PycharmProjects\\Stomato\\Logos\" />\r\n      <recent name=\"C:\\Users\\javie\\PycharmProjects\\Stomato\\AIGame\" />\r\n      <recent name=\"C:\\Users\\javie\\PycharmProjects\\Stomato\\AI Game\" />\r\n      <recent name=\"C:\\Users\\javie\\Projects\\S-TOMAto\" />\r\n      <recent name=\"C:\\Users\\javie\\Projects\\S-TOMAto\\ssl\" />\r\n    </key>\r\n  </component>\r\n  <component name=\"RunManager\" selected=\"Python.Decagon\">\r\n    <configuration default=\"true\" type=\"tests\" factoryName=\"Attests\">\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs />\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <module name=\"Stomato\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"\" />\r\n      <option name=\"CLASS_NAME\" value=\"\" />\r\n      <option name=\"METHOD_NAME\" value=\"\" />\r\n      <option name=\"FOLDER_NAME\" value=\"\" />\r\n      <option name=\"TEST_TYPE\" value=\"TEST_SCRIPT\" />\r\n      <option name=\"PATTERN\" value=\"\" />\r\n      <option name=\"USE_PATTERN\" value=\"false\" />\r\n      <method />\r\n    </configuration>\r\n    <configuration name=\"AIIrrigationGameV3 (2)\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\r\n      <module name=\"Stomato\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs>\r\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\r\n      </envs>\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$/AI Game\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/AI Game/AIIrrigationGameV3.py\" />\r\n      <option name=\"PARAMETERS\" value=\"\" />\r\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\r\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\r\n      <option name=\"MODULE_MODE\" value=\"false\" />\r\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\r\n      <option name=\"INPUT_FILE\" value=\"\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration name=\"AIIrrigationGameV3 (3)\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\r\n      <module name=\"Stomato\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs>\r\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\r\n      </envs>\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$/AIGame\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/AIGame/AIIrrigationGameV3.py\" />\r\n      <option name=\"PARAMETERS\" value=\"\" />\r\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\r\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\r\n      <option name=\"MODULE_MODE\" value=\"false\" />\r\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\r\n      <option name=\"INPUT_FILE\" value=\"\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration name=\"AIIrrigationGameV3 (4)\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\r\n      <module name=\"Stomato\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs>\r\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\r\n      </envs>\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/AIIrrigationGameV3.py\" />\r\n      <option name=\"PARAMETERS\" value=\"\" />\r\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\r\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\r\n      <option name=\"MODULE_MODE\" value=\"false\" />\r\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\r\n      <option name=\"INPUT_FILE\" value=\"\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration name=\"Decagon\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\r\n      <module name=\"Stomato\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs>\r\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\r\n      </envs>\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/Decagon.py\" />\r\n      <option name=\"PARAMETERS\" value=\"\" />\r\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\r\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\r\n      <option name=\"MODULE_MODE\" value=\"false\" />\r\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\r\n      <option name=\"INPUT_FILE\" value=\"\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration name=\"HeatUnits\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\r\n      <module name=\"Stomato\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs>\r\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\r\n      </envs>\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/HeatUnits.py\" />\r\n      <option name=\"PARAMETERS\" value=\"\" />\r\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\r\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\r\n      <option name=\"MODULE_MODE\" value=\"false\" />\r\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\r\n      <option name=\"INPUT_FILE\" value=\"\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration default=\"true\" type=\"tests\" factoryName=\"Nosetests\">\r\n      <module name=\"Stomato\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"_new_regexPattern\" value=\"&quot;&quot;\" />\r\n      <option name=\"_new_additionalArguments\" value=\"&quot;&quot;\" />\r\n      <option name=\"_new_target\" value=\"&quot;.&quot;\" />\r\n      <option name=\"_new_targetType\" value=\"&quot;PATH&quot;\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration default=\"true\" type=\"tests\" factoryName=\"Unittests\">\r\n      <module name=\"Stomato\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"_new_additionalArguments\" value=\"&quot;&quot;\" />\r\n      <option name=\"_new_target\" value=\"&quot;.&quot;\" />\r\n      <option name=\"_new_targetType\" value=\"&quot;PATH&quot;\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration default=\"true\" type=\"tests\" factoryName=\"py.test\">\r\n      <module name=\"Stomato\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"_new_keywords\" value=\"&quot;&quot;\" />\r\n      <option name=\"_new_parameters\" value=\"&quot;&quot;\" />\r\n      <option name=\"_new_additionalArguments\" value=\"&quot;&quot;\" />\r\n      <option name=\"_new_target\" value=\"&quot;.&quot;\" />\r\n      <option name=\"_new_targetType\" value=\"&quot;PATH&quot;\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <list>\r\n      <item itemvalue=\"Python.HeatUnits\" />\r\n      <item itemvalue=\"Python.AIIrrigationGameV3 (2)\" />\r\n      <item itemvalue=\"Python.AIIrrigationGameV3 (3)\" />\r\n      <item itemvalue=\"Python.AIIrrigationGameV3 (4)\" />\r\n      <item itemvalue=\"Python.Decagon\" />\r\n    </list>\r\n    <recent_temporary>\r\n      <list>\r\n        <item itemvalue=\"Python.Decagon\" />\r\n        <item itemvalue=\"Python.HeatUnits\" />\r\n        <item itemvalue=\"Python.AIIrrigationGameV3 (4)\" />\r\n        <item itemvalue=\"Python.AIIrrigationGameV3 (3)\" />\r\n        <item itemvalue=\"Python.AIIrrigationGameV3 (2)\" />\r\n      </list>\r\n    </recent_temporary>\r\n  </component>\r\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"project-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\r\n  <component name=\"SvnConfiguration\">\r\n    <configuration />\r\n  </component>\r\n  <component name=\"TaskManager\">\r\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\r\n      <changelist id=\"3aa7c90b-1f87-403f-bac4-0b49ed107be9\" name=\"Default\" comment=\"\" />\r\n      <created>1487028217187</created>\r\n      <option name=\"number\" value=\"Default\" />\r\n      <option name=\"presentableId\" value=\"Default\" />\r\n      <updated>1487028217187</updated>\r\n      <workItem from=\"1605129884620\" duration=\"145000\" />\r\n      <workItem from=\"1605130060530\" duration=\"35278000\" />\r\n      <workItem from=\"1607291245080\" duration=\"1190000\" />\r\n      <workItem from=\"1607383244511\" duration=\"7553000\" />\r\n      <workItem from=\"1607548979078\" duration=\"3754000\" />\r\n      <workItem from=\"1607553651418\" duration=\"17118000\" />\r\n      <workItem from=\"1607689891059\" duration=\"5504000\" />\r\n      <workItem from=\"1608060424541\" duration=\"58636000\" />\r\n      <workItem from=\"1610149124892\" duration=\"6211000\" />\r\n      <workItem from=\"1610537327787\" duration=\"40054000\" />\r\n      <workItem from=\"1611488172733\" duration=\"31888000\" />\r\n      <workItem from=\"1612440711302\" duration=\"17240000\" />\r\n      <workItem from=\"1612561663001\" duration=\"4655000\" />\r\n      <workItem from=\"1612830453536\" duration=\"11311000\" />\r\n      <workItem from=\"1613080557188\" duration=\"4065000\" />\r\n      <workItem from=\"1613618833495\" duration=\"2149000\" />\r\n      <workItem from=\"1613666950983\" duration=\"7717000\" />\r\n      <workItem from=\"1614009600471\" duration=\"2019000\" />\r\n      <workItem from=\"1614291091396\" duration=\"1511000\" />\r\n      <workItem from=\"1614364207160\" duration=\"2001000\" />\r\n      <workItem from=\"1614617953355\" duration=\"2152000\" />\r\n      <workItem from=\"1614703156595\" duration=\"3174000\" />\r\n      <workItem from=\"1614957784121\" duration=\"2410000\" />\r\n      <workItem from=\"1615206260553\" duration=\"50000\" />\r\n      <workItem from=\"1615218696486\" duration=\"1074000\" />\r\n      <workItem from=\"1615220753729\" duration=\"1867000\" />\r\n      <workItem from=\"1615310497153\" duration=\"3925000\" />\r\n      <workItem from=\"1615388232435\" duration=\"182000\" />\r\n      <workItem from=\"1615389899479\" duration=\"785000\" />\r\n      <workItem from=\"1615399895663\" duration=\"2323000\" />\r\n      <workItem from=\"1615419143099\" duration=\"1002000\" />\r\n      <workItem from=\"1617013211354\" duration=\"48204000\" />\r\n      <workItem from=\"1617748132407\" duration=\"26135000\" />\r\n      <workItem from=\"1617905241291\" duration=\"110000\" />\r\n      <workItem from=\"1617905461958\" duration=\"36062000\" />\r\n      <workItem from=\"1618392723430\" duration=\"183894000\" />\r\n      <workItem from=\"1620643821048\" duration=\"7864000\" />\r\n      <workItem from=\"1620819109173\" duration=\"59413000\" />\r\n      <workItem from=\"1621674236561\" duration=\"35814000\" />\r\n      <workItem from=\"1622641636696\" duration=\"31255000\" />\r\n      <workItem from=\"1623104726201\" duration=\"8910000\" />\r\n      <workItem from=\"1623305121076\" duration=\"49475000\" />\r\n      <workItem from=\"1624525983019\" duration=\"11946000\" />\r\n      <workItem from=\"1624926747360\" duration=\"8702000\" />\r\n      <workItem from=\"1625267760339\" duration=\"9175000\" />\r\n      <workItem from=\"1625667908177\" duration=\"3489000\" />\r\n      <workItem from=\"1626141654181\" duration=\"760000\" />\r\n      <workItem from=\"1626304184251\" duration=\"17573000\" />\r\n      <workItem from=\"1627179918020\" duration=\"6000000\" />\r\n      <workItem from=\"1627522193589\" duration=\"44463000\" />\r\n      <workItem from=\"1628685253434\" duration=\"7562000\" />\r\n      <workItem from=\"1628895996797\" duration=\"5405000\" />\r\n      <workItem from=\"1629519094001\" duration=\"64107000\" />\r\n      <workItem from=\"1630820604906\" duration=\"81000\" />\r\n      <workItem from=\"1630972145933\" duration=\"13068000\" />\r\n      <workItem from=\"1631043208174\" duration=\"40657000\" />\r\n      <workItem from=\"1631675344538\" duration=\"39881000\" />\r\n      <workItem from=\"1632483008669\" duration=\"62634000\" />\r\n      <workItem from=\"1633561848284\" duration=\"20514000\" />\r\n      <workItem from=\"1634071114758\" duration=\"29042000\" />\r\n      <workItem from=\"1634205505386\" duration=\"760000\" />\r\n      <workItem from=\"1634508447986\" duration=\"46186000\" />\r\n      <workItem from=\"1635563392486\" duration=\"7946000\" />\r\n      <workItem from=\"1635813530050\" duration=\"11275000\" />\r\n      <workItem from=\"1636402837909\" duration=\"7978000\" />\r\n      <workItem from=\"1636686576193\" duration=\"72544000\" />\r\n      <workItem from=\"1639623090539\" duration=\"597000\" />\r\n      <workItem from=\"1641862430443\" duration=\"10031000\" />\r\n      <workItem from=\"1642109259317\" duration=\"14670000\" />\r\n      <workItem from=\"1642468081345\" duration=\"123000\" />\r\n      <workItem from=\"1642468312662\" duration=\"4400000\" />\r\n      <workItem from=\"1642479890801\" duration=\"3012000\" />\r\n      <workItem from=\"1642607098853\" duration=\"3509000\" />\r\n      <workItem from=\"1643418289163\" duration=\"2451000\" />\r\n      <workItem from=\"1643431775486\" duration=\"2669000\" />\r\n      <workItem from=\"1643530688030\" duration=\"16607000\" />\r\n      <workItem from=\"1644884974706\" duration=\"6976000\" />\r\n      <workItem from=\"1645051866051\" duration=\"4965000\" />\r\n      <workItem from=\"1646170191631\" duration=\"1143000\" />\r\n      <workItem from=\"1647030210662\" duration=\"20674000\" />\r\n      <workItem from=\"1647899848340\" duration=\"8878000\" />\r\n      <workItem from=\"1648605161943\" duration=\"602000\" />\r\n      <workItem from=\"1648677498393\" duration=\"17335000\" />\r\n      <workItem from=\"1649028728369\" duration=\"62000\" />\r\n      <workItem from=\"1649028799373\" duration=\"41714000\" />\r\n      <workItem from=\"1649296707874\" duration=\"1532000\" />\r\n      <workItem from=\"1649715253762\" duration=\"16105000\" />\r\n      <workItem from=\"1650672932583\" duration=\"3495000\" />\r\n      <workItem from=\"1650676711602\" duration=\"124000\" />\r\n      <workItem from=\"1650676849444\" duration=\"23979000\" />\r\n      <workItem from=\"1652287991235\" duration=\"4330000\" />\r\n      <workItem from=\"1652475327231\" duration=\"59000\" />\r\n      <workItem from=\"1652475415424\" duration=\"26422000\" />\r\n      <workItem from=\"1654114664338\" duration=\"37311000\" />\r\n      <workItem from=\"1655238921783\" duration=\"2997000\" />\r\n      <workItem from=\"1655836574428\" duration=\"18511000\" />\r\n      <workItem from=\"1656846376891\" duration=\"4630000\" />\r\n      <workItem from=\"1657690237491\" duration=\"11380000\" />\r\n      <workItem from=\"1660709759094\" duration=\"1304000\" />\r\n      <workItem from=\"1663715527866\" duration=\"58524000\" />\r\n      <workItem from=\"1673917023959\" duration=\"24211000\" />\r\n      <workItem from=\"1677103677259\" duration=\"7166000\" />\r\n      <workItem from=\"1678912269971\" duration=\"22450000\" />\r\n      <workItem from=\"1679515676906\" duration=\"53089000\" />\r\n      <workItem from=\"1680132841035\" duration=\"65000\" />\r\n      <workItem from=\"1680132918916\" duration=\"137000\" />\r\n      <workItem from=\"1680133083506\" duration=\"16881000\" />\r\n      <workItem from=\"1680238363154\" duration=\"166000\" />\r\n      <workItem from=\"1680238880050\" duration=\"5824000\" />\r\n      <workItem from=\"1680553460768\" duration=\"645000\" />\r\n      <workItem from=\"1680556381530\" duration=\"857000\" />\r\n      <workItem from=\"1680557253511\" duration=\"980000\" />\r\n      <workItem from=\"1680558257466\" duration=\"32869000\" />\r\n      <workItem from=\"1680818886482\" duration=\"161344000\" />\r\n      <workItem from=\"1683923672560\" duration=\"108547000\" />\r\n      <workItem from=\"1684964327889\" duration=\"11711000\" />\r\n      <workItem from=\"1685127366248\" duration=\"81133000\" />\r\n      <workItem from=\"1685653445940\" duration=\"10983000\" />\r\n      <workItem from=\"1685740244204\" duration=\"56272000\" />\r\n      <workItem from=\"1686272407325\" duration=\"16994000\" />\r\n      <workItem from=\"1686693323310\" duration=\"23345000\" />\r\n      <workItem from=\"1686855364679\" duration=\"18047000\" />\r\n      <workItem from=\"1686875965074\" duration=\"6029000\" />\r\n    </task>\r\n    <task id=\"LOCAL-00297\" summary=\"Fixed Emails&#10;&#10;Emailing wasn't working past the first recipient. Fixed it now\">\r\n      <created>1681780581866</created>\r\n      <option name=\"number\" value=\"00297\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00297\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1681780581866</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00298\" summary=\"BigQuery Credentials Changes&#10;&#10;Changed how we get credentials for bigquery clients by setting a credentials parameter from the path of the json credentials\">\r\n      <created>1681946889382</created>\r\n      <option name=\"number\" value=\"00298\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00298\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1681946889382</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00299\" summary=\"IrrigationRecommendationExpert.py Crop Stage Changes&#10;&#10;Added an else clause in case the crop_stage cannot be determined by fitting the date between each stage range\">\r\n      <created>1681946997337</created>\r\n      <option name=\"number\" value=\"00299\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00299\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1681946997337</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00300\" summary=\"AI Function Changes&#10;&#10;Changed setup_ai_game_data so it grabs lat, long, and planting date and adds those to the tuple so we don't need to access the pickle&#10;Added funtion turn_ai_game_data_into_csv to grab ai_game_data and create a csv for it to be used by the Neural Net imports\">\r\n      <created>1681947144677</created>\r\n      <option name=\"number\" value=\"00300\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00300\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1681947144677</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00301\" summary=\"AIExpertSystemTesting.py Changes&#10;&#10;Reworked a bunch of the AI game to have a more modern look and be cleaner. Also made some changes required for the .exe packager\">\r\n      <created>1681947238632</created>\r\n      <option name=\"number\" value=\"00301\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00301\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1681947238632</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00302\" summary=\"Testing lines removed\">\r\n      <created>1681947311832</created>\r\n      <option name=\"number\" value=\"00302\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00302\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1681947311832</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00303\" summary=\"Soils&#10;&#10;Added Soils.py which contains 2 classes, AllSoils and Soil.&#10;Soil will now be the class that Logger instantiates to have a soil associated with it. &#10;Soil has soil_type, field_capacity, and wilting_point among other useful variables and functions.&#10;AllSoils is just a static class to hold all of the different soil types we use to be able to play with them and generate graphs and other things.&#10;Modified all use cases of logger.field_capacity and logger.wilting_point to now utilize logger.soil.field_capacity and logger.soil.wilting_point.\">\r\n      <created>1683067787052</created>\r\n      <option name=\"number\" value=\"00303\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00303\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1683067787052</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00304\" summary=\"Bugfix&#10;&#10;Fixed bug with calculate_portal_soil_moisture_desc() that was causing Silty Clay Loam to return low for the  wrong range of values\">\r\n      <created>1683785761195</created>\r\n      <option name=\"number\" value=\"00304\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00304\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1683785761195</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00305\" summary=\"Pickle Function Changes&#10;&#10;Removed redundant &quot;specific&quot; pickle functions like write_specific_pickle and instead modified the regular pickle functions to use optional parameters.&#10;Modified all uses of &quot;specific&quot; pickle functions to use regular functions with optional parameters\">\r\n      <created>1683786623261</created>\r\n      <option name=\"number\" value=\"00305\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00305\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1683786623261</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00306\" summary=\"Reworked grabbing data from dxd's&#10;&#10;We now loop through all applicable timeseries in a dxd to grab the data we care about instead of just assuming the data we want is in the last timeseries.&#10;Moved getting ports information out of read_dxd(). We now call it separately and don't assign the ports to as a Logger variable but instead a temporary variable.&#10;Added specific checks to select a timeseries that we care about. We now check if it has data from the year we are interested, if it has ports 1-6 configured, if port 1 is IR, port 2 VP4, and so on.&#10;get_ports() now takes a timeseries instead of a dxd. Don't need to read the dxd twice. We now read once and pass along to whatever function needs it&#10;Put all the timestamp converting functions into one function called convert_timestamp_to_local_datetime() which now handles calling the appropriate functions in order.&#10;Added a new function to Logger called set_broken() to be used for when a logger is replaced. This will set the appropriate parameters so the Logger stays in the Field but is inactive. This way we know the logger was installed in that field at some point.&#10;Added self.uninstall_date = None to Loggers __init__\">\r\n      <created>1683787119552</created>\r\n      <option name=\"number\" value=\"00306\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00306\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1683787119552</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00307\" summary=\"YearAnalysis.py changes.&#10;&#10;Added optional parameters to analyze_year() so you can specify what analysis you want to run as well as if you want to graph_data, save_new_pickle, or grab_data_from_pickle instead of dxds.&#10;Passed on appropriate optional parameters to analyze_logger(). &#10;Added a couple of checks for 2 logger ids that we know are garbage from 2022.&#10;Other changes\">\r\n      <created>1683787329352</created>\r\n      <option name=\"number\" value=\"00307\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00307\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1683787329352</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00308\" summary=\"AI Expert Game Changes&#10;&#10;Added scroll bar to the main game by creating a canvas and putthing the frames inside.&#10;Attempting to add keybinding for Enter key to buttons in each Phase so the game can be played without mouse. Work in progress\">\r\n      <created>1683787413796</created>\r\n      <option name=\"number\" value=\"00308\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00308\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1683787413796</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00309\" summary=\"Portal Soil Description Calculation Changes&#10;&#10;Modified CwsiProcessor.py function calculate_portal_soil_moisture() to use an instance of the Soil class to get the vwc range description. This moves the logic to the Soil class where it should be.&#10;Removed redundant functions soil_type_lookup() and find_closest_soil_type()\">\r\n      <created>1683934778406</created>\r\n      <option name=\"number\" value=\"00309\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00309\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1683934778407</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00310\" summary=\"Decagon test code&#10;&#10;Modified some test code for going through a pickle and assigning a Soil to each logger\">\r\n      <created>1683934842420</created>\r\n      <option name=\"number\" value=\"00310\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00310\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1683934842420</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00311\" summary=\"Formatting Cleanup\">\r\n      <created>1683934866605</created>\r\n      <option name=\"number\" value=\"00311\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00311\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1683934866605</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00312\" summary=\"Soils.py Changes&#10;&#10;Cleaned up the graph function of AllSoils to simplify color allocation and account for new ranges we defined.&#10;Modified constants in Soil.py to now have VERY_LOW, BELOW_OPT and VERY_HIGH.&#10;Modified type hinting for field_capacity and wilting_point throughout functions in Soil.py to account for cases where field capacity and wilting point aren't clean ints (like in the case of a soil type that falls in between 2 types).&#10;Modified Soil.py's vwc ranges and their functions to incorporate new below_optimum and modified very_low, high, and very_high.&#10;Made some functions static.&#10;Modified find_vwc_range_description() to incorporate the new ranges.\">\r\n      <created>1683935136026</created>\r\n      <option name=\"number\" value=\"00312\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00312\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1683935136026</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00313\" summary=\"Logos&#10;&#10;Added the Gradient and Morning Star Logos for use in AI Irrgation Game\">\r\n      <created>1684372405467</created>\r\n      <option name=\"number\" value=\"00313\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00313\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1684372405467</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00314\" summary=\"Print Statement Rearrangement&#10;&#10;Moved some print statements from CwsiProcessor.py to the Logger update function. That way we can call the CwsiProcessor.py functions without needing to print certain information.&#10;Added an optional boolean parameter to get_highest_and_lowest_temperature_indexes() called mute_prints that allows the use of the function without printing anything by passing in True.\">\r\n      <created>1684372577908</created>\r\n      <option name=\"number\" value=\"00314\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00314\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1684372577908</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00315\" summary=\"IR Active Logic&#10;&#10;Moved the ir_active check to after values have been assigned in final_results(). That way we still get the values and can then just decide if we append them to the return dictionary or not. This allows us to use those values to do some checks.&#10;Added a call to logger.update_ir_consecutive_data() that handles the 3 consecutive days of PSI data required to turn on the PSI values for a logger.\">\r\n      <created>1684372746988</created>\r\n      <option name=\"number\" value=\"00315\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00315\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1684372746988</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00316\" summary=\"New function to compare IR data&#10;&#10;Added compare_new_psi_algo_vs_old() that goes through a pickle with 2022 data and a pickle with re-processed 2022 data (using new PSI algorithm) and compares how close the new algorithm guessed the activation date for PSI.\">\r\n      <created>1684372836684</created>\r\n      <option name=\"number\" value=\"00316\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00316\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1684372836684</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00317\" summary=\"New IR Active Logic &#10;&#10;New import for deque from collections.&#10;Added self.consecutive_ir_values = deque() to a Logger's _init_ function.&#10;Went back and added the same deque to older Loggers already instantiated.&#10;Moved the check if IR should be active out of Logger's update and into CWSI final_results().&#10;Moved some print statements from CwsiProcessor.py to Logger update function.&#10;Refactored should_ir_be_active() to take in an optional parameter for the date you are checking. This way we can pass in the actual date we care about instead of assuming we should always use today's date.&#10;Added new logic to should_ir_be_active() which checks the 3 consecutive PSI values for the logger and only activates if they pass some checks.&#10;Added function update_ir_consecutive_data() that is in charge of keeping 3 consecutive days worth of PSI data in Logger for use in determining IR activation.\">\r\n      <created>1684373149201</created>\r\n      <option name=\"number\" value=\"00317\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00317\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1684373149201</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00318\" summary=\"YearAnalysis.py Updates&#10;&#10;Updated YearAnalysis.py to be able to handle psi_analysis partially. &#10;More work on psi_analysis is still pending.\">\r\n      <created>1684373219394</created>\r\n      <option name=\"number\" value=\"00318\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00318\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1684373219394</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00319\" summary=\"Add Gradient Logos&#10;&#10;Added a couple of Gradient Logos\">\r\n      <created>1685134852031</created>\r\n      <option name=\"number\" value=\"00319\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00319\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1685134852031</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00320\" summary=\"Field Type&#10;&#10;Added field_type to Field object to track if the field is a demo. &#10;field_type not holds a string that can be 'Commercial', 'Demo', or 'R&amp;D' depending on what the field is.&#10;Modified setup_field() in Decagon to incorporate new optional parameter for field_type.&#10;Modified Field objet init to have the new optional parameter field_type&#10;Added consec_psis to Logger to_string().&#10;Changed logger usage of rnd boolean to check Field.field_type instead.\">\r\n      <created>1685137571916</created>\r\n      <option name=\"number\" value=\"00320\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00320\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1685137571916</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00321\" summary=\"Notification updates&#10;&#10;Updated notifications for vwc to use the new soil class and the thresholds defined in there for the specific soil type.&#10;Updated canopy temp notifications.&#10;Added new PSI notifications for high thresholds and for when an IR should be turned on but hasn't been activated yet by our system.\">\r\n      <created>1685145496314</created>\r\n      <option name=\"number\" value=\"00321\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00321\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1685145496314</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00322\" summary=\"Formatting\">\r\n      <created>1685145590215</created>\r\n      <option name=\"number\" value=\"00322\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00322\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1685145590215</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00323\" summary=\"Changes to Decagon setup_ai_game_data()&#10;&#10;Simplified setting up new data for AI game by just passing along the logger instead of individual data points\">\r\n      <created>1685497624511</created>\r\n      <option name=\"number\" value=\"00323\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00323\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1685497624511</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00324\" summary=\"Added Notifications for All data from API, not just final results&#10;&#10;Added new method check_for_notifications_all_data() that takes in the converted data from the API call and uses that to check for notifications.&#10;Renamed original check_for_notifications() to check_for_notifications_final_results() to indicate we are using final results for our checks.&#10;Added several new notification possibilities including a sensor reporting None at all and a z6 not reporting more than 2 data points for a day.\">\r\n      <created>1685577941301</created>\r\n      <option name=\"number\" value=\"00324\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00324\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1685577941301</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00325\" summary=\"GDD Error range&#10;&#10;Modified get_crop_stage in CwsiProcessor.py to have an extra level (10) for 90-100% Red.&#10;Modified get_crop_stage_level to handle accumulated_gdds higher than 1214 since we were hitting some of those numbers already causing errors.\">\r\n      <created>1686171370132</created>\r\n      <option name=\"number\" value=\"00325\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00325\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686171370132</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00326\" summary=\"Stopping Warning Notifications&#10;&#10;Added optional boolean parameters (warnings, errors) defaulting to True to check_for_notifications. Notifications will only be generated if the boolean parameter is true. &#10;Passed in warnings=False to check_for_notifications to stop Warning Notifications for the time being&#10;Commented out writing and emailing Warning Notifications for the time being\">\r\n      <created>1686189591157</created>\r\n      <option name=\"number\" value=\"00326\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00326\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686189591157</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00327\" summary=\"VWC Portal Range Bug&#10;&#10;We were using 40 days to determine if we use vwc1 and vwc2 or vwc2 and vwc3 for the portal vwc description when we should be using 30 days.\">\r\n      <created>1686702191044</created>\r\n      <option name=\"number\" value=\"00327\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00327\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686702191046</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00328\" summary=\"Splitting Check for notifications and Email notifications&#10;&#10;Added optional parameter email_notifications to Decagon update_information() method to decide when we email notifications&#10;Additional formatting\">\r\n      <created>1686702340932</created>\r\n      <option name=\"number\" value=\"00328\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00328\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686702340932</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00329\" summary=\"Moved updated checks for Logger, Field and Grower&#10;&#10;Each class is now in charge of handling its self.updated conditionals for updating instead of it being done by its parent class\">\r\n      <created>1686702466945</created>\r\n      <option name=\"number\" value=\"00329\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00329\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686702466945</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00330\" summary=\"Modified Update Retry to handle Notification emailing via the optional parameter email_notifications=True\">\r\n      <created>1686702528358</created>\r\n      <option name=\"number\" value=\"00330\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00330\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686702528358</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00331\" summary=\"Logos location\">\r\n      <created>1686702564782</created>\r\n      <option name=\"number\" value=\"00331\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00331\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686702564782</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00332\" summary=\"IrrigationRecommendationExpert.py changes&#10;&#10;Modified get_crop_stage() so it uses the new season break points of 30 days after planting, 30 before harvest, and 14 before harvest.\">\r\n      <created>1686702695344</created>\r\n      <option name=\"number\" value=\"00332\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00332\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686702695344</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00333\" summary=\"AI Game Init files&#10;&#10;Data and Error pickles to initialize a new AI Game. Both have no game data points in them, just the logger options to play with.\">\r\n      <created>1686702834367</created>\r\n      <option name=\"number\" value=\"00333\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00333\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686702834367</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00334\" summary=\"AI Game v2&#10;&#10;The start of the new TKinter AI Game. Stopped mid way to move to Kivy instead.\">\r\n      <created>1686702947573</created>\r\n      <option name=\"number\" value=\"00334\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00334\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686702947573</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00335\" summary=\"AI Game v1 updates&#10;&#10;Attempts at adding scroll to the AI Game v1 (not very successfully).&#10;Started adding error handling.\">\r\n      <created>1686703027902</created>\r\n      <option name=\"number\" value=\"00335\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00335\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686703027902</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00336\" summary=\"Changes to AIGameData.py&#10;&#10;Added function get_random_logger_from_pool() which takes a parameter indicating if you want the logger from the South, North, or All pool.&#10;Removed individual functions to get a logger from South, North and All pools since its not in 1 function.\">\r\n      <created>1686703293416</created>\r\n      <option name=\"number\" value=\"00336\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00336\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686703293416</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00337\" summary=\"KivyTesting.py&#10;&#10;Testing file to load up and understand different Kivy examples.\">\r\n      <created>1686703416193</created>\r\n      <option name=\"number\" value=\"00337\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00337\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686703416193</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00338\" summary=\"AIIrrigationGameV3.py&#10;&#10;Brand new version 3 of the AI Game done in Kivy.&#10;The .py file specifies most of the functionality while the .kv file specifies most of the UI.&#10;Spec file was used to package the app into an executable for windows.\">\r\n      <created>1686703492418</created>\r\n      <option name=\"number\" value=\"00338\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00338\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686703492418</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00339\" summary=\"YearAnalysis.py&#10;&#10;A lot more work on psi analysis.\">\r\n      <created>1686703533946</created>\r\n      <option name=\"number\" value=\"00339\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00339\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686703533946</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00340\" summary=\"BS\">\r\n      <created>1686703545173</created>\r\n      <option name=\"number\" value=\"00340\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00340\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686703545173</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00341\" summary=\"get_logger_data optional parameter&#10;&#10;Added file_name optional parameter to get_logger_data in case you want to save the dxd file with a specific name. Useful for analysis later on\">\r\n      <created>1686710232174</created>\r\n      <option name=\"number\" value=\"00341\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00341\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686710232174</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00342\" summary=\"Added get_logger_id_and_password_dict()&#10;&#10;This method has everything it needs to go look at the Gsheet where we store the ID's and PW's and return a dict with all of them.\">\r\n      <created>1686710282261</created>\r\n      <option name=\"number\" value=\"00342\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00342\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686710282261</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00343\" summary=\"BS\">\r\n      <created>1686710296415</created>\r\n      <option name=\"number\" value=\"00343\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00343\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686710296415</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00344\" summary=\"Started HeatUnits.py&#10;&#10;This file will be used to do the processing work for the Heat Units trials this year 2023.&#10;Started by setting up Logger instances for each of the current Weather Stations we have installed.&#10;Setup download of data for each into its on directory.\">\r\n      <created>1686710371419</created>\r\n      <option name=\"number\" value=\"00344\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00344\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686710371419</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00345\" summary=\"VP4 Notification Changes&#10;&#10;Simplified vp4 notifications into 1 single method to handle air temp, rh, and vpd notifications. This allows us to just create a single notification if any of those are None instead of one for each type since it is almost never the case that just 1 fails.&#10;New method is called vp4_notifications.&#10;Removed old individual methods for air temp notifications, rh notifications, and vpd notifications.&#10;Formatting changes.\">\r\n      <created>1686858169672</created>\r\n      <option name=\"number\" value=\"00345\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00345\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1686858169672</updated>\r\n    </task>\r\n    <option name=\"localTasksCounter\" value=\"346\" />\r\n    <servers />\r\n  </component>\r\n  <component name=\"TodoView\">\r\n    <todo-panel id=\"selected-file\">\r\n      <is-autoscroll-to-source value=\"true\" />\r\n    </todo-panel>\r\n    <todo-panel id=\"all\">\r\n      <are-packages-shown value=\"true\" />\r\n      <is-autoscroll-to-source value=\"true\" />\r\n    </todo-panel>\r\n  </component>\r\n  <component name=\"ToolWindowManager\">\r\n    <frame x=\"-8\" y=\"-8\" width=\"1936\" height=\"1100\" extended-state=\"0\" />\r\n    <layout>\r\n      <window_info id=\"Project\" active=\"false\" anchor=\"left\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.25\" sideWeight=\"0.5\" order=\"0\" side_tool=\"false\" content_ui=\"combo\" />\r\n      <window_info id=\"TODO\" active=\"false\" anchor=\"bottom\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.33\" sideWeight=\"0.5\" order=\"6\" side_tool=\"false\" content_ui=\"tabs\" />\r\n      <window_info id=\"Statistic\" active=\"false\" anchor=\"bottom\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.33\" sideWeight=\"0.5\" order=\"-1\" side_tool=\"false\" content_ui=\"tabs\" />\r\n      <window_info id=\"Event Log\" active=\"false\" anchor=\"bottom\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.33\" sideWeight=\"0.5\" order=\"-1\" side_tool=\"true\" content_ui=\"tabs\" />\r\n      <window_info id=\"Version Control\" active=\"false\" anchor=\"bottom\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.33\" sideWeight=\"0.5\" order=\"-1\" side_tool=\"false\" content_ui=\"tabs\" />\r\n      <window_info id=\"Python Console\" active=\"false\" anchor=\"bottom\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.33\" sideWeight=\"0.5\" order=\"-1\" side_tool=\"false\" content_ui=\"tabs\" />\r\n      <window_info id=\"Run\" active=\"false\" anchor=\"bottom\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.33\" sideWeight=\"0.5\" order=\"2\" side_tool=\"false\" content_ui=\"tabs\" />\r\n      <window_info id=\"Structure\" active=\"false\" anchor=\"left\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.25\" sideWeight=\"0.5\" order=\"1\" side_tool=\"false\" content_ui=\"tabs\" />\r\n      <window_info id=\"Terminal\" active=\"false\" anchor=\"bottom\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.33\" sideWeight=\"0.5\" order=\"-1\" side_tool=\"false\" content_ui=\"tabs\" />\r\n      <window_info id=\"Favorites\" active=\"false\" anchor=\"left\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.33\" sideWeight=\"0.5\" order=\"-1\" side_tool=\"true\" content_ui=\"tabs\" />\r\n      <window_info id=\"Debug\" active=\"false\" anchor=\"bottom\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.4\" sideWeight=\"0.5\" order=\"3\" side_tool=\"false\" content_ui=\"tabs\" />\r\n      <window_info id=\"Cvs\" active=\"false\" anchor=\"bottom\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.25\" sideWeight=\"0.5\" order=\"4\" side_tool=\"false\" content_ui=\"tabs\" />\r\n      <window_info id=\"Hierarchy\" active=\"false\" anchor=\"right\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.25\" sideWeight=\"0.5\" order=\"2\" side_tool=\"false\" content_ui=\"combo\" />\r\n      <window_info id=\"Message\" active=\"false\" anchor=\"bottom\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.33\" sideWeight=\"0.5\" order=\"0\" side_tool=\"false\" content_ui=\"tabs\" />\r\n      <window_info id=\"Commander\" active=\"false\" anchor=\"right\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.4\" sideWeight=\"0.5\" order=\"0\" side_tool=\"false\" content_ui=\"tabs\" />\r\n      <window_info id=\"Find\" active=\"false\" anchor=\"bottom\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.33\" sideWeight=\"0.5\" order=\"1\" side_tool=\"false\" content_ui=\"tabs\" />\r\n      <window_info id=\"Inspection\" active=\"false\" anchor=\"bottom\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.4\" sideWeight=\"0.5\" order=\"5\" side_tool=\"false\" content_ui=\"tabs\" />\r\n      <window_info id=\"Ant Build\" active=\"false\" anchor=\"right\" auto_hide=\"false\" internal_type=\"DOCKED\" type=\"DOCKED\" visible=\"false\" show_stripe_button=\"true\" weight=\"0.25\" sideWeight=\"0.5\" order=\"1\" side_tool=\"false\" content_ui=\"tabs\" />\r\n    </layout>\r\n  </component>\r\n  <component name=\"TypeScriptGeneratedFilesManager\">\r\n    <option name=\"version\" value=\"3\" />\r\n  </component>\r\n  <component name=\"Vcs.Log.Tabs.Properties\">\r\n    <option name=\"RECENT_FILTERS\">\r\n      <map>\r\n        <entry key=\"Branch\">\r\n          <value>\r\n            <list>\r\n              <RecentGroup>\r\n                <option name=\"FILTER_VALUES\">\r\n                  <option value=\"master\" />\r\n                </option>\r\n              </RecentGroup>\r\n              <RecentGroup>\r\n                <option name=\"FILTER_VALUES\">\r\n                  <option value=\"loggerSetups\" />\r\n                </option>\r\n              </RecentGroup>\r\n            </list>\r\n          </value>\r\n        </entry>\r\n      </map>\r\n    </option>\r\n    <option name=\"TAB_STATES\">\r\n      <map>\r\n        <entry key=\"MAIN\">\r\n          <value>\r\n            <State>\r\n              <option name=\"FILTERS\">\r\n                <map>\r\n                  <entry key=\"branch\">\r\n                    <value>\r\n                      <list>\r\n                        <option value=\"origin/master\" />\r\n                      </list>\r\n                    </value>\r\n                  </entry>\r\n                </map>\r\n              </option>\r\n            </State>\r\n          </value>\r\n        </entry>\r\n      </map>\r\n    </option>\r\n  </component>\r\n  <component name=\"VcsManagerConfiguration\">\r\n    <option name=\"ADD_EXTERNAL_FILES_SILENTLY\" value=\"true\" />\r\n    <MESSAGE value=\"Field Type&#10;&#10;Added field_type to Field object to track if the field is a demo. &#10;field_type not holds a string that can be 'Commercial', 'Demo', or 'R&amp;D' depending on what the field is.&#10;Modified setup_field() in Decagon to incorporate new optional parameter for field_type.&#10;Modified Field objet init to have the new optional parameter field_type&#10;Added consec_psis to Logger to_string().&#10;Changed logger usage of rnd boolean to check Field.field_type instead.\" />\r\n    <MESSAGE value=\"Notification updates&#10;&#10;Updated notifications for vwc to use the new soil class and the thresholds defined in there for the specific soil type.&#10;Updated canopy temp notifications.&#10;Added new PSI notifications for high thresholds and for when an IR should be turned on but hasn't been activated yet by our system.\" />\r\n    <MESSAGE value=\"Formatting\" />\r\n    <MESSAGE value=\"Changes to Decagon setup_ai_game_data()&#10;&#10;Simplified setting up new data for AI game by just passing along the logger instead of individual data points\" />\r\n    <MESSAGE value=\"Added Notifications for All data from API, not just final results&#10;&#10;Added new method check_for_notifications_all_data() that takes in the converted data from the API call and uses that to check for notifications.&#10;Renamed original check_for_notifications() to check_for_notifications_final_results() to indicate we are using final results for our checks.&#10;Added several new notification possibilities including a sensor reporting None at all and a z6 not reporting more than 2 data points for a day.\" />\r\n    <MESSAGE value=\"GDD Error range&#10;&#10;Modified get_crop_stage in CwsiProcessor.py to have an extra level (10) for 90-100% Red.&#10;Modified get_crop_stage_level to handle accumulated_gdds higher than 1214 since we were hitting some of those numbers already causing errors.\" />\r\n    <MESSAGE value=\"Stopping Warning Notifications&#10;&#10;Added optional boolean parameters (warnings, errors) defaulting to True to check_for_notifications. Notifications will only be generated if the boolean parameter is true. &#10;Passed in warnings=False to check_for_notifications to stop Warning Notifications for the time being&#10;Commented out writing and emailing Warning Notifications for the time being\" />\r\n    <MESSAGE value=\"VWC Portal Range Bug&#10;&#10;We were using 40 days to determine if we use vwc1 and vwc2 or vwc2 and vwc3 for the portal vwc description when we should be using 30 days.\" />\r\n    <MESSAGE value=\"Splitting Check for notifications and Email notifications&#10;&#10;Added optional parameter email_notifications to Decagon update_information() method to decide when we email notifications&#10;Additional formatting\" />\r\n    <MESSAGE value=\"Moved updated checks for Logger, Field and Grower&#10;&#10;Each class is now in charge of handling its self.updated conditionals for updating instead of it being done by its parent class\" />\r\n    <MESSAGE value=\"Modified Update Retry to handle Notification emailing via the optional parameter email_notifications=True\" />\r\n    <MESSAGE value=\"Logos location\" />\r\n    <MESSAGE value=\"IrrigationRecommendationExpert.py changes&#10;&#10;Modified get_crop_stage() so it uses the new season break points of 30 days after planting, 30 before harvest, and 14 before harvest.\" />\r\n    <MESSAGE value=\"AI Game Init files&#10;&#10;Data and Error pickles to initialize a new AI Game. Both have no game data points in them, just the logger options to play with.\" />\r\n    <MESSAGE value=\"AI Game v2&#10;&#10;The start of the new TKinter AI Game. Stopped mid way to move to Kivy instead.\" />\r\n    <MESSAGE value=\"AI Game v1 updates&#10;&#10;Attempts at adding scroll to the AI Game v1 (not very successfully).&#10;Started adding error handling.\" />\r\n    <MESSAGE value=\"Changes to AIGameData.py&#10;&#10;Added function get_random_logger_from_pool() which takes a parameter indicating if you want the logger from the South, North, or All pool.&#10;Removed individual functions to get a logger from South, North and All pools since its not in 1 function.\" />\r\n    <MESSAGE value=\"KivyTesting.py&#10;&#10;Testing file to load up and understand different Kivy examples.\" />\r\n    <MESSAGE value=\"AIIrrigationGameV3.py&#10;&#10;Brand new version 3 of the AI Game done in Kivy.&#10;The .py file specifies most of the functionality while the .kv file specifies most of the UI.&#10;Spec file was used to package the app into an executable for windows.\" />\r\n    <MESSAGE value=\"YearAnalysis.py&#10;&#10;A lot more work on psi analysis.\" />\r\n    <MESSAGE value=\"get_logger_data optional parameter&#10;&#10;Added file_name optional parameter to get_logger_data in case you want to save the dxd file with a specific name. Useful for analysis later on\" />\r\n    <MESSAGE value=\"Added get_logger_id_and_password_dict()&#10;&#10;This method has everything it needs to go look at the Gsheet where we store the ID's and PW's and return a dict with all of them.\" />\r\n    <MESSAGE value=\"BS\" />\r\n    <MESSAGE value=\"Started HeatUnits.py&#10;&#10;This file will be used to do the processing work for the Heat Units trials this year 2023.&#10;Started by setting up Logger instances for each of the current Weather Stations we have installed.&#10;Setup download of data for each into its on directory.\" />\r\n    <MESSAGE value=\"VP4 Notification Changes&#10;&#10;Simplified vp4 notifications into 1 single method to handle air temp, rh, and vpd notifications. This allows us to just create a single notification if any of those are None instead of one for each type since it is almost never the case that just 1 fails.&#10;New method is called vp4_notifications.&#10;Removed old individual methods for air temp notifications, rh notifications, and vpd notifications.&#10;Formatting changes.\" />\r\n    <option name=\"LAST_COMMIT_MESSAGE\" value=\"VP4 Notification Changes&#10;&#10;Simplified vp4 notifications into 1 single method to handle air temp, rh, and vpd notifications. This allows us to just create a single notification if any of those are None instead of one for each type since it is almost never the case that just 1 fails.&#10;New method is called vp4_notifications.&#10;Removed old individual methods for air temp notifications, rh notifications, and vpd notifications.&#10;Formatting changes.\" />\r\n    <option name=\"OPTIMIZE_IMPORTS_BEFORE_PROJECT_COMMIT\" value=\"true\" />\r\n  </component>\r\n  <component name=\"XDebuggerManager\">\r\n    <breakpoint-manager>\r\n      <breakpoints>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/WeatherTest.py</url>\r\n          <line>233</line>\r\n          <option name=\"timeStamp\" value=\"66\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/Decagon.py</url>\r\n          <line>3367</line>\r\n          <option name=\"timeStamp\" value=\"109\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/CIMIS.py</url>\r\n          <line>180</line>\r\n          <option name=\"timeStamp\" value=\"127\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/Decagon.py</url>\r\n          <line>3324</line>\r\n          <option name=\"timeStamp\" value=\"144\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/Decagon.py</url>\r\n          <line>3287</line>\r\n          <option name=\"timeStamp\" value=\"147\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/AIGameData.py</url>\r\n          <line>425</line>\r\n          <option name=\"timeStamp\" value=\"157\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/IrrigationRecommendationExpert.py</url>\r\n          <line>80</line>\r\n          <option name=\"timeStamp\" value=\"172\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/Decagon.py</url>\r\n          <line>2927</line>\r\n          <option name=\"timeStamp\" value=\"205\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/YearAnalysis.py</url>\r\n          <line>1660</line>\r\n          <option name=\"timeStamp\" value=\"215\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/YearAnalysis.py</url>\r\n          <line>1586</line>\r\n          <option name=\"timeStamp\" value=\"218\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/YearAnalysis.py</url>\r\n          <line>533</line>\r\n          <option name=\"timeStamp\" value=\"232\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/Decagon.py</url>\r\n          <line>549</line>\r\n          <option name=\"timeStamp\" value=\"234\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/YearAnalysis.py</url>\r\n          <line>1518</line>\r\n          <option name=\"timeStamp\" value=\"243\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/YearAnalysis.py</url>\r\n          <line>1517</line>\r\n          <option name=\"timeStamp\" value=\"244\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/CwsiProcessor.py</url>\r\n          <line>382</line>\r\n          <option name=\"timeStamp\" value=\"247\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/YearAnalysis.py</url>\r\n          <line>1508</line>\r\n          <option name=\"timeStamp\" value=\"248\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/YearAnalysis.py</url>\r\n          <line>1507</line>\r\n          <option name=\"timeStamp\" value=\"249\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/Decagon.py</url>\r\n          <line>3328</line>\r\n          <option name=\"timeStamp\" value=\"251\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/Logger.py</url>\r\n          <line>790</line>\r\n          <option name=\"timeStamp\" value=\"259\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/HeatUnits.py</url>\r\n          <line>47</line>\r\n          <option name=\"timeStamp\" value=\"265\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/HeatUnits.py</url>\r\n          <line>49</line>\r\n          <option name=\"timeStamp\" value=\"266\" />\r\n        </line-breakpoint>\r\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\r\n          <url>file://$PROJECT_DIR$/HeatUnits.py</url>\r\n          <line>13</line>\r\n          <option name=\"timeStamp\" value=\"267\" />\r\n        </line-breakpoint>\r\n      </breakpoints>\r\n      <default-breakpoints>\r\n        <breakpoint type=\"python-exception\">\r\n          <properties notifyOnTerminate=\"true\" exception=\"BaseException\">\r\n            <option name=\"notifyOnTerminate\" value=\"true\" />\r\n          </properties>\r\n        </breakpoint>\r\n      </default-breakpoints>\r\n    </breakpoint-manager>\r\n  </component>\r\n  <component name=\"com.intellij.coverage.CoverageDataManagerImpl\">\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$TKInter.coverage\" NAME=\"TKInter Coverage Results\" MODIFIED=\"1631131790797\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$SwitchTestCase.coverage\" NAME=\"SwitchTestCase Coverage Results\" MODIFIED=\"1678730749480\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$DBWriter.coverage\" NAME=\"DBWriter Coverage Results\" MODIFIED=\"1662592976330\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$CwsiFormulaTester.coverage\" NAME=\"CwsiFormulaTester Coverage Results\" MODIFIED=\"1630459322067\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$STOMAtoUpdate.coverage\" NAME=\"STOMAtoUpdate Coverage Results\" MODIFIED=\"1642038156945\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$SQLScripts.coverage\" NAME=\"SQLScripts Coverage Results\" MODIFIED=\"1660142569019\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$formatHistoricalET.coverage\" NAME=\"formatHistoricalET Coverage Results\" MODIFIED=\"1620265637963\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$AIIrrigationGameV3__3_.coverage\" NAME=\"AIIrrigationGameV3 (3) Coverage Results\" MODIFIED=\"1686323145119\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/AIGame\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$Soils.coverage\" NAME=\"Soils Coverage Results\" MODIFIED=\"1683932387848\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$formatHistoricalET.coverage\" NAME=\"formatHistoricalET Coverage Results\" MODIFIED=\"1615220646151\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$PrerunMaintenance.coverage\" NAME=\"PrerunMaintenance Coverage Results\" MODIFIED=\"1654037151077\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$gmailTesting.coverage\" NAME=\"gmailTesting Coverage Results\" MODIFIED=\"1655757137703\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$uninstallFields.coverage\" NAME=\"uninstallFields Coverage Results\" MODIFIED=\"1666393598857\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$sqlTesting.coverage\" NAME=\"sqlTesting Coverage Results\" MODIFIED=\"1612901497912\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$TKInter.coverage\" NAME=\"TKInter Coverage Results\" MODIFIED=\"1678243631453\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$STOMAtoUpdateRetry.coverage\" NAME=\"STOMAtoUpdateRetry Coverage Results\" MODIFIED=\"1632331197894\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$DBWriter.coverage\" NAME=\"DBWriter Coverage Results\" MODIFIED=\"1621249399322\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$HeatUnits.coverage\" NAME=\"HeatUnits Coverage Results\" MODIFIED=\"1686881280835\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$.coverage\" NAME=\" Coverage Results\" MODIFIED=\"1634172899963\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$CwsiProcessor.coverage\" NAME=\"CwsiProcessor Coverage Results\" MODIFIED=\"1619518007322\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$AIIrrigationGameV3__2_.coverage\" NAME=\"AIIrrigationGameV3 (2) Coverage Results\" MODIFIED=\"1686273006519\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/AI Game\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$EmailTester.coverage\" NAME=\"EmailTester Coverage Results\" MODIFIED=\"1681779541242\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$loggerSetups.coverage\" NAME=\"loggerSetups Coverage Results\" MODIFIED=\"1679606405842\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$loggerSetups.coverage\" NAME=\"loggerSetups Coverage Results\" MODIFIED=\"1639095975188\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$AIExpertSystemTesting.coverage\" NAME=\"AIExpertSystemTesting Coverage Results\" MODIFIED=\"1683677065044\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$CimisUpdate.coverage\" NAME=\"CimisUpdate Coverage Results\" MODIFIED=\"1621340772933\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$Decagon.coverage\" NAME=\"Decagon Coverage Results\" MODIFIED=\"1687765303466\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$gSheetTest.coverage\" NAME=\"gSheetTest Coverage Results\" MODIFIED=\"1609745391990\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$WeatherTest.coverage\" NAME=\"WeatherTest Coverage Results\" MODIFIED=\"1678321995221\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$AIGameData.coverage\" NAME=\"AIGameData Coverage Results\" MODIFIED=\"1681321697188\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$AIGameData.coverage\" NAME=\"AIGameData Coverage Results\" MODIFIED=\"1632877501080\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$AIIrrigationGameV3.coverage\" NAME=\"AIIrrigationGameV3 Coverage Results\" MODIFIED=\"1686272739977\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$AIExpertSystemTesting.coverage\" NAME=\"AIExpertSystemTesting Coverage Results\" MODIFIED=\"1636765308468\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$AIIrrigationGameV3__1_.coverage\" NAME=\"AIIrrigationGameV3 (1) Coverage Results\" MODIFIED=\"1686272827720\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/AI\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$Decagon.coverage\" NAME=\"Decagon Coverage Results\" MODIFIED=\"1683932813529\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$Field.coverage\" NAME=\"Field Coverage Results\" MODIFIED=\"1618891943834\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$CimisUpdate.coverage\" NAME=\"CimisUpdate Coverage Results\" MODIFIED=\"1660869984017\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$STOMAtoUpdateRetry.coverage\" NAME=\"STOMAtoUpdateRetry Coverage Results\" MODIFIED=\"1659446223871\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$CimisStation.coverage\" NAME=\"CimisStation Coverage Results\" MODIFIED=\"1657387377095\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$SQLScripts.coverage\" NAME=\"SQLScripts Coverage Results\" MODIFIED=\"1642230710365\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$EmailProcessor.coverage\" NAME=\"EmailProcessor Coverage Results\" MODIFIED=\"1655838431141\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$KivyTesting.coverage\" NAME=\"KivyTesting Coverage Results\" MODIFIED=\"1685580311134\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato_dev$Decagon.coverage\" NAME=\"Decagon Coverage Results\" MODIFIED=\"1611789454686\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$bigQueryTest.coverage\" NAME=\"bigQueryTest Coverage Results\" MODIFIED=\"1608572673786\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$DataTests.coverage\" NAME=\"DataTests Coverage Results\" MODIFIED=\"1679072769429\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$YearAnalysis.coverage\" NAME=\"YearAnalysis Coverage Results\" MODIFIED=\"1683672160830\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$Testing.coverage\" NAME=\"Testing Coverage Results\" MODIFIED=\"1628198021719\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$AIIIrrigationGameV2.coverage\" NAME=\"AIIIrrigationGameV2 Coverage Results\" MODIFIED=\"1684454590969\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$AIIrrigationGameV3__4_.coverage\" NAME=\"AIIrrigationGameV3 (4) Coverage Results\" MODIFIED=\"1686334569719\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$technicianPortal.coverage\" NAME=\"technicianPortal Coverage Results\" MODIFIED=\"1670450349216\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$schedulerTest.coverage\" NAME=\"schedulerTest Coverage Results\" MODIFIED=\"1659650548778\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/S_TOMAto$CIMIS.coverage\" NAME=\"CIMIS Coverage Results\" MODIFIED=\"1618829670273\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n    <SUITE FILE_PATH=\"coverage/Stomato$STOMAtoUpdate.coverage\" NAME=\"STOMAtoUpdate Coverage Results\" MODIFIED=\"1643531784052\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n  </component>\r\n  <component name=\"masterDetails\">\r\n    <states>\r\n      <state key=\"ScopeChooserConfigurable.UI\">\r\n        <settings>\r\n          <splitter-proportions>\r\n            <option name=\"proportions\">\r\n              <list>\r\n                <option value=\"0.2\" />\r\n              </list>\r\n            </option>\r\n          </splitter-proportions>\r\n        </settings>\r\n      </state>\r\n    </states>\r\n  </component>\r\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	
+++ b/.idea/workspace.xml	
@@ -7,16 +7,30 @@
     <option name="autoReloadType" value="SELECTIVE" />
   </component>
   <component name="ChangeListManager">
-    <list default="true" id="3aa7c90b-1f87-403f-bac4-0b49ed107be9" name="Default" comment="VP4 Notification Changes&#10;&#10;Simplified vp4 notifications into 1 single method to handle air temp, rh, and vpd notifications. This allows us to just create a single notification if any of those are None instead of one for each type since it is almost never the case that just 1 fails.&#10;New method is called vp4_notifications.&#10;Removed old individual methods for air temp notifications, rh notifications, and vpd notifications.&#10;Formatting changes.">
+    <list default="true" id="3aa7c90b-1f87-403f-bac4-0b49ed107be9" name="Default" comment="Almond IR check change&#10;&#10;Updated checks for Almonds should_ir_be_active">
+      <change afterPath="$PROJECT_DIR$/backup.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/pylintrc" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/.idea/Stomato.iml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/Stomato.iml" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/.idea/inspectionProfiles/Project_Default.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/inspectionProfiles/Project_Default.xml" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/.idea/misc.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/misc.xml" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/CimisUpdate.py" beforeDir="false" afterPath="$PROJECT_DIR$/CimisUpdate.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/CIMIS.py" beforeDir="false" afterPath="$PROJECT_DIR$/CIMIS.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/CwsiProcessor.py" beforeDir="false" afterPath="$PROJECT_DIR$/CwsiProcessor.py" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/Decagon.py" beforeDir="false" afterPath="$PROJECT_DIR$/Decagon.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/ai_data.csv" beforeDir="false" afterPath="$PROJECT_DIR$/ai_data.csv" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/Field.py" beforeDir="false" afterPath="$PROJECT_DIR$/Field.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/GSheetCredentialSevice.py" beforeDir="false" afterPath="$PROJECT_DIR$/GSheetCredentialSevice.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/Grower.py" beforeDir="false" afterPath="$PROJECT_DIR$/Grower.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/Logger.py" beforeDir="false" afterPath="$PROJECT_DIR$/Logger.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/LoggerSetups.py" beforeDir="false" afterPath="$PROJECT_DIR$/LoggerSetups.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/SQLScripts.py" beforeDir="false" afterPath="$PROJECT_DIR$/SQLScripts.py" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/all et.csv" beforeDir="false" afterPath="$PROJECT_DIR$/all et.csv" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/credentials2.json" beforeDir="false" afterPath="$PROJECT_DIR$/credentials2.json" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/data.csv" beforeDir="false" afterPath="$PROJECT_DIR$/data.csv" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/historicalET.csv" beforeDir="false" afterPath="$PROJECT_DIR$/historicalET.csv" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/irrScheduling.csv" beforeDir="false" afterPath="$PROJECT_DIR$/irrScheduling.csv" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/newhistoricalET.csv" beforeDir="false" afterPath="$PROJECT_DIR$/newhistoricalET.csv" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/portal_data.csv" beforeDir="false" afterPath="$PROJECT_DIR$/portal_data.csv" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/requirements.txt" beforeDir="false" afterPath="$PROJECT_DIR$/requirements.txt" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/weather forecast.csv" beforeDir="false" afterPath="$PROJECT_DIR$/weather forecast.csv" afterDir="false" />
     </list>
     <option name="SHOW_DIALOG" value="false" />
@@ -82,6 +96,15 @@
     </option>
     <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
   </component>
+  <component name="GitHubPullRequestSearchHistory">{
+  &quot;history&quot;: [
+    {
+      &quot;state&quot;: &quot;OPEN&quot;
+    }
+  ],
+  &quot;lastFilter&quot;: {
+  }
+}</component>
   <component name="GitSEFilterConfiguration">
     <file-type-list>
       <filtered-out-file-type name="LOCAL_BRANCH" />
@@ -90,6 +113,14 @@
       <filtered-out-file-type name="COMMIT_BY_MESSAGE" />
     </file-type-list>
   </component>
+  <component name="GithubPullRequestsUISettings">
+    <option name="selectedUrlAndAccountId">
+      <UrlAndAccount>
+        <option name="accountId" value="860cc125-bb45-46ea-8c5c-c9197d9067dd" />
+        <option name="url" value="https://github.com/jgarrido-ms/Stomato.git" />
+      </UrlAndAccount>
+    </option>
+  </component>
   <component name="HighlightingSettingsPerFile">
     <setting file="mock:///" root0="FORCE_HIGHLIGHTING" />
   </component>
@@ -98,8 +129,11 @@
     <option name="stateVersion" value="1" />
   </component>
   <component name="ProblemsViewState">
-    <option name="selectedIndex" value="2" />
+    <option name="selectedTabId" value="CurrentFile" />
   </component>
+  <component name="ProjectColorInfo">{
+  &quot;associatedIndex&quot;: 6
+}</component>
   <component name="ProjectFrameBounds">
     <option name="x" value="-8" />
     <option name="y" value="-8" />
@@ -114,21 +148,31 @@
     <option name="hideEmptyMiddlePackages" value="true" />
     <option name="showLibraryContents" value="true" />
   </component>
-  <component name="PropertiesComponent">{
-  &quot;keyToString&quot;: {
-    &quot;WebServerToolWindowFactoryState&quot;: &quot;false&quot;,
-    &quot;git-widget-placeholder&quot;: &quot;master&quot;,
-    &quot;ignore.virus.scanning.warn.message&quot;: &quot;true&quot;,
-    &quot;last_opened_file_path&quot;: &quot;C:/Users/javie/PycharmProjects/Stomato&quot;,
-    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,
-    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,
-    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,
-    &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,
-    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,
-    &quot;settings.editor.selected.configurable&quot;: &quot;configurable.group.language&quot;,
-    &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;
+  <component name="PropertiesComponent"><![CDATA[{
+  "keyToString": {
+    "Python.AIIrrigationGameV3 (2).executor": "Debug",
+    "Python.CIMIS.executor": "Debug",
+    "Python.Decagon.executor": "Debug",
+    "Python.LoggerSetups.executor": "Run",
+    "Python.PrerunMaintenance.executor": "Debug",
+    "Python.SQLScripts.executor": "Run",
+    "Python.STOMAtoUpdate.executor": "Debug",
+    "RunOnceActivity.OpenProjectViewOnStart": "true",
+    "RunOnceActivity.ShowReadmeOnStart": "true",
+    "WebServerToolWindowFactoryState": "false",
+    "git-widget-placeholder": "master",
+    "ignore.virus.scanning.warn.message": "true",
+    "last_opened_file_path": "C:/Users/odolan/PycharmProjects/Stomato/.venv",
+    "node.js.detected.package.eslint": "true",
+    "node.js.detected.package.tslint": "true",
+    "node.js.selected.package.eslint": "(autodetect)",
+    "node.js.selected.package.tslint": "(autodetect)",
+    "nodejs_package_manager_path": "npm",
+    "run.code.analysis.last.selected.profile": "pProject Default",
+    "settings.editor.selected.configurable": "preferences.pluginManager",
+    "vue.rearranger.settings.migration": "true"
   }
-}</component>
+}]]></component>
   <component name="PyConsoleOptionsProvider">
     <option name="myPythonConsoleState">
       <console-settings module-name="Stomato" is-module-sdk="true">
@@ -136,9 +180,6 @@
         <option name="myModuleName" value="Stomato" />
       </console-settings>
     </option>
-  </component>
-  <component name="PyDebuggerOptionsProvider">
-    <option name="mySupportGeventDebugging" value="true" />
   </component>
   <component name="RecentsManager">
     <key name="CopyFile.RECENT_KEYS">
@@ -147,14 +188,19 @@
       <recent name="C:\Users\Javier\Documents\Stomato" />
     </key>
     <key name="MoveFile.RECENT_KEYS">
+      <recent name="C:\Users\odolan\PycharmProjects\Stomato" />
       <recent name="C:\Users\javie\PycharmProjects\Stomato\Logos" />
       <recent name="C:\Users\javie\PycharmProjects\Stomato\AIGame" />
       <recent name="C:\Users\javie\PycharmProjects\Stomato\AI Game" />
       <recent name="C:\Users\javie\Projects\S-TOMAto" />
-      <recent name="C:\Users\javie\Projects\S-TOMAto\ssl" />
     </key>
   </component>
-  <component name="RunManager" selected="Python.Decagon">
+  <component name="RunAnythingCache">
+    <option name="myCommands">
+      <command value="print()" />
+    </option>
+  </component>
+  <component name="RunManager" selected="Python.SQLScripts">
     <configuration default="true" type="tests" factoryName="Attests">
       <option name="INTERPRETER_OPTIONS" value="" />
       <option name="PARENT_ENVS" value="true" />
@@ -176,6 +222,7 @@
     </configuration>
     <configuration name="AIIrrigationGameV3 (2)" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
       <module name="Stomato" />
+      <option name="ENV_FILES" value="" />
       <option name="INTERPRETER_OPTIONS" value="" />
       <option name="PARENT_ENVS" value="true" />
       <envs>
@@ -196,20 +243,21 @@
       <option name="INPUT_FILE" value="" />
       <method v="2" />
     </configuration>
-    <configuration name="AIIrrigationGameV3 (3)" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
+    <configuration name="Decagon" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
       <module name="Stomato" />
+      <option name="ENV_FILES" value="" />
       <option name="INTERPRETER_OPTIONS" value="" />
       <option name="PARENT_ENVS" value="true" />
       <envs>
         <env name="PYTHONUNBUFFERED" value="1" />
       </envs>
       <option name="SDK_HOME" value="" />
-      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/AIGame" />
+      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$" />
       <option name="IS_MODULE_SDK" value="true" />
       <option name="ADD_CONTENT_ROOTS" value="true" />
       <option name="ADD_SOURCE_ROOTS" value="true" />
       <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/AIGame/AIIrrigationGameV3.py" />
+      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Decagon.py" />
       <option name="PARAMETERS" value="" />
       <option name="SHOW_COMMAND_LINE" value="false" />
       <option name="EMULATE_TERMINAL" value="false" />
@@ -218,8 +266,9 @@
       <option name="INPUT_FILE" value="" />
       <method v="2" />
     </configuration>
-    <configuration name="AIIrrigationGameV3 (4)" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
+    <configuration name="HeatUnits" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
       <module name="Stomato" />
+      <option name="ENV_FILES" value="" />
       <option name="INTERPRETER_OPTIONS" value="" />
       <option name="PARENT_ENVS" value="true" />
       <envs>
@@ -231,7 +280,7 @@
       <option name="ADD_CONTENT_ROOTS" value="true" />
       <option name="ADD_SOURCE_ROOTS" value="true" />
       <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/AIIrrigationGameV3.py" />
+      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/HeatUnits.py" />
       <option name="PARAMETERS" value="" />
       <option name="SHOW_COMMAND_LINE" value="false" />
       <option name="EMULATE_TERMINAL" value="false" />
@@ -240,8 +289,9 @@
       <option name="INPUT_FILE" value="" />
       <method v="2" />
     </configuration>
-    <configuration name="Decagon" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
+    <configuration name="LoggerSetups" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
       <module name="Stomato" />
+      <option name="ENV_FILES" value="" />
       <option name="INTERPRETER_OPTIONS" value="" />
       <option name="PARENT_ENVS" value="true" />
       <envs>
@@ -253,7 +303,7 @@
       <option name="ADD_CONTENT_ROOTS" value="true" />
       <option name="ADD_SOURCE_ROOTS" value="true" />
       <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Decagon.py" />
+      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/LoggerSetups.py" />
       <option name="PARAMETERS" value="" />
       <option name="SHOW_COMMAND_LINE" value="false" />
       <option name="EMULATE_TERMINAL" value="false" />
@@ -262,8 +312,9 @@
       <option name="INPUT_FILE" value="" />
       <method v="2" />
     </configuration>
-    <configuration name="HeatUnits" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
+    <configuration name="SQLScripts" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
       <module name="Stomato" />
+      <option name="ENV_FILES" value="" />
       <option name="INTERPRETER_OPTIONS" value="" />
       <option name="PARENT_ENVS" value="true" />
       <envs>
@@ -275,7 +326,7 @@
       <option name="ADD_CONTENT_ROOTS" value="true" />
       <option name="ADD_SOURCE_ROOTS" value="true" />
       <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/HeatUnits.py" />
+      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/SQLScripts.py" />
       <option name="PARAMETERS" value="" />
       <option name="SHOW_COMMAND_LINE" value="false" />
       <option name="EMULATE_TERMINAL" value="false" />
@@ -286,6 +337,7 @@
     </configuration>
     <configuration default="true" type="tests" factoryName="Nosetests">
       <module name="Stomato" />
+      <option name="ENV_FILES" value="" />
       <option name="INTERPRETER_OPTIONS" value="" />
       <option name="PARENT_ENVS" value="true" />
       <option name="SDK_HOME" value="" />
@@ -302,6 +354,7 @@
     </configuration>
     <configuration default="true" type="tests" factoryName="Unittests">
       <module name="Stomato" />
+      <option name="ENV_FILES" value="" />
       <option name="INTERPRETER_OPTIONS" value="" />
       <option name="PARENT_ENVS" value="true" />
       <option name="SDK_HOME" value="" />
@@ -317,6 +370,7 @@
     </configuration>
     <configuration default="true" type="tests" factoryName="py.test">
       <module name="Stomato" />
+      <option name="ENV_FILES" value="" />
       <option name="INTERPRETER_OPTIONS" value="" />
       <option name="PARENT_ENVS" value="true" />
       <option name="SDK_HOME" value="" />
@@ -333,22 +387,29 @@
       <method v="2" />
     </configuration>
     <list>
-      <item itemvalue="Python.HeatUnits" />
+      <item itemvalue="Python.SQLScripts" />
       <item itemvalue="Python.AIIrrigationGameV3 (2)" />
-      <item itemvalue="Python.AIIrrigationGameV3 (3)" />
-      <item itemvalue="Python.AIIrrigationGameV3 (4)" />
       <item itemvalue="Python.Decagon" />
+      <item itemvalue="Python.HeatUnits" />
+      <item itemvalue="Python.LoggerSetups" />
     </list>
     <recent_temporary>
       <list>
+        <item itemvalue="Python.SQLScripts" />
         <item itemvalue="Python.Decagon" />
+        <item itemvalue="Python.LoggerSetups" />
+        <item itemvalue="Python.AIIrrigationGameV3 (2)" />
         <item itemvalue="Python.HeatUnits" />
-        <item itemvalue="Python.AIIrrigationGameV3 (4)" />
-        <item itemvalue="Python.AIIrrigationGameV3 (3)" />
-        <item itemvalue="Python.AIIrrigationGameV3 (2)" />
       </list>
     </recent_temporary>
   </component>
+  <component name="SharedIndexes">
+    <attachedChunks>
+      <set>
+        <option value="bundled-python-sdk-09665e90c3a7-b11f5e8da5ad-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-233.15026.15" />
+      </set>
+    </attachedChunks>
+  </component>
   <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="project-level" UseSingleDictionary="true" transferred="true" />
   <component name="SvnConfiguration">
     <configuration />
@@ -483,6 +544,23 @@
       <workItem from="1686693323310" duration="23345000" />
       <workItem from="1686855364679" duration="18047000" />
       <workItem from="1686875965074" duration="6029000" />
+      <workItem from="1711138320669" duration="3351000" />
+      <workItem from="1711384122136" duration="597000" />
+      <workItem from="1711385043957" duration="3169000" />
+      <workItem from="1711389756816" duration="361000" />
+      <workItem from="1711390124345" duration="321000" />
+      <workItem from="1711390457229" duration="286000" />
+      <workItem from="1711390766068" duration="7400000" />
+      <workItem from="1711401161597" duration="3339000" />
+      <workItem from="1711406375563" duration="352000" />
+      <workItem from="1711407896029" duration="1713000" />
+      <workItem from="1711410000702" duration="681000" />
+      <workItem from="1711410695589" duration="735000" />
+      <workItem from="1711411440588" duration="1633000" />
+      <workItem from="1711472613882" duration="13634000" />
+      <workItem from="1711560444306" duration="20669000" />
+      <workItem from="1711657095557" duration="104567000" />
+      <workItem from="1712765765016" duration="32038000" />
     </task>
     <task id="LOCAL-00297" summary="Fixed Emails&#10;&#10;Emailing wasn't working past the first recipient. Fixed it now">
       <created>1681780581866</created>
@@ -827,7 +905,7 @@
       <option name="project" value="LOCAL" />
       <updated>1686858169672</updated>
     </task>
-    <option name="localTasksCounter" value="346" />
+    <option name="localTasksCounter" value="352" />
     <servers />
   </component>
   <component name="TodoView">
@@ -910,12 +988,6 @@
   </component>
   <component name="VcsManagerConfiguration">
     <option name="ADD_EXTERNAL_FILES_SILENTLY" value="true" />
-    <MESSAGE value="Field Type&#10;&#10;Added field_type to Field object to track if the field is a demo. &#10;field_type not holds a string that can be 'Commercial', 'Demo', or 'R&amp;D' depending on what the field is.&#10;Modified setup_field() in Decagon to incorporate new optional parameter for field_type.&#10;Modified Field objet init to have the new optional parameter field_type&#10;Added consec_psis to Logger to_string().&#10;Changed logger usage of rnd boolean to check Field.field_type instead." />
-    <MESSAGE value="Notification updates&#10;&#10;Updated notifications for vwc to use the new soil class and the thresholds defined in there for the specific soil type.&#10;Updated canopy temp notifications.&#10;Added new PSI notifications for high thresholds and for when an IR should be turned on but hasn't been activated yet by our system." />
-    <MESSAGE value="Formatting" />
-    <MESSAGE value="Changes to Decagon setup_ai_game_data()&#10;&#10;Simplified setting up new data for AI game by just passing along the logger instead of individual data points" />
-    <MESSAGE value="Added Notifications for All data from API, not just final results&#10;&#10;Added new method check_for_notifications_all_data() that takes in the converted data from the API call and uses that to check for notifications.&#10;Renamed original check_for_notifications() to check_for_notifications_final_results() to indicate we are using final results for our checks.&#10;Added several new notification possibilities including a sensor reporting None at all and a z6 not reporting more than 2 data points for a day." />
-    <MESSAGE value="GDD Error range&#10;&#10;Modified get_crop_stage in CwsiProcessor.py to have an extra level (10) for 90-100% Red.&#10;Modified get_crop_stage_level to handle accumulated_gdds higher than 1214 since we were hitting some of those numbers already causing errors." />
     <MESSAGE value="Stopping Warning Notifications&#10;&#10;Added optional boolean parameters (warnings, errors) defaulting to True to check_for_notifications. Notifications will only be generated if the boolean parameter is true. &#10;Passed in warnings=False to check_for_notifications to stop Warning Notifications for the time being&#10;Commented out writing and emailing Warning Notifications for the time being" />
     <MESSAGE value="VWC Portal Range Bug&#10;&#10;We were using 40 days to determine if we use vwc1 and vwc2 or vwc2 and vwc3 for the portal vwc description when we should be using 30 days." />
     <MESSAGE value="Splitting Check for notifications and Email notifications&#10;&#10;Added optional parameter email_notifications to Decagon update_information() method to decide when we email notifications&#10;Additional formatting" />
@@ -935,7 +1007,13 @@
     <MESSAGE value="BS" />
     <MESSAGE value="Started HeatUnits.py&#10;&#10;This file will be used to do the processing work for the Heat Units trials this year 2023.&#10;Started by setting up Logger instances for each of the current Weather Stations we have installed.&#10;Setup download of data for each into its on directory." />
     <MESSAGE value="VP4 Notification Changes&#10;&#10;Simplified vp4 notifications into 1 single method to handle air temp, rh, and vpd notifications. This allows us to just create a single notification if any of those are None instead of one for each type since it is almost never the case that just 1 fails.&#10;New method is called vp4_notifications.&#10;Removed old individual methods for air temp notifications, rh notifications, and vpd notifications.&#10;Formatting changes." />
-    <option name="LAST_COMMIT_MESSAGE" value="VP4 Notification Changes&#10;&#10;Simplified vp4 notifications into 1 single method to handle air temp, rh, and vpd notifications. This allows us to just create a single notification if any of those are None instead of one for each type since it is almost never the case that just 1 fails.&#10;New method is called vp4_notifications.&#10;Removed old individual methods for air temp notifications, rh notifications, and vpd notifications.&#10;Formatting changes." />
+    <MESSAGE value="Almond SDD change&#10;&#10;Changed the criteria for active IR for Almonds latest consecutive SDD values to be below -3.0" />
+    <MESSAGE value="Almond IR check change&#10;&#10;Changed the criteria for active IR for Almonds to not include SDD" />
+    <MESSAGE value="Update Portal Reports and Images for a grower&#10;&#10;Created a function to update a growers reports and images in the database to update portals before nightly run" />
+    <MESSAGE value="Update all eto values to DB&#10;&#10;Created function to update eto values in the DB to ensure the data is current and correct" />
+    <MESSAGE value="Typo fix&#10;&#10;Misspelled 'calculating' and it was annoying me" />
+    <MESSAGE value="Almond IR check change&#10;&#10;Updated checks for Almonds should_ir_be_active" />
+    <option name="LAST_COMMIT_MESSAGE" value="Almond IR check change&#10;&#10;Updated checks for Almonds should_ir_be_active" />
     <option name="OPTIMIZE_IMPORTS_BEFORE_PROJECT_COMMIT" value="true" />
   </component>
   <component name="XDebuggerManager">
@@ -948,22 +1026,17 @@
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/Decagon.py</url>
-          <line>3367</line>
+          <line>3449</line>
           <option name="timeStamp" value="109" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/CIMIS.py</url>
-          <line>180</line>
-          <option name="timeStamp" value="127" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/Decagon.py</url>
-          <line>3324</line>
+          <line>3406</line>
           <option name="timeStamp" value="144" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/Decagon.py</url>
-          <line>3287</line>
+          <line>3369</line>
           <option name="timeStamp" value="147" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
@@ -978,7 +1051,7 @@
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/Decagon.py</url>
-          <line>2927</line>
+          <line>3007</line>
           <option name="timeStamp" value="205" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
@@ -998,7 +1071,7 @@
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/Decagon.py</url>
-          <line>549</line>
+          <line>556</line>
           <option name="timeStamp" value="234" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
@@ -1013,7 +1086,7 @@
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/CwsiProcessor.py</url>
-          <line>382</line>
+          <line>401</line>
           <option name="timeStamp" value="247" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
@@ -1028,7 +1101,7 @@
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/Decagon.py</url>
-          <line>3328</line>
+          <line>3410</line>
           <option name="timeStamp" value="251" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
@@ -1038,18 +1111,88 @@
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/HeatUnits.py</url>
-          <line>47</line>
-          <option name="timeStamp" value="265" />
+          <line>13</line>
+          <option name="timeStamp" value="267" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/HeatUnits.py</url>
-          <line>49</line>
-          <option name="timeStamp" value="266" />
+          <url>file://$PROJECT_DIR$/STOMAtoUpdate.py</url>
+          <line>10</line>
+          <option name="timeStamp" value="278" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/Decagon.py</url>
+          <line>5743</line>
+          <option name="timeStamp" value="279" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/HeatUnits.py</url>
-          <line>13</line>
-          <option name="timeStamp" value="267" />
+          <url>file://$PROJECT_DIR$/Grower.py</url>
+          <line>120</line>
+          <option name="timeStamp" value="287" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/Decagon.py</url>
+          <line>1116</line>
+          <option name="timeStamp" value="302" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/PrerunMaintenance.py</url>
+          <line>33</line>
+          <option name="timeStamp" value="308" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/Decagon.py</url>
+          <line>740</line>
+          <option name="timeStamp" value="310" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/LoggerSetups.py</url>
+          <line>1482</line>
+          <option name="timeStamp" value="315" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/CIMIS.py</url>
+          <line>356</line>
+          <option name="timeStamp" value="326" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/Decagon.py</url>
+          <line>1009</line>
+          <option name="timeStamp" value="335" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/SQLScripts.py</url>
+          <line>1110</line>
+          <option name="timeStamp" value="336" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/Decagon.py</url>
+          <line>5801</line>
+          <option name="timeStamp" value="338" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/Field.py</url>
+          <line>249</line>
+          <option name="timeStamp" value="339" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/CwsiProcessor.py</url>
+          <line>887</line>
+          <option name="timeStamp" value="341" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/SQLScripts.py</url>
+          <line>2157</line>
+          <option name="timeStamp" value="342" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/Decagon.py</url>
+          <line>667</line>
+          <option name="timeStamp" value="343" />
+        </line-breakpoint>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/Logger.py</url>
+          <line>2165</line>
+          <option name="timeStamp" value="344" />
         </line-breakpoint>
       </breakpoints>
       <default-breakpoints>
@@ -1060,61 +1203,68 @@
         </breakpoint>
       </default-breakpoints>
     </breakpoint-manager>
+    <watches-manager>
+      <configuration name="PythonConfigurationType">
+        <watch expression="final_results[key][final_results_date_index]" language="Python" />
+      </configuration>
+    </watches-manager>
   </component>
   <component name="com.intellij.coverage.CoverageDataManagerImpl">
-    <SUITE FILE_PATH="coverage/S_TOMAto$TKInter.coverage" NAME="TKInter Coverage Results" MODIFIED="1631131790797" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$SwitchTestCase.coverage" NAME="SwitchTestCase Coverage Results" MODIFIED="1678730749480" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$DBWriter.coverage" NAME="DBWriter Coverage Results" MODIFIED="1662592976330" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$CwsiFormulaTester.coverage" NAME="CwsiFormulaTester Coverage Results" MODIFIED="1630459322067" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$STOMAtoUpdate.coverage" NAME="STOMAtoUpdate Coverage Results" MODIFIED="1642038156945" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$SQLScripts.coverage" NAME="SQLScripts Coverage Results" MODIFIED="1660142569019" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$formatHistoricalET.coverage" NAME="formatHistoricalET Coverage Results" MODIFIED="1620265637963" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$AIIrrigationGameV3__3_.coverage" NAME="AIIrrigationGameV3 (3) Coverage Results" MODIFIED="1686323145119" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/AIGame" />
-    <SUITE FILE_PATH="coverage/Stomato$Soils.coverage" NAME="Soils Coverage Results" MODIFIED="1683932387848" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$formatHistoricalET.coverage" NAME="formatHistoricalET Coverage Results" MODIFIED="1615220646151" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$PrerunMaintenance.coverage" NAME="PrerunMaintenance Coverage Results" MODIFIED="1654037151077" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$gmailTesting.coverage" NAME="gmailTesting Coverage Results" MODIFIED="1655757137703" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$uninstallFields.coverage" NAME="uninstallFields Coverage Results" MODIFIED="1666393598857" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$EmailProcessor.coverage" NAME="EmailProcessor Coverage Results" MODIFIED="1655838431141" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$SQLScripts.coverage" NAME="SQLScripts Coverage Results" MODIFIED="1642230710365" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$bigQueryTest.coverage" NAME="bigQueryTest Coverage Results" MODIFIED="1608572673786" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/Stomato$sqlTesting.coverage" NAME="sqlTesting Coverage Results" MODIFIED="1612901497912" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/Stomato$TKInter.coverage" NAME="TKInter Coverage Results" MODIFIED="1678243631453" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$STOMAtoUpdateRetry.coverage" NAME="STOMAtoUpdateRetry Coverage Results" MODIFIED="1632331197894" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$DBWriter.coverage" NAME="DBWriter Coverage Results" MODIFIED="1621249399322" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$HeatUnits.coverage" NAME="HeatUnits Coverage Results" MODIFIED="1686881280835" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$.coverage" NAME=" Coverage Results" MODIFIED="1634172899963" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$AIIrrigationGameV3__4_.coverage" NAME="AIIrrigationGameV3 (4) Coverage Results" MODIFIED="1686334569719" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$schedulerTest.coverage" NAME="schedulerTest Coverage Results" MODIFIED="1659650548778" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/S_TOMAto$CwsiProcessor.coverage" NAME="CwsiProcessor Coverage Results" MODIFIED="1619518007322" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$AIIrrigationGameV3__2_.coverage" NAME="AIIrrigationGameV3 (2) Coverage Results" MODIFIED="1686273006519" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/AI Game" />
+    <SUITE FILE_PATH="coverage/Stomato$AIIIrrigationGameV2.coverage" NAME="AIIIrrigationGameV2 Coverage Results" MODIFIED="1684454590969" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/Stomato$EmailTester.coverage" NAME="EmailTester Coverage Results" MODIFIED="1681779541242" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$loggerSetups.coverage" NAME="loggerSetups Coverage Results" MODIFIED="1679606405842" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$loggerSetups.coverage" NAME="loggerSetups Coverage Results" MODIFIED="1639095975188" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$gmailTesting.coverage" NAME="gmailTesting Coverage Results" MODIFIED="1655757137703" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$HeatUnits.coverage" NAME="HeatUnits Coverage Results" MODIFIED="1686881280835" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/Stomato$AIExpertSystemTesting.coverage" NAME="AIExpertSystemTesting Coverage Results" MODIFIED="1683677065044" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$STOMAtoUpdate.coverage" NAME="STOMAtoUpdate Coverage Results" MODIFIED="1642038156945" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$Testing.coverage" NAME="Testing Coverage Results" MODIFIED="1628198021719" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$STOMAtoUpdate.coverage" NAME="STOMAtoUpdate Coverage Results" MODIFIED="1711474530996" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$gSheetTest.coverage" NAME="gSheetTest Coverage Results" MODIFIED="1609745391990" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$DBWriter.coverage" NAME="DBWriter Coverage Results" MODIFIED="1621249399322" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$CimisUpdate.coverage" NAME="CimisUpdate Coverage Results" MODIFIED="1660869984017" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$CwsiFormulaTester.coverage" NAME="CwsiFormulaTester Coverage Results" MODIFIED="1630459322067" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$uninstallFields.coverage" NAME="uninstallFields Coverage Results" MODIFIED="1666393598857" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/S_TOMAto$CimisUpdate.coverage" NAME="CimisUpdate Coverage Results" MODIFIED="1621340772933" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$Decagon.coverage" NAME="Decagon Coverage Results" MODIFIED="1687765303466" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$gSheetTest.coverage" NAME="gSheetTest Coverage Results" MODIFIED="1609745391990" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$WeatherTest.coverage" NAME="WeatherTest Coverage Results" MODIFIED="1678321995221" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$AIGameData.coverage" NAME="AIGameData Coverage Results" MODIFIED="1681321697188" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$AIGameData.coverage" NAME="AIGameData Coverage Results" MODIFIED="1632877501080" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$TKInter.coverage" NAME="TKInter Coverage Results" MODIFIED="1631131790797" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$PrerunMaintenance.coverage" NAME="PrerunMaintenance Coverage Results" MODIFIED="1712247604261" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$Decagon.coverage" NAME="Decagon Coverage Results" MODIFIED="1712859671709" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato_dev$Decagon.coverage" NAME="Decagon Coverage Results" MODIFIED="1611789454686" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$loggerSetups.coverage" NAME="loggerSetups Coverage Results" MODIFIED="1679606405842" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$AIIrrigationGameV3__2_.coverage" NAME="AIIrrigationGameV3 (2) Coverage Results" MODIFIED="1686273006519" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/AI Game" />
+    <SUITE FILE_PATH="coverage/Stomato$Soils.coverage" NAME="Soils Coverage Results" MODIFIED="1683932387848" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$AIExpertSystemTesting.coverage" NAME="AIExpertSystemTesting Coverage Results" MODIFIED="1636765308468" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/Stomato$AIIrrigationGameV3.coverage" NAME="AIIrrigationGameV3 Coverage Results" MODIFIED="1686272739977" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$AIExpertSystemTesting.coverage" NAME="AIExpertSystemTesting Coverage Results" MODIFIED="1636765308468" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$AIIrrigationGameV3__1_.coverage" NAME="AIIrrigationGameV3 (1) Coverage Results" MODIFIED="1686272827720" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/AI" />
-    <SUITE FILE_PATH="coverage/Stomato$Decagon.coverage" NAME="Decagon Coverage Results" MODIFIED="1683932813529" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$Field.coverage" NAME="Field Coverage Results" MODIFIED="1618891943834" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$CimisUpdate.coverage" NAME="CimisUpdate Coverage Results" MODIFIED="1660869984017" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/Stomato$STOMAtoUpdateRetry.coverage" NAME="STOMAtoUpdateRetry Coverage Results" MODIFIED="1659446223871" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$CIMIS.coverage" NAME="CIMIS Coverage Results" MODIFIED="1618829670273" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$formatHistoricalET.coverage" NAME="formatHistoricalET Coverage Results" MODIFIED="1615220646151" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$loggerSetups.coverage" NAME="loggerSetups Coverage Results" MODIFIED="1639095975188" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$technicianPortal.coverage" NAME="technicianPortal Coverage Results" MODIFIED="1670450349216" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$SQLScripts.coverage" NAME="SQLScripts Coverage Results" MODIFIED="1712859976629" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/Stomato$CimisStation.coverage" NAME="CimisStation Coverage Results" MODIFIED="1657387377095" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$SQLScripts.coverage" NAME="SQLScripts Coverage Results" MODIFIED="1642230710365" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$EmailProcessor.coverage" NAME="EmailProcessor Coverage Results" MODIFIED="1655838431141" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/Stomato$KivyTesting.coverage" NAME="KivyTesting Coverage Results" MODIFIED="1685580311134" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato_dev$Decagon.coverage" NAME="Decagon Coverage Results" MODIFIED="1611789454686" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$bigQueryTest.coverage" NAME="bigQueryTest Coverage Results" MODIFIED="1608572673786" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$DataTests.coverage" NAME="DataTests Coverage Results" MODIFIED="1679072769429" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$CIMIS.coverage" NAME="CIMIS Coverage Results" MODIFIED="1712773161762" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$formatHistoricalET.coverage" NAME="formatHistoricalET Coverage Results" MODIFIED="1620265637963" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$AIIrrigationGameV3__1_.coverage" NAME="AIIrrigationGameV3 (1) Coverage Results" MODIFIED="1686272827720" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/AI" />
+    <SUITE FILE_PATH="coverage/Stomato$AIGameData.coverage" NAME="AIGameData Coverage Results" MODIFIED="1681321697188" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$STOMAtoUpdateRetry.coverage" NAME="STOMAtoUpdateRetry Coverage Results" MODIFIED="1632331197894" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$SwitchTestCase.coverage" NAME="SwitchTestCase Coverage Results" MODIFIED="1678730749480" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$AIIrrigationGameV3__3_.coverage" NAME="AIIrrigationGameV3 (3) Coverage Results" MODIFIED="1686323145119" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/AIGame" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$.coverage" NAME=" Coverage Results" MODIFIED="1634172899963" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$AIGameData.coverage" NAME="AIGameData Coverage Results" MODIFIED="1632877501080" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$Field.coverage" NAME="Field Coverage Results" MODIFIED="1618891943834" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$WeatherTest.coverage" NAME="WeatherTest Coverage Results" MODIFIED="1678321995221" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/Stomato$YearAnalysis.coverage" NAME="YearAnalysis Coverage Results" MODIFIED="1683672160830" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$Testing.coverage" NAME="Testing Coverage Results" MODIFIED="1628198021719" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$AIIIrrigationGameV2.coverage" NAME="AIIIrrigationGameV2 Coverage Results" MODIFIED="1684454590969" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$AIIrrigationGameV3__4_.coverage" NAME="AIIrrigationGameV3 (4) Coverage Results" MODIFIED="1686334569719" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$technicianPortal.coverage" NAME="technicianPortal Coverage Results" MODIFIED="1670450349216" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$schedulerTest.coverage" NAME="schedulerTest Coverage Results" MODIFIED="1659650548778" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/S_TOMAto$CIMIS.coverage" NAME="CIMIS Coverage Results" MODIFIED="1618829670273" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/Stomato$STOMAtoUpdate.coverage" NAME="STOMAtoUpdate Coverage Results" MODIFIED="1643531784052" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/S_TOMAto$Decagon.coverage" NAME="Decagon Coverage Results" MODIFIED="1687765303466" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$DBWriter.coverage" NAME="DBWriter Coverage Results" MODIFIED="1662592976330" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$DataTests.coverage" NAME="DataTests Coverage Results" MODIFIED="1679072769429" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/Stomato$LoggerSetups.coverage" NAME="LoggerSetups Coverage Results" MODIFIED="1712793445345" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
   </component>
   <component name="masterDetails">
     <states>
Index: .idea/Stomato.iml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<module type=\"PYTHON_MODULE\" version=\"4\">\r\n  <component name=\"NewModuleRootManager\">\r\n    <content url=\"file://$MODULE_DIR$\">\r\n      <excludeFolder url=\"file://$MODULE_DIR$/venv\" />\r\n      <excludeFolder url=\"file://$MODULE_DIR$/venv2\" />\r\n      <excludeFolder url=\"file://$MODULE_DIR$/venv3\" />\r\n      <excludeFolder url=\"file://$MODULE_DIR$/venv4\" />\r\n      <excludeFolder url=\"file://$MODULE_DIR$/venv/Jesus\" />\r\n    </content>\r\n    <orderEntry type=\"inheritedJdk\" />\r\n    <orderEntry type=\"sourceFolder\" forTests=\"false\" />\r\n  </component>\r\n  <component name=\"PackageRequirementsSettings\">\r\n    <option name=\"removeUnused\" value=\"true\" />\r\n  </component>\r\n</module>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/Stomato.iml b/.idea/Stomato.iml
--- a/.idea/Stomato.iml	
+++ b/.idea/Stomato.iml	
@@ -7,8 +7,9 @@
       <excludeFolder url="file://$MODULE_DIR$/venv3" />
       <excludeFolder url="file://$MODULE_DIR$/venv4" />
       <excludeFolder url="file://$MODULE_DIR$/venv/Jesus" />
+      <excludeFolder url="file://$MODULE_DIR$/.venv" />
     </content>
-    <orderEntry type="inheritedJdk" />
+    <orderEntry type="jdk" jdkName="Python 3.12 (Stomato)" jdkType="Python SDK" />
     <orderEntry type="sourceFolder" forTests="false" />
   </component>
   <component name="PackageRequirementsSettings">
Index: historicalET.csv
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>Year4,Year4ET,Year3,Year3ET,Year2,Year2ET,Year1,Year1ET,Average\r\n2018-01-01,0.06,2019-01-01,0.09,2020-01-01,0.05,2021-01-01,0.03,0.0575\r\n2018-01-02,0.03,2019-01-02,0.05,2020-01-02,0.06,2021-01-02,0,0.035\r\n2018-01-03,0.03,2019-01-03,0.04,2020-01-03,0.05,2021-01-03,0,0.03\r\n2018-01-04,0,2019-01-04,0.05,2020-01-04,0.05,2021-01-04,0.02,0.03\r\n2018-01-05,0.01,2019-01-05,0,2020-01-05,0.05,2021-01-05,0.06,0.03\r\n2018-01-06,0.04,2019-01-06,0,2020-01-06,0.08,2021-01-06,0.01,0.0325\r\n2018-01-07,0.03,2019-01-07,0,2020-01-07,0.04,2021-01-07,0.02,0.0225\r\n2018-01-08,0,2019-01-08,0,2020-01-08,0.04,2021-01-08,0.04,0.02\r\n2018-01-09,0.02,2019-01-09,0.03,2020-01-09,0.04,2021-01-09,0.07,0.04\r\n2018-01-10,0.01,2019-01-10,0.03,2020-01-10,0.05,2021-01-10,0.04,0.0325\r\n2018-01-11,0.01,2019-01-11,0.01,2020-01-11,0.04,2021-01-11,0.04,0.025\r\n2018-01-12,0.06,2019-01-12,0.05,2020-01-12,0.05,2021-01-12,0.01,0.0425\r\n2018-01-13,0.04,2019-01-13,0.06,2020-01-13,0.04,2021-01-13,0.03,0.0425\r\n2018-01-14,0.03,2019-01-14,0.04,2020-01-14,0.07,2021-01-14,0.07,0.0525\r\n2018-01-15,0.02,2019-01-15,0,2020-01-15,0.05,2021-01-15,0.04,0.0275\r\n2018-01-16,0.03,2019-01-16,0,2020-01-16,0.03,2021-01-16,0.12,0.045\r\n2018-01-17,0.04,2019-01-17,0.04,2020-01-17,0.02,2021-01-17,0.13,0.0575\r\n2018-01-18,0,2019-01-18,0.01,2020-01-18,0.05,2021-01-18,0.24,0.075\r\n2018-01-19,0.05,2019-01-19,0,2020-01-19,0.03,2021-01-19,0.17,0.0625\r\n2018-01-20,0.07,2019-01-20,0.02,2020-01-20,0.02,2021-01-20,0.1,0.0525\r\n2018-01-21,0.02,2019-01-21,0.06,2020-01-21,0.01,2021-01-21,0.05,0.035\r\n2018-01-22,0.01,2019-01-22,0.09,2020-01-22,0.03,2021-01-22,0.02,0.0375\r\n2018-01-23,0.05,2019-01-23,0.06,2020-01-23,0.01,2021-01-23,0.09,0.0525\r\n2018-01-24,0,2019-01-24,0.1,2020-01-24,0.01,2021-01-24,0.02,0.0325\r\n2018-01-25,0.02,2019-01-25,0.09,2020-01-25,0.02,2021-01-25,0.09,0.055\r\n2018-01-26,0.03,2019-01-26,0.08,2020-01-26,0.05,2021-01-26,0.03,0.0475\r\n2018-01-27,0.04,2019-01-27,0.09,2020-01-27,0.05,2021-01-27,0.03,0.0525\r\n2018-01-28,0.07,2019-01-28,0.02,2020-01-28,0.05,2021-01-28,0.01,0.0375\r\n2018-01-29,0.03,2019-01-29,0.06,2020-01-29,0.07,2021-01-29,0.02,0.045\r\n2018-01-30,0.06,2019-01-30,0.06,2020-01-30,0.07,2021-01-30,0.04,0.0575\r\n2018-01-31,0.06,2019-01-31,0.08,2020-01-31,0.07,2021-01-31,0.02,0.0575\r\n2018-02-01,0.08,2019-02-01,0.02,2020-02-01,0.05,2021-02-01,0.04,0.0475\r\n2018-02-02,0.13,2019-02-02,0.03,2020-02-02,0.12,2021-02-02,0.05,0.0825\r\n2018-02-03,0.15,2019-02-03,0.02,2020-02-03,0.11,2021-02-03,0.04,0.08\r\n2018-02-04,0.1,2019-02-04,0.05,2020-02-04,0.11,2021-02-04,0.11,0.0925\r\n2018-02-05,0.13,2019-02-05,0.06,2020-02-05,0.05,2021-02-05,0.07,0.0775\r\n2018-02-06,0.14,2019-02-06,0.05,2020-02-06,0.07,2021-02-06,0.08,0.085\r\n2018-02-07,0.11,2019-02-07,0.04,2020-02-07,0.07,2021-02-07,0.08,0.075\r\n2018-02-08,0.08,2019-02-08,0.03,2020-02-08,0.14,2021-02-08,0.05,0.075\r\n2018-02-09,0.08,2019-02-09,0.05,2020-02-09,0.17,2021-02-09,0.06,0.09\r\n2018-02-10,0.15,2019-02-10,0.05,2020-02-10,0.15,2021-02-10,0.08,0.1075\r\n2018-02-11,0.07,2019-02-11,0.07,2020-02-11,0.17,2021-02-11,0,0.0775\r\n2018-02-12,0.14,2019-02-12,0.01,2020-02-12,0.12,2021-02-12,0.07,0.085\r\n2018-02-13,0.11,2019-02-13,0,2020-02-13,0.09,2021-02-13,0.11,0.0775\r\n2018-02-14,0.08,2019-02-14,0.05,2020-02-14,0.09,2021-02-14,0.05,0.0675\r\n2018-02-15,0.14,2019-02-15,0.07,2020-02-15,0.08,2021-02-15,0.01,0.075\r\n2018-02-16,0.1,2019-02-16,0.07,2020-02-16,0.08,2021-02-16,0.1,0.0875\r\n2018-02-17,0.1,2019-02-17,0.09,2020-02-17,0.19,2021-02-17,0.14,0.13\r\n2018-02-18,0.11,2019-02-18,0.12,2020-02-18,0.11,2021-02-18,0.03,0.0925\r\n2018-02-19,0.11,2019-02-19,0.09,2020-02-19,0.11,2021-02-19,0.01,0.08\r\n2018-02-20,0.07,2019-02-20,0.08,2020-02-20,0.09,2021-02-20,0.1,0.085\r\n2018-02-21,0.09,2019-02-21,0.16,2020-02-21,0.1,2021-02-21,0.17,0.13\r\n2018-02-22,0.07,2019-02-22,0.11,2020-02-22,0.12,2021-02-22,0.14,0.11\r\n2018-02-23,0.12,2019-02-23,0.07,2020-02-23,0.08,2021-02-23,0.2,0.1175\r\n2018-02-24,0.09,2019-02-24,0.04,2020-02-24,0.16,2021-02-24,0.2,0.1225\r\n2018-02-25,0.11,2019-02-25,0.02,2020-02-25,0.18,2021-02-25,0.14,0.1125\r\n2018-02-26,0.15,2019-02-26,0,2020-02-26,0.12,2021-02-26,0.16,0.1075\r\n2018-02-27,0.18,2019-02-27,0.05,2020-02-27,0.13,2021-02-27,0.15,0.1275\r\n2018-02-28,0.07,2019-02-28,0.1,2020-02-28,0.1,2021-02-28,0.15,0.105\r\n2018-03-01,0.08,2019-03-01,0.05,2020-02-29,0.13,2021-03-01,0.12,0.095\r\n2018-03-02,0.08,2019-03-02,0.02,2020-03-01,0.23,2021-03-02,0.13,0.115\r\n2018-03-03,0.07,2019-03-03,0.02,2020-03-02,0.21,2021-03-03,0.14,0.11\r\n2018-03-04,0.08,2019-03-04,0.05,2020-03-03,0.2,2021-03-04,0.13,0.115\r\n2018-03-05,0.12,2019-03-05,0,2020-03-04,0.13,2021-03-05,0.16,0.1025\r\n2018-03-06,0.11,2019-03-06,0.06,2020-03-05,0.13,2021-03-06,0.1,0.1\r\n2018-03-07,0.12,2019-03-07,0.08,2020-03-06,0.09,2021-03-07,0.12,0.1025\r\n2018-03-08,0.09,2019-03-08,0.07,2020-03-07,0.05,2021-03-08,0.1,0.0775\r\n2018-03-09,0.06,2019-03-09,0.03,2020-03-08,0.07,2021-03-09,0.07,0.0575\r\n2018-03-10,0.11,2019-03-10,0.11,2020-03-09,0.11,2021-03-10,0.04,0.0925\r\n2018-03-11,0.13,2019-03-11,0.15,2020-03-10,0.16,2021-03-11,0.12,0.14\r\n2018-03-12,0.11,2019-03-12,0.16,2020-03-11,0.13,2021-03-12,0.16,0.14\r\n2018-03-13,0.03,2019-03-13,0.16,2020-03-12,0.22,2021-03-13,0.13,0.135\r\n2018-03-14,0.06,2019-03-14,0.15,2020-03-13,0.19,2021-03-14,0.05,0.1125\r\n2018-03-15,0.03,2019-03-15,0.14,2020-03-14,0.13,2021-03-15,0.09,0.0975\r\n2018-03-16,0.07,2019-03-16,0.14,2020-03-15,0.07,2021-03-16,0.12,0.1\r\n2018-03-17,0.1,2019-03-17,0.14,2020-03-16,0.06,2021-03-17,0.12,0.105\r\n2018-03-18,0.11,2019-03-18,0.14,2020-03-17,0.01,2021-03-18,0.01,0.0675\r\n2018-03-19,0.13,2019-03-19,0.09,2020-03-18,0.02,2021-03-19,0.11,0.0875\r\n2018-03-20,0.03,2019-03-20,0.07,2020-03-19,0.12,2021-03-20,0.13,0.0875\r\n2018-03-21,0.01,2019-03-21,0.14,2020-03-20,0.13,2021-03-21,0.16,0.11\r\n2018-03-22,0.12,2019-03-22,0.02,2020-03-21,0.14,2021-03-22,0.13,0.1025\r\n2018-03-23,0.15,2019-03-23,0.07,2020-03-22,0.15,2021-03-23,0.23,0.15\r\n2018-03-24,0.13,2019-03-24,0.12,2020-03-23,0.16,2021-03-24,0.16,0.1425\r\n2018-03-25,0.13,2019-03-25,0.01,2020-03-24,0.06,2021-03-25,0.2,0.1\r\n2018-03-26,0.19,2019-03-26,0.07,2020-03-25,0.12,2021-03-26,0.17,0.1375\r\n2018-03-27,0.21,2019-03-27,0.13,2020-03-26,0.13,2021-03-27,0.17,0.16\r\n2018-03-28,0.23,2019-03-28,0.1,2020-03-27,0.14,2021-03-28,0.17,0.16\r\n2018-03-29,0.2,2019-03-29,0.14,2020-03-28,0.07,2021-03-29,0.29,0.175\r\n2018-03-30,0.16,2019-03-30,0.18,2020-03-29,0.09,2021-03-30,0.25,0.17\r\n2018-03-31,0.16,2019-03-31,0.17,2020-03-30,0.07,2021-03-31,0.2,0.15\r\n2018-04-01,0.18,2019-04-01,0.07,2020-03-31,0.18,2021-04-01,0.18,0.1525\r\n2018-04-02,0.22,2019-04-02,0.07,2020-04-01,0.2,2021-04-02,0.16,0.1625\r\n2018-04-03,0.18,2019-04-03,0.07,2020-04-02,0.19,2021-04-03,0.17,0.1525\r\n2018-04-04,0.15,2019-04-04,0.11,2020-04-03,0.16,2021-04-04,0.14,0.14\r\n2018-04-05,0.05,2019-04-05,0.06,2020-04-04,0.03,2021-04-05,0.15,0.0725\r\n2018-04-06,0,2019-04-06,0.08,2020-04-05,0.09,2021-04-06,0.17,0.085\r\n2018-04-07,0.19,2019-04-07,0.13,2020-04-06,0.14,2021-04-07,0.17,0.1575\r\n2018-04-08,0.16,2019-04-08,0.08,2020-04-07,0.14,2021-04-08,0.17,0.1375\r\n2018-04-09,0.18,2019-04-09,0.21,2020-04-08,0.19,2021-04-09,0.18,0.19\r\n2018-04-10,0.09,2019-04-10,0.22,2020-04-09,0.08,2021-04-10,0.19,0.145\r\n2018-04-11,0.06,2019-04-11,0.15,2020-04-10,0.18,2021-04-11,0.25,0.16\r\n2018-04-12,0.16,2019-04-12,0.22,2020-04-11,0.18,2021-04-12,0.24,0.2\r\n2018-04-13,0.18,2019-04-13,0.19,2020-04-12,0.21,2021-04-13,0.27,0.2125\r\n2018-04-14,0.19,2019-04-14,0.08,2020-04-13,0.24,2021-04-14,0.21,0.18\r\n2018-04-15,0.09,2019-04-15,0.08,2020-04-14,0.22,2021-04-15,0.18,0.1425\r\n2018-04-16,0.16,2019-04-16,0.17,2020-04-15,0.19,2021-04-16,0.23,0.1875\r\n2018-04-17,0.16,2019-04-17,0.19,2020-04-16,0.22,2021-04-17,0.25,0.205\r\n2018-04-18,0.12,2019-04-18,0.2,2020-04-17,0.2,2021-04-18,0.24,0.19\r\n2018-04-19,0.22,2019-04-19,0.19,2020-04-18,0.14,2021-04-19,0.21,0.19\r\n2018-04-20,0.21,2019-04-20,0.12,2020-04-19,0.16,2021-04-20,0.23,0.18\r\n2018-04-21,0.22,2019-04-21,0.24,2020-04-20,0.14,2021-04-21,0.28,0.22\r\n2018-04-22,0.21,2019-04-22,0.27,2020-04-21,0.19,2021-04-22,0.2,0.2175\r\n2018-04-23,0.25,2019-04-23,0.25,2020-04-22,0.2,2021-04-23,0.17,0.2175\r\n2018-04-24,0.21,2019-04-24,0.23,2020-04-23,0.24,2021-04-24,0.18,0.215\r\n2018-04-25,0.21,2019-04-25,0.23,2020-04-24,0.24,2021-04-25,0.09,0.1925\r\n2018-04-26,0.22,2019-04-26,0.22,2020-04-25,0.15,2021-04-26,0.18,0.1925\r\n2018-04-27,0.14,2019-04-27,0.22,2020-04-26,0.23,2021-04-27,0.24,0.2075\r\n2018-04-28,0.14,2019-04-28,0.21,2020-04-27,0.22,2021-04-28,0.23,0.2\r\n2018-04-29,0.18,2019-04-29,0.25,2020-04-28,0.24,2021-04-29,0.22,0.2225\r\n2018-04-30,0.2,2019-04-30,0.21,2020-04-29,0.18,2021-04-30,0.21,0.2\r\n2018-05-01,0.23,2019-05-01,0.22,2020-04-30,0.21,2021-05-01,0.23,0.2225\r\n2018-05-02,0.23,2019-05-02,0.22,2020-05-01,0.22,2021-05-02,0.32,0.2475\r\n2018-05-03,0.21,2019-05-03,0.23,2020-05-02,0.21,2021-05-03,0.33,0.245\r\n2018-05-04,0.21,2019-05-04,0.23,2020-05-03,0.22,2021-05-04,0.27,0.2325\r\n2018-05-05,0.17,2019-05-05,0.25,2020-05-04,0.22,2021-05-05,0.27,0.2275\r\n2018-05-06,0.23,2019-05-06,0.23,2020-05-05,0.27,2021-05-06,0.27,0.25\r\n2018-05-07,0.23,2019-05-07,0.22,2020-05-06,0.34,2021-05-07,0.31,0.275\r\n2018-05-08,0.26,2019-05-08,0.23,2020-05-07,0.32,2021-05-08,0.38,0.2975\r\n2018-05-09,0.24,2019-05-09,0.28,2020-05-08,0.26,2021-05-09,0.39,0.2925\r\n2018-05-10,0.24,2019-05-10,0.31,2020-05-09,0.26,2021-05-10,0.35,0.29\r\n2018-05-11,0.39,2019-05-11,0.23,2020-05-10,0.29,2021-05-11,0.29,0.3\r\n2018-05-12,0.3,2019-05-12,0.24,2020-05-11,0.07,2021-05-12,0.29,0.225\r\n2018-05-13,0.24,2019-05-13,0.24,2020-05-12,0.16,2021-05-13,0.26,0.225\r\n2018-05-14,0.24,2019-05-14,0.16,2020-05-13,0.1,2021-05-14,0.24,0.185\r\n2018-05-15,0.23,2019-05-15,0.07,2020-05-14,0.19,2021-05-15,0.2,0.1725\r\n2018-05-16,0.17,2019-05-16,0.15,2020-05-15,0.23,2021-05-16,0.26,0.2025\r\n2018-05-17,0.23,2019-05-17,0.16,2020-05-16,0.12,2021-05-17,0.25,0.19\r\n2018-05-18,0.25,2019-05-18,0.02,2020-05-17,0.18,2021-05-18,0.26,0.1775\r\n2018-05-19,0.25,2019-05-19,0.12,2020-05-18,0.09,2021-05-19,0.28,0.185\r\n2018-05-20,0.22,2019-05-20,0.21,2020-05-19,0.21,2021-05-20,0.33,0.2425\r\n2018-05-21,0.27,2019-05-21,0.13,2020-05-20,0.21,2021-05-21,0.31,0.23\r\n2018-05-22,0.26,2019-05-22,0.25,2020-05-21,0.25,2021-05-22,0.27,0.2575\r\n2018-05-23,0.23,2019-05-23,0.27,2020-05-22,0.32,2021-05-23,0.25,0.2675\r\n2018-05-24,0.25,2019-05-24,0.22,2020-05-23,0.29,2021-05-24,0.28,0.26\r\n2018-05-25,0.01,2019-05-25,0.24,2020-05-24,0.29,2021-05-25,0.26,0.2\r\n2018-05-26,0.18,2019-05-26,0.1,2020-05-25,0.29,2021-05-26,0.29,0.215\r\n2018-05-27,0.31,2019-05-27,0.18,2020-05-26,0.25,2021-05-27,0.22,0.24\r\n2018-05-28,0.34,2019-05-28,0.26,2020-05-27,0.28,2021-05-28,0.27,0.2875\r\n2018-05-29,0.31,2019-05-29,0.25,2020-05-28,0.28,2021-05-29,0.26,0.275\r\n2018-05-30,0.3,2019-05-30,0.2,2020-05-29,0.28,2021-05-30,0.3,0.27\r\n2018-05-31,0.21,2019-05-31,0.26,2020-05-30,0.15,2021-05-31,0.32,0.235\r\n2018-06-01,0.28,2019-06-01,0.28,2020-05-31,0.21,2021-06-01,0.29,0.265\r\n2018-06-02,0.3,2019-06-02,0.26,2020-06-01,0.24,2021-06-02,0.29,0.2725\r\n2018-06-03,0.3,2019-06-03,0.26,2020-06-02,0.27,2021-06-03,0.28,0.2775\r\n2018-06-04,0.29,2019-06-04,0.3,2020-06-03,0.27,2021-06-04,0.29,0.2875\r\n2018-06-05,0.26,2019-06-05,0.3,2020-06-04,0.3,2021-06-05,0.29,0.2875\r\n2018-06-06,0.27,2019-06-06,0.3,2020-06-05,0.3,2021-06-06,0.34,0.3025\r\n2018-06-07,0.25,2019-06-07,0.37,2020-06-06,0.24,2021-06-07,0.3,0.29\r\n2018-06-08,0.29,2019-06-08,0.37,2020-06-07,0.27,2021-06-08,0.28,0.3025\r\n2018-06-09,0.28,2019-06-09,0.33,2020-06-08,0.27,2021-06-09,0.23,0.2775\r\n2018-06-10,0.26,2019-06-10,0.29,2020-06-09,0.23,2021-06-10,0.25,0.2575\r\n2018-06-11,0.31,2019-06-11,0.28,2020-06-10,0.29,2021-06-11,0.24,0.28\r\n2018-06-12,0.3,2019-06-12,0.2,2020-06-11,0.28,2021-06-12,0.26,0.26\r\n2018-06-13,0.3,2019-06-13,0.24,2020-06-12,0.23,2021-06-13,0.33,0.275\r\n2018-06-14,0.3,2019-06-14,0.26,2020-06-13,0.18,2021-06-14,0.3,0.26\r\n2018-06-15,0.27,2019-06-15,0.2,2020-06-14,0.24,2021-06-15,0.28,0.2475\r\n2018-06-16,0.27,2019-06-16,0.25,2020-06-15,0.13,2021-06-16,0.31,0.24\r\n2018-06-17,0.25,2019-06-17,0.32,2020-06-16,0.3,2021-06-17,0.35,0.305\r\n2018-06-18,0.25,2019-06-18,0.35,2020-06-17,0.37,2021-06-18,0.3,0.3175\r\n2018-06-19,0.27,2019-06-19,0.34,2020-06-18,0.33,2021-06-19,0.3,0.31\r\n2018-06-20,0.3,2019-06-20,0.4,2020-06-19,0.28,2021-06-20,0.31,0.3225\r\n2018-06-21,0.27,2019-06-21,0.43,2020-06-20,0.27,2021-06-21,0.32,0.3225\r\n2018-06-22,0.35,2019-06-22,0.35,2020-06-21,0.28,2021-06-22,0.29,0.3175\r\n2018-06-23,0.46,2019-06-23,0.29,2020-06-22,0.29,2021-06-23,0.28,0.33\r\n2018-06-24,0.37,2019-06-24,0.25,2020-06-23,0.29,2021-06-24,0.27,0.295\r\n2018-06-25,0.27,2019-06-25,0.28,2020-06-24,0.26,2021-06-25,0.28,0.2725\r\n2018-06-26,0.29,2019-06-26,0.31,2020-06-25,0.33,2021-06-26,0.29,0.305\r\n2018-06-27,0.3,2019-06-27,0.24,2020-06-26,0.31,2021-06-27,0.29,0.285\r\n2018-06-28,0.27,2019-06-28,0.27,2020-06-27,0.31,2021-06-28,0.29,0.285\r\n2018-06-29,0.39,2019-06-29,0.27,2020-06-28,0.33,2021-06-29,0.29,0.32\r\n2018-06-30,0.44,2019-06-30,0.29,2020-06-29,0.37,2021-06-30,0.32,0.355\r\n2018-07-01,0.35,2019-07-01,0.25,2020-06-30,0.3,2021-07-01,0.28,0.295\r\n2018-07-02,0.31,2019-07-02,0.27,2020-07-01,0.29,2021-07-02,0.29,0.29\r\n2018-07-03,0.3,2019-07-03,0.27,2020-07-02,0.29,2021-07-03,0.31,0.2925\r\n2018-07-04,0.29,2019-07-04,0.27,2020-07-03,0.28,2021-07-04,0.3,0.285\r\n2018-07-05,0.3,2019-07-05,0.27,2020-07-04,0.28,2021-07-05,0.3,0.2875\r\n2018-07-06,0.14,2019-07-06,0.27,2020-07-05,0.3,2021-07-06,0.28,0.2475\r\n2018-07-07,0.28,2019-07-07,0.27,2020-07-06,0.32,2021-07-07,0.29,0.29\r\n2018-07-08,0.29,2019-07-08,0.26,2020-07-07,0.28,2021-07-08,0.29,0.28\r\n2018-07-09,0.29,2019-07-09,0.22,2020-07-08,0.3,2021-07-09,0.31,0.28\r\n2018-07-10,0.32,2019-07-10,0.26,2020-07-09,0.29,2021-07-10,0.3,0.2925\r\n2018-07-11,0.29,2019-07-11,0.27,2020-07-10,0.3,2021-07-11,0.31,0.2925\r\n2018-07-12,0.29,2019-07-12,0.27,2020-07-11,0.3,2021-07-12,0.29,0.2875\r\n2018-07-13,0.16,2019-07-13,0.27,2020-07-12,0.3,2021-07-13,0.3,0.2575\r\n2018-07-14,0.28,2019-07-14,0.28,2020-07-13,0.29,2021-07-14,0.28,0.2825\r\n2018-07-15,0.28,2019-07-15,0.27,2020-07-14,0.27,2021-07-15,0.28,0.275\r\n2018-07-16,0.28,2019-07-16,0.27,2020-07-15,0.29,2021-07-16,0.26,0.275\r\n2018-07-17,0.28,2019-07-17,0.27,2020-07-16,0.28,2021-07-17,0.28,0.2775\r\n2018-07-18,0.27,2019-07-18,0.28,2020-07-17,0.28,2021-07-18,0.31,0.285\r\n2018-07-19,0.27,2019-07-19,0.27,2020-07-18,0.26,2021-07-19,0.28,0.27\r\n2018-07-20,0.29,2019-07-20,0.26,2020-07-19,0.28,2021-07-20,0.3,0.2825\r\n2018-07-21,0.28,2019-07-21,0.25,2020-07-20,0.27,2021-07-21,0.27,0.2675\r\n2018-07-22,0.28,2019-07-22,0.28,2020-07-21,0.26,2021-07-22,0.29,0.2775\r\n2018-07-23,0.28,2019-07-23,0.29,2020-07-22,0.25,2021-07-23,0.28,0.275\r\n2018-07-24,0.28,2019-07-24,0.28,2020-07-23,0.26,2021-07-24,0.18,0.25\r\n2018-07-25,0.27,2019-07-25,0.27,2020-07-24,0.26,2021-07-25,0.24,0.26\r\n2018-07-26,0.25,2019-07-26,0.27,2020-07-25,0.26,2021-07-26,0.25,0.2575\r\n2018-07-27,0.23,2019-07-27,0.27,2020-07-26,0.27,2021-07-27,0.17,0.235\r\n2018-07-28,0.2,2019-07-28,0.28,2020-07-27,0.27,2021-07-28,0.28,0.2575\r\n2018-07-29,0.22,2019-07-29,0.28,2020-07-28,0.26,2021-07-29,0.26,0.255\r\n2018-07-30,0.19,2019-07-30,0.26,2020-07-29,0.28,2021-07-30,0.24,0.2425\r\n2018-07-31,0.2,2019-07-31,0.26,2020-07-30,0.27,2021-07-31,0.28,0.2525\r\n2018-08-01,0.23,2019-08-01,0.26,2020-07-31,0.27,2021-08-01,0.28,0.26\r\n2018-08-02,0.25,2019-08-02,0.24,2020-08-01,0.25,2021-08-02,0.26,0.25\r\n2018-08-03,0.24,2019-08-03,0.26,2020-08-02,0.26,2021-08-03,0.26,0.255\r\n2018-08-04,0.25,2019-08-04,0.27,2020-08-03,0.26,2021-08-04,0.29,0.2675\r\n2018-08-05,0.18,2019-08-05,0.24,2020-08-04,0.26,2021-08-05,0.22,0.225\r\n2018-08-06,0.21,2019-08-06,0.27,2020-08-05,0.25,2021-08-06,0.24,0.2425\r\n2018-08-07,0.2,2019-08-07,0.26,2020-08-06,0.23,2021-08-07,0.21,0.225\r\n2018-08-08,0.21,2019-08-08,0.24,2020-08-07,0.26,2021-08-08,0.22,0.2325\r\n2018-08-09,0.19,2019-08-09,0.18,2020-08-08,0.25,2021-08-09,0.24,0.215\r\n2018-08-10,0.23,2019-08-10,0.13,2020-08-09,0.26,2021-08-10,0.23,0.2125\r\n2018-08-11,0.23,2019-08-11,0.24,2020-08-10,0.26,2021-08-11,0.2,0.2325\r\n2018-08-12,0.24,2019-08-12,0.23,2020-08-11,0.25,2021-08-12,0.2,0.23\r\n2018-08-13,0.2,2019-08-13,0.24,2020-08-12,0.25,2021-08-13,0.19,0.22\r\n2018-08-14,0.23,2019-08-14,0.25,2020-08-13,0.27,2021-08-14,0.22,0.2425\r\n2018-08-15,0.23,2019-08-15,0.27,2020-08-14,0.25,2021-08-15,0.22,0.2425\r\n2018-08-16,0.21,2019-08-16,0.28,2020-08-15,0.27,2021-08-16,0.18,0.235\r\n2018-08-17,0.23,2019-08-17,0.25,2020-08-16,0.13,2021-08-17,0.14,0.1875\r\n2018-08-18,0.21,2019-08-18,0.23,2020-08-17,0.09,2021-08-18,0.35,0.22\r\n2018-08-19,0.2,2019-08-19,0.22,2020-08-18,0.23,2021-08-19,0.25,0.225\r\n2018-08-20,0.19,2019-08-20,0.21,2020-08-19,0.12,2021-08-20,0.17,0.1725\r\n2018-08-21,0.2,2019-08-21,0.2,2020-08-20,0.11,2021-08-21,0.17,0.17\r\n2018-08-22,0.2,2019-08-22,0.26,2020-08-21,0.08,2021-08-22,0.19,0.1825\r\n2018-08-23,0.21,2019-08-23,0.24,2020-08-22,0.16,2021-08-23,0.22,0.2075\r\n2018-08-24,0.18,2019-08-24,0.23,2020-08-23,0.13,2021-08-24,0.22,0.19\r\n2018-08-25,0.19,2019-08-25,0.23,2020-08-24,0.18,2021-08-25,0.21,0.2025\r\n2018-08-26,0.18,2019-08-26,0.24,2020-08-25,0.16,2021-08-26,0.22,0.2\r\n2018-08-27,0.19,2019-08-27,0.23,2020-08-26,0.16,2021-08-27,0.27,0.2125\r\n2018-08-28,0.21,2019-08-28,0.22,2020-08-27,0.2,2021-08-28,0.2,0.2075\r\n2018-08-29,0.21,2019-08-29,0.23,2020-08-28,0.22,2021-08-29,0.2,0.215\r\n2018-08-30,0.2,2019-08-30,0.21,2020-08-29,0.15,2021-08-30,0.21,0.1925\r\n2018-08-31,0.2,2019-08-31,0.21,2020-08-30,0.17,2021-08-31,0.22,0.2\r\n2018-09-01,0.22,2019-09-01,0.23,2020-08-31,0.24,2021-09-01,0.21,0.225\r\n2018-09-02,0.21,2019-09-02,0.22,2020-09-01,0.28,2021-09-02,0.18,0.2225\r\n2018-09-03,0.19,2019-09-03,0.2,2020-09-02,0.18,2021-09-03,0.19,0.19\r\n2018-09-04,0.21,2019-09-04,0.16,2020-09-03,0.18,2021-09-04,0.2,0.1875\r\n2018-09-05,0.22,2019-09-05,0.24,2020-09-04,0.16,2021-09-05,0.21,0.2075\r\n2018-09-06,0.2,2019-09-06,0.2,2020-09-05,0.21,2021-09-06,0.22,0.2075\r\n2018-09-07,0.21,2019-09-07,0.19,2020-09-06,0.22,2021-09-07,0.24,0.215\r\n2018-09-08,0.19,2019-09-08,0.18,2020-09-07,0.2,2021-09-08,0.18,0.1875\r\n2018-09-09,0.2,2019-09-09,0.18,2020-09-08,0.37,2021-09-09,0.15,0.225\r\n2018-09-10,0.19,2019-09-10,0.17,2020-09-09,0.08,2021-09-10,0.18,0.155\r\n2018-09-11,0.22,2019-09-11,0.2,2020-09-10,0.09,2021-09-11,0.19,0.175\r\n2018-09-12,0.17,2019-09-12,0.19,2020-09-11,0.13,2021-09-12,0.18,0.1675\r\n2018-09-13,0.17,2019-09-13,0.19,2020-09-12,0.15,2021-09-13,0.18,0.1725\r\n2018-09-14,0.17,2019-09-14,0.21,2020-09-13,0.15,2021-09-14,0.22,0.1875\r\n2018-09-15,0.19,2019-09-15,0.21,2020-09-14,0.15,2021-09-15,0.18,0.1825\r\n2018-09-16,0.17,2019-09-16,0.15,2020-09-15,0.17,2021-09-16,0.17,0.165\r\n2018-09-17,0.17,2019-09-17,0.17,2020-09-16,0.15,2021-09-17,0.19,0.17\r\n2018-09-18,0.16,2019-09-18,0.1,2020-09-17,0.2,2021-09-18,0.06,0.13\r\n2018-09-19,0.21,2019-09-19,0.17,2020-09-18,0.16,2021-09-19,0.18,0.18\r\n2018-09-20,0.22,2019-09-20,0.2,2020-09-19,0.17,2021-09-20,0.28,0.2175\r\n2018-09-21,0.19,2019-09-21,0.2,2020-09-20,0.17,2021-09-21,0.2,0.19\r\n2018-09-22,0.17,2019-09-22,0.13,2020-09-21,0.13,2021-09-22,0.18,0.1525\r\n2018-09-23,0.17,2019-09-23,0.24,2020-09-22,0.15,2021-09-23,0.26,0.205\r\n2018-09-24,0.22,2019-09-24,0.26,2020-09-23,0.15,2021-09-24,0.19,0.205\r\n2018-09-25,0.25,2019-09-25,0.3,2020-09-24,0.14,2021-09-25,0.19,0.22\r\n2018-09-26,0.17,2019-09-26,0.23,2020-09-25,0.14,2021-09-26,0.16,0.175\r\n2018-09-27,0.17,2019-09-27,0.05,2020-09-26,0.22,2021-09-27,0.13,0.1425\r\n2018-09-28,0.17,2019-09-28,0.17,2020-09-27,0.32,2021-09-28,0.21,0.2175\r\n2018-09-29,0.13,2019-09-29,0.1,2020-09-28,0.29,2021-09-29,0.22,0.185\r\n2018-09-30,0.14,2019-09-30,0.12,2020-09-29,0.13,2021-09-30,0.21,0.15\r\n2018-10-01,0.07,2019-10-01,0.16,2020-09-30,0.19,2021-10-01,0.15,0.1425\r\n2018-10-02,0.1,2019-10-02,0.13,2020-10-01,0.18,2021-10-02,0.15,0.14\r\n2018-10-03,0.1,2019-10-03,0.16,2020-10-02,0.12,2021-10-03,0.14,0.13\r\n2018-10-04,0.03,2019-10-04,0.16,2020-10-03,0.11,2021-10-04,0.16,0.115\r\n2018-10-05,0.11,2019-10-05,0.2,2020-10-04,0.11,2021-10-05,0.17,0.1475\r\n2018-10-06,0.18,2019-10-06,0.18,2020-10-05,0.15,2021-10-06,0.09,0.15\r\n2018-10-07,0.26,2019-10-07,0.14,2020-10-06,0.14,2021-10-07,0.1,0.16\r\n2018-10-08,0.22,2019-10-08,0.15,2020-10-07,0.14,2021-10-08,0.13,0.16\r\n2018-10-09,0.16,2019-10-09,0.29,2020-10-08,0.09,2021-10-09,0.14,0.17\r\n2018-10-10,0.14,2019-10-10,0.22,2020-10-09,0.11,2021-10-10,0.16,0.1575\r\n2018-10-11,0.17,2019-10-11,0.14,2020-10-10,0.07,2021-10-11,0.25,0.1575\r\n2018-10-12,0.2,2019-10-12,0.12,2020-10-11,0.17,2021-10-12,0.19,0.17\r\n2018-10-13,0.21,2019-10-13,0.12,2020-10-12,0.15,2021-10-13,0.11,0.1475\r\n2018-10-14,0.24,2019-10-14,0.12,2020-10-13,0.13,2021-10-14,0.2,0.1725\r\n2018-10-15,0.2,2019-10-15,0.12,2020-10-14,0.25,2021-10-15,0.12,0.1725\r\n2018-10-16,0.19,2019-10-16,0.11,2020-10-15,0.31,2021-10-16,0.12,0.1825\r\n2018-10-17,0.11,2019-10-17,0.13,2020-10-16,0.26,2021-10-17,0.12,0.155\r\n2018-10-18,0.11,2019-10-18,0.1,2020-10-17,0.18,2021-10-18,0.05,0.11\r\n2018-10-19,0.11,2019-10-19,0.08,2020-10-18,0.15,2021-10-19,0.09,0.1075\r\n2018-10-20,0.12,2019-10-20,0.12,2020-10-19,0.13,2021-10-20,0,0.0925\r\n2018-10-21,0.11,2019-10-21,0.18,2020-10-20,0.22,2021-10-21,0.01,0.13\r\n2018-10-22,0.11,2019-10-22,0.18,2020-10-21,0.2,2021-10-22,0.08,0.1425\r\n2018-10-23,0.07,2019-10-23,0.24,2020-10-22,0.29,2021-10-23,0.01,0.1525\r\n2018-10-24,0.08,2019-10-24,0.21,2020-10-23,0.16,2021-10-24,0,0.1125\r\n2018-10-25,0.11,2019-10-25,0.11,2020-10-24,0.09,2021-10-25,0.08,0.0975\r\n2018-10-26,0.09,2019-10-26,0.2,2020-10-25,0.2,2021-10-26,0.05,0.135\r\n2018-10-27,0.1,2019-10-27,0.22,2020-10-26,0.16,2021-10-27,0.07,0.1375\r\n2018-10-28,0.06,2019-10-28,0.12,2020-10-27,0.15,2021-10-28,0.09,0.105\r\n2018-10-29,0.12,2019-10-29,0.18,2020-10-28,0.09,2021-10-29,0.07,0.115\r\n2018-10-30,0.14,2019-10-30,0.13,2020-10-29,0.09,2021-10-30,0.07,0.1075\r\n2018-10-31,0.16,2019-10-31,0.1,2020-10-30,0.09,2021-10-31,0.05,0.1\r\n2018-11-01,0.14,2019-11-01,0.09,2020-10-31,0.1,2021-11-01,0.02,0.0875\r\n2018-11-02,0.11,2019-11-02,0.1,2020-11-01,0.09,2021-11-02,0.07,0.0925\r\n2018-11-03,0.2,2019-11-03,0.09,2020-11-02,0.1,2021-11-03,0.08,0.1175\r\n2018-11-04,0.12,2019-11-04,0.09,2020-11-03,0.09,2021-11-04,0.1,0.1\r\n2018-11-05,0.17,2019-11-05,0.09,2020-11-04,0.09,2021-11-05,0.01,0.09\r\n2018-11-06,0.18,2019-11-06,0.09,2020-11-05,0.1,2021-11-06,0.02,0.0975\r\n2018-11-07,0.17,2019-11-07,0.08,2020-11-06,0.13,2021-11-07,0.08,0.115\r\n2018-11-08,0.2,2019-11-08,0.09,2020-11-07,0.07,2021-11-08,0.04,0.1\r\n2018-11-09,0.1,2019-11-09,0.08,2020-11-08,0.14,2021-11-09,0,0.08\r\n2018-11-10,0.11,2019-11-10,0.09,2020-11-09,0.11,2021-11-10,0.03,0.085\r\n2018-11-11,0.16,2019-11-11,0.12,2020-11-10,0.07,2021-11-11,0.08,0.1075\r\n2018-11-12,0.11,2019-11-12,0.07,2020-11-11,0.07,2021-11-12,0.02,0.0675\r\n2018-11-13,0.04,2019-11-13,0.06,2020-11-12,0.06,2021-11-13,0.05,0.0525\r\n2018-11-14,0.05,2019-11-14,0.07,2020-11-13,0.04,2021-11-14,0.03,0.0475\r\n2018-11-15,0.06,2019-11-15,0.08,2020-11-14,0.04,2021-11-15,0,0.045\r\n2018-11-16,0.05,2019-11-16,0.11,2020-11-15,0.06,2021-11-16,0.1,0.08\r\n2018-11-17,0.04,2019-11-17,0.07,2020-11-16,0.07,2021-11-17,0.07,0.0625\r\n2018-11-18,0.05,2019-11-18,0.08,2020-11-17,0.01,2021-11-18,0,0.035\r\n2018-11-19,0.07,2019-11-19,0.14,2020-11-18,0.07,2021-11-19,0.01,0.0725\r\n2018-11-20,0.06,2019-11-20,0.23,2020-11-19,0.08,2021-11-20,0.1,0.1175\r\n2018-11-21,0,2019-11-21,0.08,2020-11-20,0.1,2021-11-21,0.09,0.0675\r\n2018-11-22,0.04,2019-11-22,0.07,2020-11-21,0.11,2021-11-22,0.06,0.07\r\n2018-11-23,0,2019-11-23,0.09,2020-11-22,0.05,2021-11-23,0.09,0.0575\r\n2018-11-24,0.06,2019-11-24,0.06,2020-11-23,0.08,2021-11-24,0.1,0.075\r\n2018-11-25,0.07,2019-11-25,0.12,2020-11-24,0.08,2021-11-25,0.05,0.08\r\n2018-11-26,0.02,2019-11-26,0.02,2020-11-25,0.09,2021-11-26,0.06,0.0475\r\n2018-11-27,0,2019-11-27,0.04,2020-11-26,0.1,2021-11-27,0.06,0.05\r\n2018-11-28,0.01,2019-11-28,0.04,2020-11-27,0.08,2021-11-28,0.06,0.0475\r\n2018-11-29,0,2019-11-29,0.04,2020-11-28,0.07,2021-11-29,0.06,0.0425\r\n2018-11-30,0.04,2019-11-30,0,2020-11-29,0.05,2021-11-30,0.07,0.04\r\n2018-12-01,0.05,2019-12-01,0,2020-11-30,0.06,2021-12-01,0.07,0.045\r\n2018-12-02,0.05,2019-12-02,0.02,2020-12-01,0.11,2021-12-02,0.06,0.06\r\n2018-12-03,0.04,2019-12-03,0.08,2020-12-02,0.09,2021-12-03,0.05,0.065\r\n2018-12-04,0.06,2019-12-04,0.07,2020-12-03,0.05,2021-12-04,0.05,0.0575\r\n2018-12-05,0.02,2019-12-05,0.05,2020-12-04,0.08,2021-12-05,0.04,0.0475\r\n2018-12-06,0.07,2019-12-06,0.08,2020-12-05,0.04,2021-12-06,0,0.0475\r\n2018-12-07,0.04,2019-12-07,0.11,2020-12-06,0.11,2021-12-07,0.05,0.0775\r\n2018-12-08,0.06,2019-12-08,0.07,2020-12-07,0.15,2021-12-08,0,0.07\r\n2018-12-09,0.02,2019-12-09,0.05,2020-12-08,0.09,2021-12-09,0.07,0.0575\r\n2018-12-10,0.07,2019-12-10,0.04,2020-12-09,0.11,2021-12-10,0.06,0.07\r\n2018-12-11,0.06,2019-12-11,0.04,2020-12-10,0.1,2021-12-11,0.01,0.0525\r\n2018-12-12,0.08,2019-12-12,0.04,2020-12-11,0.03,2021-12-12,0,0.0375\r\n2018-12-13,0.05,2019-12-13,0.07,2020-12-12,0.05,2021-12-13,0.01,0.045\r\n2018-12-14,0.03,2019-12-14,0.05,2020-12-13,0,2021-12-14,0.03,0.0275\r\n2018-12-15,0,2019-12-15,0.04,2020-12-14,0.06,2021-12-15,0.01,0.0275\r\n2018-12-16,0,2019-12-16,0.06,2020-12-15,0.03,2021-12-16,0.01,0.025\r\n2018-12-17,0.03,2019-12-17,0.04,2020-12-16,0.01,2021-12-17,0.04,0.03\r\n2018-12-18,0.03,2019-12-18,0.05,2020-12-17,0.06,2021-12-18,0.03,0.0425\r\n2018-12-19,0.05,2019-12-19,0.04,2020-12-18,0.07,2021-12-19,0,0.04\r\n2018-12-20,0,2019-12-20,0.04,2020-12-19,0.04,2021-12-20,0.02,0.025\r\n2018-12-21,0.04,2019-12-21,0.06,2020-12-20,0.03,2021-12-21,0.01,0.035\r\n2018-12-22,0.03,2019-12-22,0.06,2020-12-21,0.04,2021-12-22,0,0.0325\r\n2018-12-23,0,2019-12-23,0.07,2020-12-22,0.09,2021-12-23,0,0.04\r\n2018-12-24,0,2019-12-24,0.04,2020-12-23,0.11,2021-12-24,0.06,0.0525\r\n2018-12-25,0.08,2019-12-25,0.05,2020-12-24,0.04,2021-12-25,0.02,0.0475\r\n2018-12-26,0.06,2019-12-26,0.07,2020-12-25,0,2021-12-26,0.03,0.04\r\n2018-12-27,0.08,2019-12-27,0.06,2020-12-26,0.04,2021-12-27,0.05,0.0575\r\n2018-12-28,0.09,2019-12-28,0.05,2020-12-27,0.04,2021-12-28,0.01,0.0475\r\n2018-12-29,0.06,2019-12-29,0.05,2020-12-28,0.04,2021-12-29,0.01,0.04\r\n2018-12-30,0.05,2019-12-30,0.09,2020-12-29,0.08,2021-12-30,0.02,0.06\r\n2018-12-31,0.11,2019-12-31,0.06,2020-12-30,0.04,2021-12-31,0.04,0.0625\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/historicalET.csv b/historicalET.csv
--- a/historicalET.csv	
+++ b/historicalET.csv	
@@ -1,366 +1,367 @@
-Year4,Year4ET,Year3,Year3ET,Year2,Year2ET,Year1,Year1ET,Average
-2018-01-01,0.06,2019-01-01,0.09,2020-01-01,0.05,2021-01-01,0.03,0.0575
-2018-01-02,0.03,2019-01-02,0.05,2020-01-02,0.06,2021-01-02,0,0.035
-2018-01-03,0.03,2019-01-03,0.04,2020-01-03,0.05,2021-01-03,0,0.03
-2018-01-04,0,2019-01-04,0.05,2020-01-04,0.05,2021-01-04,0.02,0.03
-2018-01-05,0.01,2019-01-05,0,2020-01-05,0.05,2021-01-05,0.06,0.03
-2018-01-06,0.04,2019-01-06,0,2020-01-06,0.08,2021-01-06,0.01,0.0325
-2018-01-07,0.03,2019-01-07,0,2020-01-07,0.04,2021-01-07,0.02,0.0225
-2018-01-08,0,2019-01-08,0,2020-01-08,0.04,2021-01-08,0.04,0.02
-2018-01-09,0.02,2019-01-09,0.03,2020-01-09,0.04,2021-01-09,0.07,0.04
-2018-01-10,0.01,2019-01-10,0.03,2020-01-10,0.05,2021-01-10,0.04,0.0325
-2018-01-11,0.01,2019-01-11,0.01,2020-01-11,0.04,2021-01-11,0.04,0.025
-2018-01-12,0.06,2019-01-12,0.05,2020-01-12,0.05,2021-01-12,0.01,0.0425
-2018-01-13,0.04,2019-01-13,0.06,2020-01-13,0.04,2021-01-13,0.03,0.0425
-2018-01-14,0.03,2019-01-14,0.04,2020-01-14,0.07,2021-01-14,0.07,0.0525
-2018-01-15,0.02,2019-01-15,0,2020-01-15,0.05,2021-01-15,0.04,0.0275
-2018-01-16,0.03,2019-01-16,0,2020-01-16,0.03,2021-01-16,0.12,0.045
-2018-01-17,0.04,2019-01-17,0.04,2020-01-17,0.02,2021-01-17,0.13,0.0575
-2018-01-18,0,2019-01-18,0.01,2020-01-18,0.05,2021-01-18,0.24,0.075
-2018-01-19,0.05,2019-01-19,0,2020-01-19,0.03,2021-01-19,0.17,0.0625
-2018-01-20,0.07,2019-01-20,0.02,2020-01-20,0.02,2021-01-20,0.1,0.0525
-2018-01-21,0.02,2019-01-21,0.06,2020-01-21,0.01,2021-01-21,0.05,0.035
-2018-01-22,0.01,2019-01-22,0.09,2020-01-22,0.03,2021-01-22,0.02,0.0375
-2018-01-23,0.05,2019-01-23,0.06,2020-01-23,0.01,2021-01-23,0.09,0.0525
-2018-01-24,0,2019-01-24,0.1,2020-01-24,0.01,2021-01-24,0.02,0.0325
-2018-01-25,0.02,2019-01-25,0.09,2020-01-25,0.02,2021-01-25,0.09,0.055
-2018-01-26,0.03,2019-01-26,0.08,2020-01-26,0.05,2021-01-26,0.03,0.0475
-2018-01-27,0.04,2019-01-27,0.09,2020-01-27,0.05,2021-01-27,0.03,0.0525
-2018-01-28,0.07,2019-01-28,0.02,2020-01-28,0.05,2021-01-28,0.01,0.0375
-2018-01-29,0.03,2019-01-29,0.06,2020-01-29,0.07,2021-01-29,0.02,0.045
-2018-01-30,0.06,2019-01-30,0.06,2020-01-30,0.07,2021-01-30,0.04,0.0575
-2018-01-31,0.06,2019-01-31,0.08,2020-01-31,0.07,2021-01-31,0.02,0.0575
-2018-02-01,0.08,2019-02-01,0.02,2020-02-01,0.05,2021-02-01,0.04,0.0475
-2018-02-02,0.13,2019-02-02,0.03,2020-02-02,0.12,2021-02-02,0.05,0.0825
-2018-02-03,0.15,2019-02-03,0.02,2020-02-03,0.11,2021-02-03,0.04,0.08
-2018-02-04,0.1,2019-02-04,0.05,2020-02-04,0.11,2021-02-04,0.11,0.0925
-2018-02-05,0.13,2019-02-05,0.06,2020-02-05,0.05,2021-02-05,0.07,0.0775
-2018-02-06,0.14,2019-02-06,0.05,2020-02-06,0.07,2021-02-06,0.08,0.085
-2018-02-07,0.11,2019-02-07,0.04,2020-02-07,0.07,2021-02-07,0.08,0.075
-2018-02-08,0.08,2019-02-08,0.03,2020-02-08,0.14,2021-02-08,0.05,0.075
-2018-02-09,0.08,2019-02-09,0.05,2020-02-09,0.17,2021-02-09,0.06,0.09
-2018-02-10,0.15,2019-02-10,0.05,2020-02-10,0.15,2021-02-10,0.08,0.1075
-2018-02-11,0.07,2019-02-11,0.07,2020-02-11,0.17,2021-02-11,0,0.0775
-2018-02-12,0.14,2019-02-12,0.01,2020-02-12,0.12,2021-02-12,0.07,0.085
-2018-02-13,0.11,2019-02-13,0,2020-02-13,0.09,2021-02-13,0.11,0.0775
-2018-02-14,0.08,2019-02-14,0.05,2020-02-14,0.09,2021-02-14,0.05,0.0675
-2018-02-15,0.14,2019-02-15,0.07,2020-02-15,0.08,2021-02-15,0.01,0.075
-2018-02-16,0.1,2019-02-16,0.07,2020-02-16,0.08,2021-02-16,0.1,0.0875
-2018-02-17,0.1,2019-02-17,0.09,2020-02-17,0.19,2021-02-17,0.14,0.13
-2018-02-18,0.11,2019-02-18,0.12,2020-02-18,0.11,2021-02-18,0.03,0.0925
-2018-02-19,0.11,2019-02-19,0.09,2020-02-19,0.11,2021-02-19,0.01,0.08
-2018-02-20,0.07,2019-02-20,0.08,2020-02-20,0.09,2021-02-20,0.1,0.085
-2018-02-21,0.09,2019-02-21,0.16,2020-02-21,0.1,2021-02-21,0.17,0.13
-2018-02-22,0.07,2019-02-22,0.11,2020-02-22,0.12,2021-02-22,0.14,0.11
-2018-02-23,0.12,2019-02-23,0.07,2020-02-23,0.08,2021-02-23,0.2,0.1175
-2018-02-24,0.09,2019-02-24,0.04,2020-02-24,0.16,2021-02-24,0.2,0.1225
-2018-02-25,0.11,2019-02-25,0.02,2020-02-25,0.18,2021-02-25,0.14,0.1125
-2018-02-26,0.15,2019-02-26,0,2020-02-26,0.12,2021-02-26,0.16,0.1075
-2018-02-27,0.18,2019-02-27,0.05,2020-02-27,0.13,2021-02-27,0.15,0.1275
-2018-02-28,0.07,2019-02-28,0.1,2020-02-28,0.1,2021-02-28,0.15,0.105
-2018-03-01,0.08,2019-03-01,0.05,2020-02-29,0.13,2021-03-01,0.12,0.095
-2018-03-02,0.08,2019-03-02,0.02,2020-03-01,0.23,2021-03-02,0.13,0.115
-2018-03-03,0.07,2019-03-03,0.02,2020-03-02,0.21,2021-03-03,0.14,0.11
-2018-03-04,0.08,2019-03-04,0.05,2020-03-03,0.2,2021-03-04,0.13,0.115
-2018-03-05,0.12,2019-03-05,0,2020-03-04,0.13,2021-03-05,0.16,0.1025
-2018-03-06,0.11,2019-03-06,0.06,2020-03-05,0.13,2021-03-06,0.1,0.1
-2018-03-07,0.12,2019-03-07,0.08,2020-03-06,0.09,2021-03-07,0.12,0.1025
-2018-03-08,0.09,2019-03-08,0.07,2020-03-07,0.05,2021-03-08,0.1,0.0775
-2018-03-09,0.06,2019-03-09,0.03,2020-03-08,0.07,2021-03-09,0.07,0.0575
-2018-03-10,0.11,2019-03-10,0.11,2020-03-09,0.11,2021-03-10,0.04,0.0925
-2018-03-11,0.13,2019-03-11,0.15,2020-03-10,0.16,2021-03-11,0.12,0.14
-2018-03-12,0.11,2019-03-12,0.16,2020-03-11,0.13,2021-03-12,0.16,0.14
-2018-03-13,0.03,2019-03-13,0.16,2020-03-12,0.22,2021-03-13,0.13,0.135
-2018-03-14,0.06,2019-03-14,0.15,2020-03-13,0.19,2021-03-14,0.05,0.1125
-2018-03-15,0.03,2019-03-15,0.14,2020-03-14,0.13,2021-03-15,0.09,0.0975
-2018-03-16,0.07,2019-03-16,0.14,2020-03-15,0.07,2021-03-16,0.12,0.1
-2018-03-17,0.1,2019-03-17,0.14,2020-03-16,0.06,2021-03-17,0.12,0.105
-2018-03-18,0.11,2019-03-18,0.14,2020-03-17,0.01,2021-03-18,0.01,0.0675
-2018-03-19,0.13,2019-03-19,0.09,2020-03-18,0.02,2021-03-19,0.11,0.0875
-2018-03-20,0.03,2019-03-20,0.07,2020-03-19,0.12,2021-03-20,0.13,0.0875
-2018-03-21,0.01,2019-03-21,0.14,2020-03-20,0.13,2021-03-21,0.16,0.11
-2018-03-22,0.12,2019-03-22,0.02,2020-03-21,0.14,2021-03-22,0.13,0.1025
-2018-03-23,0.15,2019-03-23,0.07,2020-03-22,0.15,2021-03-23,0.23,0.15
-2018-03-24,0.13,2019-03-24,0.12,2020-03-23,0.16,2021-03-24,0.16,0.1425
-2018-03-25,0.13,2019-03-25,0.01,2020-03-24,0.06,2021-03-25,0.2,0.1
-2018-03-26,0.19,2019-03-26,0.07,2020-03-25,0.12,2021-03-26,0.17,0.1375
-2018-03-27,0.21,2019-03-27,0.13,2020-03-26,0.13,2021-03-27,0.17,0.16
-2018-03-28,0.23,2019-03-28,0.1,2020-03-27,0.14,2021-03-28,0.17,0.16
-2018-03-29,0.2,2019-03-29,0.14,2020-03-28,0.07,2021-03-29,0.29,0.175
-2018-03-30,0.16,2019-03-30,0.18,2020-03-29,0.09,2021-03-30,0.25,0.17
-2018-03-31,0.16,2019-03-31,0.17,2020-03-30,0.07,2021-03-31,0.2,0.15
-2018-04-01,0.18,2019-04-01,0.07,2020-03-31,0.18,2021-04-01,0.18,0.1525
-2018-04-02,0.22,2019-04-02,0.07,2020-04-01,0.2,2021-04-02,0.16,0.1625
-2018-04-03,0.18,2019-04-03,0.07,2020-04-02,0.19,2021-04-03,0.17,0.1525
-2018-04-04,0.15,2019-04-04,0.11,2020-04-03,0.16,2021-04-04,0.14,0.14
-2018-04-05,0.05,2019-04-05,0.06,2020-04-04,0.03,2021-04-05,0.15,0.0725
-2018-04-06,0,2019-04-06,0.08,2020-04-05,0.09,2021-04-06,0.17,0.085
-2018-04-07,0.19,2019-04-07,0.13,2020-04-06,0.14,2021-04-07,0.17,0.1575
-2018-04-08,0.16,2019-04-08,0.08,2020-04-07,0.14,2021-04-08,0.17,0.1375
-2018-04-09,0.18,2019-04-09,0.21,2020-04-08,0.19,2021-04-09,0.18,0.19
-2018-04-10,0.09,2019-04-10,0.22,2020-04-09,0.08,2021-04-10,0.19,0.145
-2018-04-11,0.06,2019-04-11,0.15,2020-04-10,0.18,2021-04-11,0.25,0.16
-2018-04-12,0.16,2019-04-12,0.22,2020-04-11,0.18,2021-04-12,0.24,0.2
-2018-04-13,0.18,2019-04-13,0.19,2020-04-12,0.21,2021-04-13,0.27,0.2125
-2018-04-14,0.19,2019-04-14,0.08,2020-04-13,0.24,2021-04-14,0.21,0.18
-2018-04-15,0.09,2019-04-15,0.08,2020-04-14,0.22,2021-04-15,0.18,0.1425
-2018-04-16,0.16,2019-04-16,0.17,2020-04-15,0.19,2021-04-16,0.23,0.1875
-2018-04-17,0.16,2019-04-17,0.19,2020-04-16,0.22,2021-04-17,0.25,0.205
-2018-04-18,0.12,2019-04-18,0.2,2020-04-17,0.2,2021-04-18,0.24,0.19
-2018-04-19,0.22,2019-04-19,0.19,2020-04-18,0.14,2021-04-19,0.21,0.19
-2018-04-20,0.21,2019-04-20,0.12,2020-04-19,0.16,2021-04-20,0.23,0.18
-2018-04-21,0.22,2019-04-21,0.24,2020-04-20,0.14,2021-04-21,0.28,0.22
-2018-04-22,0.21,2019-04-22,0.27,2020-04-21,0.19,2021-04-22,0.2,0.2175
-2018-04-23,0.25,2019-04-23,0.25,2020-04-22,0.2,2021-04-23,0.17,0.2175
-2018-04-24,0.21,2019-04-24,0.23,2020-04-23,0.24,2021-04-24,0.18,0.215
-2018-04-25,0.21,2019-04-25,0.23,2020-04-24,0.24,2021-04-25,0.09,0.1925
-2018-04-26,0.22,2019-04-26,0.22,2020-04-25,0.15,2021-04-26,0.18,0.1925
-2018-04-27,0.14,2019-04-27,0.22,2020-04-26,0.23,2021-04-27,0.24,0.2075
-2018-04-28,0.14,2019-04-28,0.21,2020-04-27,0.22,2021-04-28,0.23,0.2
-2018-04-29,0.18,2019-04-29,0.25,2020-04-28,0.24,2021-04-29,0.22,0.2225
-2018-04-30,0.2,2019-04-30,0.21,2020-04-29,0.18,2021-04-30,0.21,0.2
-2018-05-01,0.23,2019-05-01,0.22,2020-04-30,0.21,2021-05-01,0.23,0.2225
-2018-05-02,0.23,2019-05-02,0.22,2020-05-01,0.22,2021-05-02,0.32,0.2475
-2018-05-03,0.21,2019-05-03,0.23,2020-05-02,0.21,2021-05-03,0.33,0.245
-2018-05-04,0.21,2019-05-04,0.23,2020-05-03,0.22,2021-05-04,0.27,0.2325
-2018-05-05,0.17,2019-05-05,0.25,2020-05-04,0.22,2021-05-05,0.27,0.2275
-2018-05-06,0.23,2019-05-06,0.23,2020-05-05,0.27,2021-05-06,0.27,0.25
-2018-05-07,0.23,2019-05-07,0.22,2020-05-06,0.34,2021-05-07,0.31,0.275
-2018-05-08,0.26,2019-05-08,0.23,2020-05-07,0.32,2021-05-08,0.38,0.2975
-2018-05-09,0.24,2019-05-09,0.28,2020-05-08,0.26,2021-05-09,0.39,0.2925
-2018-05-10,0.24,2019-05-10,0.31,2020-05-09,0.26,2021-05-10,0.35,0.29
-2018-05-11,0.39,2019-05-11,0.23,2020-05-10,0.29,2021-05-11,0.29,0.3
-2018-05-12,0.3,2019-05-12,0.24,2020-05-11,0.07,2021-05-12,0.29,0.225
-2018-05-13,0.24,2019-05-13,0.24,2020-05-12,0.16,2021-05-13,0.26,0.225
-2018-05-14,0.24,2019-05-14,0.16,2020-05-13,0.1,2021-05-14,0.24,0.185
-2018-05-15,0.23,2019-05-15,0.07,2020-05-14,0.19,2021-05-15,0.2,0.1725
-2018-05-16,0.17,2019-05-16,0.15,2020-05-15,0.23,2021-05-16,0.26,0.2025
-2018-05-17,0.23,2019-05-17,0.16,2020-05-16,0.12,2021-05-17,0.25,0.19
-2018-05-18,0.25,2019-05-18,0.02,2020-05-17,0.18,2021-05-18,0.26,0.1775
-2018-05-19,0.25,2019-05-19,0.12,2020-05-18,0.09,2021-05-19,0.28,0.185
-2018-05-20,0.22,2019-05-20,0.21,2020-05-19,0.21,2021-05-20,0.33,0.2425
-2018-05-21,0.27,2019-05-21,0.13,2020-05-20,0.21,2021-05-21,0.31,0.23
-2018-05-22,0.26,2019-05-22,0.25,2020-05-21,0.25,2021-05-22,0.27,0.2575
-2018-05-23,0.23,2019-05-23,0.27,2020-05-22,0.32,2021-05-23,0.25,0.2675
-2018-05-24,0.25,2019-05-24,0.22,2020-05-23,0.29,2021-05-24,0.28,0.26
-2018-05-25,0.01,2019-05-25,0.24,2020-05-24,0.29,2021-05-25,0.26,0.2
-2018-05-26,0.18,2019-05-26,0.1,2020-05-25,0.29,2021-05-26,0.29,0.215
-2018-05-27,0.31,2019-05-27,0.18,2020-05-26,0.25,2021-05-27,0.22,0.24
-2018-05-28,0.34,2019-05-28,0.26,2020-05-27,0.28,2021-05-28,0.27,0.2875
-2018-05-29,0.31,2019-05-29,0.25,2020-05-28,0.28,2021-05-29,0.26,0.275
-2018-05-30,0.3,2019-05-30,0.2,2020-05-29,0.28,2021-05-30,0.3,0.27
-2018-05-31,0.21,2019-05-31,0.26,2020-05-30,0.15,2021-05-31,0.32,0.235
-2018-06-01,0.28,2019-06-01,0.28,2020-05-31,0.21,2021-06-01,0.29,0.265
-2018-06-02,0.3,2019-06-02,0.26,2020-06-01,0.24,2021-06-02,0.29,0.2725
-2018-06-03,0.3,2019-06-03,0.26,2020-06-02,0.27,2021-06-03,0.28,0.2775
-2018-06-04,0.29,2019-06-04,0.3,2020-06-03,0.27,2021-06-04,0.29,0.2875
-2018-06-05,0.26,2019-06-05,0.3,2020-06-04,0.3,2021-06-05,0.29,0.2875
-2018-06-06,0.27,2019-06-06,0.3,2020-06-05,0.3,2021-06-06,0.34,0.3025
-2018-06-07,0.25,2019-06-07,0.37,2020-06-06,0.24,2021-06-07,0.3,0.29
-2018-06-08,0.29,2019-06-08,0.37,2020-06-07,0.27,2021-06-08,0.28,0.3025
-2018-06-09,0.28,2019-06-09,0.33,2020-06-08,0.27,2021-06-09,0.23,0.2775
-2018-06-10,0.26,2019-06-10,0.29,2020-06-09,0.23,2021-06-10,0.25,0.2575
-2018-06-11,0.31,2019-06-11,0.28,2020-06-10,0.29,2021-06-11,0.24,0.28
-2018-06-12,0.3,2019-06-12,0.2,2020-06-11,0.28,2021-06-12,0.26,0.26
-2018-06-13,0.3,2019-06-13,0.24,2020-06-12,0.23,2021-06-13,0.33,0.275
-2018-06-14,0.3,2019-06-14,0.26,2020-06-13,0.18,2021-06-14,0.3,0.26
-2018-06-15,0.27,2019-06-15,0.2,2020-06-14,0.24,2021-06-15,0.28,0.2475
-2018-06-16,0.27,2019-06-16,0.25,2020-06-15,0.13,2021-06-16,0.31,0.24
-2018-06-17,0.25,2019-06-17,0.32,2020-06-16,0.3,2021-06-17,0.35,0.305
-2018-06-18,0.25,2019-06-18,0.35,2020-06-17,0.37,2021-06-18,0.3,0.3175
-2018-06-19,0.27,2019-06-19,0.34,2020-06-18,0.33,2021-06-19,0.3,0.31
-2018-06-20,0.3,2019-06-20,0.4,2020-06-19,0.28,2021-06-20,0.31,0.3225
-2018-06-21,0.27,2019-06-21,0.43,2020-06-20,0.27,2021-06-21,0.32,0.3225
-2018-06-22,0.35,2019-06-22,0.35,2020-06-21,0.28,2021-06-22,0.29,0.3175
-2018-06-23,0.46,2019-06-23,0.29,2020-06-22,0.29,2021-06-23,0.28,0.33
-2018-06-24,0.37,2019-06-24,0.25,2020-06-23,0.29,2021-06-24,0.27,0.295
-2018-06-25,0.27,2019-06-25,0.28,2020-06-24,0.26,2021-06-25,0.28,0.2725
-2018-06-26,0.29,2019-06-26,0.31,2020-06-25,0.33,2021-06-26,0.29,0.305
-2018-06-27,0.3,2019-06-27,0.24,2020-06-26,0.31,2021-06-27,0.29,0.285
-2018-06-28,0.27,2019-06-28,0.27,2020-06-27,0.31,2021-06-28,0.29,0.285
-2018-06-29,0.39,2019-06-29,0.27,2020-06-28,0.33,2021-06-29,0.29,0.32
-2018-06-30,0.44,2019-06-30,0.29,2020-06-29,0.37,2021-06-30,0.32,0.355
-2018-07-01,0.35,2019-07-01,0.25,2020-06-30,0.3,2021-07-01,0.28,0.295
-2018-07-02,0.31,2019-07-02,0.27,2020-07-01,0.29,2021-07-02,0.29,0.29
-2018-07-03,0.3,2019-07-03,0.27,2020-07-02,0.29,2021-07-03,0.31,0.2925
-2018-07-04,0.29,2019-07-04,0.27,2020-07-03,0.28,2021-07-04,0.3,0.285
-2018-07-05,0.3,2019-07-05,0.27,2020-07-04,0.28,2021-07-05,0.3,0.2875
-2018-07-06,0.14,2019-07-06,0.27,2020-07-05,0.3,2021-07-06,0.28,0.2475
-2018-07-07,0.28,2019-07-07,0.27,2020-07-06,0.32,2021-07-07,0.29,0.29
-2018-07-08,0.29,2019-07-08,0.26,2020-07-07,0.28,2021-07-08,0.29,0.28
-2018-07-09,0.29,2019-07-09,0.22,2020-07-08,0.3,2021-07-09,0.31,0.28
-2018-07-10,0.32,2019-07-10,0.26,2020-07-09,0.29,2021-07-10,0.3,0.2925
-2018-07-11,0.29,2019-07-11,0.27,2020-07-10,0.3,2021-07-11,0.31,0.2925
-2018-07-12,0.29,2019-07-12,0.27,2020-07-11,0.3,2021-07-12,0.29,0.2875
-2018-07-13,0.16,2019-07-13,0.27,2020-07-12,0.3,2021-07-13,0.3,0.2575
-2018-07-14,0.28,2019-07-14,0.28,2020-07-13,0.29,2021-07-14,0.28,0.2825
-2018-07-15,0.28,2019-07-15,0.27,2020-07-14,0.27,2021-07-15,0.28,0.275
-2018-07-16,0.28,2019-07-16,0.27,2020-07-15,0.29,2021-07-16,0.26,0.275
-2018-07-17,0.28,2019-07-17,0.27,2020-07-16,0.28,2021-07-17,0.28,0.2775
-2018-07-18,0.27,2019-07-18,0.28,2020-07-17,0.28,2021-07-18,0.31,0.285
-2018-07-19,0.27,2019-07-19,0.27,2020-07-18,0.26,2021-07-19,0.28,0.27
-2018-07-20,0.29,2019-07-20,0.26,2020-07-19,0.28,2021-07-20,0.3,0.2825
-2018-07-21,0.28,2019-07-21,0.25,2020-07-20,0.27,2021-07-21,0.27,0.2675
-2018-07-22,0.28,2019-07-22,0.28,2020-07-21,0.26,2021-07-22,0.29,0.2775
-2018-07-23,0.28,2019-07-23,0.29,2020-07-22,0.25,2021-07-23,0.28,0.275
-2018-07-24,0.28,2019-07-24,0.28,2020-07-23,0.26,2021-07-24,0.18,0.25
-2018-07-25,0.27,2019-07-25,0.27,2020-07-24,0.26,2021-07-25,0.24,0.26
-2018-07-26,0.25,2019-07-26,0.27,2020-07-25,0.26,2021-07-26,0.25,0.2575
-2018-07-27,0.23,2019-07-27,0.27,2020-07-26,0.27,2021-07-27,0.17,0.235
-2018-07-28,0.2,2019-07-28,0.28,2020-07-27,0.27,2021-07-28,0.28,0.2575
-2018-07-29,0.22,2019-07-29,0.28,2020-07-28,0.26,2021-07-29,0.26,0.255
-2018-07-30,0.19,2019-07-30,0.26,2020-07-29,0.28,2021-07-30,0.24,0.2425
-2018-07-31,0.2,2019-07-31,0.26,2020-07-30,0.27,2021-07-31,0.28,0.2525
-2018-08-01,0.23,2019-08-01,0.26,2020-07-31,0.27,2021-08-01,0.28,0.26
-2018-08-02,0.25,2019-08-02,0.24,2020-08-01,0.25,2021-08-02,0.26,0.25
-2018-08-03,0.24,2019-08-03,0.26,2020-08-02,0.26,2021-08-03,0.26,0.255
-2018-08-04,0.25,2019-08-04,0.27,2020-08-03,0.26,2021-08-04,0.29,0.2675
-2018-08-05,0.18,2019-08-05,0.24,2020-08-04,0.26,2021-08-05,0.22,0.225
-2018-08-06,0.21,2019-08-06,0.27,2020-08-05,0.25,2021-08-06,0.24,0.2425
-2018-08-07,0.2,2019-08-07,0.26,2020-08-06,0.23,2021-08-07,0.21,0.225
-2018-08-08,0.21,2019-08-08,0.24,2020-08-07,0.26,2021-08-08,0.22,0.2325
-2018-08-09,0.19,2019-08-09,0.18,2020-08-08,0.25,2021-08-09,0.24,0.215
-2018-08-10,0.23,2019-08-10,0.13,2020-08-09,0.26,2021-08-10,0.23,0.2125
-2018-08-11,0.23,2019-08-11,0.24,2020-08-10,0.26,2021-08-11,0.2,0.2325
-2018-08-12,0.24,2019-08-12,0.23,2020-08-11,0.25,2021-08-12,0.2,0.23
-2018-08-13,0.2,2019-08-13,0.24,2020-08-12,0.25,2021-08-13,0.19,0.22
-2018-08-14,0.23,2019-08-14,0.25,2020-08-13,0.27,2021-08-14,0.22,0.2425
-2018-08-15,0.23,2019-08-15,0.27,2020-08-14,0.25,2021-08-15,0.22,0.2425
-2018-08-16,0.21,2019-08-16,0.28,2020-08-15,0.27,2021-08-16,0.18,0.235
-2018-08-17,0.23,2019-08-17,0.25,2020-08-16,0.13,2021-08-17,0.14,0.1875
-2018-08-18,0.21,2019-08-18,0.23,2020-08-17,0.09,2021-08-18,0.35,0.22
-2018-08-19,0.2,2019-08-19,0.22,2020-08-18,0.23,2021-08-19,0.25,0.225
-2018-08-20,0.19,2019-08-20,0.21,2020-08-19,0.12,2021-08-20,0.17,0.1725
-2018-08-21,0.2,2019-08-21,0.2,2020-08-20,0.11,2021-08-21,0.17,0.17
-2018-08-22,0.2,2019-08-22,0.26,2020-08-21,0.08,2021-08-22,0.19,0.1825
-2018-08-23,0.21,2019-08-23,0.24,2020-08-22,0.16,2021-08-23,0.22,0.2075
-2018-08-24,0.18,2019-08-24,0.23,2020-08-23,0.13,2021-08-24,0.22,0.19
-2018-08-25,0.19,2019-08-25,0.23,2020-08-24,0.18,2021-08-25,0.21,0.2025
-2018-08-26,0.18,2019-08-26,0.24,2020-08-25,0.16,2021-08-26,0.22,0.2
-2018-08-27,0.19,2019-08-27,0.23,2020-08-26,0.16,2021-08-27,0.27,0.2125
-2018-08-28,0.21,2019-08-28,0.22,2020-08-27,0.2,2021-08-28,0.2,0.2075
-2018-08-29,0.21,2019-08-29,0.23,2020-08-28,0.22,2021-08-29,0.2,0.215
-2018-08-30,0.2,2019-08-30,0.21,2020-08-29,0.15,2021-08-30,0.21,0.1925
-2018-08-31,0.2,2019-08-31,0.21,2020-08-30,0.17,2021-08-31,0.22,0.2
-2018-09-01,0.22,2019-09-01,0.23,2020-08-31,0.24,2021-09-01,0.21,0.225
-2018-09-02,0.21,2019-09-02,0.22,2020-09-01,0.28,2021-09-02,0.18,0.2225
-2018-09-03,0.19,2019-09-03,0.2,2020-09-02,0.18,2021-09-03,0.19,0.19
-2018-09-04,0.21,2019-09-04,0.16,2020-09-03,0.18,2021-09-04,0.2,0.1875
-2018-09-05,0.22,2019-09-05,0.24,2020-09-04,0.16,2021-09-05,0.21,0.2075
-2018-09-06,0.2,2019-09-06,0.2,2020-09-05,0.21,2021-09-06,0.22,0.2075
-2018-09-07,0.21,2019-09-07,0.19,2020-09-06,0.22,2021-09-07,0.24,0.215
-2018-09-08,0.19,2019-09-08,0.18,2020-09-07,0.2,2021-09-08,0.18,0.1875
-2018-09-09,0.2,2019-09-09,0.18,2020-09-08,0.37,2021-09-09,0.15,0.225
-2018-09-10,0.19,2019-09-10,0.17,2020-09-09,0.08,2021-09-10,0.18,0.155
-2018-09-11,0.22,2019-09-11,0.2,2020-09-10,0.09,2021-09-11,0.19,0.175
-2018-09-12,0.17,2019-09-12,0.19,2020-09-11,0.13,2021-09-12,0.18,0.1675
-2018-09-13,0.17,2019-09-13,0.19,2020-09-12,0.15,2021-09-13,0.18,0.1725
-2018-09-14,0.17,2019-09-14,0.21,2020-09-13,0.15,2021-09-14,0.22,0.1875
-2018-09-15,0.19,2019-09-15,0.21,2020-09-14,0.15,2021-09-15,0.18,0.1825
-2018-09-16,0.17,2019-09-16,0.15,2020-09-15,0.17,2021-09-16,0.17,0.165
-2018-09-17,0.17,2019-09-17,0.17,2020-09-16,0.15,2021-09-17,0.19,0.17
-2018-09-18,0.16,2019-09-18,0.1,2020-09-17,0.2,2021-09-18,0.06,0.13
-2018-09-19,0.21,2019-09-19,0.17,2020-09-18,0.16,2021-09-19,0.18,0.18
-2018-09-20,0.22,2019-09-20,0.2,2020-09-19,0.17,2021-09-20,0.28,0.2175
-2018-09-21,0.19,2019-09-21,0.2,2020-09-20,0.17,2021-09-21,0.2,0.19
-2018-09-22,0.17,2019-09-22,0.13,2020-09-21,0.13,2021-09-22,0.18,0.1525
-2018-09-23,0.17,2019-09-23,0.24,2020-09-22,0.15,2021-09-23,0.26,0.205
-2018-09-24,0.22,2019-09-24,0.26,2020-09-23,0.15,2021-09-24,0.19,0.205
-2018-09-25,0.25,2019-09-25,0.3,2020-09-24,0.14,2021-09-25,0.19,0.22
-2018-09-26,0.17,2019-09-26,0.23,2020-09-25,0.14,2021-09-26,0.16,0.175
-2018-09-27,0.17,2019-09-27,0.05,2020-09-26,0.22,2021-09-27,0.13,0.1425
-2018-09-28,0.17,2019-09-28,0.17,2020-09-27,0.32,2021-09-28,0.21,0.2175
-2018-09-29,0.13,2019-09-29,0.1,2020-09-28,0.29,2021-09-29,0.22,0.185
-2018-09-30,0.14,2019-09-30,0.12,2020-09-29,0.13,2021-09-30,0.21,0.15
-2018-10-01,0.07,2019-10-01,0.16,2020-09-30,0.19,2021-10-01,0.15,0.1425
-2018-10-02,0.1,2019-10-02,0.13,2020-10-01,0.18,2021-10-02,0.15,0.14
-2018-10-03,0.1,2019-10-03,0.16,2020-10-02,0.12,2021-10-03,0.14,0.13
-2018-10-04,0.03,2019-10-04,0.16,2020-10-03,0.11,2021-10-04,0.16,0.115
-2018-10-05,0.11,2019-10-05,0.2,2020-10-04,0.11,2021-10-05,0.17,0.1475
-2018-10-06,0.18,2019-10-06,0.18,2020-10-05,0.15,2021-10-06,0.09,0.15
-2018-10-07,0.26,2019-10-07,0.14,2020-10-06,0.14,2021-10-07,0.1,0.16
-2018-10-08,0.22,2019-10-08,0.15,2020-10-07,0.14,2021-10-08,0.13,0.16
-2018-10-09,0.16,2019-10-09,0.29,2020-10-08,0.09,2021-10-09,0.14,0.17
-2018-10-10,0.14,2019-10-10,0.22,2020-10-09,0.11,2021-10-10,0.16,0.1575
-2018-10-11,0.17,2019-10-11,0.14,2020-10-10,0.07,2021-10-11,0.25,0.1575
-2018-10-12,0.2,2019-10-12,0.12,2020-10-11,0.17,2021-10-12,0.19,0.17
-2018-10-13,0.21,2019-10-13,0.12,2020-10-12,0.15,2021-10-13,0.11,0.1475
-2018-10-14,0.24,2019-10-14,0.12,2020-10-13,0.13,2021-10-14,0.2,0.1725
-2018-10-15,0.2,2019-10-15,0.12,2020-10-14,0.25,2021-10-15,0.12,0.1725
-2018-10-16,0.19,2019-10-16,0.11,2020-10-15,0.31,2021-10-16,0.12,0.1825
-2018-10-17,0.11,2019-10-17,0.13,2020-10-16,0.26,2021-10-17,0.12,0.155
-2018-10-18,0.11,2019-10-18,0.1,2020-10-17,0.18,2021-10-18,0.05,0.11
-2018-10-19,0.11,2019-10-19,0.08,2020-10-18,0.15,2021-10-19,0.09,0.1075
-2018-10-20,0.12,2019-10-20,0.12,2020-10-19,0.13,2021-10-20,0,0.0925
-2018-10-21,0.11,2019-10-21,0.18,2020-10-20,0.22,2021-10-21,0.01,0.13
-2018-10-22,0.11,2019-10-22,0.18,2020-10-21,0.2,2021-10-22,0.08,0.1425
-2018-10-23,0.07,2019-10-23,0.24,2020-10-22,0.29,2021-10-23,0.01,0.1525
-2018-10-24,0.08,2019-10-24,0.21,2020-10-23,0.16,2021-10-24,0,0.1125
-2018-10-25,0.11,2019-10-25,0.11,2020-10-24,0.09,2021-10-25,0.08,0.0975
-2018-10-26,0.09,2019-10-26,0.2,2020-10-25,0.2,2021-10-26,0.05,0.135
-2018-10-27,0.1,2019-10-27,0.22,2020-10-26,0.16,2021-10-27,0.07,0.1375
-2018-10-28,0.06,2019-10-28,0.12,2020-10-27,0.15,2021-10-28,0.09,0.105
-2018-10-29,0.12,2019-10-29,0.18,2020-10-28,0.09,2021-10-29,0.07,0.115
-2018-10-30,0.14,2019-10-30,0.13,2020-10-29,0.09,2021-10-30,0.07,0.1075
-2018-10-31,0.16,2019-10-31,0.1,2020-10-30,0.09,2021-10-31,0.05,0.1
-2018-11-01,0.14,2019-11-01,0.09,2020-10-31,0.1,2021-11-01,0.02,0.0875
-2018-11-02,0.11,2019-11-02,0.1,2020-11-01,0.09,2021-11-02,0.07,0.0925
-2018-11-03,0.2,2019-11-03,0.09,2020-11-02,0.1,2021-11-03,0.08,0.1175
-2018-11-04,0.12,2019-11-04,0.09,2020-11-03,0.09,2021-11-04,0.1,0.1
-2018-11-05,0.17,2019-11-05,0.09,2020-11-04,0.09,2021-11-05,0.01,0.09
-2018-11-06,0.18,2019-11-06,0.09,2020-11-05,0.1,2021-11-06,0.02,0.0975
-2018-11-07,0.17,2019-11-07,0.08,2020-11-06,0.13,2021-11-07,0.08,0.115
-2018-11-08,0.2,2019-11-08,0.09,2020-11-07,0.07,2021-11-08,0.04,0.1
-2018-11-09,0.1,2019-11-09,0.08,2020-11-08,0.14,2021-11-09,0,0.08
-2018-11-10,0.11,2019-11-10,0.09,2020-11-09,0.11,2021-11-10,0.03,0.085
-2018-11-11,0.16,2019-11-11,0.12,2020-11-10,0.07,2021-11-11,0.08,0.1075
-2018-11-12,0.11,2019-11-12,0.07,2020-11-11,0.07,2021-11-12,0.02,0.0675
-2018-11-13,0.04,2019-11-13,0.06,2020-11-12,0.06,2021-11-13,0.05,0.0525
-2018-11-14,0.05,2019-11-14,0.07,2020-11-13,0.04,2021-11-14,0.03,0.0475
-2018-11-15,0.06,2019-11-15,0.08,2020-11-14,0.04,2021-11-15,0,0.045
-2018-11-16,0.05,2019-11-16,0.11,2020-11-15,0.06,2021-11-16,0.1,0.08
-2018-11-17,0.04,2019-11-17,0.07,2020-11-16,0.07,2021-11-17,0.07,0.0625
-2018-11-18,0.05,2019-11-18,0.08,2020-11-17,0.01,2021-11-18,0,0.035
-2018-11-19,0.07,2019-11-19,0.14,2020-11-18,0.07,2021-11-19,0.01,0.0725
-2018-11-20,0.06,2019-11-20,0.23,2020-11-19,0.08,2021-11-20,0.1,0.1175
-2018-11-21,0,2019-11-21,0.08,2020-11-20,0.1,2021-11-21,0.09,0.0675
-2018-11-22,0.04,2019-11-22,0.07,2020-11-21,0.11,2021-11-22,0.06,0.07
-2018-11-23,0,2019-11-23,0.09,2020-11-22,0.05,2021-11-23,0.09,0.0575
-2018-11-24,0.06,2019-11-24,0.06,2020-11-23,0.08,2021-11-24,0.1,0.075
-2018-11-25,0.07,2019-11-25,0.12,2020-11-24,0.08,2021-11-25,0.05,0.08
-2018-11-26,0.02,2019-11-26,0.02,2020-11-25,0.09,2021-11-26,0.06,0.0475
-2018-11-27,0,2019-11-27,0.04,2020-11-26,0.1,2021-11-27,0.06,0.05
-2018-11-28,0.01,2019-11-28,0.04,2020-11-27,0.08,2021-11-28,0.06,0.0475
-2018-11-29,0,2019-11-29,0.04,2020-11-28,0.07,2021-11-29,0.06,0.0425
-2018-11-30,0.04,2019-11-30,0,2020-11-29,0.05,2021-11-30,0.07,0.04
-2018-12-01,0.05,2019-12-01,0,2020-11-30,0.06,2021-12-01,0.07,0.045
-2018-12-02,0.05,2019-12-02,0.02,2020-12-01,0.11,2021-12-02,0.06,0.06
-2018-12-03,0.04,2019-12-03,0.08,2020-12-02,0.09,2021-12-03,0.05,0.065
-2018-12-04,0.06,2019-12-04,0.07,2020-12-03,0.05,2021-12-04,0.05,0.0575
-2018-12-05,0.02,2019-12-05,0.05,2020-12-04,0.08,2021-12-05,0.04,0.0475
-2018-12-06,0.07,2019-12-06,0.08,2020-12-05,0.04,2021-12-06,0,0.0475
-2018-12-07,0.04,2019-12-07,0.11,2020-12-06,0.11,2021-12-07,0.05,0.0775
-2018-12-08,0.06,2019-12-08,0.07,2020-12-07,0.15,2021-12-08,0,0.07
-2018-12-09,0.02,2019-12-09,0.05,2020-12-08,0.09,2021-12-09,0.07,0.0575
-2018-12-10,0.07,2019-12-10,0.04,2020-12-09,0.11,2021-12-10,0.06,0.07
-2018-12-11,0.06,2019-12-11,0.04,2020-12-10,0.1,2021-12-11,0.01,0.0525
-2018-12-12,0.08,2019-12-12,0.04,2020-12-11,0.03,2021-12-12,0,0.0375
-2018-12-13,0.05,2019-12-13,0.07,2020-12-12,0.05,2021-12-13,0.01,0.045
-2018-12-14,0.03,2019-12-14,0.05,2020-12-13,0,2021-12-14,0.03,0.0275
-2018-12-15,0,2019-12-15,0.04,2020-12-14,0.06,2021-12-15,0.01,0.0275
-2018-12-16,0,2019-12-16,0.06,2020-12-15,0.03,2021-12-16,0.01,0.025
-2018-12-17,0.03,2019-12-17,0.04,2020-12-16,0.01,2021-12-17,0.04,0.03
-2018-12-18,0.03,2019-12-18,0.05,2020-12-17,0.06,2021-12-18,0.03,0.0425
-2018-12-19,0.05,2019-12-19,0.04,2020-12-18,0.07,2021-12-19,0,0.04
-2018-12-20,0,2019-12-20,0.04,2020-12-19,0.04,2021-12-20,0.02,0.025
-2018-12-21,0.04,2019-12-21,0.06,2020-12-20,0.03,2021-12-21,0.01,0.035
-2018-12-22,0.03,2019-12-22,0.06,2020-12-21,0.04,2021-12-22,0,0.0325
-2018-12-23,0,2019-12-23,0.07,2020-12-22,0.09,2021-12-23,0,0.04
-2018-12-24,0,2019-12-24,0.04,2020-12-23,0.11,2021-12-24,0.06,0.0525
-2018-12-25,0.08,2019-12-25,0.05,2020-12-24,0.04,2021-12-25,0.02,0.0475
-2018-12-26,0.06,2019-12-26,0.07,2020-12-25,0,2021-12-26,0.03,0.04
-2018-12-27,0.08,2019-12-27,0.06,2020-12-26,0.04,2021-12-27,0.05,0.0575
-2018-12-28,0.09,2019-12-28,0.05,2020-12-27,0.04,2021-12-28,0.01,0.0475
-2018-12-29,0.06,2019-12-29,0.05,2020-12-28,0.04,2021-12-29,0.01,0.04
-2018-12-30,0.05,2019-12-30,0.09,2020-12-29,0.08,2021-12-30,0.02,0.06
-2018-12-31,0.11,2019-12-31,0.06,2020-12-30,0.04,2021-12-31,0.04,0.0625
+Year_1,Year_1_ET,Year_2,Year_2_ET,Year_3,Year_3_ET,Year_4,Year_4_ET,Year_5,Year_5_ET
+2023-01-01,0.08,2022-01-01,0.04,2021-01-01,0.05,2020-01-01,0.05,2019-01-01,0.07
+2023-01-02,0.01,2022-01-02,0.05,2021-01-02,0.05,2020-01-02,0.06,2019-01-02,0.06
+2023-01-03,0.03,2022-01-03,0.04,2021-01-03,0.05,2020-01-03,0.06,2019-01-03,0.06
+2023-01-04,0.04,2022-01-04,0.05,2021-01-04,0.05,2020-01-04,0.06,2019-01-04,0.07
+2023-01-05,0.03,2022-01-05,0.03,2021-01-05,0.07,2020-01-05,0.07,2019-01-05,0.04
+2023-01-06,0.05,2022-01-06,0.04,2021-01-06,0.05,2020-01-06,0.03,2019-01-06,0.02
+2023-01-07,0.04,2022-01-07,0.03,2021-01-07,0.03,2020-01-07,0.02,2019-01-07,0.06
+2023-01-08,0.04,2022-01-08,0.06,2021-01-08,0.05,2020-01-08,0.03,2019-01-08,0.05
+2023-01-09,0,2022-01-09,0.04,2021-01-09,0.07,2020-01-09,0.02,2019-01-09,0.02
+2023-01-10,0.07,2022-01-10,0.04,2021-01-10,0.06,2020-01-10,0.05,2019-01-10,0.04
+2023-01-11,0.01,2022-01-11,0.06,2021-01-11,0.06,2020-01-11,0.06,2019-01-11,0.02
+2023-01-12,0.06,2022-01-12,0.05,2021-01-12,0.03,2020-01-12,0.06,2019-01-12,0.06
+2023-01-13,0.04,2022-01-13,0.04,2021-01-13,0.07,2020-01-13,0.06,2019-01-13,0.06
+2023-01-14,0,2022-01-14,0.03,2021-01-14,0.07,2020-01-14,0.04,2019-01-14,0.01
+2023-01-15,0.01,2022-01-15,0.01,2021-01-15,0.08,2020-01-15,0.06,2019-01-15,0.02
+2023-01-16,0.03,2022-01-16,0.05,2021-01-16,0.08,2020-01-16,0.06,2019-01-16,0.05
+2023-01-17,0.04,2022-01-17,0.04,2021-01-17,0.08,2020-01-17,0.04,2019-01-17,0.04
+2023-01-18,0.04,2022-01-18,0.07,2021-01-18,0.13,2020-01-18,0.03,2019-01-18,0.07
+2023-01-19,0.04,2022-01-19,0.07,2021-01-19,0.15,2020-01-19,0.01,2019-01-19,0.07
+2023-01-20,0.05,2022-01-20,0.07,2021-01-20,0.13,2020-01-20,0.02,2019-01-20,0.05
+2023-01-21,0.05,2022-01-21,0.09,2021-01-21,0.09,2020-01-21,0.05,2019-01-21,0.08
+2023-01-22,0.07,2022-01-22,0.08,2021-01-22,0.04,2020-01-22,0.06,2019-01-22,0.08
+2023-01-23,0.07,2022-01-23,0.07,2021-01-23,0.03,2020-01-23,0.05,2019-01-23,0.07
+2023-01-24,0.06,2022-01-24,0.08,2021-01-24,0.06,2020-01-24,0.05,2019-01-24,0.07
+2023-01-25,0.06,2022-01-25,0.08,2021-01-25,0.06,2020-01-25,0.05,2019-01-25,0.08
+2023-01-26,0.06,2022-01-26,0.08,2021-01-26,0.09,2020-01-26,0.06,2019-01-26,0.07
+2023-01-27,0.05,2022-01-27,0.08,2021-01-27,0.03,2020-01-27,0.08,2019-01-27,0.08
+2023-01-28,0.06,2022-01-28,0.09,2021-01-28,0,2020-01-28,0.08,2019-01-28,0.06
+2023-01-29,0.03,2022-01-29,0.07,2021-01-29,0.06,2020-01-29,0.06,2019-01-29,0.04
+2023-01-30,0.08,2022-01-30,0.09,2021-01-30,0.06,2020-01-30,0.06,2019-01-30,0.08
+2023-01-31,0.06,2022-01-31,0.05,2021-01-31,0.06,2020-01-31,0.07,2019-01-31,0.08
+2023-02-01,0.06,2022-02-01,0.12,2021-02-01,0.11,2020-02-01,0.08,2019-02-01,0.03
+2023-02-02,0.05,2022-02-02,0.12,2021-02-02,0.09,2020-02-02,0.12,2019-02-02,0.06
+2023-02-03,0.07,2022-02-03,0.09,2021-02-03,0.09,2020-02-03,0.15,2019-02-03,0.06
+2023-02-04,0.07,2022-02-04,0.09,2021-02-04,0.09,2020-02-04,0.1,2019-02-04,0.09
+2023-02-05,0.07,2022-02-05,0.09,2021-02-05,0.08,2020-02-05,0.09,2019-02-05,0.07
+2023-02-06,0.07,2022-02-06,0.09,2021-02-06,0.08,2020-02-06,0.09,2019-02-06,0.08
+2023-02-07,0.07,2022-02-07,0.1,2021-02-07,0.08,2020-02-07,0.09,2019-02-07,0.08
+2023-02-08,0.07,2022-02-08,0.1,2021-02-08,0.08,2020-02-08,0.1,2019-02-08,0.1
+2023-02-09,0.08,2022-02-09,0.1,2021-02-09,0.07,2020-02-09,0.11,2019-02-09,0.08
+2023-02-10,0.1,2022-02-10,0.11,2021-02-10,0.09,2020-02-10,0.12,2019-02-10,0.06
+2023-02-11,0.07,2022-02-11,0.12,2021-02-11,0.06,2020-02-11,0.11,2019-02-11,0.08
+2023-02-12,0.1,2022-02-12,0.13,2021-02-12,0.11,2020-02-12,0.1,2019-02-12,0.04
+2023-02-13,0.09,2022-02-13,0.12,2021-02-13,0.08,2020-02-13,0.11,2019-02-13,0.02
+2023-02-14,0.14,2022-02-14,0.13,2021-02-14,0.11,2020-02-14,0.1,2019-02-14,0.12
+2023-02-15,0.11,2022-02-15,0.13,2021-02-15,0.08,2020-02-15,0.1,2019-02-15,0.08
+2023-02-16,0.09,2022-02-16,0.14,2021-02-16,0.13,2020-02-16,0.12,2019-02-16,0.08
+2023-02-17,0.09,2022-02-17,0.12,2021-02-17,0.15,2020-02-17,0.14,2019-02-17,0.06
+2023-02-18,0.1,2022-02-18,0.11,2021-02-18,0.11,2020-02-18,0.14,2019-02-18,0.11
+2023-02-19,0.1,2022-02-19,0.13,2021-02-19,0.11,2020-02-19,0.12,2019-02-19,0.11
+2023-02-20,0.1,2022-02-20,0.12,2021-02-20,0.14,2020-02-20,0.13,2019-02-20,0.06
+2023-02-21,0.14,2022-02-21,0.13,2021-02-21,0.13,2020-02-21,0.13,2019-02-21,0.07
+2023-02-22,0.07,2022-02-22,0.07,2021-02-22,0.12,2020-02-22,0.04,2019-02-22,0.11
+2023-02-23,0.08,2022-02-23,0.14,2021-02-23,0.12,2020-02-23,0.11,2019-02-23,0.1
+2023-02-24,0.01,2022-02-24,0.13,2021-02-24,0.2,2020-02-24,0.14,2019-02-24,0.11
+2023-02-25,0.03,2022-02-25,0.12,2021-02-25,0.16,2020-02-25,0.14,2019-02-25,0.16
+2023-02-26,0.06,2022-02-26,0.1,2021-02-26,0.14,2020-02-26,0.15,2019-02-26,0.09
+2023-02-27,0.06,2022-02-27,0.13,2021-02-27,0.2,2020-02-27,0.14,2019-02-27,0.07
+2023-02-28,0.04,2022-02-28,0.15,2021-02-28,0.14,2020-02-28,0.14,2019-02-28,0.1
+2023-03-01,0.13,2022-03-01,0.13,2021-03-01,0.17,2020-02-29,0.18,2019-03-01,0.05
+2023-03-02,0.11,2022-03-02,0.15,2021-03-02,0.15,2020-03-01,0.11,2019-03-02,0.12
+2023-03-03,0.1,2022-03-03,0.12,2021-03-03,0.12,2020-03-02,0.16,2019-03-03,0.11
+2023-03-04,0.09,2022-03-04,0.06,2021-03-04,0.13,2020-03-03,0.14,2019-03-04,0.07
+2023-03-05,0.06,2022-03-05,0.1,2021-03-05,0.14,2020-03-04,0.14,2019-03-05,0.02
+2023-03-06,0.07,2022-03-06,0.13,2021-03-06,0.16,2020-03-05,0.15,2019-03-06,0.09
+2023-03-07,0.09,2022-03-07,0.14,2021-03-07,0.12,2020-03-06,0.16,2019-03-07,0.08
+2023-03-08,0.08,2022-03-08,0.15,2021-03-08,0.14,2020-03-07,0.09,2019-03-08,0.13
+2023-03-09,0.05,2022-03-09,0.16,2021-03-09,0.11,2020-03-08,0.12,2019-03-09,0.12
+2023-03-10,0.02,2022-03-10,0.22,2021-03-10,0.08,2020-03-09,0.11,2019-03-10,0.12
+2023-03-11,0.1,2022-03-11,0.15,2021-03-11,0.08,2020-03-10,0.07,2019-03-11,0.17
+2023-03-12,0.11,2022-03-12,0.17,2021-03-12,0.12,2020-03-11,0.12,2019-03-12,0.19
+2023-03-13,0.11,2022-03-13,0.18,2021-03-13,0.15,2020-03-12,0.14,2019-03-13,0.21
+2023-03-14,0.02,2022-03-14,0.15,2021-03-14,0.11,2020-03-13,0.18,2019-03-14,0.15
+2023-03-15,0.13,2022-03-15,0.13,2021-03-15,0.08,2020-03-14,0.18,2019-03-15,0.16
+2023-03-16,0.13,2022-03-16,0.19,2021-03-16,0.13,2020-03-15,0.13,2019-03-16,0.17
+2023-03-17,0.13,2022-03-17,0.15,2021-03-17,0.14,2020-03-16,0,2019-03-17,0.17
+2023-03-18,0.11,2022-03-18,0.17,2021-03-18,0.14,2020-03-17,0.05,2019-03-18,0.18
+2023-03-19,0.06,2022-03-19,0.09,2021-03-19,0.05,2020-03-18,0.08,2019-03-19,0.18
+2023-03-20,0.1,2022-03-20,0.19,2021-03-20,0.16,2020-03-19,0.08,2019-03-20,0.07
+2023-03-21,0.09,2022-03-21,0.2,2021-03-21,0.18,2020-03-20,0.14,2019-03-21,0.14
+2023-03-22,0.05,2022-03-22,0.18,2021-03-22,0.16,2020-03-21,0.06,2019-03-22,0.14
+2023-03-23,0.08,2022-03-23,0.19,2021-03-23,0.25,2020-03-22,0.09,2019-03-23,0.08
+2023-03-24,0.17,2022-03-24,0.2,2021-03-24,0.16,2020-03-23,0.12,2019-03-24,0.15
+2023-03-25,0.17,2022-03-25,0.2,2021-03-25,0.14,2020-03-24,0.07,2019-03-25,0.21
+2023-03-26,0.17,2022-03-26,0.21,2021-03-26,0.19,2020-03-25,0.09,2019-03-26,0.17
+2023-03-27,0.15,2022-03-27,0.25,2021-03-27,0.18,2020-03-26,0.13,2019-03-27,0.13
+2023-03-28,0.08,2022-03-28,0.07,2021-03-28,0.2,2020-03-27,0.14,2019-03-28,0.19
+2023-03-29,0.09,2022-03-29,0.13,2021-03-29,0.24,2020-03-28,0.1,2019-03-29,0.21
+2023-03-30,0.07,2022-03-30,0.13,2021-03-30,0.26,2020-03-29,0.11,2019-03-30,0.21
+2023-03-31,0.11,2022-03-31,0.13,2021-03-31,0.2,2020-03-30,0.16,2019-03-31,0.2
+2023-04-01,0.15,2022-04-01,0.16,2021-04-01,0.2,2020-03-31,0.18,2019-04-01,0.19
+2023-04-02,0.14,2022-04-02,0.19,2021-04-02,0.22,2020-04-01,0.19,2019-04-02,0.17
+2023-04-03,0.21,2022-04-03,0.23,2021-04-03,0.21,2020-04-02,0.22,2019-04-03,0.16
+2023-04-04,0.18,2022-04-04,0.22,2021-04-04,0.18,2020-04-03,0.18,2019-04-04,0.13
+2023-04-05,0.16,2022-04-05,0.23,2021-04-05,0.2,2020-04-04,0.16,2019-04-05,0.12
+2023-04-06,0.17,2022-04-06,0.22,2021-04-06,0.19,2020-04-05,0.12,2019-04-06,0.18
+2023-04-07,0.1,2022-04-07,0.23,2021-04-07,0.21,2020-04-06,0.14,2019-04-07,0.2
+2023-04-08,0.14,2022-04-08,0.26,2021-04-08,0.23,2020-04-07,0.16,2019-04-08,0.19
+2023-04-09,0.19,2022-04-09,0.35,2021-04-09,0.22,2020-04-08,0.11,2019-04-09,0.31
+2023-04-10,0.21,2022-04-10,0.3,2021-04-10,0.22,2020-04-09,0.11,2019-04-10,0.31
+2023-04-11,0.18,2022-04-11,0.15,2021-04-11,0.22,2020-04-10,0.16,2019-04-11,0.23
+2023-04-12,0.19,2022-04-12,0.24,2021-04-12,0.23,2020-04-11,0.15,2019-04-12,0.25
+2023-04-13,0.23,2022-04-13,0.2,2021-04-13,0.27,2020-04-12,0.17,2019-04-13,0.23
+2023-04-14,0.18,2022-04-14,0.18,2021-04-14,0.2,2020-04-13,0.19,2019-04-14,0.24
+2023-04-15,0.2,2022-04-15,0.19,2021-04-15,0.23,2020-04-14,0.24,2019-04-15,0.23
+2023-04-16,0.21,2022-04-16,0.17,2021-04-16,0.26,2020-04-15,0.22,2019-04-16,0.15
+2023-04-17,0.18,2022-04-17,0.22,2021-04-17,0.25,2020-04-16,0.22,2019-04-17,0.21
+2023-04-18,0.16,2022-04-18,0.22,2021-04-18,0.27,2020-04-17,0.14,2019-04-18,0.22
+2023-04-19,0.22,2022-04-19,0.18,2021-04-19,0.26,2020-04-18,0.1,2019-04-19,0.23
+2023-04-20,0.24,2022-04-20,0.21,2021-04-20,0.24,2020-04-19,0.18,2019-04-20,0.22
+2023-04-21,0.24,2022-04-21,0.12,2021-04-21,0.22,2020-04-20,0.1,2019-04-21,0.22
+2023-04-22,0.25,2022-04-22,0.18,2021-04-22,0.24,2020-04-21,0.21,2019-04-22,0.27
+2023-04-23,0.24,2022-04-23,0.23,2021-04-23,0.22,2020-04-22,0.23,2019-04-23,0.26
+2023-04-24,0.25,2022-04-24,0.23,2021-04-24,0.23,2020-04-23,0.29,2019-04-24,0.27
+2023-04-25,0.25,2022-04-25,0.25,2021-04-25,0.09,2020-04-24,0.29,2019-04-25,0.27
+2023-04-26,0.24,2022-04-26,0.22,2021-04-26,0.21,2020-04-25,0.29,2019-04-26,0.28
+2023-04-27,0.23,2022-04-27,0.22,2021-04-27,0.24,2020-04-26,0.28,2019-04-27,0.25
+2023-04-28,0.25,2022-04-28,0.28,2021-04-28,0.25,2020-04-27,0.29,2019-04-28,0.25
+2023-04-29,0.24,2022-04-29,0.26,2021-04-29,0.26,2020-04-28,0.28,2019-04-29,0.24
+2023-04-30,0.29,2022-04-30,0.27,2021-04-30,0.29,2020-04-29,0.26,2019-04-30,0.2
+2023-05-01,0.16,2022-05-01,0.27,2021-05-01,0.32,2020-04-30,0.34,2019-05-01,0.22
+2023-05-02,0.15,2022-05-02,0.27,2021-05-02,0.33,2020-05-01,0.3,2019-05-02,0.24
+2023-05-03,0.09,2022-05-03,0.3,2021-05-03,0.33,2020-05-02,0.27,2019-05-03,0.26
+2023-05-04,0.09,2022-05-04,0.24,2021-05-04,0.3,2020-05-03,0.26,2019-05-04,0.27
+2023-05-05,0.06,2022-05-05,0.3,2021-05-05,0.27,2020-05-04,0.29,2019-05-05,0.24
+2023-05-06,0.08,2022-05-06,0.26,2021-05-06,0.33,2020-05-05,0.31,2019-05-06,0.19
+2023-05-07,0.11,2022-05-07,0.27,2021-05-07,0.28,2020-05-06,0.32,2019-05-07,0.22
+2023-05-08,0.12,2022-05-08,0.31,2021-05-08,0.34,2020-05-07,0.3,2019-05-08,0.23
+2023-05-09,0.09,2022-05-09,0.2,2021-05-09,0.34,2020-05-08,0.28,2019-05-09,0.25
+2023-05-10,0.1,2022-05-10,0.22,2021-05-10,0.32,2020-05-09,0.28,2019-05-10,0.13
+2023-05-11,0.12,2022-05-11,0.27,2021-05-11,0.29,2020-05-10,0.28,2019-05-11,0.23
+2023-05-12,0.12,2022-05-12,0.25,2021-05-12,0.3,2020-05-11,0.29,2019-05-12,0.27
+2023-05-13,0.11,2022-05-13,0.28,2021-05-13,0.31,2020-05-12,0.23,2019-05-13,0.3
+2023-05-14,0.16,2022-05-14,0.31,2021-05-14,0.28,2020-05-13,0.26,2019-05-14,0.27
+2023-05-15,0.26,2022-05-15,0.32,2021-05-15,0.24,2020-05-14,0.29,2019-05-15,0.12
+2023-05-16,0.34,2022-05-16,0.31,2021-05-16,0.24,2020-05-15,0.28,2019-05-16,0.14
+2023-05-17,0.33,2022-05-17,0.29,2021-05-17,0.27,2020-05-16,0.27,2019-05-17,0.23
+2023-05-18,0.32,2022-05-18,0.32,2021-05-18,0.31,2020-05-17,0.24,2019-05-18,0.1
+2023-05-19,0.29,2022-05-19,0.39,2021-05-19,0.3,2020-05-18,0.25,2019-05-19,0.13
+2023-05-20,0.28,2022-05-20,0.37,2021-05-20,0.34,2020-05-19,0.21,2019-05-20,0.19
+2023-05-21,0.27,2022-05-21,0.28,2021-05-21,0.28,2020-05-20,0.25,2019-05-21,0.2
+2023-05-22,0.28,2022-05-22,0.3,2021-05-22,0.26,2020-05-21,0.28,2019-05-22,0.16
+2023-05-23,0.26,2022-05-23,0.34,2021-05-23,0.27,2020-05-22,0.31,2019-05-23,0.15
+2023-05-24,0.23,2022-05-24,0.32,2021-05-24,0.29,2020-05-23,0.3,2019-05-24,0.22
+2023-05-25,0.24,2022-05-25,0.29,2021-05-25,0.33,2020-05-24,0.29,2019-05-25,0.27
+2023-05-26,0.24,2022-05-26,0.3,2021-05-26,0.29,2020-05-25,0.28,2019-05-26,0.09
+2023-05-27,0.26,2022-05-27,0.26,2021-05-27,0.31,2020-05-26,0.3,2019-05-27,0.17
+2023-05-28,0.26,2022-05-28,0.31,2021-05-28,0.28,2020-05-27,0.32,2019-05-28,0.19
+2023-05-29,0.24,2022-05-29,0.33,2021-05-29,0.28,2020-05-28,0.32,2019-05-29,0.25
+2023-05-30,0.22,2022-05-30,0.32,2021-05-30,0.28,2020-05-29,0.32,2019-05-30,0.26
+2023-05-31,0.24,2022-05-31,0.31,2021-05-31,0.3,2020-05-30,0.24,2019-05-31,0.3
+2023-06-01,0.25,2022-06-01,0.31,2021-06-01,0.32,2020-05-31,0.17,2019-06-01,0.29
+2023-06-02,0.26,2022-06-02,0.33,2021-06-02,0.32,2020-06-01,0.22,2019-06-02,0.28
+2023-06-03,0.27,2022-06-03,0.31,2021-06-03,0.31,2020-06-02,0.29,2019-06-03,0.29
+2023-06-04,0.3,2022-06-04,0.29,2021-06-04,0.31,2020-06-03,0.32,2019-06-04,0.31
+2023-06-05,0.21,2022-06-05,0.29,2021-06-05,0.31,2020-06-04,0.34,2019-06-05,0.31
+2023-06-06,0.22,2022-06-06,0.33,2021-06-06,0.3,2020-06-05,0.28,2019-06-06,0.37
+2023-06-07,0.17,2022-06-07,0.31,2021-06-07,0.25,2020-06-06,0.27,2019-06-07,0.34
+2023-06-08,0.17,2022-06-08,0.31,2021-06-08,0.27,2020-06-07,0.32,2019-06-08,0.34
+2023-06-09,0.25,2022-06-09,0.29,2021-06-09,0.28,2020-06-08,0.3,2019-06-09,0.31
+2023-06-10,0.22,2022-06-10,0.35,2021-06-10,0.29,2020-06-09,0.29,2019-06-10,0.29
+2023-06-11,0.18,2022-06-11,0.37,2021-06-11,0.29,2020-06-10,0.31,2019-06-11,0.27
+2023-06-12,0.22,2022-06-12,0.31,2021-06-12,0.29,2020-06-11,0.31,2019-06-12,0.3
+2023-06-13,0.26,2022-06-13,0.36,2021-06-13,0.3,2020-06-12,0.29,2019-06-13,0.32
+2023-06-14,0.26,2022-06-14,0.35,2021-06-14,0.3,2020-06-13,0.28,2019-06-14,0.3
+2023-06-15,0.27,2022-06-15,0.35,2021-06-15,0.36,2020-06-14,0.28,2019-06-15,0.29
+2023-06-16,0.27,2022-06-16,0.33,2021-06-16,0.31,2020-06-15,0.29,2019-06-16,0.26
+2023-06-17,0.27,2022-06-17,0.23,2021-06-17,0.32,2020-06-16,0.3,2019-06-17,0.28
+2023-06-18,0.29,2022-06-18,0.28,2021-06-18,0.31,2020-06-17,0.33,2019-06-18,0.3
+2023-06-19,0.29,2022-06-19,0.32,2021-06-19,0.33,2020-06-18,0.3,2019-06-19,0.31
+2023-06-20,0.3,2022-06-20,0.32,2021-06-20,0.32,2020-06-19,0.31,2019-06-20,0.28
+2023-06-21,0.26,2022-06-21,0.33,2021-06-21,0.32,2020-06-20,0.31,2019-06-21,0.31
+2023-06-22,0.24,2022-06-22,0.28,2021-06-22,0.3,2020-06-21,0.31,2019-06-22,0.31
+2023-06-23,0.23,2022-06-23,0.31,2021-06-23,0.3,2020-06-22,0.29,2019-06-23,0.31
+2023-06-24,0.23,2022-06-24,0.33,2021-06-24,0.28,2020-06-23,0.31,2019-06-24,0.31
+2023-06-25,0.28,2022-06-25,0.34,2021-06-25,0.29,2020-06-24,0.28,2019-06-25,0.32
+2023-06-26,0.25,2022-06-26,0.36,2021-06-26,0.3,2020-06-25,0.3,2019-06-26,0.31
+2023-06-27,0.26,2022-06-27,0.37,2021-06-27,0.33,2020-06-26,0.29,2019-06-27,0.29
+2023-06-28,0.26,2022-06-28,0.36,2021-06-28,0.34,2020-06-27,0.31,2019-06-28,0.26
+2023-06-29,0.26,2022-06-29,0.33,2021-06-29,0.29,2020-06-28,0.31,2019-06-29,0.29
+2023-06-30,0.28,2022-06-30,0.3,2021-06-30,0.31,2020-06-29,0.3,2019-06-30,0.3
+2023-07-01,0.33,2022-07-01,0.3,2021-07-01,0.3,2020-06-30,0.28,2019-07-01,0.31
+2023-07-02,0.34,2022-07-02,0.32,2021-07-02,0.29,2020-07-01,0.27,2019-07-02,0.3
+2023-07-03,0.3,2022-07-03,0.29,2021-07-03,0.29,2020-07-02,0.28,2019-07-03,0.28
+2023-07-04,0.28,2022-07-04,0.28,2021-07-04,0.3,2020-07-03,0.29,2019-07-04,0.28
+2023-07-05,0.29,2022-07-05,0.28,2021-07-05,0.31,2020-07-04,0.3,2019-07-05,0.3
+2023-07-06,0.29,2022-07-06,0.29,2021-07-06,0.33,2020-07-05,0.32,2019-07-06,0.29
+2023-07-07,0.27,2022-07-07,0.3,2021-07-07,0.32,2020-07-06,0.31,2019-07-07,0.28
+2023-07-08,0.29,2022-07-08,0.29,2021-07-08,0.31,2020-07-07,0.29,2019-07-08,0.29
+2023-07-09,0.27,2022-07-09,0.33,2021-07-09,0.33,2020-07-08,0.28,2019-07-09,0.29
+2023-07-10,0.26,2022-07-10,0.3,2021-07-10,0.34,2020-07-09,0.3,2019-07-10,0.29
+2023-07-11,0.27,2022-07-11,0.3,2021-07-11,0.35,2020-07-10,0.29,2019-07-11,0.3
+2023-07-12,0.3,2022-07-12,0.33,2021-07-12,0.31,2020-07-11,0.31,2019-07-12,0.3
+2023-07-13,0.3,2022-07-13,0.31,2021-07-13,0.3,2020-07-12,0.31,2019-07-13,0.31
+2023-07-14,0.3,2022-07-14,0.33,2021-07-14,0.29,2020-07-13,0.3,2019-07-14,0.34
+2023-07-15,0.29,2022-07-15,0.35,2021-07-15,0.29,2020-07-14,0.26,2019-07-15,0.31
+2023-07-16,0.26,2022-07-16,0.33,2021-07-16,0.28,2020-07-15,0.27,2019-07-16,0.31
+2023-07-17,0.28,2022-07-17,0.33,2021-07-17,0.28,2020-07-16,0.29,2019-07-17,0.28
+2023-07-18,0.24,2022-07-18,0.21,2021-07-18,0.2,2020-07-17,0.28,2019-07-18,0.29
+2023-07-19,0.3,2022-07-19,0.34,2021-07-19,0.3,2020-07-18,0.28,2019-07-19,0.28
+2023-07-20,0.3,2022-07-20,0.33,2021-07-20,0.33,2020-07-19,0.29,2019-07-20,0.28
+2023-07-21,0.28,2022-07-21,0.34,2021-07-21,0.3,2020-07-20,0.29,2019-07-21,0.28
+2023-07-22,0.28,2022-07-22,0.34,2021-07-22,0.3,2020-07-21,0.23,2019-07-22,0.29
+2023-07-23,0.28,2022-07-23,0.3,2021-07-23,0.29,2020-07-22,0.27,2019-07-23,0.3
+2023-07-24,0.3,2022-07-24,0.3,2021-07-24,0.29,2020-07-23,0.26,2019-07-24,0.31
+2023-07-25,0.28,2022-07-25,0.29,2021-07-25,0.28,2020-07-24,0.28,2019-07-25,0.26
+2023-07-26,0.28,2022-07-26,0.31,2021-07-26,0.27,2020-07-25,0.27,2019-07-26,0.31
+2023-07-27,0.28,2022-07-27,0.31,2021-07-27,0.32,2020-07-26,0.3,2019-07-27,0.31
+2023-07-28,0.28,2022-07-28,0.29,2021-07-28,0.28,2020-07-27,0.3,2019-07-28,0.31
+2023-07-29,0.29,2022-07-29,0.28,2021-07-29,0.3,2020-07-28,0.31,2019-07-29,0.31
+2023-07-30,0.26,2022-07-30,0.28,2021-07-30,0.3,2020-07-29,0.31,2019-07-30,0.3
+2023-07-31,0.27,2022-07-31,0.27,2021-07-31,0.3,2020-07-30,0.32,2019-07-31,0.28
+2023-08-01,0.27,2022-08-01,0.24,2021-08-01,0.3,2020-07-31,0.33,2019-08-01,0.29
+2023-08-02,0.25,2022-08-02,0.29,2021-08-02,0.29,2020-08-01,0.3,2019-08-02,0.29
+2023-08-03,0.25,2022-08-03,0.31,2021-08-03,0.31,2020-08-02,0.29,2019-08-03,0.28
+2023-08-04,0.25,2022-08-04,0.29,2021-08-04,0.33,2020-08-03,0.3,2019-08-04,0.31
+2023-08-05,0.29,2022-08-05,0.24,2021-08-05,0.3,2020-08-04,0.27,2019-08-05,0.27
+2023-08-06,0.29,2022-08-06,0.28,2021-08-06,0.29,2020-08-05,0.27,2019-08-06,0.29
+2023-08-07,0.27,2022-08-07,0.3,2021-08-07,0.25,2020-08-06,0.23,2019-08-07,0.3
+2023-08-08,0.27,2022-08-08,0.3,2021-08-08,0.26,2020-08-07,0.25,2019-08-08,0.29
+2023-08-09,0.25,2022-08-09,0.3,2021-08-09,0.27,2020-08-08,0.26,2019-08-09,0.28
+2023-08-10,0.2,2022-08-10,0.28,2021-08-10,0.28,2020-08-09,0.28,2019-08-10,0.28
+2023-08-11,0.22,2022-08-11,0.3,2021-08-11,0.29,2020-08-10,0.29,2019-08-11,0.28
+2023-08-12,0.21,2022-08-12,0.3,2021-08-12,0.29,2020-08-11,0.27,2019-08-12,0.28
+2023-08-13,0.23,2022-08-13,0.29,2021-08-13,0.28,2020-08-12,0.27,2019-08-13,0.29
+2023-08-14,0.25,2022-08-14,0.3,2021-08-14,0.26,2020-08-13,0.09,2019-08-14,0.3
+2023-08-15,0.24,2022-08-15,0.29,2021-08-15,0.27,2020-08-14,0.28,2019-08-15,0.29
+2023-08-16,0.19,2022-08-16,0.29,2021-08-16,0.24,2020-08-15,0.15,2019-08-16,0.29
+2023-08-17,0.25,2022-08-17,0.28,2021-08-17,0.27,2020-08-16,0.35,2019-08-17,0.28
+2023-08-18,0.25,2022-08-18,0.31,2021-08-18,0.25,2020-08-17,0.34,2019-08-18,0.25
+2023-08-19,0.21,2022-08-19,0.28,2021-08-19,0.17,2020-08-18,0.33,2019-08-19,0.26
+2023-08-20,0.04,2022-08-20,0.25,2021-08-20,0.21,2020-08-19,0.26,2019-08-20,0.27
+2023-08-21,0.24,2022-08-21,0.26,2021-08-21,0.24,2020-08-20,0.26,2019-08-21,0.27
+2023-08-22,0.22,2022-08-22,0.27,2021-08-22,0.22,2020-08-21,0.21,2019-08-22,0.25
+2023-08-23,0.23,2022-08-23,0.24,2021-08-23,0.24,2020-08-22,0.2,2019-08-23,0.25
+2023-08-24,0.24,2022-08-24,0.24,2021-08-24,0.24,2020-08-23,0.16,2019-08-24,0.27
+2023-08-25,0.22,2022-08-25,0.26,2021-08-25,0.24,2020-08-24,0.23,2019-08-25,0.26
+2023-08-26,0.23,2022-08-26,0.24,2021-08-26,0.26,2020-08-25,0.24,2019-08-26,0.27
+2023-08-27,0.26,2022-08-27,0.24,2021-08-27,0.26,2020-08-26,0.24,2019-08-27,0.28
+2023-08-28,0.27,2022-08-28,0.24,2021-08-28,0.25,2020-08-27,0.27,2019-08-28,0.29
+2023-08-29,0.28,2022-08-29,0.24,2021-08-29,0.27,2020-08-28,0.25,2019-08-29,0.26
+2023-08-30,0.26,2022-08-30,0.26,2021-08-30,0.27,2020-08-29,0.26,2019-08-30,0.25
+2023-08-31,0.28,2022-08-31,0.27,2021-08-31,0.26,2020-08-30,0.26,2019-08-31,0.25
+2023-09-01,0.22,2022-09-01,0.28,2021-09-01,0.23,2020-08-31,0.23,2019-09-01,0.28
+2023-09-02,0.09,2022-09-02,0.3,2021-09-02,0.22,2020-09-01,0.24,2019-09-02,0.27
+2023-09-03,0.12,2022-09-03,0.31,2021-09-03,0.22,2020-09-02,0.24,2019-09-03,0.28
+2023-09-04,0.19,2022-09-04,0.22,2021-09-04,0.23,2020-09-03,0.23,2019-09-04,0.26
+2023-09-05,0.19,2022-09-05,0.22,2021-09-05,0.24,2020-09-04,0.27,2019-09-05,0.25
+2023-09-06,0.2,2022-09-06,0.21,2021-09-06,0.24,2020-09-05,0.26,2019-09-06,0.26
+2023-09-07,0.21,2022-09-07,0.25,2021-09-07,0.29,2020-09-06,0.27,2019-09-07,0.26
+2023-09-08,0.21,2022-09-08,0.22,2021-09-08,0.25,2020-09-07,0.25,2019-09-08,0.21
+2023-09-09,0.23,2022-09-09,0.25,2021-09-09,0.22,2020-09-08,0.3,2019-09-09,0.23
+2023-09-10,0.23,2022-09-10,0.16,2021-09-10,0.27,2020-09-09,0.19,2019-09-10,0.21
+2023-09-11,0.18,2022-09-11,0.24,2021-09-11,0.24,2020-09-10,0.09,2019-09-11,0.22
+2023-09-12,0.21,2022-09-12,0.23,2021-09-12,0.25,2020-09-11,0.13,2019-09-12,0.23
+2023-09-13,0.2,2022-09-13,0.24,2021-09-13,0.22,2020-09-12,0.17,2019-09-13,0.23
+2023-09-14,0.18,2022-09-14,0.18,2021-09-14,0.23,2020-09-13,0.16,2019-09-14,0.22
+2023-09-15,0.2,2022-09-15,0.21,2021-09-15,0.21,2020-09-14,0.19,2019-09-15,0.21
+2023-09-16,0.2,2022-09-16,0.19,2021-09-16,0.22,2020-09-15,0.16,2019-09-16,0.19
+2023-09-17,0.16,2022-09-17,0.2,2021-09-17,0.19,2020-09-16,0.19,2019-09-17,0.2
+2023-09-18,0.12,2022-09-18,0.15,2021-09-18,0.21,2020-09-17,0.14,2019-09-18,0.21
+2023-09-19,0.16,2022-09-19,0.05,2021-09-19,0.22,2020-09-18,0.21,2019-09-19,0.22
+2023-09-20,0.17,2022-09-20,0.15,2021-09-20,0.2,2020-09-19,0.21,2019-09-20,0.21
+2023-09-21,0.15,2022-09-21,0.15,2021-09-21,0.18,2020-09-20,0.18,2019-09-21,0.21
+2023-09-22,0.16,2022-09-22,0.19,2021-09-22,0.21,2020-09-21,0.19,2019-09-22,0.2
+2023-09-23,0.16,2022-09-23,0.17,2021-09-23,0.22,2020-09-22,0.23,2019-09-23,0.23
+2023-09-24,0.16,2022-09-24,0.18,2021-09-24,0.17,2020-09-23,0.22,2019-09-24,0.22
+2023-09-25,0.17,2022-09-25,0.19,2021-09-25,0.19,2020-09-24,0.22,2019-09-25,0.2
+2023-09-26,0.18,2022-09-26,0.19,2021-09-26,0.16,2020-09-25,0.2,2019-09-26,0.21
+2023-09-27,0.19,2022-09-27,0.21,2021-09-27,0.17,2020-09-26,0.21,2019-09-27,0.17
+2023-09-28,0.19,2022-09-28,0.22,2021-09-28,0.21,2020-09-27,0.19,2019-09-28,0.19
+2023-09-29,0.18,2022-09-29,0.13,2021-09-29,0.2,2020-09-28,0.18,2019-09-29,0.17
+2023-09-30,0.1,2022-09-30,0.1,2021-09-30,0.16,2020-09-29,0.19,2019-09-30,0.18
+2023-10-01,0.09,2022-10-01,0.11,2021-10-01,0.17,2020-09-30,0.2,2019-10-01,0.18
+2023-10-02,0.16,2022-10-02,0.11,2021-10-02,0.18,2020-10-01,0.16,2019-10-02,0.17
+2023-10-03,0.15,2022-10-03,0.1,2021-10-03,0.17,2020-10-02,0.16,2019-10-03,0.17
+2023-10-04,0.15,2022-10-04,0.11,2021-10-04,0.15,2020-10-03,0.17,2019-10-04,0.21
+2023-10-05,0.16,2022-10-05,0.1,2021-10-05,0.17,2020-10-04,0.18,2019-10-05,0.18
+2023-10-06,0.16,2022-10-06,0.11,2021-10-06,0.18,2020-10-05,0.19,2019-10-06,0.16
+2023-10-07,0.15,2022-10-07,0.12,2021-10-07,0.16,2020-10-06,0.11,2019-10-07,0.17
+2023-10-08,0.16,2022-10-08,0.12,2021-10-08,0.12,2020-10-07,0.17,2019-10-08,0.18
+2023-10-09,0.14,2022-10-09,0.13,2021-10-09,0.14,2020-10-08,0.15,2019-10-09,0.25
+2023-10-10,0.14,2022-10-10,0.15,2021-10-10,0.14,2020-10-09,0.13,2019-10-10,0.19
+2023-10-11,0.22,2022-10-11,0.14,2021-10-11,0.29,2020-10-10,0.13,2019-10-11,0.16
+2023-10-12,0.16,2022-10-12,0.16,2021-10-12,0.22,2020-10-11,0.17,2019-10-12,0.15
+2023-10-13,0.17,2022-10-13,0.17,2021-10-13,0.15,2020-10-12,0.17,2019-10-13,0.16
+2023-10-14,0.14,2022-10-14,0.15,2021-10-14,0.17,2020-10-13,0.17,2019-10-14,0.16
+2023-10-15,0.14,2022-10-15,0.16,2021-10-15,0.14,2020-10-14,0.19,2019-10-15,0.15
+2023-10-16,0.16,2022-10-16,0.12,2021-10-16,0.15,2020-10-15,0.17,2019-10-16,0.12
+2023-10-17,0.16,2022-10-17,0.12,2021-10-17,0.18,2020-10-16,0.15,2019-10-17,0.19
+2023-10-18,0.13,2022-10-18,0.11,2021-10-18,0.13,2020-10-17,0.14,2019-10-18,0.16
+2023-10-19,0.14,2022-10-19,0.14,2021-10-19,0.13,2020-10-18,0.15,2019-10-19,0.14
+2023-10-20,0.14,2022-10-20,0.14,2021-10-20,0.14,2020-10-19,0.15,2019-10-20,0.17
+2023-10-21,0.15,2022-10-21,0.13,2021-10-21,0.12,2020-10-20,0.15,2019-10-21,0.15
+2023-10-22,0.11,2022-10-22,0.12,2021-10-22,0.07,2020-10-21,0.14,2019-10-22,0.14
+2023-10-23,0.12,2022-10-23,0.2,2021-10-23,0.11,2020-10-22,0.18,2019-10-23,0.14
+2023-10-24,0.11,2022-10-24,0.13,2021-10-24,0.08,2020-10-23,0.17,2019-10-24,0.14
+2023-10-25,0.14,2022-10-25,0.12,2021-10-25,0.07,2020-10-24,0.12,2019-10-25,0.13
+2023-10-26,0.12,2022-10-26,0.14,2021-10-26,0.06,2020-10-25,0.1,2019-10-26,0.13
+2023-10-27,0.11,2022-10-27,0.12,2021-10-27,0.07,2020-10-26,0.14,2019-10-27,0.21
+2023-10-28,0.14,2022-10-28,0.12,2021-10-28,0.08,2020-10-27,0.11,2019-10-28,0.13
+2023-10-29,0.12,2022-10-29,0.13,2021-10-29,0.09,2020-10-28,0.11,2019-10-29,0.13
+2023-10-30,0.1,2022-10-30,0.11,2021-10-30,0.05,2020-10-29,0.11,2019-10-30,0.13
+2023-10-31,0.1,2022-10-31,0.05,2021-10-31,0.06,2020-10-30,0.11,2019-10-31,0.11
+2023-11-01,0.11,2022-11-01,0.09,2021-11-01,0.07,2020-10-31,0.11,2019-11-01,0.11
+2023-11-02,0.11,2022-11-02,0.07,2021-11-02,0.1,2020-11-01,0.11,2019-11-02,0.11
+2023-11-03,0.11,2022-11-03,0.1,2021-11-03,0.08,2020-11-02,0.09,2019-11-03,0.11
+2023-11-04,0.11,2022-11-04,0.08,2021-11-04,0.08,2020-11-03,0.11,2019-11-04,0.11
+2023-11-05,0.11,2022-11-05,0.08,2021-11-05,0.08,2020-11-04,0.13,2019-11-05,0.11
+2023-11-06,0.11,2022-11-06,0.07,2021-11-06,0.1,2020-11-05,0.09,2019-11-06,0.11
+2023-11-07,0.12,2022-11-07,0.02,2021-11-07,0.11,2020-11-06,0.12,2019-11-07,0.11
+2023-11-08,0.11,2022-11-08,0.04,2021-11-08,0.09,2020-11-07,0.04,2019-11-08,0.11
+2023-11-09,0.09,2022-11-09,0.07,2021-11-09,0.06,2020-11-08,0.09,2019-11-09,0.1
+2023-11-10,0.09,2022-11-10,0.08,2021-11-10,0.07,2020-11-09,0.09,2019-11-10,0.1
+2023-11-11,0.09,2022-11-11,0.06,2021-11-11,0.05,2020-11-10,0.07,2019-11-11,0.1
+2023-11-12,0.11,2022-11-12,0.07,2021-11-12,0.06,2020-11-11,0.06,2019-11-12,0.1
+2023-11-13,0.1,2022-11-13,0.09,2021-11-13,0.04,2020-11-12,0.08,2019-11-13,0.09
+2023-11-14,0.1,2022-11-14,0.07,2021-11-14,0.02,2020-11-13,0.08,2019-11-14,0.09
+2023-11-15,0.04,2022-11-15,0.09,2021-11-15,0.01,2020-11-14,0.09,2019-11-15,0.08
+2023-11-16,0.09,2022-11-16,0.07,2021-11-16,0,2020-11-15,0.07,2019-11-16,0.08
+2023-11-17,0.08,2022-11-17,0.08,2021-11-17,0.03,2020-11-16,0.08,2019-11-17,0.08
+2023-11-18,0.05,2022-11-18,0.08,2021-11-18,0.06,2020-11-17,0.11,2019-11-18,0.09
+2023-11-19,0.14,2022-11-19,0.08,2021-11-19,0.07,2020-11-18,0.06,2019-11-19,0.1
+2023-11-20,0.08,2022-11-20,0.08,2021-11-20,0.06,2020-11-19,0.11,2019-11-20,0.05
+2023-11-21,0.08,2022-11-21,0.06,2021-11-21,0.06,2020-11-20,0.06,2019-11-21,0.08
+2023-11-22,0.08,2022-11-22,0.07,2021-11-22,0.06,2020-11-21,0.06,2019-11-22,0.08
+2023-11-23,0.11,2022-11-23,0.07,2021-11-23,0.06,2020-11-22,0.08,2019-11-23,0.09
+2023-11-24,0.11,2022-11-24,0.08,2021-11-24,0.09,2020-11-23,0.09,2019-11-24,0.08
+2023-11-25,0.08,2022-11-25,0.07,2021-11-25,0.08,2020-11-24,0.08,2019-11-25,0.17
+2023-11-26,0.05,2022-11-26,0.08,2021-11-26,0.06,2020-11-25,0.1,2019-11-26,0.1
+2023-11-27,0.07,2022-11-27,0.07,2021-11-27,0.07,2020-11-26,0.09,2019-11-27,0.04
+2023-11-28,0.09,2022-11-28,0.09,2021-11-28,0.07,2020-11-27,0.07,2019-11-28,0.02
+2023-11-29,0.07,2022-11-29,0.07,2021-11-29,0.07,2020-11-28,0.07,2019-11-29,0.06
+2023-11-30,0.08,2022-11-30,0.08,2021-11-30,0.06,2020-11-29,0.07,2019-11-30,0.01
+2023-12-01,0.09,2022-12-01,0.03,2021-12-01,0.07,2020-11-30,0.08,2019-12-01,0
+2023-12-02,0.07,2022-12-02,0.04,2021-12-02,0.06,2020-12-01,0.07,2019-12-02,0.05
+2023-12-03,0.05,2022-12-03,0.03,2021-12-03,0.06,2020-12-02,0.07,2019-12-03,0
+2023-12-04,0.06,2022-12-04,0.05,2021-12-04,0.01,2020-12-03,0.11,2019-12-04,0.01
+2023-12-05,0.06,2022-12-05,0.05,2021-12-05,0,2020-12-04,0.06,2019-12-05,0.06
+2023-12-06,0.1,2022-12-06,0.04,2021-12-06,0.02,2020-12-05,0.08,2019-12-06,0.07
+2023-12-07,0.09,2022-12-07,0.04,2021-12-07,0.01,2020-12-06,0.07,2019-12-07,0.04
+2023-12-08,0.08,2022-12-08,0.04,2021-12-08,0.04,2020-12-07,0.09,2019-12-08,0.04
+2023-12-09,0.07,2022-12-09,0.05,2021-12-09,0.03,2020-12-08,0.05,2019-12-09,0.02
+2023-12-10,0.06,2022-12-10,0.06,2021-12-10,0.06,2020-12-09,0.08,2019-12-10,0.02
+2023-12-11,0.06,2022-12-11,0.04,2021-12-11,0.06,2020-12-10,0.07,2019-12-11,0
+2023-12-12,0.07,2022-12-12,0.03,2021-12-12,0.04,2020-12-11,0.07,2019-12-12,0.05
+2023-12-13,0.06,2022-12-13,0.04,2021-12-13,0.04,2020-12-12,0.02,2019-12-13,0.04
+2023-12-14,0.06,2022-12-14,0.04,2021-12-14,0.01,2020-12-13,0.02,2019-12-14,0.06
+2023-12-15,0.06,2022-12-15,0.03,2021-12-15,0.01,2020-12-14,0.07,2019-12-15,0.07
+2023-12-16,0.07,2022-12-16,0.03,2021-12-16,0.01,2020-12-15,0.05,2019-12-16,0.06
+2023-12-17,0.04,2022-12-17,0.01,2021-12-17,0.01,2020-12-16,0.05,2019-12-17,0.05
+2023-12-18,0.02,2022-12-18,0,2021-12-18,0.01,2020-12-17,0.06,2019-12-18,0.07
+2023-12-19,0.04,2022-12-19,0,2021-12-19,0,2020-12-18,0.07,2019-12-19,0.06
+2023-12-20,0,2022-12-20,0.01,2021-12-20,0,2020-12-19,0.06,2019-12-20,0.06
+2023-12-21,0,2022-12-21,0,2021-12-21,0,2020-12-20,0.05,2019-12-21,0.07
+2023-12-22,0.02,2022-12-22,0,2021-12-22,0,2020-12-21,0.04,2019-12-22,0.04
+2023-12-23,0.02,2022-12-23,0,2021-12-23,0,2020-12-22,0.01,2019-12-23,0
+2023-12-24,0.04,2022-12-24,0.01,2021-12-24,0.05,2020-12-23,0.04,2019-12-24,0.04
+2023-12-25,0.04,2022-12-25,0,2021-12-25,0.05,2020-12-24,0.02,2019-12-25,0.04
+2023-12-26,0.03,2022-12-26,0,2021-12-26,0.05,2020-12-25,0.06,2019-12-26,0.03
+2023-12-27,0.06,2022-12-27,0,2021-12-27,0.03,2020-12-26,0.07,2019-12-27,0.05
+2023-12-28,0.06,2022-12-28,0.04,2021-12-28,0.03,2020-12-27,0.06,2019-12-28,0.04
+2023-12-29,0.08,2022-12-29,0,2021-12-29,0.02,2020-12-28,0.05,2019-12-29,0.02
+2023-12-30,0.03,2022-12-30,0.01,2021-12-30,0.02,2020-12-29,0.07,2019-12-30,0.06
+2023-12-31,0.02,2022-12-31,0.01,2021-12-31,0.02,2020-12-30,0.06,2019-12-31,0.05
+,,,,,,2020-12-31,0,,
Index: GSheetCredentialSevice.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import os\r\nimport pickle\r\n\r\nfrom google.auth.transport.requests import Request\r\nfrom google_auth_oauthlib.flow import InstalledAppFlow\r\nfrom googleapiclient import discovery\r\n\r\n\r\nclass GSheetCredentialSevice(object):\r\n    SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\r\n    creds = None\r\n\r\n    def __init__(self):\r\n        self.SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\r\n\r\n    def getCreds(self):\r\n        creds = self.creds\r\n        if os.path.exists('C:\\\\Users\\\\javie\\\\Projects\\\\S-TOMAto\\\\credentials.json'):\r\n            os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/javie/Projects/S-TOMAto/credentials.json\"\r\n        elif os.path.exists('C:\\\\Users\\\\javie\\\\PycharmProjects\\\\Stomato\\\\credentials2.json'):\r\n            os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/javie/PycharmProjects/Stomato/credentials.json\"\r\n        elif os.path.exists('C:\\\\Users\\\\jsalcedo\\\\PycharmProjects\\\\Stomato\\\\credentials2.json'):\r\n            os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/jsalcedo/PycharmProjects/Stomato/credentials.json\"\r\n        elif os.path.exists('C:\\\\Users\\\\jesus\\\\PycharmProjects\\\\Stomato\\\\credentials2.json'):\r\n            os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/jesus/PycharmProjects/Stomato/credentials2.json\"\r\n\r\n        if os.path.exists('token.pickle'):\r\n            with open('token.pickle', 'rb') as token:\r\n                creds = pickle.load(token)\r\n                self.creds = creds\r\n        else:\r\n            creds = None\r\n        if not creds or not creds.valid:\r\n            if creds and creds.expired and creds.refresh_token:\r\n                self.creds.refresh(Request())\r\n            else:\r\n                flow = InstalledAppFlow.from_client_secrets_file(\r\n                    'credentials2.json', self.SCOPES)\r\n                self.creds = flow.run_local_server(port=0)\r\n            # Save the credentials for the next run\r\n            with open('token.pickle', 'wb') as token:\r\n                pickle.dump(self.creds, token)\r\n        self.creds = creds\r\n\r\n    def getService(self):\r\n        self.getCreds()\r\n        return discovery.build('sheets', 'v4', credentials=self.creds)\r\n\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/GSheetCredentialSevice.py b/GSheetCredentialSevice.py
--- a/GSheetCredentialSevice.py	
+++ b/GSheetCredentialSevice.py	
@@ -23,7 +23,8 @@
             os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "C:/Users/jsalcedo/PycharmProjects/Stomato/credentials.json"
         elif os.path.exists('C:\\Users\\jesus\\PycharmProjects\\Stomato\\credentials2.json'):
             os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "C:/Users/jesus/PycharmProjects/Stomato/credentials2.json"
-
+        elif os.path.exists('C:\\Users\\odolan\\PycharmProjects\\Stomato\\credentials.json'):
+            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "C:/Users/odolan/PycharmProjects/Stomato/credentials.json"
         if os.path.exists('token.pickle'):
             with open('token.pickle', 'rb') as token:
                 creds = pickle.load(token)
Index: requirements.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>requests==2.27.1\r\nuuid~=1.30\r\npython-dateutil~=2.8.2\r\ngspread==5.3.2\r\ngoogle-api-python-client~=1.6.4\r\noauth2client~=4.1.3\r\nfuture==0.18.2\r\nnumpy~=1.22.0\r\nPyJWT~=2.6.0\r\npandas~=1.3.3\r\nmatplotlib~=3.7.1\r\npytz~=2023.3
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/requirements.txt b/requirements.txt
--- a/requirements.txt	
+++ b/requirements.txt	
@@ -1,12 +1,13 @@
 requests==2.27.1
 uuid~=1.30
-python-dateutil~=2.8.2
-gspread==5.3.2
-google-api-python-client~=1.6.4
+python-dateutil~=2.9.0.post0
+google-api-python-client~=2.123.0
 oauth2client~=4.1.3
 future==0.18.2
-numpy~=1.22.0
+numpy~=1.26.4
 PyJWT~=2.6.0
-pandas~=1.3.3
-matplotlib~=3.7.1
-pytz~=2023.3
\ No newline at end of file
+pandas~=2.2.1
+matplotlib~=3.8.3
+pytz~=2023.3
+google~=3.0.0
+pillow~=10.2.0
\ No newline at end of file
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project version=\"4\">\r\n  <component name=\"ProjectRootManager\" version=\"2\" project-jdk-name=\"Python 3.9 (venv4)\" project-jdk-type=\"Python SDK\" />\r\n  <component name=\"PythonCompatibilityInspectionAdvertiser\">\r\n    <option name=\"version\" value=\"3\" />\r\n  </component>\r\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/misc.xml b/.idea/misc.xml
--- a/.idea/misc.xml	
+++ b/.idea/misc.xml	
@@ -1,6 +1,9 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
-  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.9 (venv4)" project-jdk-type="Python SDK" />
+  <component name="Black">
+    <option name="sdkName" value="Python 3.12" />
+  </component>
+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.12 (Stomato)" project-jdk-type="Python SDK" />
   <component name="PythonCompatibilityInspectionAdvertiser">
     <option name="version" value="3" />
   </component>
Index: .idea/inspectionProfiles/Project_Default.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><component name=\"InspectionProjectProfileManager\">\r\n  <profile version=\"1.0\">\r\n    <option name=\"myName\" value=\"Project Default\" />\r\n    <inspection_tool class=\"DuplicatedCode\" enabled=\"true\" level=\"WEAK WARNING\" enabled_by_default=\"true\">\r\n      <Languages>\r\n        <language minSize=\"63\" name=\"Python\" />\r\n      </Languages>\r\n    </inspection_tool>\r\n    <inspection_tool class=\"PyClassicStyleClassInspection\" enabled=\"true\" level=\"WARNING\" enabled_by_default=\"true\" />\r\n    <inspection_tool class=\"PyCompatibilityInspection\" enabled=\"true\" level=\"WARNING\" enabled_by_default=\"true\">\r\n      <option name=\"ourVersions\">\r\n        <value>\r\n          <list size=\"5\">\r\n            <item index=\"0\" class=\"java.lang.String\" itemvalue=\"3.6\" />\r\n            <item index=\"1\" class=\"java.lang.String\" itemvalue=\"3.7\" />\r\n            <item index=\"2\" class=\"java.lang.String\" itemvalue=\"3.8\" />\r\n            <item index=\"3\" class=\"java.lang.String\" itemvalue=\"3.9\" />\r\n            <item index=\"4\" class=\"java.lang.String\" itemvalue=\"3.10\" />\r\n          </list>\r\n        </value>\r\n      </option>\r\n    </inspection_tool>\r\n    <inspection_tool class=\"PyMissingOrEmptyDocstringInspection\" enabled=\"true\" level=\"WEAK WARNING\" enabled_by_default=\"true\" />\r\n    <inspection_tool class=\"PyPackageRequirementsInspection\" enabled=\"true\" level=\"WARNING\" enabled_by_default=\"true\">\r\n      <option name=\"ignoredPackages\">\r\n        <value>\r\n          <list size=\"24\">\r\n            <item index=\"0\" class=\"java.lang.String\" itemvalue=\"greenlet\" />\r\n            <item index=\"1\" class=\"java.lang.String\" itemvalue=\"wxPython\" />\r\n            <item index=\"2\" class=\"java.lang.String\" itemvalue=\"cffi\" />\r\n            <item index=\"3\" class=\"java.lang.String\" itemvalue=\"cryptography\" />\r\n            <item index=\"4\" class=\"java.lang.String\" itemvalue=\"MarkupSafe\" />\r\n            <item index=\"5\" class=\"java.lang.String\" itemvalue=\"numpy\" />\r\n            <item index=\"6\" class=\"java.lang.String\" itemvalue=\"pyclipper\" />\r\n            <item index=\"7\" class=\"java.lang.String\" itemvalue=\"pandas\" />\r\n            <item index=\"8\" class=\"java.lang.String\" itemvalue=\"pyzmq\" />\r\n            <item index=\"9\" class=\"java.lang.String\" itemvalue=\"matplotlib\" />\r\n            <item index=\"10\" class=\"java.lang.String\" itemvalue=\"lxml\" />\r\n            <item index=\"11\" class=\"java.lang.String\" itemvalue=\"grpcio\" />\r\n            <item index=\"12\" class=\"java.lang.String\" itemvalue=\"weather-api\" />\r\n            <item index=\"13\" class=\"java.lang.String\" itemvalue=\"Pillow\" />\r\n            <item index=\"14\" class=\"java.lang.String\" itemvalue=\"google-cloud-bigquery\" />\r\n            <item index=\"15\" class=\"java.lang.String\" itemvalue=\"protobuf\" />\r\n            <item index=\"16\" class=\"java.lang.String\" itemvalue=\"six\" />\r\n            <item index=\"17\" class=\"java.lang.String\" itemvalue=\"googleapis-common-protos\" />\r\n            <item index=\"18\" class=\"java.lang.String\" itemvalue=\"google-cloud-core\" />\r\n            <item index=\"19\" class=\"java.lang.String\" itemvalue=\"google-auth\" />\r\n            <item index=\"20\" class=\"java.lang.String\" itemvalue=\"google-api-python-client\" />\r\n            <item index=\"21\" class=\"java.lang.String\" itemvalue=\"httplib2\" />\r\n            <item index=\"22\" class=\"java.lang.String\" itemvalue=\"python-dateutil\" />\r\n            <item index=\"23\" class=\"java.lang.String\" itemvalue=\"gspread\" />\r\n          </list>\r\n        </value>\r\n      </option>\r\n    </inspection_tool>\r\n    <inspection_tool class=\"PyPep8NamingInspection\" enabled=\"true\" level=\"WEAK WARNING\" enabled_by_default=\"true\">\r\n      <option name=\"ignoredErrors\">\r\n        <list>\r\n          <option value=\"N802\" />\r\n          <option value=\"N803\" />\r\n          <option value=\"N806\" />\r\n        </list>\r\n      </option>\r\n    </inspection_tool>\r\n    <inspection_tool class=\"PyUnresolvedReferencesInspection\" enabled=\"true\" level=\"WARNING\" enabled_by_default=\"true\">\r\n      <option name=\"ignoredIdentifiers\">\r\n        <list>\r\n          <option value=\"Notifications.AllNotifications\" />\r\n        </list>\r\n      </option>\r\n    </inspection_tool>\r\n  </profile>\r\n</component>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/inspectionProfiles/Project_Default.xml b/.idea/inspectionProfiles/Project_Default.xml
--- a/.idea/inspectionProfiles/Project_Default.xml	
+++ b/.idea/inspectionProfiles/Project_Default.xml	
@@ -65,7 +65,7 @@
     <inspection_tool class="PyUnresolvedReferencesInspection" enabled="true" level="WARNING" enabled_by_default="true">
       <option name="ignoredIdentifiers">
         <list>
-          <option value="Notifications.AllNotifications" />
+          <option value="bool.*" />
         </list>
       </option>
     </inspection_tool>
Index: all et.csv
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>dates,eto\r\n2023-06-24,0.23\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/all et.csv b/all et.csv
--- a/all et.csv	
+++ b/all et.csv	
@@ -1,2 +1,93 @@
 dates,eto
-2023-06-24,0.23
+2024-01-01,0.02
+2024-01-02,0
+2024-01-03,0.05
+2024-01-04,0.05
+2024-01-05,0.04
+2024-01-06,0.02
+2024-01-07,0.08
+2024-01-08,0.06
+2024-01-09,0.06
+2024-01-10,0.07
+2024-01-11,0.08
+2024-01-12,0.05
+2024-01-13,0.02
+2024-01-14,0.05
+2024-01-15,0.02
+2024-01-16,0.01
+2024-01-17,0.02
+2024-01-18,0.02
+2024-01-19,0.02
+2024-01-20,0.03
+2024-01-21,0
+2024-01-22,0
+2024-01-23,0
+2024-01-24,0.01
+2024-01-25,0.06
+2024-01-26,0.05
+2024-01-27,0.04
+2024-01-28,0.06
+2024-01-29,0.07
+2024-01-30,0.08
+2024-01-31,0.08
+2024-02-01,0.04
+2024-02-02,0.06
+2024-02-03,0.04
+2024-02-04,0.02
+2024-02-05,0.06
+2024-02-06,0.05
+2024-02-07,0.03
+2024-02-08,0.04
+2024-02-09,0.06
+2024-02-10,0.07
+2024-02-11,0.07
+2024-02-12,0.07
+2024-02-13,0.07
+2024-02-14,0.08
+2024-02-15,0.07
+2024-02-16,0.06
+2024-02-17,0.02
+2024-02-18,0.09
+2024-02-19,0.1
+2024-02-20,0.08
+2024-02-21,0.09
+2024-02-22,0.1
+2024-02-23,0.08
+2024-02-24,0.11
+2024-02-25,0.1
+2024-02-26,0.04
+2024-02-27,0.11
+2024-02-28,0.11
+2024-02-29,0.13
+2024-03-01,0.08
+2024-03-02,0.05
+2024-03-03,0.09
+2024-03-04,0.1
+2024-03-05,0.12
+2024-03-06,0.08
+2024-03-07,0.12
+2024-03-08,0.13
+2024-03-09,0.13
+2024-03-10,0.12
+2024-03-11,0.14
+2024-03-12,0.1
+2024-03-13,0.16
+2024-03-14,0.2
+2024-03-15,0.16
+2024-03-16,0.17
+2024-03-17,0.16
+2024-03-18,0.16
+2024-03-19,0.18
+2024-03-20,0.2
+2024-03-21,0.17
+2024-03-22,0.2
+2024-03-23,0.08
+2024-03-24,0.09
+2024-03-25,0.13
+2024-03-26,0.16
+2024-03-27,0.17
+2024-03-28,0.13
+2024-03-29,0.07
+2024-03-30,0.05
+2024-03-31,0.09
+2024-04-01,0.15
Index: LoggerSetups.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from datetime import datetime, date, timedelta\r\n\r\nimport DBWriter\r\nimport Decagon\r\nimport GSheetCredentialSevice\r\nimport SQLScripts\r\nimport gSheetReader\r\nfrom CIMIS import CIMIS\r\nfrom CimisStation import CimisStation\r\nfrom Notifications import Notification_LoggerSetups\r\n\r\n\r\ndef setup_grower(grower: str, technician_name: str, email:str='', region:str=''):\r\n    \"\"\"\r\n    Function setups a new grower in the pickle\r\n    :param grower: name of grower\r\n    :param technician_name: name of technician\r\n    :param email: grower email\r\n    :param region: grower region\r\n    \"\"\"\r\n    print(\"Adding new grower to Pickle: \" + grower)\r\n    newGrower = Decagon.setup_grower(grower, technician_name, email, region=region)\r\n    # Decagon.addGrowerToGrowers(newGrower)\r\n\r\n\r\ndef setup_growers_fields_loggers_lists() -> tuple[list, list, list]:\r\n    \"\"\"\r\n    Function sets up a list of growers, fields, and active loggers in the current pickle\r\n    :return: Returns a grower list, field list, and active logger list\r\n    \"\"\"\r\n    grower_list = []\r\n    field_list = []\r\n    logger_list = []\r\n    growers = Decagon.open_pickle()\r\n    for grower in growers:\r\n        grower_list.append(grower.name)\r\n        for field in grower.fields:\r\n            field_list.append(field.name)\r\n            for logger in field.loggers:\r\n                if logger.active and field.active:\r\n                    logger_list.append(logger.id)\r\n    return grower_list, field_list, logger_list\r\n\r\ndef check_if_grower_in_list(grower_name:str, grower_list:list, technician:str, region:str) -> list:\r\n    \"\"\"\r\n    Checks to see if grower exists in the grower list, and if not it creates a new grower in the pickle\r\n    :param grower_name: Grower Name\r\n    :param grower_list: List of growers\r\n    :param technician: Assigned Technician\r\n    :param region: Grower Region\r\n    :return: Grower List\r\n    \"\"\"\r\n    if grower_name not in grower_list:\r\n        print(\"Did not find grower, setting up new grower\")\r\n        setup_grower(grower_name, technician, region=region)\r\n        grower_list.append(grower_name)\r\n    return grower_list\r\n\r\n\r\ndef add_logger_id_to_pickle(logger_id:str):\r\n    \"\"\"\r\n    Function adds a logger id to the logger id pickle\r\n    :param logger_id: Logger ID\r\n    \"\"\"\r\n    loggers = Decagon.open_pickle(filename=\"loggerList.pickle\")\r\n    loggers.append(logger_id)\r\n    Decagon.write_pickle(loggers, filename=\"loggerList.pickle\")\r\n\r\n\r\ndef remove_field(grower_target:str, field_target:str):\r\n    \"\"\"\r\n    Function removes a field from a grower\r\n    :param grower_target: Grower Name\r\n    :param field_target: Field Name\r\n    \"\"\"\r\n    growers = Decagon.open_pickle()\r\n    for grower in growers:\r\n        if grower.name == grower_target:\r\n            for field in grower.fields:\r\n                if field.name == field_target:\r\n                    print(f\"Removing Field: {field_target}\")\r\n                    for logger in field.loggers:\r\n                        remove_logger_id_from_pickle(logger.id)\r\n                Decagon.remove_field(grower_target, field_target, True)\r\n    # Decagon.deactivate_field(grower, field)\r\n\r\n    # Decagon.write_pickle(growers)\r\n\r\n\r\ndef deactivate_field(grower:str, field: str, uninstall_date:date):\r\n    \"\"\"\r\n    Function deactivates a field from a grower\r\n    :param grower: Grower Name\r\n    :param field: Field Name\r\n    :param uninstall_date: Uninstall Date\r\n    \"\"\"\r\n    growers = Decagon.open_pickle()\r\n    for g in growers:\r\n        if g.name == grower:\r\n            for f in g.fields:\r\n                if f.name == field:\r\n                    print(\"Removing Field: \" + field)\r\n                    for l in f.loggers:\r\n                        remove_logger_id_from_pickle(l.id)\r\n                        l.uninstall_date = uninstall_date\r\n    Decagon.write_pickle(growers)\r\n    Decagon.deactivate_field(grower, field)\r\n\r\n\r\n\r\ndef remove_logger_id_from_pickle(logger_id: str):\r\n    \"\"\"\r\n\r\n    :param logger_id: Logger ID\r\n    \"\"\"\r\n    loggers = Decagon.open_pickle(filename=\"loggerList.pickle\")\r\n    try:\r\n        loggers.remove(logger_id)\r\n        Decagon.write_pickle(loggers, filename=\"loggerList.pickle\")\r\n        print(\"Removed Logger from Logger ID List\")\r\n    except ValueError:\r\n        print(\"Could not find logger: \" + logger_id)\r\n\r\n\r\ndef remove_all_logger_id_from_pickle():\r\n    \"\"\"\r\n    Removes all logger ID's from a pickle file\r\n    \"\"\"\r\n    id_list = Decagon.open_pickle(filename=\"loggerList.pickle\")\r\n    for logger_id in id_list:\r\n        id_list.remove(logger_id)\r\n    Decagon.write_pickle(id_list, filename=\"loggerList.pickle\")\r\n\r\n\r\ndef show_logger_id_pickle():\r\n    \"\"\"\r\n    Show all the logger ID's from a pickle file\r\n    \"\"\"\r\n    logger = Decagon.open_pickle(filename=\"loggerList.pickle\")\r\n    for logger in logger:\r\n        print(logger)\r\n\r\n\r\ndef set_up_password_dict(service, logger_dict: dict, sheet_id: str) -> dict:\r\n    \"\"\"\r\n    Sets up dictionary of passwords that belong to each logger\r\n    :param service: G Sheet Service\r\n    :param logger_dict: Empty Logger Dictionary\r\n    :param sheet_id: G Sheet ID\r\n    :return: Returns Logger Dictionary with passwords\r\n    \"\"\"\r\n    range_name = \"Logger Passwords\"\r\n\r\n    result = gSheetReader.getServiceRead(range_name, sheet_id, service)\r\n\r\n    row_result = result['valueRanges'][0]['values']\r\n\r\n    for index, row in enumerate(row_result):\r\n        if index == 0:\r\n            continue\r\n        logger_id = row[0]\r\n        logger_id = logger_id.replace(' ', '')\r\n        logger_password = row[1]\r\n        logger_password = logger_password.replace(' ', '')\r\n        logger_id = logger_id.lower()\r\n\r\n        logger_dict[logger_id] = logger_password\r\n\r\n    # print(loggerDict)\r\n    return logger_dict\r\n\r\ndef find_password(logger_id: str, logger_dict: dict) -> str:\r\n    \"\"\"\r\n    Find password for a logger in the given logger dictionary\r\n    :param logger_id: Logger ID\r\n    :param logger_dict: Logger Dictionary\r\n    :return: Logger Password\r\n    \"\"\"\r\n    return logger_dict.get(logger_id)\r\n\r\ndef check_if_logger_has_been_added_to_field_prev(logger_id: str, field_name: str, grower_name: str) -> bool:\r\n    \"\"\"\r\n    Checks if logger has been added to a previous field\r\n    :param logger_id: Logger ID\r\n    :param field_name: Field Name\r\n    :param grower_name: Grower Name\r\n    :return: True if logger has been added to a field previously, else False\r\n    \"\"\"\r\n    growers = Decagon.open_pickle()\r\n    for grower in growers:\r\n        if grower.name == grower_name:\r\n            for field in grower.fields:\r\n                if field.name == field_name:\r\n                    for logger in field.loggers:\r\n                        if logger.id == logger_id:\r\n                            return True\r\n    return False\r\n\r\n\r\n\r\ndef add_logger_to_field(row, result, logger_num: str, logger_dict: dict, logger_list: list, grower_name: str, field_list: list, field_name_pickle: str, tab_id, field_name:str,\r\n                        additional_stations:bool):\r\n    \"\"\"\r\n\r\n    :param row:\r\n    :param result:\r\n    :param logger_num: The index of the logger\r\n    :param logger_dict: Dictionary of all known loggers and their passwords\r\n    :param logger_list: List of loggers\r\n    :param grower_name: Grower Name\r\n    :param field_list: List of fields\r\n    :param field_name_pickle: Field Name in Pickle File\r\n    :param tab_id:\r\n    :param field_name: Field Name\r\n    :param additional_stations: Boolean to know whether we are adding additional stations to a previous field\r\n    :return: None, only used if an error occurred and need to break out.\r\n    \"\"\"\r\n    # Assign Headers\r\n    crop_type_header = gSheetReader.getColumnHeader(\"Crop\", result)\r\n    planting_header = gSheetReader.getColumnHeader(\"Planting Date\", result)\r\n    field_type_header = gSheetReader.getColumnHeader(\"Field type\", result)\r\n    region_header = gSheetReader.getColumnHeader(\"North or South\", result)\r\n    logger_id_name_header = gSheetReader.getColumnHeader(\"Logger ID Logger \" + logger_num, result)\r\n    logger_name_header = gSheetReader.getColumnHeader(\"Logger Name Logger \" + logger_num, result)\r\n    soil_type_header = gSheetReader.getColumnHeader(\"Soil Type Logger \" + logger_num, result)\r\n    gpm_header = gSheetReader.getColumnHeader(\"Gallons Per Minute Logger \" + logger_num, result)\r\n    acres_header = gSheetReader.getColumnHeader(\"Acres Logger \" + logger_num, result)\r\n    lat_name_header = gSheetReader.getColumnHeader(\"Lat Logger \" + logger_num, result)\r\n    long_name_header = gSheetReader.getColumnHeader(\"Long Logger \" + logger_num, result)\r\n    total_acres_header = gSheetReader.getColumnHeader(\"Total Field Acres\", result)\r\n    install_header = gSheetReader.getColumnHeader(\"Install Date\", result)\r\n\r\n    # Assign Values\r\n    logger_id = row[logger_id_name_header]\r\n    logger_name = row[logger_name_header]\r\n    if logger_id == \"\" and logger_name == \"\":\r\n        return\r\n    elif logger_id == \"\" and logger_name:\r\n        print(\"Logger ID is blank for Logger: \" + logger_name)\r\n\r\n    # Removing blanks form Logger ID and Logger Name\r\n    logger_id = logger_id.replace(' ', '')\r\n    logger_name = logger_name.replace(' ', '')\r\n\r\n    # Should always add logger as long as it hasn't been added to the field previously\r\n    # This prevents a bug where logger gets added multiple times to the same field due to additional stations flag\r\n    should_add_logger = True\r\n    if additional_stations:\r\n        should_add_logger = not check_if_logger_has_been_added_to_field_prev(logger_id, field_name, grower_name)\r\n    soil_type = row[soil_type_header]\r\n    gpm = float(row[gpm_header])\r\n    acres = float(row[acres_header])\r\n    total_acres = float(row[total_acres_header])\r\n    planting_date = row[planting_header]\r\n    crop_type = row[crop_type_header]\r\n    field_type = row[field_type_header]\r\n    region = row[region_header]\r\n    install_date = row[install_header]\r\n    install_date_converted = datetime.strptime(install_date, '%m/%d/%Y').date()\r\n    logger_direction = logger_name.split('-')[-1]\r\n    if field_type == \"R&D\":\r\n        rnd = True\r\n    else:\r\n        rnd = False\r\n    lat = row[lat_name_header]\r\n    long = row[long_name_header]\r\n    field_id = \"\"\r\n    # Remove trailing blanks from field name\r\n    if field_name_pickle[-1] == ' ':\r\n        field_name_pickle = field_name_pickle.rstrip()\r\n\r\n    if (lat or long) == \"\":\r\n        print(\"Lat or Long is empty\")\r\n        return\r\n\r\n    planting_date_converted = datetime.strptime(planting_date, '%m/%d/%Y')\r\n\r\n    # Check that planting date is not from a previous year if dealing with tomatoes\r\n    if planting_date_converted.year < datetime.today().year and (crop_type == 'Tomatoes' or crop_type == 'tomatoes'\r\n                                                                 or crop_type == 'tomato' or crop_type == 'Tomato'):\r\n        print(f\"Error with planting date: Planting Date is from a previous year\")\r\n        planting_date_converted = planting_date_converted.replace(year=datetime.today().year)\r\n        planting_date = planting_date_converted.strftime('%m/%d/%Y')\r\n        print(f\"Planting Date Fixed: {planting_date}\")\r\n\r\n    # Check to see if field has been set up previously\r\n    if field_name_pickle not in field_list and logger_id not in logger_list and should_add_logger:\r\n        logger_id = logger_id.replace(' ', '')\r\n        logger_name = logger_name.replace(' ', '')\r\n        logger_password = find_password(logger_id, logger_dict)\r\n\r\n        # If logger password has been found, set up a new field and loggers\r\n        if logger_password:\r\n            print(\"Adding New \" + grower_name + \" Field: \" + field_name)\r\n            try:\r\n                # Get closest cimis station\r\n                print(\"\\tAttempting to get closest cimis station\")\r\n                cimis = CIMIS()\r\n                cimis_station = CimisStation()\r\n                inactive_cimis_station_list = cimis_station.return_inactive_cimis_stations_list()\r\n                closest_cimis_station = cimis.get_closest_cimis_station(float(lat), float(long), inactive_cimis_station_list)\r\n                if closest_cimis_station is None:\r\n                    print(\"ERROR with return from cimis.get_closest_cimis_station() - did not get closes cimis station\")\r\n                    return\r\n            except Exception as error:\r\n                print(f'\\tERROR in loggerSetups add_logger_to_field() when trying to get closest cimis station')\r\n                print(error)\r\n                print(\"\\t\\tLat: \" + lat)\r\n                print(\"\\t\\tLong: \" + long)\r\n                return\r\n\r\n            # Setup Field and Logger to Pickle\r\n            field = Decagon.setup_field(field_name_pickle, lat, long, closest_cimis_station, total_acres, crop_type, field_type=field_type)\r\n            logger = Decagon.setup_logger(logger_id, logger_password, logger_name, crop_type, soil_type, gpm, acres, logger_direction, lat, long,\r\n                                          install_date_converted, planting_date=planting_date, rnd=rnd)\r\n            field.add_logger(logger)\r\n            Decagon.add_field_to_grower(grower_name, field)\r\n            field_list.append(field_name_pickle)\r\n            add_logger_id_to_pickle(logger_id)\r\n            print(\"Added logger: \" + logger_id)\r\n        else:\r\n            print(\"\\tCouldn't find logger ID in password sheet\")\r\n\r\n    # Checks to see if logger has to be added to field, only if field has been set up previously\r\n    elif logger_id not in logger_list and should_add_logger:\r\n        logger_password = find_password(logger_id, logger_dict)\r\n\r\n        # If logger password has been found, set up new logger\r\n        if logger_password:\r\n            logger = Decagon.setup_logger(logger_id, logger_password, logger_name, crop_type, soil_type, gpm, acres, logger_direction, lat, long,\r\n                                          install_date_converted, planting_date=planting_date, rnd=rnd)\r\n            growers = Decagon.open_pickle()\r\n            print(\"\\tLogger is not in List\")\r\n            for grower in growers:\r\n                for field in grower.fields:\r\n                    if field.name == field_name_pickle and grower.name == grower_name:\r\n                        field.add_logger(logger)\r\n                        for logger in field.loggers:\r\n                            if logger.grower == None:\r\n                                logger.grower = grower\r\n                            if logger.field == None:\r\n                                logger.field = field\r\n                        print(\"\\t\\tAdded logger: \" + logger_id)\r\n                        add_logger_id_to_pickle(logger_id)\r\n            Decagon.write_pickle(growers)\r\n        else:\r\n            print(\"\\t\\tPassword does not match logger ID\")\r\n\r\n\r\ndef loop_through_loggers(field_name_pickle: str, grower_name: str, field_name: str, field_list: list, logger_list: list, row, result, logger_dict: dict, num_of_loggers: int, tab_id=\"\",\r\n                         add_stations: bool = False):\r\n    \"\"\"\r\n\r\n    :param field_name_pickle: Field Name in Pickle File\r\n    :param grower_name: Grower Name\r\n    :param field_name: Field Name\r\n    :param field_list: Field List\r\n    :param logger_list: Logger List\r\n    :param row: G Sheet logger row for current logger\r\n    :param result: G Sheet result that contains all logger rows\r\n    :param logger_dict: Dictionary of all known loggers and their passwords\r\n    :param num_of_loggers: Number of loggers in field\r\n    :param tab_id:\r\n    :param add_stations: Boolean to know whether we are adding additional stations to a previous field\r\n    \"\"\"\r\n    for logger_num in range(1, num_of_loggers + 1):\r\n        add_logger_to_field(row, result, str(logger_num), logger_dict, logger_list, grower_name, field_list, field_name_pickle, tab_id, field_name,\r\n                            add_stations)\r\n\r\n\r\ndef setup_field():\r\n    \"\"\"\r\n    Starts Logger Setup Process to setup loggers using the logger setup form Google sheet\r\n    \"\"\"\r\n\r\n    # Logger Setups Google Sheet ID\r\n    sheet_id = '1rsPrX44pCHOhbOHZfWubDkuuexP8pSG8kspW03FAqOU'\r\n    logger_dict = {}\r\n\r\n    # Logger Setups Tab Name\r\n    range_name = \"S-Logger Info\"\r\n\r\n    # Setups service to read google sheets\r\n    g_sheet = GSheetCredentialSevice.GSheetCredentialSevice()\r\n    service = g_sheet.getService()\r\n\r\n    # Set up logger dictionary with passwords\r\n    logger_dict = set_up_password_dict(service, logger_dict, sheet_id)\r\n\r\n    # Read Google Sheet\r\n    result = gSheetReader.getServiceRead(range_name, sheet_id, service)\r\n    row_result = result['valueRanges'][0]['values']\r\n\r\n    # Assign indexes to columns\r\n    grower_header = gSheetReader.getColumnHeader(\"Grower Name\", row_result)\r\n    field_name_header = gSheetReader.getColumnHeader(\"Grower Field\", row_result)\r\n    region_header = gSheetReader.getColumnHeader(\"North or South\", row_result)\r\n    technician_header = gSheetReader.getColumnHeader(\"Technician\", row_result)\r\n    email_header = gSheetReader.getColumnHeader(\"Grower Email\", row_result)\r\n    num_of_loggers_header = gSheetReader.getColumnHeader(\"Total Number of Loggers in Field\", row_result)\r\n    adding_additional_stations_header = gSheetReader.getColumnHeader(\"Are you adding stations to a previous field?\",\r\n                                                                     row_result)\r\n    planting_header = gSheetReader.getColumnHeader(\"Planting Date\", row_result)\r\n    install_header = gSheetReader.getColumnHeader(\"Install Date\", row_result)\r\n\r\n    # Setup grower, field, and logger lists\r\n    grower_list, field_list, logger_list = setup_growers_fields_loggers_lists()\r\n\r\n    # Loop through each logger in the Google sheet and set it up if it hasn't been set up before\r\n    for row_index, row in enumerate(row_result):\r\n        try:\r\n            # Ignore header row and empty rows\r\n            if row_index == 0:\r\n                continue\r\n            elif row[grower_header] == \"\":\r\n                continue\r\n\r\n            # Set up variables\r\n            grower_name = row[grower_header]\r\n            field_name = row[field_name_header].rstrip()\r\n            field_name_pickle = grower_name + field_name\r\n            region = row[region_header]\r\n            email = row[email_header]\r\n            technician = row[technician_header]\r\n            num_of_loggers = int(row[num_of_loggers_header])\r\n            additional_stations = row[adding_additional_stations_header]\r\n            planting_date = row[planting_header]\r\n            install_date = row[install_header]\r\n            planting_date_converted = datetime.strptime(planting_date, '%m/%d/%Y')\r\n            install_date_converted = datetime.strptime(install_date, '%m/%d/%Y')\r\n\r\n            # Check to make sure technician entered planting date correctly\r\n            if planting_date_converted > install_date_converted:\r\n                # Send Notification that field was setup incorrectly. Planting date is after install date\r\n                print(f\"Error Planting Date is after Install Date For Field: {field_name}\")\r\n                print(f\"\\tPlanting Date: {planting_date}; Install Date: {install_date}\")\r\n                growers = Decagon.open_pickle()\r\n                for grower in growers:\r\n                    if grower.name == grower_name:\r\n                        grower.technician.all_notifications.add_notification(\r\n                            Notification_LoggerSetups(\r\n                                datetime.now(),\r\n                                grower_name,\r\n                                field_name,\r\n                                issue=\"Planting Date is after Install Date\"\r\n                            )\r\n                        )\r\n                Decagon.write_pickle(growers)\r\n                continue\r\n\r\n            # Check to see if field has already been added before\r\n            if field_name_pickle not in field_list or additional_stations == 'Yes':\r\n                # If field has been added and this is an additional station, assign additional station flag\r\n                if additional_stations == 'Yes':\r\n                    print('Attempting to add additional stations')\r\n                    additional_stations_boolean = True\r\n\r\n                else:\r\n                    print(\"Field is not in pickle, setting up new field: \" + field_name_pickle)\r\n                    print(\"Checking to see if grower is in list\")\r\n                    grower_list = check_if_grower_in_list(grower_name, grower_list, technician, region=region)\r\n                    additional_stations_boolean = False\r\n\r\n                # Loop through each logger that is in the form for that specific field\r\n                loop_through_loggers(field_name_pickle, grower_name, field_name, field_list, logger_list, row, row_result, logger_dict,\r\n                                     num_of_loggers, add_stations=additional_stations_boolean)\r\n\r\n                # Sets up nickname for field\r\n                setup_nickname(field_name_pickle)\r\n\r\n                # Setup Irrigation Scheduling\r\n                if additional_stations == 'No':\r\n                    growers = Decagon.open_pickle()\r\n                    for grower in growers:\r\n                        for field in grower.fields:\r\n                            if field.name == field_name_pickle:\r\n                                print(\"Setting up Irrigation Scheduling for Field\")\r\n                                station_number = int(field.cimis_station)\r\n                                start_date = date(datetime.now().year - 1, 1, 1)\r\n                                end_date = date(datetime.now().year - 1, 12, 31)\r\n                                # Check to see if Irr. Scheduling has been set up already\r\n                                check_if_irr_scheduling_is_set_up(station_number, field, start_date, end_date, datetime.now().year)\r\n\r\n        except IndexError:\r\n            continue\r\n        except Exception as err:\r\n            print(err)\r\n            continue\r\n\r\n\r\ndef check_for_missing_report_or_preview_in_pickle():\r\n    \"\"\"\r\n    Sets up missing report preview links for the fields in the pickle\r\n    \"\"\"\r\n    # Old version of resetting notifications. Don't need anymore but will still be keeping it, just in case\r\n    notification_setup()\r\n\r\n    # Set up a list of missing report and preview fields\r\n    missing_report_preview_list = setup_missing_report_preview_list()\r\n\r\n    # G Sheet ID and tab\r\n    sheet_id = '1rsPrX44pCHOhbOHZfWubDkuuexP8pSG8kspW03FAqOU'\r\n    range_name = \"S-Logger Info\"\r\n\r\n    g_sheet = GSheetCredentialSevice.GSheetCredentialSevice()\r\n    service = g_sheet.getService()\r\n\r\n    # Grab Sheet Values form S-Logger Info\r\n    result = gSheetReader.getServiceRead(range_name, sheet_id, service)\r\n    row_result = result['valueRanges'][0]['values']\r\n\r\n    # Setup variables\r\n    field_name_header = gSheetReader.getColumnHeader(\"Grower Field\", row_result)\r\n    grower_header = gSheetReader.getColumnHeader(\"Grower Name\", row_result)\r\n    field_setup_done_header = gSheetReader.getColumnHeader(\"Field Setup Done\", row_result)\r\n    report_header = gSheetReader.getColumnHeader(\"Report\", row_result)\r\n    preview_header = gSheetReader.getColumnHeader(\"Preview\", row_result)\r\n\r\n    # Loop through Sheet values by row\r\n    for row, x in enumerate(row_result):\r\n        try:\r\n            if row == 0:\r\n                continue\r\n            elif x[grower_header] == \"\":\r\n                continue\r\n            grower_name = x[grower_header]\r\n            field_name = x[field_name_header]\r\n            field_name_pickle = grower_name + field_name\r\n            field_setup_done = x[field_setup_done_header]\r\n            if field_setup_done == \"TRUE\":\r\n                field_setup_done = True\r\n            else:\r\n                field_setup_done = False\r\n\r\n            field_name_pickle_cleaned_up = field_name_pickle.strip()\r\n\r\n            # Check to see if field has missing report or preview and has been flagged as done\r\n            if field_name_pickle_cleaned_up in missing_report_preview_list and field_setup_done:\r\n                report = x[report_header]\r\n                preview = x[preview_header]\r\n                # Update the field in the pickle with the correct report and preview values\r\n                update_report_and_image_in_pickle(field_name_pickle_cleaned_up, report, preview)\r\n                # Send notification that field is finished and ready to be shown to the grower\r\n                growers = Decagon.open_pickle()\r\n                for grower in growers:\r\n                    if grower.name == grower_name:\r\n                        grower.technician.all_notifications.add_notification(\r\n                            Notification_LoggerSetups(\r\n                                datetime.now(),\r\n                                grower_name,\r\n                                field_name,\r\n                                page_link=report\r\n                            )\r\n                        )\r\n                Decagon.write_pickle(growers)\r\n        except IndexError:\r\n            continue\r\n        except Exception as err:\r\n            print(err)\r\n            continue\r\n\r\n\r\ndef notification_setup():\r\n    \"\"\"\r\n\r\n    \"\"\"\r\n    growers = Decagon.open_pickle()\r\n    all_technicians = Decagon.get_all_technicians(growers)\r\n    Decagon.reset_notifications(all_technicians)\r\n    Decagon.notifications_setup(growers, all_technicians, file_type='html')\r\n    Decagon.write_pickle(growers)\r\n\r\n\r\ndef setup_missing_report_preview_list() -> list:\r\n    \"\"\"\r\n    Sets up list of fields that has the default report value\r\n    :return: List of fields that has the default report value\r\n    \"\"\"\r\n    missing_report_preview_list = []\r\n    growers = Decagon.open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            # If report is the default link then add to missing report and preview list\r\n            if field.report_url == 'https://i.imgur.com/04UdmBH.png' and field.active:\r\n                print('Found field without report url:', field.name)\r\n                missing_report_preview_list.append(field.name)\r\n    return missing_report_preview_list\r\n\r\n\r\ndef setup_nickname(field_name: str):\r\n    \"\"\"\r\n    Setups up field nickname as field name without grower name\r\n    :param field_name: Pickle Field Name\r\n    \"\"\"\r\n    growers = Decagon.open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            if field.name == field_name:\r\n                field.nickname = field.name.split(grower.name)[-1]\r\n    Decagon.write_pickle(growers)\r\n\r\n\r\ndef update_field(grower_name: str, field_name: str, only_one_logger:bool=False, logger_name:str=\"\", subtract_mrid:int=0, rerun:bool=False):\r\n    \"\"\"\r\n    Updates either the whole field or only a specific logger for the field\r\n    and resets previous day switch and removes duplicate data and updates ET at once\r\n    :param grower_name: Grower Name\r\n    :param field_name: Field Name\r\n    :param only_one_logger: Are you updating only one logger or the whole field?\r\n    :param logger_name: Logger Name\r\n    :param subtract_mrid: Subtract MRID value in case you want to go back days\r\n    :param rerun: Is this field being rerun again after the Default run?\r\n    \"\"\"\r\n    growers = Decagon.open_pickle()\r\n    # Set previous day switch to 0 for loggers that will be updated\r\n    for grower in growers:\r\n        if grower.name == grower_name:\r\n            for field in grower.fields:\r\n                if field.name == field_name:\r\n                    if only_one_logger:\r\n                        for logger in field.loggers:\r\n                            if logger_name == logger.name:\r\n                                if subtract_mrid > 0:\r\n                                    print(\"Setting previous day switch to zero\")\r\n                                    logger.prev_day_switch = 0\r\n                                    logger.crashed = False\r\n                                logger.updated = False\r\n                                Decagon.write_pickle(growers)\r\n                    else:\r\n                        for logger in field.loggers:\r\n                            logger.updated = False\r\n                            # If field is a rerun, need to clear previous day switch value to not mess up any summed totals\r\n                            if rerun:\r\n                                logger.prev_day_switch = 0\r\n                            # print(l.updated)\r\n                            Decagon.write_pickle(growers)\r\n\r\n    # Update field for one logger, and then delete duplicate date and update the logger ET value in the DB\r\n    if only_one_logger:\r\n        Decagon.only_certain_growers_field_logger_update(grower_name, field_name, logger_name,\r\n                                                         write_to_db=True, subtract_from_mrid=subtract_mrid)\r\n        for grower in growers:\r\n            if grower.name == grower_name:\r\n                for field in grower.fields:\r\n                    if field.name == field_name:\r\n                        for logger in field.loggers:\r\n                            if logger.name == logger_name:\r\n                                SQLScripts.remove_duplicate_data(logger)\r\n        SQLScripts.update_logger_et(field_name, logger_name)\r\n    else:\r\n    # Update all loggers in the field\r\n        Decagon.only_certain_growers_field_update(grower_name, field_name, get_et=False, get_weather=True, get_data=True,\r\n                                                  write_to_db=True)\r\n        for grower in growers:\r\n            if grower.name == grower_name:\r\n                for field in grower.fields:\r\n                    if field.name == field_name:\r\n                        for logger in field.loggers:\r\n                            SQLScripts.remove_duplicate_data(logger)\r\n        SQLScripts.update_field_et(field_name)\r\n\r\n\r\ndef col_to_letter(col):\r\n    \"\"\"Gets the letter of a column number, only works for letters A-Z\"\"\"\r\n    r = ''\r\n    v = col % 26\r\n    r = chr(v + 65)\r\n    return r\r\n\r\ndef check_if_irr_scheduling_is_set_up(et_station: int, field, start_date: date, end_date: date, year: int, perennial:bool = False):\r\n    \"\"\"\r\n    Function Checks Datasets to see if Irrigation Scheduling table has already been set up. If it's a perennial, then we want to reprocess irr.\r\n    scheduling table so we want to set the value as True.\r\n\r\n    :param et_station: ET station number\r\n    :param field: Field Object from pickle\r\n    :param start_date: start date / usually start of last year\r\n    :param end_date: end date / usually end of last year\r\n    :param year: year we will be processing\r\n    :param perennial: Check to see whether to reprocess irr scheduling for perennial crops\r\n    \"\"\"\r\n    tableFound = False\r\n    datasetFound = True\r\n    db = DBWriter.DBWriter()\r\n    field_Name = db.remove_unwanted_chars_for_db_dataset(field.name)\r\n    dataset = field_Name + \"_Irr_Scheduling\"\r\n    project = db.get_db_project(field.loggers[-1].crop_type)\r\n    tables = db.get_tables(field_Name, project=project)\r\n    try:\r\n        # Check to see if we received a response from getting the field dataset tables. If we error out, then the dataset does not exist.\r\n        for table in tables:\r\n            # If we received a response, the dataset exists so we have to loop through all tables to see if Irr. Scheduling exists\r\n            datasetFound = True\r\n            # Check if Irr. Scheduling Table already exists\r\n            if table.table_id ==  dataset and not perennial:\r\n                # print(\"Table Found\")\r\n                # print(table.table_id)\r\n                print('\\tFound Irr. Scheduling For Field')\r\n                print('\\t', table.table_id)\r\n                tableFound = True\r\n            # If processing for a perennial, we want to redo irr. scheduling since it changes every new year.\r\n            elif table.table_id == dataset and perennial:\r\n                print(f'\\tReprocessing Irr. Scheduling For Field:{table.table_id}')\r\n                tableFound = False\r\n    # Dataset does not exist\r\n    except Exception as Error:\r\n        print(Error)\r\n        datasetFound = False\r\n\r\n\r\n    try:\r\n        # Create dataset if it does not exist\r\n        if not datasetFound:\r\n            print(\"Dataset does not exist \\n\\tCreating Dataset\")\r\n            db.create_dataset(field_Name, project)\r\n\r\n        # Create table if Irr. Scheduling does not exist\r\n        if not tableFound:\r\n            print(\"\\tDidn't Find Irr Scheduling Table\")\r\n            print(\"\\t\\tFirst checking to see if historical table is in database\")\r\n            et_table_found = SQLScripts.return_if_et_table_found(et_station)\r\n            # Irr. Scheduling needs a Historical ET table to reference when creating the table\r\n            if et_table_found:\r\n                print(\"\\t\\tFound ET Table, Setting up Irr. Scheduling\")\r\n                SQLScripts.setupIrrigationSchedulingDB(et_station, field.name, start_date, end_date, year)\r\n            # Create Historical ET table if it does not exist\r\n            else:\r\n                print(\"\\t\\tHistorical ET Table Not Found \\n\\t\\t\\tCreating Table\")\r\n                # Grab_historical_data should create a new historical et table but it is not dynamic. Right now it creates it from years 2018 - 2022\r\n                # SQLScripts.grab_historical_data(et_station, newStation=True)\r\n                SQLScripts.setupIrrigationSchedulingDB(et_station, field.name, start_date, end_date, year)\r\n\r\n    except Exception as err:\r\n        print(\"\\tField Name Incorrect Or Not In Database\")\r\n        print(err)\r\n\r\n\r\ndef update_historical_et_for_perennials():\r\n    \"\"\"\r\n    Update Irrigation Scheduling Tables for Perennial Crops\r\n    \"\"\"\r\n    growers = Decagon.open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            if (field.crop_type.lower() == \"almonds\" or field.crop_type.lower() == \"almond\"\r\n                    or field.crop_type.lower() == \"pistachios\" or field.crop_type.lower() == \"pistachio\"):\r\n                station_number = int(field.cimis_station)\r\n                #Previous year start and end date\r\n                start_date = date(datetime.now().year - 1, 1, 1)\r\n                end_date = date(datetime.now().year - 1, 12, 31)\r\n                check_if_irr_scheduling_is_set_up(station_number, field, start_date, end_date, datetime.now().year, perennial=True)\r\n\r\n\r\ndef update_report_and_image_in_pickle(field_name_pickle, report, portal_image):\r\n    \"\"\"\r\n\r\n    :param field_name_pickle:\r\n    :param report:\r\n    :param portal_image:\r\n    \"\"\"\r\n    growers = Decagon.open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            if field.name == field_name_pickle:\r\n                field.report_url = report\r\n                field.preview_url = portal_image\r\n                print('Updated ', field_name_pickle)\r\n                print('\\tReport URL', report)\r\n                print('\\tPortal Image', portal_image)\r\n                print()\r\n    Decagon.write_pickle(growers)\r\n\r\n\r\ndef update_missing_data_yesterday():\r\n    \"\"\"\r\n    Updates any fields with missing data for yesterday\r\n    \"\"\"\r\n    dbwriter = DBWriter.DBWriter()\r\n    growers = Decagon.open_pickle()\r\n    today = datetime.today()\r\n    yesterday = today - timedelta(days=1)\r\n    # Loop through pickle checking active fields to see if they updated yesterday\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            if field.active:\r\n                field_name = dbwriter.remove_unwanted_chars_for_db_dataset(field.name)\r\n                print(\"Working on Field: \", field.name)\r\n                for logger in field.loggers:\r\n                    print('\\t Working on Logger: ', logger.name)\r\n                    updated = False\r\n                    # Check to see if data updated yesterday for the logger\r\n                    print(\"\\t\\tChecking Date to see if yesterday updated\")\r\n                    project = dbwriter.get_db_project(logger.crop_type)\r\n                    dataset_id = project + \".\" + field_name + \".\" + logger.name\r\n                    dml_statement = \"select date from`\" + dataset_id + \"` order by date\"\r\n                    result = dbwriter.run_dml(dml_statement, project=project)\r\n                    for r in result:\r\n                        if str(r[0]) == str(yesterday.date()):\r\n                            # print(\"Field Updated\")\r\n                            updated = True\r\n                    # If the data wasn't updated for the logger, then update the logger\r\n                    if not updated:\r\n                        print(\"\\t\\t\\tField did not update: \", field.name, \"\\n Logger: \", logger.name)\r\n                        print(\"\\t\\t\\tUpdating Field\")\r\n                        update_field(grower.name, field.name, True, logger.name, subtract_mrid=24)\r\n\r\n\r\ndef return_active_fields(region:str=\"Both\")->list:\r\n    \"\"\"\r\n    Return active fields for a specific region or both regions\r\n    :param region: Default value is \"Both\", but can be \"North\" or \"South\"\r\n    :return: Returns a list of fields that are active and belong to the given region\r\n    \"\"\"\r\n    field_list = []\r\n    growers = Decagon.open_pickle()\r\n\r\n    for grower in growers:\r\n        if region == \"Both\":\r\n            for field in grower.fields:\r\n                if field.active:\r\n                    field_list.append(field.name)\r\n        else:\r\n            if grower.region == region:\r\n                for field in grower.fields:\r\n                    if field.active:\r\n                        field_list.append(field.name)\r\n    return field_list\r\n\r\n\r\ndef check_for_new_cimis_stations():\r\n    \"\"\"\r\n    Check to see if any new cimis stations has been added to the pickle\r\n    \"\"\"\r\n    cimisStation = CimisStation()\r\n    stomato_pickle = Decagon.open_pickle()\r\n    cimisStation.check_for_new_cimis_stations(stomato_pickle=stomato_pickle)\r\n\r\n\r\ndef replace_logger(old_logger_id:str, new_logger_id:str, old_logger_name:str, new_logger_password:str, swap_date:date)->bool:\r\n    \"\"\"\r\n    Function sets up a new logger using the information of the old logger\r\n    :param old_logger_id: Old Logger ID\r\n    :param new_logger_id: New Logger ID\r\n    :param old_logger_name: Old Logger Name\r\n    :param new_logger_password: New Logger Password\r\n    :param swap_date: Date logger swap occurred\r\n    :return: Was logger swapped successfully? True or False\r\n    \"\"\"\r\n    logger_added_successfully = False\r\n    logger_information_saved = False\r\n    growers = Decagon.open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            for logger in field.loggers:\r\n                # Set up old logger as broken and store old information to set up new logger with\r\n                if old_logger_id == logger.id and old_logger_name == logger.name:\r\n                    logger.broken = True\r\n                    logger.active = False\r\n                    logger.uninstall_date = swap_date\r\n                    crop_type = logger.crop_type\r\n                    soil_type = logger.soil.soil_type\r\n                    gpm = logger.gpm\r\n                    irrigation_acres = logger.irrigation_set_acres\r\n                    logger_direction = logger.logger_direction\r\n                    lat = logger.lat\r\n                    long = logger.long\r\n                    planting_date = logger.planting_date\r\n                    rnd = logger.rnd\r\n                    field_name = field.name\r\n                    logger_information_saved = True\r\n\r\n    Decagon.write_pickle(growers)\r\n\r\n    # Add new logger using old logger information\r\n    if logger_information_saved:\r\n        new_logger = Decagon.setup_logger(new_logger_id, new_logger_password, old_logger_name, crop_type, soil_type,\r\n                                          gpm, irrigation_acres, logger_direction, lat, long,\r\n                                          swap_date, planting_date=planting_date, rnd=rnd)\r\n        logger_added_successfully = True\r\n\r\n        growers = Decagon.open_pickle()\r\n        print(\"Logger is not in List\")\r\n        for grower in growers:\r\n            for field in grower.fields:\r\n                if field_name == field.name:\r\n                    field.add_logger(new_logger)\r\n                    for logger in field.loggers:\r\n                        if logger.grower == None:\r\n                            logger.grower = grower\r\n                        if logger.field == None:\r\n                            logger.field = field\r\n                    print(\"\\tAdded logger: \" + new_logger_id)\r\n                    # Add new logger id to pickle of logger ID's in the pickle\r\n                    add_logger_id_to_pickle(new_logger_id)\r\n        Decagon.write_pickle(growers)\r\n\r\n    return logger_added_successfully\r\n\r\n\r\ndef check_for_broken_loggers():\r\n    \"\"\"\r\n    Checks to see if there are any new submissions for broken loggers\r\n    \"\"\"\r\n    # G Sheet ID and tab name\r\n    sheet_id = '1rsPrX44pCHOhbOHZfWubDkuuexP8pSG8kspW03FAqOU'\r\n    logger_dict = {}\r\n\r\n    range_name = \"Logger Swap Form\"\r\n\r\n    g_sheet = GSheetCredentialSevice.GSheetCredentialSevice()\r\n\r\n    service = g_sheet.getService()\r\n\r\n    set_up_password_dict(service, logger_dict, sheet_id)\r\n\r\n    result = gSheetReader.getServiceRead(range_name, sheet_id, service)\r\n    row_result = result['valueRanges'][0]['values']\r\n\r\n    # Assign indexes to columns\r\n    # technician_header = gSheetReader.getColumnHeader(\"Technician Name\", row_result)\r\n    old_logger_id_header = gSheetReader.getColumnHeader(\"Old Logger ID\", row_result)\r\n    new_logger_id_header = gSheetReader.getColumnHeader(\"New Logger ID\", row_result)\r\n    old_logger_name_header = gSheetReader.getColumnHeader(\"Old Logger Name\", row_result)\r\n    date_swapped_header = gSheetReader.getColumnHeader(\"Date Swap Occurred\", row_result)\r\n    backed_swap_done_header = gSheetReader.getColumnHeader(\"Backend Swap Done\", row_result)\r\n    timestamp_header = gSheetReader.getColumnHeader(\"Timestamp\", row_result)\r\n\r\n    # Loop through each row\r\n    for row_index, row in enumerate(row_result):\r\n        try:\r\n            if row_index == 0:\r\n                continue\r\n            elif row[timestamp_header] == \"\":\r\n                continue\r\n            # Read information technician submitted\r\n            # technician = row[technician_header]\r\n            old_logger_id = row[old_logger_id_header]\r\n            new_logger_id = row[new_logger_id_header]\r\n            backed_swap_done = row[backed_swap_done_header]\r\n            old_logger_name = row[old_logger_name_header]\r\n            date_swapped = row[date_swapped_header]\r\n            date_swapped_converted = datetime.strptime(date_swapped, '%m/%d/%Y').date()\r\n\r\n            # Check swap flag to see if we have already completed the swap before\r\n            if backed_swap_done == 'FALSE':\r\n                backed_swap_done = False\r\n            if not backed_swap_done:\r\n                # Replace logger\r\n                replaced_logger_successfully = replace_logger(old_logger_id, new_logger_id, old_logger_name, logger_dict[new_logger_id],\r\n                                                              date_swapped_converted)\r\n\r\n                # If logger was replaced update swap flag on G Sheet\r\n                if replaced_logger_successfully:\r\n                    target_cell = f'{range_name}!G{row_index + 1}'\r\n                    # print(target_cell)\r\n                    gSheetReader.write_target_cell(target_cell, True, sheet_id, service)\r\n                    print(\"Logger Replaced Successfully\")\r\n\r\n\r\n        except IndexError:\r\n            continue\r\n\r\n        except Exception as err:\r\n            print(err)\r\n            continue\r\n\r\n\r\ndef change_psi_for_specific_field_logger(field_name: str, logger_name: str, should_be_on: bool = False):\r\n    \"\"\"\r\n    Turns on PSI for a specific logger in a specific field\r\n    :param should_be_on: Should PSI be on or off\r\n    :param field_name: Name of field\r\n    :param logger_name: Name of logger\r\n    :return:\r\n    \"\"\"\r\n    growers = Decagon.open_pickle()\r\n    for grower in growers:\r\n        for field in grower.fields:\r\n            if field.name == field_name:\r\n                for logger in field.loggers:\r\n                    if logger.name == logger_name:\r\n                        if should_be_on:\r\n                            logger.ir_active = True\r\n                            print(f\"Turned on PSI for {field.name}:{logger_name}\")\r\n                        else:\r\n                            logger.ir_active = False\r\n                            print(f\"Turned off PSI for {field.name}:{logger_name}\")\r\n    Decagon.write_pickle(growers)\r\n\r\n\r\n# setup_field()\r\n\r\n# addLoggerIDToPickle('z6-07262')\r\n# setup_uninstallation_dates_2022()\r\n# setup_installation_dates_2022()\r\n# print(returnActiveFields(\"North\"))\r\n# update_field(\"CM Ochoa\", \"CMOchoaL36\")\r\n# Decagon.only_certain_growers_field_update(\"CM Ochoa\", \"CM OchoaL36\", True, True, True, True, False)\r\n# check_for_new_cimis_stations()\r\n# check_for_broken_loggers()\r\n# Decagon.show_pickle()\r\n# setup_field()\r\n# update_historical_et_for_perennials()\r\n\r\n# growers = Decagon.open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         logger_id_list = []\r\n#         for ind, logger in enumerate(field.loggers):\r\n#             if logger.id in logger_id_list:\r\n#                 print(f\"Duplicate Detected: {field.name}:{logger.name}\")\r\n#                 print(f\"{logger.id}:{ind}\")\r\n#                 del field.loggers[ind]\r\n#             logger_id_list.append(logger.id)\r\n# Decagon.write_pickle(growers)\r\n\r\n# change_psi_for_specific_field_logger(\"Lucero Rio VistaB 1-4, 8\", \"LR-148-NW\", should_be_on=True)\r\n# change_psi_for_specific_field_logger(\"Lucero Rio VistaB 1-4, 8\", \"LR-148-S\", should_be_on=True)\r\n# change_psi_for_specific_field_logger(\"JJB FarmsGI 17\", \"GI-17-C\", should_be_on=True)\r\n# change_psi_for_specific_field_logger(\"Lucero Stokes Tyler Island11, 12, 28\", \"LS-12-C\", should_be_on=True)\r\n# change_psi_for_specific_field_logger(\"Lucero Thornton StokesStokes 1/2\", \"LU-Stokes1-NW\", should_be_on=True)\r\n\r\n# change_psi_for_specific_field_logger(\"Matteoli BrothersN3\", \"MB-N3-S\", should_be_on=True)\r\n# change_psi_for_specific_field_logger(\"Matteoli BrothersN3\", \"MB-N3-N\", should_be_on=True)\r\n# change_psi_for_specific_field_logger(\"Lucero BakersfieldHeadquarters\", \"LB-Blue-W\")\r\n# change_psi_for_specific_field_logger(\"Lucero BakersfieldHeadquarters\", \"LB-Green-S\")\r\n# print(returnActiveFields())\r\n# check_for_missing_report_or_preview_in_pickle()\r\n# SQLScripts.delete_last_day('stomato-permanents', 'Andrew3106', 'AN-3106-C')\r\n# read_harvesting_dates()\r\n# removeField('Lucero Rio Vista','Lucero Rio Vista4')\r\n# updateField('Lucero Rio Vista', 'Lucero Rio Vista3', True, 'RV-03-N')\r\n# update_field('Andrew', 'Andrew3106', True, 'AN-3106-C', 24 * 3)\r\n# Decagon.show_pickle()\r\n# removeField('Lucero Rio Vista','Lucero Rio Vista2')\r\n# remove_field('Dougherty Bros', 'Dougherty BrosKRE')\r\n# remove_field('Rincon Farms Inc.', 'Rincon Farms Inc.2N, 2M, 2S')\r\n# remove_field('Lucero Mandeville', 'Lucero Mandeville5')\r\n# remove_field('Lucero Watermark', 'Lucero Watermark5, 6, 7')\r\n# remove_field('Muller Ag', 'Muller Ag219')\r\n# remove_field('Lucero Goosepond', 'Lucero Goosepondsepond3')\r\n# remove_field('Lucero Goosepond', 'Lucero Goosepond2')\r\n# remove_field('Lucero Goosepond', 'Lucero Goosepond1')\r\n# remove_logger_id_from_pickle('z6-11580')\r\n# SQLScripts.removeDuplicateET()\r\n# SQLScripts.deleteETDay('Matteoli BrothersK7', '2022-07-25', '2022-08-11')\r\n# SQLScripts.update_field_et('KTN JVYA1')\r\n# Decagon.remove_grower('Rincon Farms Inc.')\r\n# setup_field()\r\n# test_bug('Bone Farms LLCR12-13')\r\n# check_for_new_cimis_stations()\r\n# growers = Decagon.open_pickle()\r\n# for grower in growers:\r\n#     for field in grower.fields:\r\n#         if grower.name == 'Bone Farms LLC':\r\n#             for logger in field.loggers:\r\n#                 print(f\"{field.name}:{logger.name}:{logger.uninstall_date}\")\r\n#             field.cimis_station = '148'\r\n            # for logger in field.loggers:\r\n                # if logger.active:\r\n                    # if logger.name == 'LM-5DEF-E':\r\n#                         update_field(grower_name=grower.name, field_name=field.name, only_one_logger=True, logger_name=logger.name,\r\n#                                      subtract_mrid=24*0, rerun=False)\r\n# #                     # SQLScripts.remove_duplicate_data(logger)\r\n# #                     # result = logger.read_dxd()\r\n# #                     # print(result)\r\n# #                 # print(field.name)\r\n# #                 # logger.ir_active = True\r\n# #                 print(f\"{field.name} \\n\\t {logger.name} \\n\\t\\t {logger.ir_active}\")\r\n# Decagon.write_pickle(growers)\r\n\r\n# check_for_missing_report_or_preview_in_pickle()\r\n\r\n# Decagon.show_pickle()\r\n# update_field(\"Bone FarmsLLC\", \"Bone Farms LLCR12-13\")\r\n# updateField(\"Carvalho\", \"Carvalho316\", True, 'CA-316-NW', subtractMRID=24)\r\n# updateField(\"Carvalho\", \"Carvalho308\", True, 'CA-308-SW', subtractMRID=24)\r\n# updateField(\"Hughes\", \"Hughes301\", True, 'HU-301-NW', subtractMRID=24)\r\n# updateField(\"Hughes\", \"Hughes301\", True, 'HU-301-SE', subtractMRID=24)\r\n# updateField(\"Hughes\", \"Hughes303-4\", True, 'JH-303_4-NW', subtractMRID=24)\r\n# updateField(\"Hughes\", \"Hughes303-4\", True, 'JH-303_4-SE', subtractMRID=24)\r\n# update_field('Bone Farms LLC', 'Bone Farms LLCF6', True, 'BO-PI-NW', subtract_mrid=24*10, rerun=True)\r\n\r\n# update_field('Bone Farms LLC', 'Bone Farms LLCN42 N43', True, 'BF-N4243-NE', subtract_mrid=0, rerun=True)\r\n# update_field()\r\n# growers = Decagon.open_pickle()\r\n# for grower in growers:\r\n#     # print(grower.name)\r\n#     # if grower.name == 'Knight Farms':\r\n#     for field in grower.fields:\r\n#         if not hasattr(field, 'crop_type'):\r\n#             print(field.name)\r\n            # field.crop_type = field.loggers[0].crop_type\r\n            # print('\\t', field.crop_type)\r\n        # if field.crop_type == 'Pistachio' or field.crop_type == 'Pistachios':\r\n        #     print(field.name)\r\n        # if field.name == 'Bullseye FarmsOE10' or field.name == 'Matteoli Brothers42' or field.name == 'CM OchoaA11N':\r\n        #     for logger in field.loggers:\r\n                # logger.soil.set_soil_type('Clay')\r\n                # print(logger.name)\r\n                # print(logger.soil.field_capacity)\r\n                # print(logger.soil.wilting_point)\r\n#                 print(f\"{field.acres}: {type(field.acres)}\")\r\n                # field.acres = 113.0\r\n# Decagon.write_pickle(growers)\r\n#                 for logger in field.loggers:\r\n#                     if logger.name == 'BO-PI-NW':\r\n#                         SQLScripts.remove_duplicate_data(logger)\r\n# remove_field('OPC', 'OPC5-4')\r\n# Decagon.only_certain_growers_field_update('T&P', 'T&PCO4', False, True, True, True, True, False)\r\n# growers = Decagon.open_pickle()\r\n# # # # testBug('Lucero Watermark9')\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if f.active and f.name == 'Meza':\r\n#             print(f\"{f.name} : {f.cimisStation}\")\r\n#             f.cimisStation = '124'\r\n#             print(f.cimisStation)\r\n# Decagon.write_pickle(growers)\r\n# for l in f.loggers:\r\n# if l.name == 'TAG-WM-SE':\r\n#                 print(l.active)\r\n#             if l.id == 'z6-11556':\r\n#                 print(f.name, \", \", f.id, \", \", l.name, \", \", f.active)\r\n#             print(g.region, ';', g.name, ';', f.nickname)\r\n#\r\n#         if f.name == 'Lucero SE Honkerlake04':\r\n#             SQLScripts.deleteETDay(f.name, '2022-08-29', '2022-09-05')\r\n#         if f.name == \"Lucero Rio Vista3\":\r\n#             for l in f.loggers:\r\n#                 if l.id == 'z6-03544':\r\n#                     l.id = 'z6-12396'\r\n#                     l.password = '84372-16909'\r\n#             print(type(f.cimisStation))\r\n#             for l in f.loggers:\r\n#                 # print(type(l.gpm))\r\n#                 # l.gpm = float(1400)\r\n#                 print(l.gpm)\r\n#     g.technician.logger_setup_notification_file_path = ''\r\n# Decagon.write_pickle(growers)\r\n# techs = Decagon.get_all_technicians(growers)\r\n# for t in techs:\r\n#     print(t)\r\n# t.logger_setup_notification_file_path = ''\r\n# print(t.logger_setup_notification_file_path)\r\n# Decagon.write_pickle(growers)\r\n# uninstallField('OPC', 'OPC3-3')\r\n# SQLScripts.removeDuplicateET()\r\n# SQLScripts.update_field_et('Lucero Watermark9')\r\n# growers = Decagon.open_pickle()\r\n# toma = TomatoKC.TomatoKC()\r\n# # dates = ['2022-07-21', '2022-07-22', '2022-07-23', '2022-07-24', '2022-07-25', '2022-07-26', '2022-07-27', '2022-07-28', '2022-07-29',\r\n# # '2022-07-30', '2022-07-31', '2022-08-01']\r\n# base = datetime.datetime.today() - datetime.timedelta(days=1)\r\n# date_list = [(base - datetime.timedelta(days=x)).date() for x in range(12)]\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if f.name == 'Lucero SE Honkerlake04':\r\n#             # SQLScripts.update_field_et(f.name)\r\n#             for d in date_list:\r\n#                 kc = TomatoKC.TomatoKC.get_kc(toma, f.loggers[-1].planting_date, d)\r\n#                 SQLScripts.deleteNegativeET(f.name, d.strftime('%Y-%m-%d'), str(kc))\r\n#             # SQLScripts.deleteETDay(f.name, date_list[-1].strftime('%Y-%m-%d'))\r\n#             SQLScripts.update_field_et(f.name)\r\n\r\n#             testBug(f.name)\r\n\r\n#             for l in f.loggers:\r\n#                 removeLoggerIDFromPickle(l.id)\r\n#                 if l.id == 'z6-07113':\r\n#                     l.prev_day_switch = 240\r\n# Decagon.write_pickle(growers)\r\n#         try:\r\n#             print(\"Setting up Irrigation Scheduling for Field\")\r\n#             stationNumber = int(f.cimisStation)\r\n#             startDate = date(datetime.now().year - 1, 1, 1)\r\n#             endDate = date(datetime.now().year - 1, 12, 31)\r\n#             SQLScripts.setupIrrigationSchedulingDB(stationNumber, f.name, startDate, endDate,\r\n#                                                    datetime.now().year)\r\n#         except Exception as err:\r\n#             print(err)\r\n#             continue\r\n# check_for_missing_report_or_preview_in_pickle()\r\n# addLoggerIDToPickle('z6-11518')\r\n# removeField('Bullseye Farms', 'Bullseye FarmsYO2E East')\r\n# removeField('RnD', 'RnDRate Trial')\r\n# Decagon.removeGrower('Maricopa Orchards')\r\n# update_report_and_image_in_pickle('Dougherty BrosHB',\r\n#                                   'https://datastudio.google.com/reporting/81d4de96-c5d1-4629-b143-7c7324f05d6d',\r\n#                                   'https://i.imgur.com/q35zn9z.png')\r\n# setup_field()\r\n# check_for_new_cimis_stations()\r\n# Decagon.show_pickle()\r\n# SQLScripts.removeDuplicateET()\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if f.name == \"Bullseye FarmsYO2E\":\r\n#             for logger in f.loggers:\r\n#                 update_field(g.name, f.name, True, logger.name, subtract_mrid=19*24)\r\n\r\n#             for l in f.loggers:\r\n#                 if l.id == 'z6-11532':\r\n#                     l.crashed = False\r\n#             for l in f.loggers:\r\n#                 l.prev_day_switch = 0\r\n#             f.preview_url = 'https://i.imgur.com/AXjQrAw.png'\r\n#             for l in f.loggers:\r\n#                 if l.id == 'z6-11959':\r\n#                     l.id = 'z6-01882'\r\n#                     l.password = '36070-33974'\r\n# Decagon.write_pickle(growers)\r\n# updateField('Lucero Rio Vista', 'Lucero Rio Vista3', True, 'RV-03-N', subtractMRID=0)\r\n# if os.path.exists('C:\\\\Users\\\\javie\\\\Projects\\\\S-TOMAto\\\\credentials.json'):\r\n#     os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/javie/Projects/S-TOMAto/credentials.json\"\r\n# elif os.path.exists('C:\\\\Users\\\\javie\\\\PycharmProjects\\\\Stomato\\\\credentials.json'):\r\n#     os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/javie/PycharmProjects/Stomato/credentials.json\"\r\n# elif os.path.exists('C:\\\\Users\\\\jsalcedo\\\\PycharmProjects\\\\Stomato\\\\credentials.json'):\r\n#     os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/jsalcedo/PycharmProjects/Stomato/credentials.json\"\r\n# elif os.path.exists('C:\\\\Users\\\\jesus\\\\PycharmProjects\\\\Stomato\\\\credentials.json'):\r\n#     os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/jesus/PycharmProjects/Stomato/credentials.json\"\r\n#\r\n# updateField(\"Bullseye Farms\", \"Bullseye FarmsRG28\", True, \"Bull-RG28-NW\", subtractMRID=60)\r\n# SQLScripts.update_field_et('Maricopa Orchards1831')\r\n# removeField('F&S', 'F&SVerway FB 1, 8')\r\n# checkIfIrrSchedulingIsSetUp(\"Andrew3125\")\r\n# Decagon.show_pickle()\r\n# updateField(\"Fantozzi\", \"Fantozzi2_7 East\", True, \"DAT-NE\", subtractMRID=0)\r\n# uninstallField('Tim Kalfsbeek', 'Tim KalfsbeekBack 40 Farm')\r\n# updateGpmAcres()\r\n# updateRndLoggers()\r\n# Decagon.show_pickle()\r\n\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         # if f.name == \"KTN JVYA1\":\r\n#         if f.active:\r\n#             # if f.name == 'Barrios Farms84':\r\n#             #     f.preview_url = 'https://i.imgur.com/PfzkMVe.png'\r\n#             print(f.name)\r\n#             print(\"\\t\"+f.preview_url)\r\n#             print(\"\\t\"+f.report_url)\r\n#             SQLScripts.update_portal_image(g, f, f.preview_url)\r\n#                 for l in f.loggers:\r\n#                     if l.name == 'BF-84-NE':\r\n#                         # l.id = 'z6-11518'\r\n#                         # l.password = '51428-59165'\r\n#                         print(l.id)\r\n#                         print(l.password)\r\n\r\n\r\n# if g.name == 'CM Ochoa':\r\n#     for l in f.loggers:\r\n#         if l.name == 'CM-L37WM-N' or l.name == 'CM-L37WM2-S' or l.name == 'CM-L35WM-N' or l.name == 'CM-L35WM2-S':\r\n#             print(l.name)\r\n#             l.active = False\r\n#             print('\\t' + str(l.active))\r\n# print(l.active)\r\n# f.cwsi_processor = CwsiProcessor.CwsiProcessor()\r\n# print('done')\r\n# if f.name == 'Dougherty BrosPC':\r\n# f.report_url = 'https://datastudio.google.com/reporting/29513a03-37e1-4873-85e0-17c1bcd2b636'\r\n# f.preview_url = 'https://i.imgur.com/0kQGrxZ.png'\r\n#             print(f.active)\r\n#             f.active = False\r\n#             print(f.active)\r\n#         print(f.name)\r\n# Decagon.write_pickle(growers)\r\n# if g.name == 'Hughes':\r\n# report = input(\"Please input portal report for field: \" + f.name + \"\\n\")\r\n# preview = input(\"Please input portal preview for field: \" + f.name + \"\\n\")\r\n# f.report_url = report\r\n# f.preview_url = preview\r\n# print(f.report_url)\r\n# print(f.preview_url)\r\n#     if newNickname == \"\":\r\n#         print(\"Keeping nickname the same\")\r\n#     else:\r\n#         print(\"Changing nickname to : \" + newNickname)\r\n#         f.nickname = newNickname\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n# if g.name == 'Carvalho':\r\n#     f.nickname = input(\"Enter Nickname for Carvalho Field: \" + f.name + \"\\n\")\r\n# f.nickname = f.name.split(g.name)[-1]\r\n# print(f.nickname)\r\n# Decagon.write_pickle(growers)\r\n\r\n# Decagon.removeGrower('Jesus')\r\n# Decagon.remove_field(\"Fantozzi\", \"Fantozzi2_7 East\")\r\n# removeLoggerIDFromPickle(\"z6-07262\")\r\n# removeLoggerIDFromPickle(\"z6-07264\")\r\n# removeLoggerIDFromPickle(\"z6-12337\")\r\n\r\n# setupField()\r\n# showLoggerIDPickle()\r\n# testBug(\"Bone Farms LLCF7\")\r\n# Decagon.show_pickle()\r\n# fieldName = 'Carvalho315'\r\n# loggerName = ''\r\n# fc = 36\r\n# wp = 22\r\n# dbwriter = DBWriter.DBWriter()\r\n# Decagon.show_pickle()\r\n# Decagon.removeGrower('Lucero Watermark')\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if f.name == 'RKB115_116_107':\r\n#             for l in f.loggers:\r\n#                 if l.active:\r\n#                     print(l.id)\r\n# Decagon.removeLogger('Bullseye Farms', 'Bullseye FarmsME4', 'z6-11968')\r\n#             field_name = dbwriter.remove_unwanted_chars_for_db(f.name)\r\n#             print(\"Working on Field: \", f.name)\r\n#             for l in f.loggers:\r\n#                 print('\\t Working on Logger: ', l.name)\r\n#                 # print(\"\\t\\tDeleting Repeat Data\")\r\n#                 # SQLScripts.delete_repeat_data(f.name,l.name)\r\n#                 updated = False\r\n#                 print(\"\\t\\tChecking Date to see if yesterday updated\")\r\n#                 dataset_id = \"stomato.\" + field_name + \".\" + l.name\r\n#                 dmlStatement = \"select date from`\" + dataset_id + \"` order by date\"\r\n#                 # print(dmlStatement)\r\n#                 result = dbwriter.run_dml(dmlStatement)\r\n#                 for r in result:\r\n#                     if str(r[0]) == '2022-07-15':\r\n#                         # print(\"Field Updated\")\r\n#                         updated = True\r\n#                 if not updated:\r\n#                     print(\"\\t\\t\\tField did not update: \", f.name, \"\\n Logger: \", l.name)\r\n#                     print(\"\\t\\t\\tUpdating Field\")\r\n#                     updateField(g.name, f.name, True, l.name, subtractMRID=24)\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if f.name == 'DCBVerway T1, T2, T3':\r\n#             for l in f.loggers:\r\n#                 if l.id == 'z6-12309':\r\n#                     l.password = '82466-02422'\r\n# Decagon.write_pickle(growers)\r\n#                     print(\"Changing fc and wp for logger: \" + l.name)\r\n#                     l.fieldCapacity = fc\r\n#                     l.wiltingPoint = wp\r\n#                     SQLScripts.update_FC_WP(f.name, l.name, fc, wp)\r\n#                 elif loggerName == '':\r\n#                     print(\"Changing fc and wp for logger: \" + l.name)\r\n#                     l.fieldCapacity = fc\r\n#                     l.wiltingPoint = wp\r\n#                     SQLScripts.update_FC_WP(f.name, l.name, fc, wp)\r\n#\r\n#\r\n# Decagon.write_pickle(growers)\r\n\r\n# count = 0\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if f.active == True:\r\n#             if f.name == \"DCBVerway T1, T2, T3\":\r\n#                 for l in f.loggers:\r\n#                     if l.id == 'z6-01892':\r\n#                         Decagon.removeLogger(g.name, f.name, l.id)\r\n# print(\"Do I have a second logger?\")\r\n#                         l.name = 'Bull-RG60-SE'\r\n#                     if l.id == 'z6-01953':\r\n#                         l.name = 'Bull-RG60-NW'\r\n# #             print(f.name)\r\n#             f.name = 'RKB115_116_107'\r\n#             # for l in f.loggers:\r\n#                 # print(\"\\t\" + l.name)\r\n# Decagon.write_pickle(growers)\r\n# Decagon.show_pickle()\r\n\r\n# l.name = 'SMonica1-BlkY-C'\r\n# if l.name == 'MA-BW-PI':\r\n#     l.name = 'MA-BWPI-SW'\r\n# if l.name == 'MA-YW-PI':\r\n#     l.name = 'MA-YWPI-SW'\r\n# if l.name == 'MA-BE-PI':\r\n#     l.name = 'MA-BEPI-NE'\r\n# if l.name == 'MA-YE-PI':\r\n#     l.name = 'MA-YEPI-NE'\r\n\r\n# if g.name == \"Meza\":\r\n#     for f in g.fields:\r\n#         print(f.name)\r\n#         for l in f.loggers:\r\n#             print(l.name)\r\n#             print(l.id)\r\n#             print(l.password)\r\n# print(count)\r\n# Decagon.deactivate_growers_with_all_inactive_fields()\r\n# fieldName = \"OPC3-2\"\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if fieldName == f.name:\r\n#             f.active = True\r\n#             for l in f.loggers:\r\n#                 l.active = True\r\n# Decagon.write_pickle(growers)\r\n#             Decagon.deactivate_field(g.name, f.name)\r\n#             # for l in f.loggers:\r\n#             #     Decagon.deactivate_logger(g.name, f.name, l.id)\r\n# # Decagon.deactivate_field(\"OPC\", 'OPC3-2')\r\n\r\n# SQLScripts.deleteLastDay('DCBNees 7-8', 'z6-12427', '2021-08-18')\r\n# updateField(\"DCB\", \"DCBRogerro 30-40\", True, 'DCB-Rog30_40-N', subtractMRID=24)\r\n\r\n# updateField('RnD', 'RnDDouble-Single Trial', True, 'SLine-DTape-S', subtractMRID=6*24+10)\r\n# updateField('Lucero Bakersfield', 'Lucero BakersfieldTowerline', True, 'TO-Green-N', subtractMRID=0)\r\n# updateField('Carvalho', 'Carvalho308', True, 'z6-03436', subtractMRID=0)\r\n# updateField('JJB Farms', 'JJB FarmsJones Tract', True, 'z6-12336', subtractMRID=31)\r\n# updateField('JJB Farms', 'JJB FarmsJones Tract', True, 'z6-12429', subtractMRID=31)\r\n\r\n# Decagon.removeField(\"JHP\", \"JHPBase 5\")\r\n# removeLoggerIDFromPickle(\"z6-07214\")\r\n# removeLoggerIDFromPickle(\"5G118559\")\r\n# Decagon.removeField(\"DCB\", \"DCBNees 7-8\")\r\n# removeLoggerIDFromPickle(\"z6-11976\")\r\n# removeLoggerIDFromPickle(\"z6-01887\")\r\n# removeLoggerIDFromPickle(\"z6-01871\")\r\n# #\r\n# removeAllLoggerIDFromPickle()\r\n# showLoggerIDPickle()\r\n# Decagon.removeGrower(\"KTN JV\")\r\n# Decagon.removeLastGrower()\r\n# addLoggerIDToPickle(\"5G105816\")\r\n\r\n# updateField('DCB', 'DCBEdgemar 228', hasLogger=True, logger='z6-12309', subtractMRID=24*12)\r\n#\r\n# Decagon.onlyCertainGrowersFieldUpdate(\"UC Davis\", \"UC DavisUCD Veg Crops\", get_et=False, get_weather=True, get_data=False,\r\n#                                       write_to_sheet=True, write_to_portal_sheet=False, write_to_db=False)\r\n# Decagon.onlyCertainGrowersFieldUpdate(\"David Santos\", \"David SantosSP3\", get_et=False, get_weather=True, get_data=True,\r\n#                                       write_to_sheet=True, write_to_portal_sheet=True, write_to_db=True)\r\n\r\n# Decagon.onlyCertainGrowersFieldUpdate(\"DCB\", \"DCBMadd\", get_et=False, get_weather=True, get_data=True,\r\n#                                       write_to_sheet=True, write_to_portal_sheet=True, write_to_db=True)\r\n\r\n# Decagon.onlyCertainGrowersFieldUpdate(\"Maricopa Orchards\", \"Maricopa Orchards3425\", get_et=False, get_weather=True, get_data=True,\r\n#                                       write_to_sheet=True, write_to_portal_sheet=True, write_to_db=True)\r\n\r\n# Decagon.onlyCertainGrowersFieldUpdate(\"Hughes\", \"Hughes301\", get_et=False, get_weather=True, get_data=True,\r\n#                                       write_to_sheet=True, write_to_portal_sheet=True, write_to_db=True)\r\n\r\n# Decagon.onlyCertainGrowersFieldLoggerUpdate(\"Hughes\", \"Hughes309-4\", \"z6-07220\", write_to_sheet=True,\r\n#                                             write_to_portal_sheet=True, write_to_db=True, subtract_from_mrid=28)\r\n\r\n# ET Update\r\n\r\n# Decagon.onlyCertainGrowersETUpdate(\"Hughes\", writeToSheet=False, writeToDB=True)\r\n\r\n# Decagon.onlyCertainGrowersUpdate(\"Carvalho\", get_et=True, write_to_sheet=True)\r\n\r\n# Decagon.onlyCertainGrowersUpdate(\"DCB\", get_et=False, get_weather=True, get_data=True,\r\n#                                  write_to_sheet=True, write_to_portal_sheet=True, write_to_db=False)\r\n\r\n# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:\\\\Users\\\\jsalcedo\\\\PycharmProjects\\\\Stomato\\\\credentials.json\"\r\n\r\n# Decagon.onlyCertainGrowersFieldLoggerUpdate(\"Maricopa Orchards\", \"Maricopa Orchards3425\", \"z6-06012\", write_to_sheet=True,\r\n#                                             write_to_portal_sheet=True, write_to_db=True, subtract_from_mrid=33)\r\n\r\n# Decagon.show_pickle()\r\n\r\n# Decagon.onlyCertainGrowersFieldLoggerUpdate(\"OPC\", \"OPC24-3\", \"5G129309\", write_to_sheet=False,\r\n#                                             write_to_portal_sheet=False, write_to_db=False, subtract_from_mrid=80)\r\n\r\n# creds = GSheetCredentialSevice.GSheetCredentialSevice()\r\n# creds.getCreds()\r\n\r\n# growers = Decagon.open_pickle()\r\n# for g in growers:\r\n#     for f in g.fields:\r\n#         if f.name == \"DCBMaricopa West\" and g.name == \"DCB\":\r\n#             print(type(f.cimisStation))\r\n#             f.cimisStation = \"105\"\r\n#             print(f.cimisStation)\r\n#\r\n#             Decagon.write_pickle(growers)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/LoggerSetups.py b/LoggerSetups.py
--- a/LoggerSetups.py	
+++ b/LoggerSetups.py	
@@ -10,7 +10,7 @@
 from Notifications import Notification_LoggerSetups
 
 
-def setup_grower(grower: str, technician_name: str, email:str='', region:str=''):
+def setup_grower(grower: str, technician_name: str, email: str='', region: str=''):
     """
     Function setups a new grower in the pickle
     :param grower: name of grower
@@ -69,8 +69,8 @@
 
 def remove_field(grower_target:str, field_target:str):
     """
-    Function removes a field from a grower
-    :param grower_target: Grower Name
+    Function removes a field from a Grower
+    :param grower_target: Growers Name
     :param field_target: Field Name
     """
     growers = Decagon.open_pickle()
@@ -87,7 +87,7 @@
     # Decagon.write_pickle(growers)
 
 
-def deactivate_field(grower:str, field: str, uninstall_date:date):
+def deactivate_field(grower: str, field: str, uninstall_date:date):
     """
     Function deactivates a field from a grower
     :param grower: Grower Name
@@ -722,13 +722,11 @@
             # Irr. Scheduling needs a Historical ET table to reference when creating the table
             if et_table_found:
                 print("\t\tFound ET Table, Setting up Irr. Scheduling")
-                SQLScripts.setupIrrigationSchedulingDB(et_station, field.name, start_date, end_date, year)
             # Create Historical ET table if it does not exist
             else:
                 print("\t\tHistorical ET Table Not Found \n\t\t\tCreating Table")
-                # Grab_historical_data should create a new historical et table but it is not dynamic. Right now it creates it from years 2018 - 2022
-                # SQLScripts.grab_historical_data(et_station, newStation=True)
-                SQLScripts.setupIrrigationSchedulingDB(et_station, field.name, start_date, end_date, year)
+                SQLScripts.new_et_station_data(et_station)
+            SQLScripts.setupIrrigationSchedulingDB(et_station, field.name, start_date, end_date, year)
 
     except Exception as err:
         print("\tField Name Incorrect Or Not In Database")
@@ -805,7 +803,7 @@
                         update_field(grower.name, field.name, True, logger.name, subtract_mrid=24)
 
 
-def return_active_fields(region:str="Both")->list:
+def return_active_fields(region: str = "Both") -> list:
     """
     Return active fields for a specific region or both regions
     :param region: Default value is "Both", but can be "North" or "South"
@@ -1462,7 +1460,7 @@
 # Decagon.onlyCertainGrowersFieldLoggerUpdate("Maricopa Orchards", "Maricopa Orchards3425", "z6-06012", write_to_sheet=True,
 #                                             write_to_portal_sheet=True, write_to_db=True, subtract_from_mrid=33)
 
-# Decagon.show_pickle()
+Decagon.show_pickle()
 
 # Decagon.onlyCertainGrowersFieldLoggerUpdate("OPC", "OPC24-3", "5G129309", write_to_sheet=False,
 #                                             write_to_portal_sheet=False, write_to_db=False, subtract_from_mrid=80)
@@ -1470,12 +1468,16 @@
 # creds = GSheetCredentialSevice.GSheetCredentialSevice()
 # creds.getCreds()
 
-# growers = Decagon.open_pickle()
-# for g in growers:
-#     for f in g.fields:
-#         if f.name == "DCBMaricopa West" and g.name == "DCB":
-#             print(type(f.cimisStation))
-#             f.cimisStation = "105"
-#             print(f.cimisStation)
+growers = Decagon.open_pickle()
+for grower in growers:
+    for field in grower.fields:
+        if field.name == field_name_pickle:
+            print("Setting up Irrigation Scheduling for Field")
+            station_number = int(field.cimis_station)
+            start_date = date(datetime.now().year - 1, 1, 1)
+            end_date = date(datetime.now().year - 1, 12, 31)
+            # Check to see if Irr. Scheduling has been set up already
+            check_if_irr_scheduling_is_set_up(station_number, field, start_date, end_date, datetime.now().year)
 #
-#             Decagon.write_pickle(growers)
+            # Decagon.write_pickle(growers)
+# setup_field()
\ No newline at end of file
